[32m[20221127 04:17:32 @logger.py:105][0m Log file set to ./tmp/pendulum/swingup/20221127_041732/log/pendulum_swingup-20221127_041732.log
[32m[20221127 04:17:32 @pendulum_agent.py:284][0m #------------------------ Iteration 0 --------------------------#
[32m[20221127 04:17:35 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:17:35 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:17:35 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:17:35 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:17:35 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:17:35 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:17:35 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:17:35 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:17:35 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:17:35 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:17:38 @pendulum_agent.py:310][0m Sample time: 5.604523658752441
[32m[20221127 04:18:05 @pendulum_agent.py:315][0m Update time: 27.352757215499878
[32m[20221127 04:18:06 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:18:06 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:18:06 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:18:06 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:18:06 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:18:06 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:18:06 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:18:06 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:18:06 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:18:06 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:18:06 @pendulum_agent.py:320][0m Evaluation time: 1.1525869369506836
[32m[20221127 04:18:07 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:18:07 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:18:07 @pendulum_agent.py:265][0m [4m[34mCRITICAL[0m Get the best episode reward: 0
[32m[20221127 04:18:07 @pendulum_agent.py:269][0m [4m[34mCRITICAL[0m Saving the best checkpoint with rewards 0.00
[32m[20221127 04:18:07 @pendulum_agent.py:292][0m Total time: 34.571815967559814
[32m[20221127 04:18:07 @pendulum_agent.py:294][0m 50000 total steps have happened
[32m[20221127 04:18:07 @pendulum_agent.py:284][0m #------------------------ Iteration 1 --------------------------#
[32m[20221127 04:18:09 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:18:09 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:18:09 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:18:10 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:18:10 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:18:10 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:18:10 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:18:10 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:18:10 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:18:10 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:18:14 @pendulum_agent.py:310][0m Sample time: 7.186683893203735
[32m[20221127 04:18:40 @pendulum_agent.py:315][0m Update time: 25.975284099578857
[32m[20221127 04:18:41 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:18:41 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:18:41 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:18:41 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:18:41 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:18:41 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:18:41 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:18:41 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:18:41 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:18:41 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:18:41 @pendulum_agent.py:320][0m Evaluation time: 1.340284824371338
[32m[20221127 04:18:42 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:18:42 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:18:42 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:18:42 @pendulum_agent.py:292][0m Total time: 69.44358611106873
[32m[20221127 04:18:42 @pendulum_agent.py:294][0m 100000 total steps have happened
[32m[20221127 04:18:42 @pendulum_agent.py:284][0m #------------------------ Iteration 2 --------------------------#
[32m[20221127 04:18:44 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:18:44 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:18:44 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:18:44 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:18:44 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:18:44 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:18:44 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:18:44 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:18:44 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:18:44 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:18:47 @pendulum_agent.py:310][0m Sample time: 4.990243911743164
[32m[20221127 04:19:13 @pendulum_agent.py:315][0m Update time: 25.905004024505615
[32m[20221127 04:19:13 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:19:13 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:19:13 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:19:13 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:19:13 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:19:13 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:19:13 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:19:13 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:19:13 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:19:13 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:19:15 @pendulum_agent.py:320][0m Evaluation time: 2.4013490676879883
[32m[20221127 04:19:15 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:19:15 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:19:15 @pendulum_agent.py:292][0m Total time: 103.1535701751709
[32m[20221127 04:19:15 @pendulum_agent.py:294][0m 150000 total steps have happened
[32m[20221127 04:19:15 @pendulum_agent.py:284][0m #------------------------ Iteration 3 --------------------------#
[32m[20221127 04:19:18 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:19:18 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:19:18 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:19:18 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:19:18 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:19:18 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:19:18 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:19:18 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:19:18 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:19:19 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:19:22 @pendulum_agent.py:310][0m Sample time: 6.455551862716675
[32m[20221127 04:19:49 @pendulum_agent.py:315][0m Update time: 27.538193941116333
[32m[20221127 04:19:50 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:19:50 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:19:50 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:19:50 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:19:50 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:19:50 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:19:50 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:19:50 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:19:50 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:19:50 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:19:51 @pendulum_agent.py:320][0m Evaluation time: 1.9215128421783447
[32m[20221127 04:19:52 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:19:52 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:19:52 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:19:52 @pendulum_agent.py:292][0m Total time: 139.46424508094788
[32m[20221127 04:19:52 @pendulum_agent.py:294][0m 200000 total steps have happened
[32m[20221127 04:19:52 @pendulum_agent.py:284][0m #------------------------ Iteration 4 --------------------------#
[32m[20221127 04:19:54 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:19:54 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:19:54 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:19:54 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:19:54 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:19:54 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:19:54 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:19:54 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:19:54 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:19:54 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:19:58 @pendulum_agent.py:310][0m Sample time: 6.223211050033569
[32m[20221127 04:20:25 @pendulum_agent.py:315][0m Update time: 27.247637033462524
[32m[20221127 04:20:26 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:20:26 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:20:26 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:20:26 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:20:26 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:20:26 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:20:26 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:20:26 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:20:26 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:20:26 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:20:26 @pendulum_agent.py:320][0m Evaluation time: 1.166313886642456
[32m[20221127 04:20:27 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:20:27 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:20:27 @pendulum_agent.py:292][0m Total time: 174.54502511024475
[32m[20221127 04:20:27 @pendulum_agent.py:294][0m 250000 total steps have happened
[32m[20221127 04:20:27 @pendulum_agent.py:284][0m #------------------------ Iteration 5 --------------------------#
[32m[20221127 04:20:29 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 3.6
[32m[20221127 04:20:29 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 4.6
[32m[20221127 04:20:29 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 9.8
[32m[20221127 04:20:29 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 5.0
[32m[20221127 04:20:29 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 2.8
[32m[20221127 04:20:29 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 2.6
[32m[20221127 04:20:29 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 3.2
[32m[20221127 04:20:30 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 4.4
[32m[20221127 04:20:30 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 2.8
[32m[20221127 04:20:30 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 4.0
[32m[20221127 04:20:33 @pendulum_agent.py:310][0m Sample time: 6.430531024932861
[32m[20221127 04:20:59 @pendulum_agent.py:315][0m Update time: 25.640338897705078
[32m[20221127 04:20:59 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:20:59 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:20:59 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:20:59 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:20:59 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:20:59 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:20:59 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:20:59 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:20:59 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:21:00 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:21:00 @pendulum_agent.py:320][0m Evaluation time: 1.2071928977966309
[32m[20221127 04:21:00 @pendulum_agent.py:288][0m Average TRAINING episode reward: 4.28
[32m[20221127 04:21:00 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:21:00 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:21:00 @pendulum_agent.py:292][0m Total time: 208.14071822166443
[32m[20221127 04:21:00 @pendulum_agent.py:294][0m 300000 total steps have happened
[32m[20221127 04:21:00 @pendulum_agent.py:284][0m #------------------------ Iteration 6 --------------------------#
[32m[20221127 04:21:03 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:21:03 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:21:03 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:21:03 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:21:03 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:21:03 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:21:03 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:21:03 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:21:03 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:21:03 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:21:06 @pendulum_agent.py:310][0m Sample time: 5.985157251358032
[32m[20221127 04:21:33 @pendulum_agent.py:315][0m Update time: 26.185444831848145
[32m[20221127 04:21:33 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:21:33 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:21:33 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:21:33 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:21:33 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:21:33 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:21:33 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:21:33 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:21:33 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:21:33 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:21:34 @pendulum_agent.py:320][0m Evaluation time: 1.3143699169158936
[32m[20221127 04:21:34 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:21:34 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:21:34 @pendulum_agent.py:292][0m Total time: 241.948637008667
[32m[20221127 04:21:34 @pendulum_agent.py:294][0m 350000 total steps have happened
[32m[20221127 04:21:34 @pendulum_agent.py:284][0m #------------------------ Iteration 7 --------------------------#
[32m[20221127 04:21:37 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:21:37 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:21:37 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:21:37 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:21:37 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:21:37 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:21:37 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:21:37 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:21:37 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:21:37 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:21:40 @pendulum_agent.py:310][0m Sample time: 5.76560378074646
[32m[20221127 04:22:07 @pendulum_agent.py:315][0m Update time: 26.577174186706543
[32m[20221127 04:22:07 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:22:07 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:22:07 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:22:07 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:22:07 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:22:07 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:22:07 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:22:07 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:22:07 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:22:07 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:22:08 @pendulum_agent.py:320][0m Evaluation time: 1.699950933456421
[32m[20221127 04:22:09 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:22:09 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:22:09 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:22:09 @pendulum_agent.py:292][0m Total time: 276.35948610305786
[32m[20221127 04:22:09 @pendulum_agent.py:294][0m 400000 total steps have happened
[32m[20221127 04:22:09 @pendulum_agent.py:284][0m #------------------------ Iteration 8 --------------------------#
[32m[20221127 04:22:11 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:22:11 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:22:11 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:22:11 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:22:11 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:22:11 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:22:11 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:22:11 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:22:11 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:22:11 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:22:15 @pendulum_agent.py:310][0m Sample time: 6.298533916473389
[32m[20221127 04:22:40 @pendulum_agent.py:315][0m Update time: 25.136590003967285
[32m[20221127 04:22:41 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:22:41 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:22:41 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:22:41 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:22:41 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:22:41 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:22:41 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:22:41 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:22:41 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:22:41 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:22:42 @pendulum_agent.py:320][0m Evaluation time: 1.7774670124053955
[32m[20221127 04:22:42 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:22:42 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:22:42 @pendulum_agent.py:292][0m Total time: 309.9231491088867
[32m[20221127 04:22:42 @pendulum_agent.py:294][0m 450000 total steps have happened
[32m[20221127 04:22:42 @pendulum_agent.py:284][0m #------------------------ Iteration 9 --------------------------#
[32m[20221127 04:22:45 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:22:45 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:22:45 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:22:45 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:22:45 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:22:45 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:22:45 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:22:45 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:22:45 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:22:45 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:22:48 @pendulum_agent.py:310][0m Sample time: 5.966499090194702
[32m[20221127 04:23:13 @pendulum_agent.py:315][0m Update time: 25.288408994674683
[32m[20221127 04:23:14 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:23:14 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:23:14 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:23:14 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:23:14 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:23:14 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:23:14 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:23:14 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:23:14 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:23:14 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:23:15 @pendulum_agent.py:320][0m Evaluation time: 1.1867127418518066
[32m[20221127 04:23:15 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:23:15 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:23:15 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:23:15 @pendulum_agent.py:292][0m Total time: 342.6995131969452
[32m[20221127 04:23:15 @pendulum_agent.py:294][0m 500000 total steps have happened
[32m[20221127 04:23:15 @pendulum_agent.py:284][0m #------------------------ Iteration 10 --------------------------#
[32m[20221127 04:23:17 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:23:17 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:23:17 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:23:17 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:23:17 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:23:18 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:23:18 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:23:18 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:23:18 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:23:18 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:23:21 @pendulum_agent.py:310][0m Sample time: 5.7824859619140625
[32m[20221127 04:23:47 @pendulum_agent.py:315][0m Update time: 26.567401885986328
[32m[20221127 04:23:48 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:23:48 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:23:48 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:23:48 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:23:48 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:23:48 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:23:48 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:23:48 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:23:48 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:23:48 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:23:49 @pendulum_agent.py:320][0m Evaluation time: 1.3865671157836914
[32m[20221127 04:23:49 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:23:49 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:23:49 @pendulum_agent.py:292][0m Total time: 376.8655970096588
[32m[20221127 04:23:49 @pendulum_agent.py:294][0m 550000 total steps have happened
[32m[20221127 04:23:49 @pendulum_agent.py:284][0m #------------------------ Iteration 11 --------------------------#
[32m[20221127 04:23:51 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 1.4
[32m[20221127 04:23:52 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 2.2
[32m[20221127 04:23:52 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 1.2
[32m[20221127 04:23:52 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 1.0
[32m[20221127 04:23:52 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 1.8
[32m[20221127 04:23:52 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 1.6
[32m[20221127 04:23:52 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 1.2
[32m[20221127 04:23:52 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 2.0
[32m[20221127 04:23:52 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 1.4
[32m[20221127 04:23:52 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 1.4
[32m[20221127 04:23:55 @pendulum_agent.py:310][0m Sample time: 5.563077211380005
[32m[20221127 04:24:21 @pendulum_agent.py:315][0m Update time: 25.907718896865845
[32m[20221127 04:24:21 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:24:21 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:24:21 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:24:21 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:24:21 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:24:21 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:24:21 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:24:21 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:24:21 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:24:21 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:24:22 @pendulum_agent.py:320][0m Evaluation time: 1.5959579944610596
[32m[20221127 04:24:23 @pendulum_agent.py:288][0m Average TRAINING episode reward: 1.52
[32m[20221127 04:24:23 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:24:23 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:24:23 @pendulum_agent.py:292][0m Total time: 410.3485791683197
[32m[20221127 04:24:23 @pendulum_agent.py:294][0m 600000 total steps have happened
[32m[20221127 04:24:23 @pendulum_agent.py:284][0m #------------------------ Iteration 12 --------------------------#
[32m[20221127 04:24:25 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:24:25 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:24:25 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:24:25 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:24:25 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:24:25 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:24:25 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:24:25 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:24:25 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:24:25 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:24:29 @pendulum_agent.py:310][0m Sample time: 6.1843650341033936
[32m[20221127 04:24:54 @pendulum_agent.py:315][0m Update time: 25.273348093032837
[32m[20221127 04:24:55 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:24:55 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:24:55 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:24:55 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:24:55 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:24:55 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:24:55 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:24:55 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:24:55 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:24:55 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:24:56 @pendulum_agent.py:320][0m Evaluation time: 1.632356882095337
[32m[20221127 04:24:56 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:24:56 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:24:56 @pendulum_agent.py:292][0m Total time: 443.86775302886963
[32m[20221127 04:24:56 @pendulum_agent.py:294][0m 650000 total steps have happened
[32m[20221127 04:24:56 @pendulum_agent.py:284][0m #------------------------ Iteration 13 --------------------------#
[32m[20221127 04:24:59 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:24:59 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:24:59 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:24:59 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:24:59 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:24:59 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:24:59 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:24:59 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:24:59 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:24:59 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:25:02 @pendulum_agent.py:310][0m Sample time: 5.804548978805542
[32m[20221127 04:25:28 @pendulum_agent.py:315][0m Update time: 25.749690055847168
[32m[20221127 04:25:28 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:25:28 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:25:28 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:25:28 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:25:28 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:25:28 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:25:28 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:25:28 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:25:28 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:25:28 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:25:30 @pendulum_agent.py:320][0m Evaluation time: 1.917992115020752
[32m[20221127 04:25:30 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:25:30 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:25:30 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:25:30 @pendulum_agent.py:292][0m Total time: 477.7598421573639
[32m[20221127 04:25:30 @pendulum_agent.py:294][0m 700000 total steps have happened
[32m[20221127 04:25:30 @pendulum_agent.py:284][0m #------------------------ Iteration 14 --------------------------#
[32m[20221127 04:25:32 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:25:33 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:25:33 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:25:33 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:25:33 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:25:33 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:25:33 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:25:33 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:25:33 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:25:33 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:25:36 @pendulum_agent.py:310][0m Sample time: 6.17592191696167
[32m[20221127 04:26:01 @pendulum_agent.py:315][0m Update time: 25.024210929870605
[32m[20221127 04:26:02 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:26:02 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:26:02 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:26:02 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:26:02 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:26:02 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:26:02 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:26:02 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:26:02 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:26:02 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:26:02 @pendulum_agent.py:320][0m Evaluation time: 1.19730806350708
[32m[20221127 04:26:03 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:26:03 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:26:03 @pendulum_agent.py:292][0m Total time: 510.5248191356659
[32m[20221127 04:26:03 @pendulum_agent.py:294][0m 750000 total steps have happened
[32m[20221127 04:26:03 @pendulum_agent.py:284][0m #------------------------ Iteration 15 --------------------------#
[32m[20221127 04:26:05 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:26:05 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:26:05 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:26:05 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:26:05 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:26:05 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:26:05 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:26:05 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:26:06 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:26:06 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:26:10 @pendulum_agent.py:310][0m Sample time: 7.082832098007202
[32m[20221127 04:26:34 @pendulum_agent.py:315][0m Update time: 24.424898147583008
[32m[20221127 04:26:35 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:26:35 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:26:35 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:26:35 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:26:35 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:26:35 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:26:35 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:26:35 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:26:35 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:26:35 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:26:35 @pendulum_agent.py:320][0m Evaluation time: 1.0418000221252441
[32m[20221127 04:26:36 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:26:36 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:26:36 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:26:36 @pendulum_agent.py:292][0m Total time: 543.4925091266632
[32m[20221127 04:26:36 @pendulum_agent.py:294][0m 800000 total steps have happened
[32m[20221127 04:26:36 @pendulum_agent.py:284][0m #------------------------ Iteration 16 --------------------------#
[32m[20221127 04:26:38 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:26:38 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:26:38 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:26:38 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:26:38 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:26:38 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:26:38 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:26:38 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:26:38 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:26:39 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:26:42 @pendulum_agent.py:310][0m Sample time: 6.283493995666504
[32m[20221127 04:27:08 @pendulum_agent.py:315][0m Update time: 26.226656198501587
[32m[20221127 04:27:09 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:27:09 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:27:09 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:27:09 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:27:09 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:27:09 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:27:09 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:27:09 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:27:09 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:27:09 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:27:09 @pendulum_agent.py:320][0m Evaluation time: 1.0185327529907227
[32m[20221127 04:27:10 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:27:10 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:27:10 @pendulum_agent.py:292][0m Total time: 577.4368441104889
[32m[20221127 04:27:10 @pendulum_agent.py:294][0m 850000 total steps have happened
[32m[20221127 04:27:10 @pendulum_agent.py:284][0m #------------------------ Iteration 17 --------------------------#
[32m[20221127 04:27:12 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:27:12 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:27:12 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:27:12 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:27:12 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:27:12 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:27:12 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:27:12 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:27:12 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:27:12 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:27:16 @pendulum_agent.py:310][0m Sample time: 6.254333972930908
[32m[20221127 04:27:41 @pendulum_agent.py:315][0m Update time: 25.247963905334473
[32m[20221127 04:27:42 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:27:42 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:27:42 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:27:42 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:27:42 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:27:42 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:27:42 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:27:42 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:27:42 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:27:42 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:27:42 @pendulum_agent.py:320][0m Evaluation time: 1.1942081451416016
[32m[20221127 04:27:43 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:27:43 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:27:43 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:27:43 @pendulum_agent.py:292][0m Total time: 610.4786162376404
[32m[20221127 04:27:43 @pendulum_agent.py:294][0m 900000 total steps have happened
[32m[20221127 04:27:43 @pendulum_agent.py:284][0m #------------------------ Iteration 18 --------------------------#
[32m[20221127 04:27:45 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:27:45 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:27:45 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:27:45 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:27:45 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:27:45 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:27:45 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:27:45 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:27:46 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:27:46 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:27:49 @pendulum_agent.py:310][0m Sample time: 6.1176629066467285
[32m[20221127 04:28:14 @pendulum_agent.py:315][0m Update time: 25.55935001373291
[32m[20221127 04:28:15 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:28:15 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:28:15 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:28:15 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:28:15 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:28:15 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:28:15 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:28:15 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:28:15 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:28:15 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:28:16 @pendulum_agent.py:320][0m Evaluation time: 1.1780030727386475
[32m[20221127 04:28:16 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:28:16 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:28:16 @pendulum_agent.py:292][0m Total time: 643.6755290031433
[32m[20221127 04:28:16 @pendulum_agent.py:294][0m 950000 total steps have happened
[32m[20221127 04:28:16 @pendulum_agent.py:284][0m #------------------------ Iteration 19 --------------------------#
[32m[20221127 04:28:18 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:28:18 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:28:18 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:28:19 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:28:19 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:28:19 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:28:19 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:28:19 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:28:19 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:28:19 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:28:22 @pendulum_agent.py:310][0m Sample time: 5.984231948852539
[32m[20221127 04:28:47 @pendulum_agent.py:315][0m Update time: 25.382297039031982
[32m[20221127 04:28:48 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:28:48 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:28:48 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:28:48 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:28:48 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:28:48 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:28:48 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:28:48 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:28:48 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:28:48 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:28:48 @pendulum_agent.py:320][0m Evaluation time: 1.232156753540039
[32m[20221127 04:28:49 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:28:49 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:28:49 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:28:49 @pendulum_agent.py:292][0m Total time: 676.6174919605255
[32m[20221127 04:28:49 @pendulum_agent.py:294][0m 1000000 total steps have happened
[32m[20221127 04:28:49 @pendulum_agent.py:284][0m #------------------------ Iteration 20 --------------------------#
[32m[20221127 04:28:51 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:28:51 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:28:51 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:28:51 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:28:51 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:28:52 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:28:52 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:28:52 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:28:52 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:28:52 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:28:55 @pendulum_agent.py:310][0m Sample time: 6.156422138214111
[32m[20221127 04:29:21 @pendulum_agent.py:315][0m Update time: 25.734715938568115
[32m[20221127 04:29:21 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:29:21 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:29:21 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:29:21 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:29:21 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:29:21 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:29:21 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:29:21 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:29:21 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:29:21 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:29:22 @pendulum_agent.py:320][0m Evaluation time: 1.1768012046813965
[32m[20221127 04:29:22 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:29:22 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:29:22 @pendulum_agent.py:292][0m Total time: 710.0038211345673
[32m[20221127 04:29:22 @pendulum_agent.py:294][0m 1050000 total steps have happened
[32m[20221127 04:29:22 @pendulum_agent.py:284][0m #------------------------ Iteration 21 --------------------------#
[32m[20221127 04:29:24 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:29:25 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:29:25 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:29:25 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:29:25 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:29:25 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:29:25 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:29:25 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:29:25 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:29:25 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:29:28 @pendulum_agent.py:310][0m Sample time: 5.797784090042114
[32m[20221127 04:29:54 @pendulum_agent.py:315][0m Update time: 25.5879328250885
[32m[20221127 04:29:54 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:29:54 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:29:54 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:29:54 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:29:54 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:29:54 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:29:54 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:29:54 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:29:54 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:29:54 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:29:55 @pendulum_agent.py:320][0m Evaluation time: 1.1070172786712646
[32m[20221127 04:29:55 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:29:55 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:29:55 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:29:55 @pendulum_agent.py:292][0m Total time: 742.8382380008698
[32m[20221127 04:29:55 @pendulum_agent.py:294][0m 1100000 total steps have happened
[32m[20221127 04:29:55 @pendulum_agent.py:284][0m #------------------------ Iteration 22 --------------------------#
[32m[20221127 04:29:57 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:29:57 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:29:58 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:29:58 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:29:58 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:29:58 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:29:58 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:29:58 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:29:58 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:29:58 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:30:01 @pendulum_agent.py:310][0m Sample time: 5.622329950332642
[32m[20221127 04:30:26 @pendulum_agent.py:315][0m Update time: 25.37274718284607
[32m[20221127 04:30:26 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:30:26 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:30:27 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:30:27 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:30:27 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:30:27 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:30:27 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:30:27 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:30:27 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:30:27 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:30:27 @pendulum_agent.py:320][0m Evaluation time: 1.3055768013000488
[32m[20221127 04:30:28 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:30:28 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:30:28 @pendulum_agent.py:292][0m Total time: 775.4931001663208
[32m[20221127 04:30:28 @pendulum_agent.py:294][0m 1150000 total steps have happened
[32m[20221127 04:30:28 @pendulum_agent.py:284][0m #------------------------ Iteration 23 --------------------------#
[32m[20221127 04:30:30 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:30:30 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:30:30 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:30:30 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:30:30 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:30:30 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:30:30 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:30:31 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:30:31 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:30:31 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:30:33 @pendulum_agent.py:310][0m Sample time: 5.492417812347412
[32m[20221127 04:30:59 @pendulum_agent.py:315][0m Update time: 25.49476718902588
[32m[20221127 04:30:59 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:30:59 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:30:59 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:30:59 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:30:59 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:30:59 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:30:59 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:30:59 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:30:59 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:30:59 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:31:00 @pendulum_agent.py:320][0m Evaluation time: 1.5398268699645996
[32m[20221127 04:31:01 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:31:01 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:31:01 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:31:01 @pendulum_agent.py:292][0m Total time: 808.3892011642456
[32m[20221127 04:31:01 @pendulum_agent.py:294][0m 1200000 total steps have happened
[32m[20221127 04:31:01 @pendulum_agent.py:284][0m #------------------------ Iteration 24 --------------------------#
[32m[20221127 04:31:03 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:31:03 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:31:03 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:31:03 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:31:03 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:31:03 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:31:03 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:31:03 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:31:03 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:31:03 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:31:06 @pendulum_agent.py:310][0m Sample time: 5.809180974960327
[32m[20221127 04:31:31 @pendulum_agent.py:315][0m Update time: 25.020162105560303
[32m[20221127 04:31:32 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:31:32 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:31:32 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:31:32 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:31:32 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:31:32 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:31:32 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:31:32 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:31:32 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:31:32 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:31:33 @pendulum_agent.py:320][0m Evaluation time: 1.733853816986084
[32m[20221127 04:31:34 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:31:34 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:31:34 @pendulum_agent.py:292][0m Total time: 841.2976751327515
[32m[20221127 04:31:34 @pendulum_agent.py:294][0m 1250000 total steps have happened
[32m[20221127 04:31:34 @pendulum_agent.py:284][0m #------------------------ Iteration 25 --------------------------#
[32m[20221127 04:31:36 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:31:36 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:31:36 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:31:36 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:31:36 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:31:36 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:31:36 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:31:36 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:31:36 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:31:36 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:31:39 @pendulum_agent.py:310][0m Sample time: 5.520857095718384
[32m[20221127 04:32:04 @pendulum_agent.py:315][0m Update time: 25.45314598083496
[32m[20221127 04:32:05 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:32:05 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:32:05 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:32:05 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:32:05 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:32:05 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:32:05 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:32:05 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:32:05 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:32:05 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:32:06 @pendulum_agent.py:320][0m Evaluation time: 1.7595701217651367
[32m[20221127 04:32:07 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:32:07 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:32:07 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:32:07 @pendulum_agent.py:292][0m Total time: 874.3828182220459
[32m[20221127 04:32:07 @pendulum_agent.py:294][0m 1300000 total steps have happened
[32m[20221127 04:32:07 @pendulum_agent.py:284][0m #------------------------ Iteration 26 --------------------------#
[32m[20221127 04:32:09 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:32:09 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:32:09 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:32:09 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:32:09 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:32:09 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:32:09 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:32:09 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:32:09 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:32:09 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:32:12 @pendulum_agent.py:310][0m Sample time: 5.883270025253296
[32m[20221127 04:32:39 @pendulum_agent.py:315][0m Update time: 26.186604022979736
[32m[20221127 04:32:39 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:32:39 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:32:39 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:32:39 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:32:39 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:32:39 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:32:39 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:32:39 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:32:39 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:32:39 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:32:40 @pendulum_agent.py:320][0m Evaluation time: 1.1718831062316895
[32m[20221127 04:32:40 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:32:40 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:32:40 @pendulum_agent.py:292][0m Total time: 907.9966793060303
[32m[20221127 04:32:40 @pendulum_agent.py:294][0m 1350000 total steps have happened
[32m[20221127 04:32:40 @pendulum_agent.py:284][0m #------------------------ Iteration 27 --------------------------#
[32m[20221127 04:32:43 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:32:43 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:32:43 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:32:43 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:32:43 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:32:43 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:32:43 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:32:43 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:32:43 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:32:43 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:32:46 @pendulum_agent.py:310][0m Sample time: 5.926776647567749
[32m[20221127 04:33:12 @pendulum_agent.py:315][0m Update time: 25.39888620376587
[32m[20221127 04:33:12 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:33:12 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:33:12 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:33:12 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:33:12 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:33:12 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:33:12 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:33:12 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:33:12 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:33:12 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:33:13 @pendulum_agent.py:320][0m Evaluation time: 1.172271966934204
[32m[20221127 04:33:13 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:33:13 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:33:13 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:33:13 @pendulum_agent.py:292][0m Total time: 940.8353140354156
[32m[20221127 04:33:13 @pendulum_agent.py:294][0m 1400000 total steps have happened
[32m[20221127 04:33:13 @pendulum_agent.py:284][0m #------------------------ Iteration 28 --------------------------#
[32m[20221127 04:33:15 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:33:16 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:33:16 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:33:16 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:33:16 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:33:16 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:33:16 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:33:16 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:33:16 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:33:16 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:33:19 @pendulum_agent.py:310][0m Sample time: 5.6975860595703125
[32m[20221127 04:33:45 @pendulum_agent.py:315][0m Update time: 25.858299016952515
[32m[20221127 04:33:45 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:33:45 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:33:45 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:33:45 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:33:45 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:33:45 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:33:45 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:33:45 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:33:45 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:33:45 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:33:46 @pendulum_agent.py:320][0m Evaluation time: 1.197279930114746
[32m[20221127 04:33:46 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:33:46 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:33:46 @pendulum_agent.py:292][0m Total time: 973.951730966568
[32m[20221127 04:33:46 @pendulum_agent.py:294][0m 1450000 total steps have happened
[32m[20221127 04:33:46 @pendulum_agent.py:284][0m #------------------------ Iteration 29 --------------------------#
[32m[20221127 04:33:48 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 2.0
[32m[20221127 04:33:49 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 2.8
[32m[20221127 04:33:49 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 1.8
[32m[20221127 04:33:49 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 1.6
[32m[20221127 04:33:49 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 2.4
[32m[20221127 04:33:49 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 1.2
[32m[20221127 04:33:49 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.8
[32m[20221127 04:33:49 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 2.6
[32m[20221127 04:33:49 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 2.2
[32m[20221127 04:33:49 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 1.2
[32m[20221127 04:33:52 @pendulum_agent.py:310][0m Sample time: 6.084668159484863
[32m[20221127 04:34:18 @pendulum_agent.py:315][0m Update time: 25.64657187461853
[32m[20221127 04:34:18 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:34:18 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:34:18 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:34:18 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:34:19 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:34:19 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:34:19 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:34:19 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:34:19 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:34:19 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:34:19 @pendulum_agent.py:320][0m Evaluation time: 1.007444143295288
[32m[20221127 04:34:19 @pendulum_agent.py:288][0m Average TRAINING episode reward: 1.86
[32m[20221127 04:34:19 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:34:19 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:34:19 @pendulum_agent.py:292][0m Total time: 1007.0229620933533
[32m[20221127 04:34:19 @pendulum_agent.py:294][0m 1500000 total steps have happened
[32m[20221127 04:34:19 @pendulum_agent.py:284][0m #------------------------ Iteration 30 --------------------------#
[32m[20221127 04:34:22 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:34:22 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:34:22 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:34:22 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:34:22 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:34:22 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:34:22 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:34:22 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:34:22 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:34:22 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:34:25 @pendulum_agent.py:310][0m Sample time: 6.045126914978027
[32m[20221127 04:34:51 @pendulum_agent.py:315][0m Update time: 25.806571006774902
[32m[20221127 04:34:51 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:34:52 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:34:52 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:34:52 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:34:52 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:34:52 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:34:52 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:34:52 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:34:52 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:34:52 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:34:52 @pendulum_agent.py:320][0m Evaluation time: 1.178800106048584
[32m[20221127 04:34:53 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:34:53 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:34:53 @pendulum_agent.py:292][0m Total time: 1040.3697381019592
[32m[20221127 04:34:53 @pendulum_agent.py:294][0m 1550000 total steps have happened
[32m[20221127 04:34:53 @pendulum_agent.py:284][0m #------------------------ Iteration 31 --------------------------#
[32m[20221127 04:34:55 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:34:55 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:34:55 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:34:55 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:34:55 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:34:55 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:34:55 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:34:55 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:34:55 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:34:55 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:34:58 @pendulum_agent.py:310][0m Sample time: 5.8247292041778564
[32m[20221127 04:35:24 @pendulum_agent.py:315][0m Update time: 25.986937046051025
[32m[20221127 04:35:25 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 2.0
[32m[20221127 04:35:25 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 2.0
[32m[20221127 04:35:25 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 2.0
[32m[20221127 04:35:25 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 2.0
[32m[20221127 04:35:25 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 2.0
[32m[20221127 04:35:25 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 2.0
[32m[20221127 04:35:25 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 2.0
[32m[20221127 04:35:25 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 2.0
[32m[20221127 04:35:25 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 2.0
[32m[20221127 04:35:25 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 2.0
[32m[20221127 04:35:26 @pendulum_agent.py:320][0m Evaluation time: 1.1712357997894287
[32m[20221127 04:35:26 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:35:26 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:35:26 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:35:26 @pendulum_agent.py:292][0m Total time: 1073.6969442367554
[32m[20221127 04:35:26 @pendulum_agent.py:294][0m 1600000 total steps have happened
[32m[20221127 04:35:26 @pendulum_agent.py:284][0m #------------------------ Iteration 32 --------------------------#
[32m[20221127 04:35:28 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 5.2
[32m[20221127 04:35:28 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 7.0
[32m[20221127 04:35:28 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 3.4
[32m[20221127 04:35:28 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 3.8
[32m[20221127 04:35:29 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 2.8
[32m[20221127 04:35:29 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 4.8
[32m[20221127 04:35:29 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 3.4
[32m[20221127 04:35:29 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 3.6
[32m[20221127 04:35:29 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 4.0
[32m[20221127 04:35:29 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 4.2
[32m[20221127 04:35:32 @pendulum_agent.py:310][0m Sample time: 5.768150806427002
[32m[20221127 04:35:58 @pendulum_agent.py:315][0m Update time: 25.934266328811646
[32m[20221127 04:35:58 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:35:58 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:35:58 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:35:58 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:35:58 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:35:58 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:35:58 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:35:58 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:35:58 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:35:58 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:35:59 @pendulum_agent.py:320][0m Evaluation time: 1.2914419174194336
[32m[20221127 04:35:59 @pendulum_agent.py:288][0m Average TRAINING episode reward: 4.22
[32m[20221127 04:35:59 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:35:59 @pendulum_agent.py:292][0m Total time: 1107.054326057434
[32m[20221127 04:35:59 @pendulum_agent.py:294][0m 1650000 total steps have happened
[32m[20221127 04:35:59 @pendulum_agent.py:284][0m #------------------------ Iteration 33 --------------------------#
[32m[20221127 04:36:02 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:36:02 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:36:02 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:36:02 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:36:02 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:36:02 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:36:02 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:36:02 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:36:02 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:36:02 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:36:05 @pendulum_agent.py:310][0m Sample time: 5.622703790664673
[32m[20221127 04:36:31 @pendulum_agent.py:315][0m Update time: 25.723194122314453
[32m[20221127 04:36:31 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 1.0
[32m[20221127 04:36:31 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 1.0
[32m[20221127 04:36:31 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 1.0
[32m[20221127 04:36:31 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 1.0
[32m[20221127 04:36:31 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 1.0
[32m[20221127 04:36:31 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 1.0
[32m[20221127 04:36:31 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 1.0
[32m[20221127 04:36:31 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 1.0
[32m[20221127 04:36:31 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 1.0
[32m[20221127 04:36:31 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 1.0
[32m[20221127 04:36:32 @pendulum_agent.py:320][0m Evaluation time: 1.6864118576049805
[32m[20221127 04:36:33 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:36:33 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:36:33 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:36:33 @pendulum_agent.py:292][0m Total time: 1140.450735092163
[32m[20221127 04:36:33 @pendulum_agent.py:294][0m 1700000 total steps have happened
[32m[20221127 04:36:33 @pendulum_agent.py:284][0m #------------------------ Iteration 34 --------------------------#
[32m[20221127 04:36:35 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:36:35 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:36:35 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:36:35 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:36:35 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:36:35 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:36:35 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:36:35 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:36:35 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:36:36 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:36:38 @pendulum_agent.py:310][0m Sample time: 5.663250923156738
[32m[20221127 04:37:04 @pendulum_agent.py:315][0m Update time: 25.46929407119751
[32m[20221127 04:37:04 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:37:04 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:37:04 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:37:04 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:37:04 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:37:04 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:37:04 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:37:04 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:37:05 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:37:05 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:37:05 @pendulum_agent.py:320][0m Evaluation time: 1.6352779865264893
[32m[20221127 04:37:06 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:37:06 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:37:06 @pendulum_agent.py:292][0m Total time: 1173.5942542552948
[32m[20221127 04:37:06 @pendulum_agent.py:294][0m 1750000 total steps have happened
[32m[20221127 04:37:06 @pendulum_agent.py:284][0m #------------------------ Iteration 35 --------------------------#
[32m[20221127 04:37:08 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:37:08 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:37:08 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:37:08 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:37:08 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:37:09 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:37:09 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:37:09 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:37:09 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:37:09 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:37:12 @pendulum_agent.py:310][0m Sample time: 6.257903099060059
[32m[20221127 04:37:37 @pendulum_agent.py:315][0m Update time: 25.04381799697876
[32m[20221127 04:37:37 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:37:38 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:37:38 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:37:38 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:37:38 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:37:38 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:37:38 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:37:38 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:37:38 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:37:38 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:37:38 @pendulum_agent.py:320][0m Evaluation time: 1.1662259101867676
[32m[20221127 04:37:39 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:37:39 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:37:39 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:37:39 @pendulum_agent.py:292][0m Total time: 1206.4201962947845
[32m[20221127 04:37:39 @pendulum_agent.py:294][0m 1800000 total steps have happened
[32m[20221127 04:37:39 @pendulum_agent.py:284][0m #------------------------ Iteration 36 --------------------------#
[32m[20221127 04:37:41 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:37:41 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:37:41 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:37:41 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:37:41 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:37:41 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:37:41 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:37:41 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:37:41 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:37:41 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:37:44 @pendulum_agent.py:310][0m Sample time: 5.688740015029907
[32m[20221127 04:38:10 @pendulum_agent.py:315][0m Update time: 25.602880716323853
[32m[20221127 04:38:10 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:38:10 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:38:10 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:38:10 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:38:10 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:38:10 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:38:11 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:38:11 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:38:11 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:38:11 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:38:11 @pendulum_agent.py:320][0m Evaluation time: 1.1689682006835938
[32m[20221127 04:38:11 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:38:11 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:38:11 @pendulum_agent.py:292][0m Total time: 1239.2412040233612
[32m[20221127 04:38:11 @pendulum_agent.py:294][0m 1850000 total steps have happened
[32m[20221127 04:38:11 @pendulum_agent.py:284][0m #------------------------ Iteration 37 --------------------------#
[32m[20221127 04:38:14 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 1.0
[32m[20221127 04:38:14 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 1.6
[32m[20221127 04:38:14 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.6
[32m[20221127 04:38:14 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 1.2
[32m[20221127 04:38:14 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.8
[32m[20221127 04:38:14 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.6
[32m[20221127 04:38:14 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.6
[32m[20221127 04:38:14 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.8
[32m[20221127 04:38:14 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 1.0
[32m[20221127 04:38:14 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.6
[32m[20221127 04:38:18 @pendulum_agent.py:310][0m Sample time: 6.127967119216919
[32m[20221127 04:38:43 @pendulum_agent.py:315][0m Update time: 25.25879192352295
[32m[20221127 04:38:43 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:38:43 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:38:43 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:38:43 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:38:43 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:38:43 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:38:43 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:38:44 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:38:44 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:38:44 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:38:44 @pendulum_agent.py:320][0m Evaluation time: 1.1726441383361816
[32m[20221127 04:38:44 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.88
[32m[20221127 04:38:44 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:38:44 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:38:44 @pendulum_agent.py:292][0m Total time: 1272.1292221546173
[32m[20221127 04:38:44 @pendulum_agent.py:294][0m 1900000 total steps have happened
[32m[20221127 04:38:44 @pendulum_agent.py:284][0m #------------------------ Iteration 38 --------------------------#
[32m[20221127 04:38:47 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:38:47 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:38:47 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:38:47 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:38:47 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:38:47 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:38:47 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:38:47 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:38:47 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:38:47 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:38:50 @pendulum_agent.py:310][0m Sample time: 5.942723035812378
[32m[20221127 04:39:16 @pendulum_agent.py:315][0m Update time: 25.470004081726074
[32m[20221127 04:39:16 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:39:16 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:39:16 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:39:16 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:39:16 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:39:16 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:39:16 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:39:16 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:39:16 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:39:16 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:39:17 @pendulum_agent.py:320][0m Evaluation time: 1.3284080028533936
[32m[20221127 04:39:17 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:39:17 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:39:17 @pendulum_agent.py:292][0m Total time: 1305.197035074234
[32m[20221127 04:39:17 @pendulum_agent.py:294][0m 1950000 total steps have happened
[32m[20221127 04:39:17 @pendulum_agent.py:284][0m #------------------------ Iteration 39 --------------------------#
[32m[20221127 04:39:20 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:39:20 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:39:20 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:39:20 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:39:20 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:39:20 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:39:20 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:39:20 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:39:20 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:39:20 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:39:23 @pendulum_agent.py:310][0m Sample time: 5.753830194473267
[32m[20221127 04:39:49 @pendulum_agent.py:315][0m Update time: 25.465555906295776
[32m[20221127 04:39:49 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:39:49 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:39:49 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:39:49 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:39:49 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:39:49 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:39:49 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:39:49 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:39:49 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:39:49 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:39:50 @pendulum_agent.py:320][0m Evaluation time: 1.549745798110962
[32m[20221127 04:39:51 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:39:51 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:39:51 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:39:51 @pendulum_agent.py:292][0m Total time: 1338.3127591609955
[32m[20221127 04:39:51 @pendulum_agent.py:294][0m 2000000 total steps have happened
[32m[20221127 04:39:51 @pendulum_agent.py:284][0m #------------------------ Iteration 40 --------------------------#
[32m[20221127 04:39:53 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:39:53 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:39:53 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:39:53 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:39:53 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:39:53 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:39:53 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:39:54 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:39:54 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:39:54 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:39:57 @pendulum_agent.py:310][0m Sample time: 5.998115062713623
[32m[20221127 04:40:22 @pendulum_agent.py:315][0m Update time: 25.618578910827637
[32m[20221127 04:40:23 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:40:23 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:40:23 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:40:23 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:40:23 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:40:23 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:40:23 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:40:23 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:40:23 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:40:23 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:40:23 @pendulum_agent.py:320][0m Evaluation time: 1.1922669410705566
[32m[20221127 04:40:24 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:40:24 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:40:24 @pendulum_agent.py:292][0m Total time: 1371.4713521003723
[32m[20221127 04:40:24 @pendulum_agent.py:294][0m 2050000 total steps have happened
[32m[20221127 04:40:24 @pendulum_agent.py:284][0m #------------------------ Iteration 41 --------------------------#
[32m[20221127 04:40:26 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 2.8
[32m[20221127 04:40:26 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 4.2
[32m[20221127 04:40:26 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 1.6
[32m[20221127 04:40:26 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 2.8
[32m[20221127 04:40:26 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 2.6
[32m[20221127 04:40:26 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 4.2
[32m[20221127 04:40:26 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 2.2
[32m[20221127 04:40:26 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 2.4
[32m[20221127 04:40:26 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 3.4
[32m[20221127 04:40:26 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 6.6
[32m[20221127 04:40:30 @pendulum_agent.py:310][0m Sample time: 5.909458875656128
[32m[20221127 04:40:55 @pendulum_agent.py:315][0m Update time: 24.896740913391113
[32m[20221127 04:40:55 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:40:55 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:40:55 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:40:55 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:40:55 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:40:55 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:40:55 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:40:55 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:40:55 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:40:55 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:40:56 @pendulum_agent.py:320][0m Evaluation time: 1.1846930980682373
[32m[20221127 04:40:56 @pendulum_agent.py:288][0m Average TRAINING episode reward: 3.28
[32m[20221127 04:40:56 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:40:56 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:40:56 @pendulum_agent.py:292][0m Total time: 1403.8078572750092
[32m[20221127 04:40:56 @pendulum_agent.py:294][0m 2100000 total steps have happened
[32m[20221127 04:40:56 @pendulum_agent.py:284][0m #------------------------ Iteration 42 --------------------------#
[32m[20221127 04:40:58 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 4.2
[32m[20221127 04:40:59 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 1.2
[32m[20221127 04:40:59 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 1.6
[32m[20221127 04:40:59 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 1.2
[32m[20221127 04:40:59 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.8
[32m[20221127 04:40:59 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 1.2
[32m[20221127 04:40:59 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.8
[32m[20221127 04:40:59 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 1.6
[32m[20221127 04:40:59 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 2.8
[32m[20221127 04:40:59 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 1.8
[32m[20221127 04:41:02 @pendulum_agent.py:310][0m Sample time: 6.137783050537109
[32m[20221127 04:41:28 @pendulum_agent.py:315][0m Update time: 25.685686111450195
[32m[20221127 04:41:28 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:41:28 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:41:28 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:41:28 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:41:28 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:41:28 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:41:28 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:41:28 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:41:29 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:41:29 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:41:29 @pendulum_agent.py:320][0m Evaluation time: 1.0156211853027344
[32m[20221127 04:41:29 @pendulum_agent.py:288][0m Average TRAINING episode reward: 1.72
[32m[20221127 04:41:29 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:41:29 @pendulum_agent.py:292][0m Total time: 1437.0028862953186
[32m[20221127 04:41:29 @pendulum_agent.py:294][0m 2150000 total steps have happened
[32m[20221127 04:41:29 @pendulum_agent.py:284][0m #------------------------ Iteration 43 --------------------------#
[32m[20221127 04:41:32 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:41:32 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:41:32 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:41:32 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:41:32 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:41:32 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:41:32 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:41:32 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:41:32 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:41:32 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:41:35 @pendulum_agent.py:310][0m Sample time: 5.88739800453186
[32m[20221127 04:42:00 @pendulum_agent.py:315][0m Update time: 25.130793809890747
[32m[20221127 04:42:01 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:42:01 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:42:01 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:42:01 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:42:01 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:42:01 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:42:01 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:42:01 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:42:01 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:42:01 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:42:01 @pendulum_agent.py:320][0m Evaluation time: 1.1850860118865967
[32m[20221127 04:42:02 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:42:02 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:42:02 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:42:02 @pendulum_agent.py:292][0m Total time: 1469.5512840747833
[32m[20221127 04:42:02 @pendulum_agent.py:294][0m 2200000 total steps have happened
[32m[20221127 04:42:02 @pendulum_agent.py:284][0m #------------------------ Iteration 44 --------------------------#
[32m[20221127 04:42:04 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:42:04 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:42:04 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:42:04 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:42:04 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:42:04 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:42:04 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:42:04 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:42:04 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:42:05 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:42:07 @pendulum_agent.py:310][0m Sample time: 5.685145139694214
[32m[20221127 04:42:33 @pendulum_agent.py:315][0m Update time: 25.677846670150757
[32m[20221127 04:42:34 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:42:34 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:42:34 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:42:34 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:42:34 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:42:34 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:42:34 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:42:34 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:42:34 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:42:34 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:42:34 @pendulum_agent.py:320][0m Evaluation time: 1.1584041118621826
[32m[20221127 04:42:35 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:42:35 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:42:35 @pendulum_agent.py:292][0m Total time: 1502.424800157547
[32m[20221127 04:42:35 @pendulum_agent.py:294][0m 2250000 total steps have happened
[32m[20221127 04:42:35 @pendulum_agent.py:284][0m #------------------------ Iteration 45 --------------------------#
[32m[20221127 04:42:37 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.8
[32m[20221127 04:42:37 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.6
[32m[20221127 04:42:37 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 1.2
[32m[20221127 04:42:37 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 1.4
[32m[20221127 04:42:37 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 1.2
[32m[20221127 04:42:37 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.8
[32m[20221127 04:42:37 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 1.8
[32m[20221127 04:42:37 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 1.4
[32m[20221127 04:42:37 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 1.2
[32m[20221127 04:42:37 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 1.2
[32m[20221127 04:42:40 @pendulum_agent.py:310][0m Sample time: 5.748290061950684
[32m[20221127 04:43:06 @pendulum_agent.py:315][0m Update time: 25.989062786102295
[32m[20221127 04:43:07 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:43:07 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:43:07 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:43:07 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:43:07 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:43:07 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:43:07 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:43:07 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:43:07 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:43:07 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:43:08 @pendulum_agent.py:320][0m Evaluation time: 1.205998182296753
[32m[20221127 04:43:08 @pendulum_agent.py:288][0m Average TRAINING episode reward: 1.16
[32m[20221127 04:43:08 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:43:08 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:43:08 @pendulum_agent.py:292][0m Total time: 1535.7281169891357
[32m[20221127 04:43:08 @pendulum_agent.py:294][0m 2300000 total steps have happened
[32m[20221127 04:43:08 @pendulum_agent.py:284][0m #------------------------ Iteration 46 --------------------------#
[32m[20221127 04:43:10 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 2.8
[32m[20221127 04:43:10 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 4.8
[32m[20221127 04:43:10 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 2.6
[32m[20221127 04:43:10 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 4.0
[32m[20221127 04:43:10 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 5.8
[32m[20221127 04:43:11 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 2.8
[32m[20221127 04:43:11 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 2.4
[32m[20221127 04:43:11 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 4.8
[32m[20221127 04:43:11 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 4.4
[32m[20221127 04:43:11 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 3.6
[32m[20221127 04:43:14 @pendulum_agent.py:310][0m Sample time: 6.050612926483154
[32m[20221127 04:43:40 @pendulum_agent.py:315][0m Update time: 25.864405155181885
[32m[20221127 04:43:40 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:43:40 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:43:40 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:43:40 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:43:40 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:43:40 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:43:40 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:43:40 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:43:40 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:43:41 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:43:41 @pendulum_agent.py:320][0m Evaluation time: 0.9984478950500488
[32m[20221127 04:43:41 @pendulum_agent.py:288][0m Average TRAINING episode reward: 3.8
[32m[20221127 04:43:41 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:43:41 @pendulum_agent.py:292][0m Total time: 1568.9926691055298
[32m[20221127 04:43:41 @pendulum_agent.py:294][0m 2350000 total steps have happened
[32m[20221127 04:43:41 @pendulum_agent.py:284][0m #------------------------ Iteration 47 --------------------------#
[32m[20221127 04:43:44 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:43:44 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:43:44 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:43:44 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:43:44 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:43:44 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:43:44 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:43:44 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:43:44 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:43:44 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:43:47 @pendulum_agent.py:310][0m Sample time: 5.732274055480957
[32m[20221127 04:44:13 @pendulum_agent.py:315][0m Update time: 25.601845026016235
[32m[20221127 04:44:13 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:44:13 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:44:13 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:44:13 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:44:13 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:44:13 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:44:13 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:44:13 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:44:13 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:44:13 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:44:14 @pendulum_agent.py:320][0m Evaluation time: 1.2909798622131348
[32m[20221127 04:44:14 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:44:14 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:44:14 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:44:14 @pendulum_agent.py:292][0m Total time: 1601.9604091644287
[32m[20221127 04:44:14 @pendulum_agent.py:294][0m 2400000 total steps have happened
[32m[20221127 04:44:14 @pendulum_agent.py:284][0m #------------------------ Iteration 48 --------------------------#
[32m[20221127 04:44:16 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:44:16 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:44:17 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:44:17 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:44:17 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:44:17 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:44:17 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:44:17 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:44:17 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:44:17 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:44:20 @pendulum_agent.py:310][0m Sample time: 5.663766145706177
[32m[20221127 04:44:45 @pendulum_agent.py:315][0m Update time: 25.465464115142822
[32m[20221127 04:44:46 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:44:46 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:44:46 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:44:46 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:44:46 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:44:46 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:44:46 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:44:46 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:44:46 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:44:46 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:44:48 @pendulum_agent.py:320][0m Evaluation time: 2.4467129707336426
[32m[20221127 04:44:48 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:44:48 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:44:48 @pendulum_agent.py:292][0m Total time: 1635.8851821422577
[32m[20221127 04:44:48 @pendulum_agent.py:294][0m 2450000 total steps have happened
[32m[20221127 04:44:48 @pendulum_agent.py:284][0m #------------------------ Iteration 49 --------------------------#
[32m[20221127 04:44:51 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:44:51 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:44:51 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:44:51 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:44:51 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:44:51 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:44:51 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:44:51 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:44:51 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:44:51 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:44:54 @pendulum_agent.py:310][0m Sample time: 5.993937969207764
[32m[20221127 04:45:20 @pendulum_agent.py:315][0m Update time: 25.64230704307556
[32m[20221127 04:45:20 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:45:20 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:45:20 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:45:20 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:45:20 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:45:20 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:45:20 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:45:20 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:45:20 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:45:20 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:45:21 @pendulum_agent.py:320][0m Evaluation time: 1.2029712200164795
[32m[20221127 04:45:21 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:45:21 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:45:21 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:45:21 @pendulum_agent.py:292][0m Total time: 1669.0524590015411
[32m[20221127 04:45:21 @pendulum_agent.py:294][0m 2500000 total steps have happened
[32m[20221127 04:45:21 @pendulum_agent.py:284][0m #------------------------ Iteration 50 --------------------------#
[32m[20221127 04:45:24 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 2.2
[32m[20221127 04:45:24 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 4.0
[32m[20221127 04:45:24 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 2.6
[32m[20221127 04:45:24 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 2.8
[32m[20221127 04:45:24 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 2.4
[32m[20221127 04:45:24 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 3.6
[32m[20221127 04:45:24 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 4.0
[32m[20221127 04:45:24 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 2.6
[32m[20221127 04:45:24 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 5.2
[32m[20221127 04:45:24 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 6.8
[32m[20221127 04:45:27 @pendulum_agent.py:310][0m Sample time: 6.131141901016235
[32m[20221127 04:45:53 @pendulum_agent.py:315][0m Update time: 25.609268188476562
[32m[20221127 04:45:54 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:45:54 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:45:54 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:45:54 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:45:54 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:45:54 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:45:54 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:45:54 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:45:54 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:45:54 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:45:54 @pendulum_agent.py:320][0m Evaluation time: 1.2072689533233643
[32m[20221127 04:45:55 @pendulum_agent.py:288][0m Average TRAINING episode reward: 3.62
[32m[20221127 04:45:55 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:45:55 @pendulum_agent.py:292][0m Total time: 1702.36128616333
[32m[20221127 04:45:55 @pendulum_agent.py:294][0m 2550000 total steps have happened
[32m[20221127 04:45:55 @pendulum_agent.py:284][0m #------------------------ Iteration 51 --------------------------#
[32m[20221127 04:45:57 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 1.4
[32m[20221127 04:45:57 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 2.4
[32m[20221127 04:45:57 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 1.4
[32m[20221127 04:45:57 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 1.4
[32m[20221127 04:45:57 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 1.6
[32m[20221127 04:45:57 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 2.0
[32m[20221127 04:45:58 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 1.8
[32m[20221127 04:45:58 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 1.8
[32m[20221127 04:45:58 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 2.0
[32m[20221127 04:45:58 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 1.4
[32m[20221127 04:46:01 @pendulum_agent.py:310][0m Sample time: 6.221967697143555
[32m[20221127 04:46:26 @pendulum_agent.py:315][0m Update time: 25.487714052200317
[32m[20221127 04:46:27 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:46:27 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:46:27 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:46:27 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:46:27 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:46:27 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:46:27 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:46:27 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:46:27 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:46:27 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:46:28 @pendulum_agent.py:320][0m Evaluation time: 1.6254510879516602
[32m[20221127 04:46:28 @pendulum_agent.py:288][0m Average TRAINING episode reward: 1.72
[32m[20221127 04:46:28 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:46:28 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:46:28 @pendulum_agent.py:292][0m Total time: 1736.0805401802063
[32m[20221127 04:46:28 @pendulum_agent.py:294][0m 2600000 total steps have happened
[32m[20221127 04:46:28 @pendulum_agent.py:284][0m #------------------------ Iteration 52 --------------------------#
[32m[20221127 04:46:31 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:46:31 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:46:31 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:46:31 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:46:31 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:46:31 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:46:31 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:46:31 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:46:31 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:46:31 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:46:34 @pendulum_agent.py:310][0m Sample time: 6.16733717918396
[32m[20221127 04:47:00 @pendulum_agent.py:315][0m Update time: 25.661507844924927
[32m[20221127 04:47:01 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:47:01 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:47:01 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:47:01 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:47:01 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:47:01 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:47:01 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:47:01 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:47:01 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:47:01 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:47:01 @pendulum_agent.py:320][0m Evaluation time: 1.32338285446167
[32m[20221127 04:47:02 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:47:02 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:47:02 @pendulum_agent.py:292][0m Total time: 1769.5762021541595
[32m[20221127 04:47:02 @pendulum_agent.py:294][0m 2650000 total steps have happened
[32m[20221127 04:47:02 @pendulum_agent.py:284][0m #------------------------ Iteration 53 --------------------------#
[32m[20221127 04:47:04 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 3.8
[32m[20221127 04:47:04 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 2.0
[32m[20221127 04:47:04 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 2.2
[32m[20221127 04:47:04 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 2.2
[32m[20221127 04:47:04 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 2.0
[32m[20221127 04:47:04 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 2.2
[32m[20221127 04:47:04 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 2.4
[32m[20221127 04:47:04 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 1.8
[32m[20221127 04:47:05 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 2.8
[32m[20221127 04:47:05 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 2.2
[32m[20221127 04:47:08 @pendulum_agent.py:310][0m Sample time: 5.885325193405151
[32m[20221127 04:47:33 @pendulum_agent.py:315][0m Update time: 25.567139863967896
[32m[20221127 04:47:34 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:47:34 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:47:34 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:47:34 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:47:34 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:47:34 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:47:34 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:47:34 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:47:34 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:47:34 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:47:34 @pendulum_agent.py:320][0m Evaluation time: 1.0590901374816895
[32m[20221127 04:47:35 @pendulum_agent.py:288][0m Average TRAINING episode reward: 2.36
[32m[20221127 04:47:35 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:47:35 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:47:35 @pendulum_agent.py:292][0m Total time: 1802.4501860141754
[32m[20221127 04:47:35 @pendulum_agent.py:294][0m 2700000 total steps have happened
[32m[20221127 04:47:35 @pendulum_agent.py:284][0m #------------------------ Iteration 54 --------------------------#
[32m[20221127 04:47:37 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:47:37 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:47:37 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:47:37 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:47:37 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:47:37 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:47:37 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:47:37 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:47:37 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:47:37 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:47:41 @pendulum_agent.py:310][0m Sample time: 6.321865081787109
[32m[20221127 04:48:06 @pendulum_agent.py:315][0m Update time: 25.287025690078735
[32m[20221127 04:48:07 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:48:07 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:48:07 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:48:07 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:48:07 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:48:07 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:48:07 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:48:07 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:48:07 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:48:07 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:48:07 @pendulum_agent.py:320][0m Evaluation time: 1.213996171951294
[32m[20221127 04:48:08 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:48:08 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:48:08 @pendulum_agent.py:292][0m Total time: 1835.6305491924286
[32m[20221127 04:48:08 @pendulum_agent.py:294][0m 2750000 total steps have happened
[32m[20221127 04:48:08 @pendulum_agent.py:284][0m #------------------------ Iteration 55 --------------------------#
[32m[20221127 04:48:10 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:48:10 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:48:10 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:48:10 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:48:10 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:48:10 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:48:11 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:48:11 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:48:11 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:48:11 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:48:14 @pendulum_agent.py:310][0m Sample time: 6.304445743560791
[32m[20221127 04:48:40 @pendulum_agent.py:315][0m Update time: 25.751789093017578
[32m[20221127 04:48:40 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:48:40 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:48:40 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:48:41 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:48:41 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:48:41 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:48:41 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:48:41 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:48:41 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:48:41 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:48:41 @pendulum_agent.py:320][0m Evaluation time: 1.0132770538330078
[32m[20221127 04:48:41 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:48:41 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:48:41 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:48:41 @pendulum_agent.py:292][0m Total time: 1869.0644512176514
[32m[20221127 04:48:41 @pendulum_agent.py:294][0m 2800000 total steps have happened
[32m[20221127 04:48:41 @pendulum_agent.py:284][0m #------------------------ Iteration 56 --------------------------#
[32m[20221127 04:48:44 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:48:44 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:48:44 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:48:44 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:48:44 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:48:44 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:48:44 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:48:44 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:48:44 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:48:44 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:48:47 @pendulum_agent.py:310][0m Sample time: 6.1209962368011475
[32m[20221127 04:49:13 @pendulum_agent.py:315][0m Update time: 25.806278944015503
[32m[20221127 04:49:14 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:49:14 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:49:14 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:49:14 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:49:14 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:49:14 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:49:14 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:49:14 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:49:14 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:49:14 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:49:15 @pendulum_agent.py:320][0m Evaluation time: 1.326714038848877
[32m[20221127 04:49:15 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:49:15 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:49:15 @pendulum_agent.py:292][0m Total time: 1902.7027683258057
[32m[20221127 04:49:15 @pendulum_agent.py:294][0m 2850000 total steps have happened
[32m[20221127 04:49:15 @pendulum_agent.py:284][0m #------------------------ Iteration 57 --------------------------#
[32m[20221127 04:49:17 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:49:17 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:49:17 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:49:18 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:49:18 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:49:18 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:49:18 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:49:18 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:49:18 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:49:18 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:49:21 @pendulum_agent.py:310][0m Sample time: 5.723644971847534
[32m[20221127 04:49:45 @pendulum_agent.py:315][0m Update time: 24.064851999282837
[32m[20221127 04:49:45 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:49:45 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:49:45 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:49:45 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:49:45 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:49:45 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:49:45 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:49:45 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:49:45 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:49:45 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:49:46 @pendulum_agent.py:320][0m Evaluation time: 1.412513017654419
[32m[20221127 04:49:46 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:49:46 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:49:46 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:49:46 @pendulum_agent.py:292][0m Total time: 1934.2014331817627
[32m[20221127 04:49:46 @pendulum_agent.py:294][0m 2900000 total steps have happened
[32m[20221127 04:49:46 @pendulum_agent.py:284][0m #------------------------ Iteration 58 --------------------------#
[32m[20221127 04:49:49 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:49:49 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:49:49 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:49:49 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:49:49 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:49:49 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:49:49 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:49:49 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:49:49 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:49:49 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:49:51 @pendulum_agent.py:310][0m Sample time: 5.024960041046143
[32m[20221127 04:50:17 @pendulum_agent.py:315][0m Update time: 25.995139837265015
[32m[20221127 04:50:18 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:50:18 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:50:18 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:50:18 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:50:18 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:50:18 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:50:18 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:50:18 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:50:18 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:50:18 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:50:19 @pendulum_agent.py:320][0m Evaluation time: 1.7486209869384766
[32m[20221127 04:50:20 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:50:20 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:50:20 @pendulum_agent.py:292][0m Total time: 1967.368334054947
[32m[20221127 04:50:20 @pendulum_agent.py:294][0m 2950000 total steps have happened
[32m[20221127 04:50:20 @pendulum_agent.py:284][0m #------------------------ Iteration 59 --------------------------#
[32m[20221127 04:50:22 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 3.2
[32m[20221127 04:50:22 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 5.6
[32m[20221127 04:50:22 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 3.2
[32m[20221127 04:50:22 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 2.8
[32m[20221127 04:50:22 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 3.2
[32m[20221127 04:50:22 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 3.0
[32m[20221127 04:50:22 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 3.0
[32m[20221127 04:50:22 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 3.2
[32m[20221127 04:50:22 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 2.2
[32m[20221127 04:50:22 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 5.6
[32m[20221127 04:50:25 @pendulum_agent.py:310][0m Sample time: 5.545953989028931
[32m[20221127 04:50:50 @pendulum_agent.py:315][0m Update time: 25.16524600982666
[32m[20221127 04:50:51 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:50:51 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:50:51 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:50:51 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:50:51 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:50:51 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:50:51 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:50:51 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:50:51 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:50:51 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:50:53 @pendulum_agent.py:320][0m Evaluation time: 2.424443244934082
[32m[20221127 04:50:53 @pendulum_agent.py:288][0m Average TRAINING episode reward: 3.5
[32m[20221127 04:50:53 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:50:53 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:50:53 @pendulum_agent.py:292][0m Total time: 2000.844583272934
[32m[20221127 04:50:53 @pendulum_agent.py:294][0m 3000000 total steps have happened
[32m[20221127 04:50:53 @pendulum_agent.py:284][0m #------------------------ Iteration 60 --------------------------#
[32m[20221127 04:50:56 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:50:56 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:50:56 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:50:56 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:50:56 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:50:56 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:50:56 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:50:56 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:50:56 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:50:56 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:50:59 @pendulum_agent.py:310][0m Sample time: 6.042203903198242
[32m[20221127 04:51:25 @pendulum_agent.py:315][0m Update time: 25.627723932266235
[32m[20221127 04:51:25 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:51:25 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:51:25 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:51:25 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:51:25 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:51:25 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:51:25 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:51:25 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:51:25 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:51:25 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:51:26 @pendulum_agent.py:320][0m Evaluation time: 1.5819361209869385
[32m[20221127 04:51:27 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:51:27 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:51:27 @pendulum_agent.py:292][0m Total time: 2034.505196094513
[32m[20221127 04:51:27 @pendulum_agent.py:294][0m 3050000 total steps have happened
[32m[20221127 04:51:27 @pendulum_agent.py:284][0m #------------------------ Iteration 61 --------------------------#
[32m[20221127 04:51:29 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:51:29 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:51:29 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:51:29 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:51:29 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:51:29 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:51:29 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:51:29 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:51:29 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:51:30 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:51:33 @pendulum_agent.py:310][0m Sample time: 6.223737001419067
[32m[20221127 04:51:58 @pendulum_agent.py:315][0m Update time: 24.997048139572144
[32m[20221127 04:51:58 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:51:58 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:51:58 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:51:58 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:51:59 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:51:59 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:51:59 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:51:59 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:51:59 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:51:59 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:52:00 @pendulum_agent.py:320][0m Evaluation time: 1.6229948997497559
[32m[20221127 04:52:00 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:52:00 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:52:00 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:52:00 @pendulum_agent.py:292][0m Total time: 2067.7122440338135
[32m[20221127 04:52:00 @pendulum_agent.py:294][0m 3100000 total steps have happened
[32m[20221127 04:52:00 @pendulum_agent.py:284][0m #------------------------ Iteration 62 --------------------------#
[32m[20221127 04:52:03 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 2.8
[32m[20221127 04:52:03 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 3.2
[32m[20221127 04:52:03 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 3.0
[32m[20221127 04:52:03 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 3.6
[32m[20221127 04:52:03 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 3.2
[32m[20221127 04:52:03 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 4.2
[32m[20221127 04:52:03 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 3.4
[32m[20221127 04:52:03 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 3.4
[32m[20221127 04:52:03 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 4.4
[32m[20221127 04:52:03 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 3.4
[32m[20221127 04:52:06 @pendulum_agent.py:310][0m Sample time: 6.0071728229522705
[32m[20221127 04:52:32 @pendulum_agent.py:315][0m Update time: 26.309235095977783
[32m[20221127 04:52:33 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:52:33 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:52:33 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:52:33 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:52:33 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:52:33 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:52:33 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:52:33 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:52:33 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:52:33 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:52:33 @pendulum_agent.py:320][0m Evaluation time: 1.1662039756774902
[32m[20221127 04:52:34 @pendulum_agent.py:288][0m Average TRAINING episode reward: 3.46
[32m[20221127 04:52:34 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:52:34 @pendulum_agent.py:292][0m Total time: 2101.576215028763
[32m[20221127 04:52:34 @pendulum_agent.py:294][0m 3150000 total steps have happened
[32m[20221127 04:52:34 @pendulum_agent.py:284][0m #------------------------ Iteration 63 --------------------------#
[32m[20221127 04:52:36 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:52:36 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:52:36 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:52:36 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:52:36 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:52:36 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:52:37 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:52:37 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:52:37 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:52:37 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:52:40 @pendulum_agent.py:310][0m Sample time: 6.181794881820679
[32m[20221127 04:53:05 @pendulum_agent.py:315][0m Update time: 25.045719861984253
[32m[20221127 04:53:05 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:53:06 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:53:06 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:53:06 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:53:06 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:53:06 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:53:06 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:53:06 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:53:06 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:53:06 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:53:06 @pendulum_agent.py:320][0m Evaluation time: 1.0167791843414307
[32m[20221127 04:53:06 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:53:06 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:53:06 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:53:06 @pendulum_agent.py:292][0m Total time: 2134.1791322231293
[32m[20221127 04:53:06 @pendulum_agent.py:294][0m 3200000 total steps have happened
[32m[20221127 04:53:06 @pendulum_agent.py:284][0m #------------------------ Iteration 64 --------------------------#
[32m[20221127 04:53:09 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:53:09 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:53:09 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:53:09 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:53:09 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:53:09 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:53:09 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:53:09 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:53:09 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:53:09 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:53:12 @pendulum_agent.py:310][0m Sample time: 5.970780849456787
[32m[20221127 04:53:38 @pendulum_agent.py:315][0m Update time: 25.305258989334106
[32m[20221127 04:53:38 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:53:38 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:53:38 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:53:38 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:53:38 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:53:38 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:53:38 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:53:38 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:53:38 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:53:38 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:53:39 @pendulum_agent.py:320][0m Evaluation time: 1.1900222301483154
[32m[20221127 04:53:39 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:53:39 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:53:39 @pendulum_agent.py:292][0m Total time: 2166.974607229233
[32m[20221127 04:53:39 @pendulum_agent.py:294][0m 3250000 total steps have happened
[32m[20221127 04:53:39 @pendulum_agent.py:284][0m #------------------------ Iteration 65 --------------------------#
[32m[20221127 04:53:42 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:53:42 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:53:42 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:53:42 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:53:42 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:53:42 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:53:42 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:53:42 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:53:42 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:53:42 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:53:45 @pendulum_agent.py:310][0m Sample time: 5.7652130126953125
[32m[20221127 04:54:10 @pendulum_agent.py:315][0m Update time: 25.43504309654236
[32m[20221127 04:54:11 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:54:11 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:54:11 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:54:11 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:54:11 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:54:11 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:54:11 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:54:11 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:54:11 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:54:11 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:54:12 @pendulum_agent.py:320][0m Evaluation time: 1.1566200256347656
[32m[20221127 04:54:12 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:54:12 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:54:12 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:54:12 @pendulum_agent.py:292][0m Total time: 2199.705287218094
[32m[20221127 04:54:12 @pendulum_agent.py:294][0m 3300000 total steps have happened
[32m[20221127 04:54:12 @pendulum_agent.py:284][0m #------------------------ Iteration 66 --------------------------#
[32m[20221127 04:54:14 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:54:14 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:54:14 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:54:15 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:54:15 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:54:15 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:54:15 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:54:15 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:54:15 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:54:15 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:54:18 @pendulum_agent.py:310][0m Sample time: 6.08318018913269
[32m[20221127 04:54:44 @pendulum_agent.py:315][0m Update time: 25.52767586708069
[32m[20221127 04:54:44 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:54:44 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:54:44 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:54:44 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:54:44 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:54:44 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:54:44 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:54:44 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:54:44 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:54:44 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:54:45 @pendulum_agent.py:320][0m Evaluation time: 1.0174908638000488
[32m[20221127 04:54:45 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:54:45 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:54:45 @pendulum_agent.py:292][0m Total time: 2232.692150115967
[32m[20221127 04:54:45 @pendulum_agent.py:294][0m 3350000 total steps have happened
[32m[20221127 04:54:45 @pendulum_agent.py:284][0m #------------------------ Iteration 67 --------------------------#
[32m[20221127 04:54:47 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:54:47 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:54:47 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:54:48 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:54:48 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:54:48 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:54:48 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:54:48 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:54:48 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:54:48 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:54:51 @pendulum_agent.py:310][0m Sample time: 6.150501012802124
[32m[20221127 04:55:16 @pendulum_agent.py:315][0m Update time: 24.55889105796814
[32m[20221127 04:55:16 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:55:16 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:55:16 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:55:16 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:55:16 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:55:16 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:55:16 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:55:16 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:55:16 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:55:16 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:55:17 @pendulum_agent.py:320][0m Evaluation time: 0.9891409873962402
[32m[20221127 04:55:17 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:55:17 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:55:17 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:55:17 @pendulum_agent.py:292][0m Total time: 2264.7472021579742
[32m[20221127 04:55:17 @pendulum_agent.py:294][0m 3400000 total steps have happened
[32m[20221127 04:55:17 @pendulum_agent.py:284][0m #------------------------ Iteration 68 --------------------------#
[32m[20221127 04:55:20 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:55:20 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:55:20 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:55:20 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:55:20 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:55:20 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:55:20 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:55:20 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:55:20 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:55:20 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:55:23 @pendulum_agent.py:310][0m Sample time: 6.004894971847534
[32m[20221127 04:55:48 @pendulum_agent.py:315][0m Update time: 24.831088066101074
[32m[20221127 04:55:49 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:55:49 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:55:49 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:55:49 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:55:49 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:55:49 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:55:49 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:55:49 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:55:49 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:55:49 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:55:50 @pendulum_agent.py:320][0m Evaluation time: 1.7801060676574707
[32m[20221127 04:55:50 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:55:50 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:55:50 @pendulum_agent.py:292][0m Total time: 2297.722330093384
[32m[20221127 04:55:50 @pendulum_agent.py:294][0m 3450000 total steps have happened
[32m[20221127 04:55:50 @pendulum_agent.py:284][0m #------------------------ Iteration 69 --------------------------#
[32m[20221127 04:55:52 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:55:52 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:55:53 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:55:53 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:55:53 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:55:53 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:55:53 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:55:53 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:55:53 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:55:53 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:55:55 @pendulum_agent.py:310][0m Sample time: 5.52405309677124
[32m[20221127 04:56:21 @pendulum_agent.py:315][0m Update time: 25.69850993156433
[32m[20221127 04:56:22 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:56:22 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:56:22 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:56:22 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:56:22 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:56:22 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:56:22 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:56:22 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:56:22 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:56:22 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:56:23 @pendulum_agent.py:320][0m Evaluation time: 1.8154208660125732
[32m[20221127 04:56:23 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:56:23 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:56:23 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:56:23 @pendulum_agent.py:292][0m Total time: 2331.116912126541
[32m[20221127 04:56:23 @pendulum_agent.py:294][0m 3500000 total steps have happened
[32m[20221127 04:56:23 @pendulum_agent.py:284][0m #------------------------ Iteration 70 --------------------------#
[32m[20221127 04:56:26 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:56:26 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:56:26 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:56:26 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:56:26 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:56:26 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:56:26 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:56:26 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:56:26 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:56:26 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:56:29 @pendulum_agent.py:310][0m Sample time: 5.39823579788208
[32m[20221127 04:56:55 @pendulum_agent.py:315][0m Update time: 25.78308892250061
[32m[20221127 04:56:55 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:56:55 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:56:55 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:56:55 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:56:55 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:56:55 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:56:55 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:56:55 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:56:55 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:56:55 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:56:56 @pendulum_agent.py:320][0m Evaluation time: 1.5806021690368652
[32m[20221127 04:56:56 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:56:56 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:56:56 @pendulum_agent.py:292][0m Total time: 2364.256044149399
[32m[20221127 04:56:56 @pendulum_agent.py:294][0m 3550000 total steps have happened
[32m[20221127 04:56:56 @pendulum_agent.py:284][0m #------------------------ Iteration 71 --------------------------#
[32m[20221127 04:56:59 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:56:59 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:56:59 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:56:59 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:56:59 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:56:59 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:56:59 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:56:59 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:56:59 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:56:59 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:57:02 @pendulum_agent.py:310][0m Sample time: 5.573597192764282
[32m[20221127 04:57:28 @pendulum_agent.py:315][0m Update time: 25.573285818099976
[32m[20221127 04:57:28 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:57:28 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:57:28 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:57:28 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:57:28 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:57:28 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:57:28 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:57:28 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:57:28 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:57:28 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:57:29 @pendulum_agent.py:320][0m Evaluation time: 1.782641887664795
[32m[20221127 04:57:30 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:57:30 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:57:30 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:57:30 @pendulum_agent.py:292][0m Total time: 2397.527736186981
[32m[20221127 04:57:30 @pendulum_agent.py:294][0m 3600000 total steps have happened
[32m[20221127 04:57:30 @pendulum_agent.py:284][0m #------------------------ Iteration 72 --------------------------#
[32m[20221127 04:57:32 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:57:32 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:57:32 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:57:32 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:57:32 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:57:32 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:57:32 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:57:32 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:57:32 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:57:32 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:57:36 @pendulum_agent.py:310][0m Sample time: 5.836782932281494
[32m[20221127 04:58:01 @pendulum_agent.py:315][0m Update time: 25.625624179840088
[32m[20221127 04:58:02 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:58:02 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:58:02 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:58:02 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:58:02 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:58:02 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:58:02 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:58:02 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:58:02 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:58:02 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:58:02 @pendulum_agent.py:320][0m Evaluation time: 1.1987829208374023
[32m[20221127 04:58:03 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:58:03 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:58:03 @pendulum_agent.py:292][0m Total time: 2430.5747051239014
[32m[20221127 04:58:03 @pendulum_agent.py:294][0m 3650000 total steps have happened
[32m[20221127 04:58:03 @pendulum_agent.py:284][0m #------------------------ Iteration 73 --------------------------#
[32m[20221127 04:58:05 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 1.2
[32m[20221127 04:58:05 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.6
[32m[20221127 04:58:05 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 1.0
[32m[20221127 04:58:05 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.6
[32m[20221127 04:58:05 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.6
[32m[20221127 04:58:05 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 1.2
[32m[20221127 04:58:05 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 1.2
[32m[20221127 04:58:05 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 1.2
[32m[20221127 04:58:06 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.4
[32m[20221127 04:58:06 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 1.4
[32m[20221127 04:58:09 @pendulum_agent.py:310][0m Sample time: 5.831745862960815
[32m[20221127 04:58:34 @pendulum_agent.py:315][0m Update time: 25.587032794952393
[32m[20221127 04:58:35 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:58:35 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:58:35 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:58:35 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:58:35 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:58:35 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:58:35 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:58:35 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:58:35 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:58:35 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:58:35 @pendulum_agent.py:320][0m Evaluation time: 1.2090482711791992
[32m[20221127 04:58:36 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.94
[32m[20221127 04:58:36 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:58:36 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:58:36 @pendulum_agent.py:292][0m Total time: 2463.5494980812073
[32m[20221127 04:58:36 @pendulum_agent.py:294][0m 3700000 total steps have happened
[32m[20221127 04:58:36 @pendulum_agent.py:284][0m #------------------------ Iteration 74 --------------------------#
[32m[20221127 04:58:38 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:58:38 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:58:38 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:58:38 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:58:38 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:58:38 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:58:38 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:58:39 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:58:39 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:58:39 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:58:42 @pendulum_agent.py:310][0m Sample time: 5.906521797180176
[32m[20221127 04:59:07 @pendulum_agent.py:315][0m Update time: 25.559978008270264
[32m[20221127 04:59:08 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:59:08 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:59:08 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:59:08 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:59:08 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:59:08 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:59:08 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:59:08 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:59:08 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:59:08 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:59:08 @pendulum_agent.py:320][0m Evaluation time: 1.0232691764831543
[32m[20221127 04:59:09 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:59:09 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:59:09 @pendulum_agent.py:292][0m Total time: 2496.4203803539276
[32m[20221127 04:59:09 @pendulum_agent.py:294][0m 3750000 total steps have happened
[32m[20221127 04:59:09 @pendulum_agent.py:284][0m #------------------------ Iteration 75 --------------------------#
[32m[20221127 04:59:11 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:59:11 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:59:11 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:59:11 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:59:11 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:59:11 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:59:11 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:59:11 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:59:11 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:59:11 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:59:15 @pendulum_agent.py:310][0m Sample time: 6.267106056213379
[32m[20221127 04:59:41 @pendulum_agent.py:315][0m Update time: 25.777378797531128
[32m[20221127 04:59:41 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:59:41 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:59:41 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:59:41 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:59:41 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:59:41 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:59:41 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:59:41 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:59:41 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:59:41 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:59:42 @pendulum_agent.py:320][0m Evaluation time: 1.1825101375579834
[32m[20221127 04:59:42 @pendulum_agent.py:288][0m Average TRAINING episode reward: 0.0
[32m[20221127 04:59:42 @pendulum_agent.py:289][0m Average EVALUATION episode reward: 0
[32m[20221127 04:59:42 @pendulum_agent.py:259][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221127 04:59:42 @pendulum_agent.py:292][0m Total time: 2530.028699159622
[32m[20221127 04:59:42 @pendulum_agent.py:294][0m 3800000 total steps have happened
[32m[20221127 04:59:42 @pendulum_agent.py:284][0m #------------------------ Iteration 76 --------------------------#
[32m[20221127 04:59:45 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 04:59:45 @pendulum_agent.py:147][0m agent 2 avg episode training reward: 0.0
[32m[20221127 04:59:45 @pendulum_agent.py:147][0m agent 6 avg episode training reward: 0.0
[32m[20221127 04:59:45 @pendulum_agent.py:147][0m agent 1 avg episode training reward: 0.0
[32m[20221127 04:59:45 @pendulum_agent.py:147][0m agent 4 avg episode training reward: 0.0
[32m[20221127 04:59:45 @pendulum_agent.py:147][0m agent 5 avg episode training reward: 0.0
[32m[20221127 04:59:45 @pendulum_agent.py:147][0m agent 3 avg episode training reward: 0.0
[32m[20221127 04:59:45 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
[32m[20221127 04:59:45 @pendulum_agent.py:147][0m agent 7 avg episode training reward: 0.0
[32m[20221127 04:59:45 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 04:59:48 @pendulum_agent.py:310][0m Sample time: 5.916082859039307
[32m[20221127 05:00:13 @pendulum_agent.py:315][0m Update time: 24.820341110229492
[32m[20221127 05:00:13 @pendulum_agent.py:147][0m agent 9 avg episode training reward: 0.0
[32m[20221127 05:00:13 @pendulum_agent.py:147][0m agent 0 avg episode training reward: 0.0
[32m[20221127 05:00:13 @pendulum_agent.py:147][0m agent 8 avg episode training reward: 0.0
