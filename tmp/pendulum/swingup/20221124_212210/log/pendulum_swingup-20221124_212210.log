[32m[20221124 21:22:10 @logger.py:105][0m Log file set to ./tmp/pendulum/swingup/20221124_212210/log/pendulum_swingup-20221124_212210.log
[32m[20221124 21:22:10 @pendulum_agent.py:281][0m #------------------------ Iteration 0 --------------------------#
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:14 @pendulum_agent.py:307][0m Sample time: 3.1671769618988037
[32m[20221124 21:22:24 @pendulum_agent.py:312][0m Update time: 10.182775020599365
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:25 @pendulum_agent.py:317][0m Evaluation time: 0.7066848278045654
[32m[20221124 21:22:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:22:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:22:25 @pendulum_agent.py:262][0m [4m[34mCRITICAL[0m Get the best episode reward: 0
[32m[20221124 21:22:25 @pendulum_agent.py:266][0m [4m[34mCRITICAL[0m Saving the best checkpoint with rewards 0.00
[32m[20221124 21:22:25 @pendulum_agent.py:289][0m Total time: 14.412011861801147
[32m[20221124 21:22:25 @pendulum_agent.py:291][0m 50000 total steps have happened
[32m[20221124 21:22:25 @pendulum_agent.py:281][0m #------------------------ Iteration 1 --------------------------#
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 10.0
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 8.2
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.4
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.2
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.0
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 9.6
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 10.6
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 13.6
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 8.2
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.0
[32m[20221124 21:22:28 @pendulum_agent.py:307][0m Sample time: 3.667067289352417
[32m[20221124 21:22:39 @pendulum_agent.py:312][0m Update time: 10.338197946548462
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:40 @pendulum_agent.py:317][0m Evaluation time: 0.8967838287353516
[32m[20221124 21:22:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 8.58
[32m[20221124 21:22:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:22:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:22:40 @pendulum_agent.py:289][0m Total time: 29.60549807548523
[32m[20221124 21:22:40 @pendulum_agent.py:291][0m 100000 total steps have happened
[32m[20221124 21:22:40 @pendulum_agent.py:281][0m #------------------------ Iteration 2 --------------------------#
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:43 @pendulum_agent.py:307][0m Sample time: 3.320499897003174
[32m[20221124 21:22:53 @pendulum_agent.py:312][0m Update time: 9.787917137145996
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:55 @pendulum_agent.py:317][0m Evaluation time: 1.6933870315551758
[32m[20221124 21:22:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:22:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:22:55 @pendulum_agent.py:289][0m Total time: 44.73661208152771
[32m[20221124 21:22:55 @pendulum_agent.py:291][0m 150000 total steps have happened
[32m[20221124 21:22:55 @pendulum_agent.py:281][0m #------------------------ Iteration 3 --------------------------#
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:59 @pendulum_agent.py:307][0m Sample time: 3.956012010574341
[32m[20221124 21:23:08 @pendulum_agent.py:312][0m Update time: 9.399237155914307
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 8.0
[32m[20221124 21:23:10 @pendulum_agent.py:317][0m Evaluation time: 1.132004976272583
[32m[20221124 21:23:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:23:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:23:10 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:23:10 @pendulum_agent.py:289][0m Total time: 59.51204705238342
[32m[20221124 21:23:10 @pendulum_agent.py:291][0m 200000 total steps have happened
[32m[20221124 21:23:10 @pendulum_agent.py:281][0m #------------------------ Iteration 4 --------------------------#
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:14 @pendulum_agent.py:307][0m Sample time: 4.030349016189575
[32m[20221124 21:23:23 @pendulum_agent.py:312][0m Update time: 9.464911937713623
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:317][0m Evaluation time: 0.6265170574188232
[32m[20221124 21:23:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:23:24 @pendulum_agent.py:289][0m Total time: 73.94265103340149
[32m[20221124 21:23:24 @pendulum_agent.py:291][0m 250000 total steps have happened
[32m[20221124 21:23:24 @pendulum_agent.py:281][0m #------------------------ Iteration 5 --------------------------#
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:29 @pendulum_agent.py:307][0m Sample time: 4.347484827041626
[32m[20221124 21:23:38 @pendulum_agent.py:312][0m Update time: 9.268596887588501
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:39 @pendulum_agent.py:317][0m Evaluation time: 0.7509191036224365
[32m[20221124 21:23:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:23:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:23:39 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:23:39 @pendulum_agent.py:289][0m Total time: 88.58560609817505
[32m[20221124 21:23:39 @pendulum_agent.py:291][0m 300000 total steps have happened
[32m[20221124 21:23:39 @pendulum_agent.py:281][0m #------------------------ Iteration 6 --------------------------#
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:43 @pendulum_agent.py:307][0m Sample time: 3.7762839794158936
[32m[20221124 21:23:52 @pendulum_agent.py:312][0m Update time: 9.632896900177002
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:317][0m Evaluation time: 0.8944182395935059
[32m[20221124 21:23:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:23:54 @pendulum_agent.py:289][0m Total time: 103.17595791816711
[32m[20221124 21:23:54 @pendulum_agent.py:291][0m 350000 total steps have happened
[32m[20221124 21:23:54 @pendulum_agent.py:281][0m #------------------------ Iteration 7 --------------------------#
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:57 @pendulum_agent.py:307][0m Sample time: 3.759889841079712
[32m[20221124 21:24:07 @pendulum_agent.py:312][0m Update time: 9.495968103408813
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:08 @pendulum_agent.py:317][0m Evaluation time: 1.0805740356445312
[32m[20221124 21:24:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:24:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:24:08 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:24:08 @pendulum_agent.py:289][0m Total time: 117.79941296577454
[32m[20221124 21:24:08 @pendulum_agent.py:291][0m 400000 total steps have happened
[32m[20221124 21:24:08 @pendulum_agent.py:281][0m #------------------------ Iteration 8 --------------------------#
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:12 @pendulum_agent.py:307][0m Sample time: 3.9493608474731445
[32m[20221124 21:24:22 @pendulum_agent.py:312][0m Update time: 10.314635038375854
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:24 @pendulum_agent.py:317][0m Evaluation time: 1.130450963973999
[32m[20221124 21:24:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:24:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:24:24 @pendulum_agent.py:289][0m Total time: 133.54208612442017
[32m[20221124 21:24:24 @pendulum_agent.py:291][0m 450000 total steps have happened
[32m[20221124 21:24:24 @pendulum_agent.py:281][0m #------------------------ Iteration 9 --------------------------#
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:28 @pendulum_agent.py:307][0m Sample time: 3.991119146347046
[32m[20221124 21:24:38 @pendulum_agent.py:312][0m Update time: 9.57673192024231
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:317][0m Evaluation time: 0.7411489486694336
[32m[20221124 21:24:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:24:39 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:24:39 @pendulum_agent.py:289][0m Total time: 148.14663696289062
[32m[20221124 21:24:39 @pendulum_agent.py:291][0m 500000 total steps have happened
[32m[20221124 21:24:39 @pendulum_agent.py:281][0m #------------------------ Iteration 10 --------------------------#
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:42 @pendulum_agent.py:307][0m Sample time: 3.6015400886535645
[32m[20221124 21:24:52 @pendulum_agent.py:312][0m Update time: 9.454082727432251
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:53 @pendulum_agent.py:317][0m Evaluation time: 1.0222010612487793
[32m[20221124 21:24:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:24:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:24:53 @pendulum_agent.py:289][0m Total time: 162.54990601539612
[32m[20221124 21:24:53 @pendulum_agent.py:291][0m 550000 total steps have happened
[32m[20221124 21:24:53 @pendulum_agent.py:281][0m #------------------------ Iteration 11 --------------------------#
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:57 @pendulum_agent.py:307][0m Sample time: 4.550530910491943
[32m[20221124 21:25:07 @pendulum_agent.py:312][0m Update time: 9.554733991622925
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:08 @pendulum_agent.py:317][0m Evaluation time: 1.1111979484558105
[32m[20221124 21:25:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:25:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:25:08 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:25:08 @pendulum_agent.py:289][0m Total time: 178.04467797279358
[32m[20221124 21:25:08 @pendulum_agent.py:291][0m 600000 total steps have happened
[32m[20221124 21:25:08 @pendulum_agent.py:281][0m #------------------------ Iteration 12 --------------------------#
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:12 @pendulum_agent.py:307][0m Sample time: 3.3175113201141357
[32m[20221124 21:25:22 @pendulum_agent.py:312][0m Update time: 9.878046989440918
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:23 @pendulum_agent.py:317][0m Evaluation time: 1.1368699073791504
[32m[20221124 21:25:23 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:25:23 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:25:23 @pendulum_agent.py:289][0m Total time: 192.70419716835022
[32m[20221124 21:25:23 @pendulum_agent.py:291][0m 650000 total steps have happened
[32m[20221124 21:25:23 @pendulum_agent.py:281][0m #------------------------ Iteration 13 --------------------------#
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:27 @pendulum_agent.py:307][0m Sample time: 3.664860963821411
[32m[20221124 21:25:37 @pendulum_agent.py:312][0m Update time: 9.964576959609985
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:38 @pendulum_agent.py:317][0m Evaluation time: 1.348435878753662
[32m[20221124 21:25:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:25:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:25:38 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:25:38 @pendulum_agent.py:289][0m Total time: 208.03109288215637
[32m[20221124 21:25:38 @pendulum_agent.py:291][0m 700000 total steps have happened
[32m[20221124 21:25:38 @pendulum_agent.py:281][0m #------------------------ Iteration 14 --------------------------#
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:42 @pendulum_agent.py:307][0m Sample time: 3.758925199508667
[32m[20221124 21:25:51 @pendulum_agent.py:312][0m Update time: 9.300325870513916
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:317][0m Evaluation time: 0.7165210247039795
[32m[20221124 21:25:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:25:52 @pendulum_agent.py:289][0m Total time: 222.09285020828247
[32m[20221124 21:25:52 @pendulum_agent.py:291][0m 750000 total steps have happened
[32m[20221124 21:25:52 @pendulum_agent.py:281][0m #------------------------ Iteration 15 --------------------------#
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 10.8
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 11.0
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.6
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 9.6
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.8
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.8
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.4
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 11.8
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.6
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.0
[32m[20221124 21:25:56 @pendulum_agent.py:307][0m Sample time: 3.857785940170288
[32m[20221124 21:26:06 @pendulum_agent.py:312][0m Update time: 9.402270078659058
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:317][0m Evaluation time: 0.585536003112793
[32m[20221124 21:26:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.74
[32m[20221124 21:26:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:26:07 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:26:07 @pendulum_agent.py:289][0m Total time: 236.2581958770752
[32m[20221124 21:26:07 @pendulum_agent.py:291][0m 800000 total steps have happened
[32m[20221124 21:26:07 @pendulum_agent.py:281][0m #------------------------ Iteration 16 --------------------------#
[32m[20221124 21:26:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.2
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 10.6
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.2
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 13.0
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.8
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.8
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.6
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.6
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.0
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.6
[32m[20221124 21:26:11 @pendulum_agent.py:307][0m Sample time: 4.421933174133301
[32m[20221124 21:26:21 @pendulum_agent.py:312][0m Update time: 10.280722856521606
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:317][0m Evaluation time: 0.6696891784667969
[32m[20221124 21:26:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.04
[32m[20221124 21:26:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:26:22 @pendulum_agent.py:289][0m Total time: 251.91746592521667
[32m[20221124 21:26:22 @pendulum_agent.py:291][0m 850000 total steps have happened
[32m[20221124 21:26:22 @pendulum_agent.py:281][0m #------------------------ Iteration 17 --------------------------#
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:26:27 @pendulum_agent.py:307][0m Sample time: 4.382888078689575
[32m[20221124 21:26:36 @pendulum_agent.py:312][0m Update time: 9.39745283126831
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:26:37 @pendulum_agent.py:317][0m Evaluation time: 0.7907352447509766
[32m[20221124 21:26:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:26:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:26:37 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:26:37 @pendulum_agent.py:289][0m Total time: 266.80646896362305
[32m[20221124 21:26:37 @pendulum_agent.py:291][0m 900000 total steps have happened
[32m[20221124 21:26:37 @pendulum_agent.py:281][0m #------------------------ Iteration 18 --------------------------#
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:26:41 @pendulum_agent.py:307][0m Sample time: 3.8235442638397217
[32m[20221124 21:26:51 @pendulum_agent.py:312][0m Update time: 9.60810899734497
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:26:52 @pendulum_agent.py:317][0m Evaluation time: 1.030914068222046
[32m[20221124 21:26:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:26:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:26:52 @pendulum_agent.py:289][0m Total time: 281.55777502059937
[32m[20221124 21:26:52 @pendulum_agent.py:291][0m 950000 total steps have happened
[32m[20221124 21:26:52 @pendulum_agent.py:281][0m #------------------------ Iteration 19 --------------------------#
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:26:56 @pendulum_agent.py:307][0m Sample time: 3.7137248516082764
[32m[20221124 21:27:05 @pendulum_agent.py:312][0m Update time: 9.720340013504028
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:317][0m Evaluation time: 0.6694061756134033
[32m[20221124 21:27:06 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:27:06 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:27:06 @pendulum_agent.py:289][0m Total time: 295.93836212158203
[32m[20221124 21:27:06 @pendulum_agent.py:291][0m 1000000 total steps have happened
[32m[20221124 21:27:06 @pendulum_agent.py:281][0m #------------------------ Iteration 20 --------------------------#
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:27:10 @pendulum_agent.py:307][0m Sample time: 4.129297971725464
[32m[20221124 21:27:20 @pendulum_agent.py:312][0m Update time: 9.089486122131348
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:27:21 @pendulum_agent.py:317][0m Evaluation time: 1.1732959747314453
[32m[20221124 21:27:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:27:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:27:21 @pendulum_agent.py:289][0m Total time: 310.62915992736816
[32m[20221124 21:27:21 @pendulum_agent.py:291][0m 1050000 total steps have happened
[32m[20221124 21:27:21 @pendulum_agent.py:281][0m #------------------------ Iteration 21 --------------------------#
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:27:26 @pendulum_agent.py:307][0m Sample time: 4.515446901321411
[32m[20221124 21:27:35 @pendulum_agent.py:312][0m Update time: 9.58899998664856
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:27:36 @pendulum_agent.py:317][0m Evaluation time: 0.5710229873657227
[32m[20221124 21:27:36 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:27:36 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:27:36 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:27:36 @pendulum_agent.py:289][0m Total time: 325.5869870185852
[32m[20221124 21:27:36 @pendulum_agent.py:291][0m 1100000 total steps have happened
[32m[20221124 21:27:36 @pendulum_agent.py:281][0m #------------------------ Iteration 22 --------------------------#
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:27:40 @pendulum_agent.py:307][0m Sample time: 3.8567967414855957
[32m[20221124 21:27:49 @pendulum_agent.py:312][0m Update time: 9.587045192718506
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:317][0m Evaluation time: 0.8442208766937256
[32m[20221124 21:27:51 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:27:51 @pendulum_agent.py:289][0m Total time: 340.1868100166321
[32m[20221124 21:27:51 @pendulum_agent.py:291][0m 1150000 total steps have happened
[32m[20221124 21:27:51 @pendulum_agent.py:281][0m #------------------------ Iteration 23 --------------------------#
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:27:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
