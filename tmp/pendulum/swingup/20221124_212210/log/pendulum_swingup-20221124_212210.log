[32m[20221124 21:22:10 @logger.py:105][0m Log file set to ./tmp/pendulum/swingup/20221124_212210/log/pendulum_swingup-20221124_212210.log
[32m[20221124 21:22:10 @pendulum_agent.py:281][0m #------------------------ Iteration 0 --------------------------#
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:14 @pendulum_agent.py:307][0m Sample time: 3.1671769618988037
[32m[20221124 21:22:24 @pendulum_agent.py:312][0m Update time: 10.182775020599365
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:25 @pendulum_agent.py:317][0m Evaluation time: 0.7066848278045654
[32m[20221124 21:22:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:22:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:22:25 @pendulum_agent.py:262][0m [4m[34mCRITICAL[0m Get the best episode reward: 0
[32m[20221124 21:22:25 @pendulum_agent.py:266][0m [4m[34mCRITICAL[0m Saving the best checkpoint with rewards 0.00
[32m[20221124 21:22:25 @pendulum_agent.py:289][0m Total time: 14.412011861801147
[32m[20221124 21:22:25 @pendulum_agent.py:291][0m 50000 total steps have happened
[32m[20221124 21:22:25 @pendulum_agent.py:281][0m #------------------------ Iteration 1 --------------------------#
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 10.0
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 8.2
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.4
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.2
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.0
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 9.6
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 10.6
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 13.6
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 8.2
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.0
[32m[20221124 21:22:28 @pendulum_agent.py:307][0m Sample time: 3.667067289352417
[32m[20221124 21:22:39 @pendulum_agent.py:312][0m Update time: 10.338197946548462
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:40 @pendulum_agent.py:317][0m Evaluation time: 0.8967838287353516
[32m[20221124 21:22:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 8.58
[32m[20221124 21:22:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:22:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:22:40 @pendulum_agent.py:289][0m Total time: 29.60549807548523
[32m[20221124 21:22:40 @pendulum_agent.py:291][0m 100000 total steps have happened
[32m[20221124 21:22:40 @pendulum_agent.py:281][0m #------------------------ Iteration 2 --------------------------#
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:43 @pendulum_agent.py:307][0m Sample time: 3.320499897003174
[32m[20221124 21:22:53 @pendulum_agent.py:312][0m Update time: 9.787917137145996
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:55 @pendulum_agent.py:317][0m Evaluation time: 1.6933870315551758
[32m[20221124 21:22:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:22:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:22:55 @pendulum_agent.py:289][0m Total time: 44.73661208152771
[32m[20221124 21:22:55 @pendulum_agent.py:291][0m 150000 total steps have happened
[32m[20221124 21:22:55 @pendulum_agent.py:281][0m #------------------------ Iteration 3 --------------------------#
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:59 @pendulum_agent.py:307][0m Sample time: 3.956012010574341
[32m[20221124 21:23:08 @pendulum_agent.py:312][0m Update time: 9.399237155914307
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 8.0
[32m[20221124 21:23:10 @pendulum_agent.py:317][0m Evaluation time: 1.132004976272583
[32m[20221124 21:23:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:23:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:23:10 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:23:10 @pendulum_agent.py:289][0m Total time: 59.51204705238342
[32m[20221124 21:23:10 @pendulum_agent.py:291][0m 200000 total steps have happened
[32m[20221124 21:23:10 @pendulum_agent.py:281][0m #------------------------ Iteration 4 --------------------------#
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:14 @pendulum_agent.py:307][0m Sample time: 4.030349016189575
[32m[20221124 21:23:23 @pendulum_agent.py:312][0m Update time: 9.464911937713623
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:317][0m Evaluation time: 0.6265170574188232
[32m[20221124 21:23:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:23:24 @pendulum_agent.py:289][0m Total time: 73.94265103340149
[32m[20221124 21:23:24 @pendulum_agent.py:291][0m 250000 total steps have happened
[32m[20221124 21:23:24 @pendulum_agent.py:281][0m #------------------------ Iteration 5 --------------------------#
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:29 @pendulum_agent.py:307][0m Sample time: 4.347484827041626
[32m[20221124 21:23:38 @pendulum_agent.py:312][0m Update time: 9.268596887588501
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:39 @pendulum_agent.py:317][0m Evaluation time: 0.7509191036224365
[32m[20221124 21:23:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:23:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:23:39 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:23:39 @pendulum_agent.py:289][0m Total time: 88.58560609817505
[32m[20221124 21:23:39 @pendulum_agent.py:291][0m 300000 total steps have happened
[32m[20221124 21:23:39 @pendulum_agent.py:281][0m #------------------------ Iteration 6 --------------------------#
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:43 @pendulum_agent.py:307][0m Sample time: 3.7762839794158936
[32m[20221124 21:23:52 @pendulum_agent.py:312][0m Update time: 9.632896900177002
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:317][0m Evaluation time: 0.8944182395935059
[32m[20221124 21:23:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:23:54 @pendulum_agent.py:289][0m Total time: 103.17595791816711
[32m[20221124 21:23:54 @pendulum_agent.py:291][0m 350000 total steps have happened
[32m[20221124 21:23:54 @pendulum_agent.py:281][0m #------------------------ Iteration 7 --------------------------#
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:57 @pendulum_agent.py:307][0m Sample time: 3.759889841079712
[32m[20221124 21:24:07 @pendulum_agent.py:312][0m Update time: 9.495968103408813
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:08 @pendulum_agent.py:317][0m Evaluation time: 1.0805740356445312
[32m[20221124 21:24:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:24:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:24:08 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:24:08 @pendulum_agent.py:289][0m Total time: 117.79941296577454
[32m[20221124 21:24:08 @pendulum_agent.py:291][0m 400000 total steps have happened
[32m[20221124 21:24:08 @pendulum_agent.py:281][0m #------------------------ Iteration 8 --------------------------#
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:12 @pendulum_agent.py:307][0m Sample time: 3.9493608474731445
[32m[20221124 21:24:22 @pendulum_agent.py:312][0m Update time: 10.314635038375854
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:24 @pendulum_agent.py:317][0m Evaluation time: 1.130450963973999
[32m[20221124 21:24:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:24:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:24:24 @pendulum_agent.py:289][0m Total time: 133.54208612442017
[32m[20221124 21:24:24 @pendulum_agent.py:291][0m 450000 total steps have happened
[32m[20221124 21:24:24 @pendulum_agent.py:281][0m #------------------------ Iteration 9 --------------------------#
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:28 @pendulum_agent.py:307][0m Sample time: 3.991119146347046
[32m[20221124 21:24:38 @pendulum_agent.py:312][0m Update time: 9.57673192024231
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:317][0m Evaluation time: 0.7411489486694336
[32m[20221124 21:24:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:24:39 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:24:39 @pendulum_agent.py:289][0m Total time: 148.14663696289062
[32m[20221124 21:24:39 @pendulum_agent.py:291][0m 500000 total steps have happened
[32m[20221124 21:24:39 @pendulum_agent.py:281][0m #------------------------ Iteration 10 --------------------------#
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:42 @pendulum_agent.py:307][0m Sample time: 3.6015400886535645
[32m[20221124 21:24:52 @pendulum_agent.py:312][0m Update time: 9.454082727432251
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:53 @pendulum_agent.py:317][0m Evaluation time: 1.0222010612487793
[32m[20221124 21:24:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:24:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:24:53 @pendulum_agent.py:289][0m Total time: 162.54990601539612
[32m[20221124 21:24:53 @pendulum_agent.py:291][0m 550000 total steps have happened
[32m[20221124 21:24:53 @pendulum_agent.py:281][0m #------------------------ Iteration 11 --------------------------#
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:57 @pendulum_agent.py:307][0m Sample time: 4.550530910491943
[32m[20221124 21:25:07 @pendulum_agent.py:312][0m Update time: 9.554733991622925
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:08 @pendulum_agent.py:317][0m Evaluation time: 1.1111979484558105
[32m[20221124 21:25:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:25:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:25:08 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:25:08 @pendulum_agent.py:289][0m Total time: 178.04467797279358
[32m[20221124 21:25:08 @pendulum_agent.py:291][0m 600000 total steps have happened
[32m[20221124 21:25:08 @pendulum_agent.py:281][0m #------------------------ Iteration 12 --------------------------#
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:12 @pendulum_agent.py:307][0m Sample time: 3.3175113201141357
[32m[20221124 21:25:22 @pendulum_agent.py:312][0m Update time: 9.878046989440918
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:23 @pendulum_agent.py:317][0m Evaluation time: 1.1368699073791504
[32m[20221124 21:25:23 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:25:23 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:25:23 @pendulum_agent.py:289][0m Total time: 192.70419716835022
[32m[20221124 21:25:23 @pendulum_agent.py:291][0m 650000 total steps have happened
[32m[20221124 21:25:23 @pendulum_agent.py:281][0m #------------------------ Iteration 13 --------------------------#
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:27 @pendulum_agent.py:307][0m Sample time: 3.664860963821411
[32m[20221124 21:25:37 @pendulum_agent.py:312][0m Update time: 9.964576959609985
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:38 @pendulum_agent.py:317][0m Evaluation time: 1.348435878753662
[32m[20221124 21:25:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:25:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:25:38 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:25:38 @pendulum_agent.py:289][0m Total time: 208.03109288215637
[32m[20221124 21:25:38 @pendulum_agent.py:291][0m 700000 total steps have happened
[32m[20221124 21:25:38 @pendulum_agent.py:281][0m #------------------------ Iteration 14 --------------------------#
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:42 @pendulum_agent.py:307][0m Sample time: 3.758925199508667
[32m[20221124 21:25:51 @pendulum_agent.py:312][0m Update time: 9.300325870513916
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:317][0m Evaluation time: 0.7165210247039795
[32m[20221124 21:25:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:25:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:25:52 @pendulum_agent.py:289][0m Total time: 222.09285020828247
[32m[20221124 21:25:52 @pendulum_agent.py:291][0m 750000 total steps have happened
[32m[20221124 21:25:52 @pendulum_agent.py:281][0m #------------------------ Iteration 15 --------------------------#
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 10.8
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 11.0
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.6
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 9.6
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.8
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.8
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.4
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 11.8
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.6
[32m[20221124 21:25:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.0
[32m[20221124 21:25:56 @pendulum_agent.py:307][0m Sample time: 3.857785940170288
[32m[20221124 21:26:06 @pendulum_agent.py:312][0m Update time: 9.402270078659058
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:26:06 @pendulum_agent.py:317][0m Evaluation time: 0.585536003112793
[32m[20221124 21:26:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.74
[32m[20221124 21:26:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:26:07 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:26:07 @pendulum_agent.py:289][0m Total time: 236.2581958770752
[32m[20221124 21:26:07 @pendulum_agent.py:291][0m 800000 total steps have happened
[32m[20221124 21:26:07 @pendulum_agent.py:281][0m #------------------------ Iteration 16 --------------------------#
[32m[20221124 21:26:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.2
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 10.6
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.2
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 13.0
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.8
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.8
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.6
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.6
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.0
[32m[20221124 21:26:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.6
[32m[20221124 21:26:11 @pendulum_agent.py:307][0m Sample time: 4.421933174133301
[32m[20221124 21:26:21 @pendulum_agent.py:312][0m Update time: 10.280722856521606
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:26:22 @pendulum_agent.py:317][0m Evaluation time: 0.6696891784667969
[32m[20221124 21:26:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.04
[32m[20221124 21:26:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:26:22 @pendulum_agent.py:289][0m Total time: 251.91746592521667
[32m[20221124 21:26:22 @pendulum_agent.py:291][0m 850000 total steps have happened
[32m[20221124 21:26:22 @pendulum_agent.py:281][0m #------------------------ Iteration 17 --------------------------#
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:26:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:26:27 @pendulum_agent.py:307][0m Sample time: 4.382888078689575
[32m[20221124 21:26:36 @pendulum_agent.py:312][0m Update time: 9.39745283126831
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:26:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:26:37 @pendulum_agent.py:317][0m Evaluation time: 0.7907352447509766
[32m[20221124 21:26:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:26:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:26:37 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:26:37 @pendulum_agent.py:289][0m Total time: 266.80646896362305
[32m[20221124 21:26:37 @pendulum_agent.py:291][0m 900000 total steps have happened
[32m[20221124 21:26:37 @pendulum_agent.py:281][0m #------------------------ Iteration 18 --------------------------#
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:26:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:26:41 @pendulum_agent.py:307][0m Sample time: 3.8235442638397217
[32m[20221124 21:26:51 @pendulum_agent.py:312][0m Update time: 9.60810899734497
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:26:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:26:52 @pendulum_agent.py:317][0m Evaluation time: 1.030914068222046
[32m[20221124 21:26:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:26:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:26:52 @pendulum_agent.py:289][0m Total time: 281.55777502059937
[32m[20221124 21:26:52 @pendulum_agent.py:291][0m 950000 total steps have happened
[32m[20221124 21:26:52 @pendulum_agent.py:281][0m #------------------------ Iteration 19 --------------------------#
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:26:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:26:56 @pendulum_agent.py:307][0m Sample time: 3.7137248516082764
[32m[20221124 21:27:05 @pendulum_agent.py:312][0m Update time: 9.720340013504028
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:317][0m Evaluation time: 0.6694061756134033
[32m[20221124 21:27:06 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:27:06 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:27:06 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:27:06 @pendulum_agent.py:289][0m Total time: 295.93836212158203
[32m[20221124 21:27:06 @pendulum_agent.py:291][0m 1000000 total steps have happened
[32m[20221124 21:27:06 @pendulum_agent.py:281][0m #------------------------ Iteration 20 --------------------------#
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:27:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:27:10 @pendulum_agent.py:307][0m Sample time: 4.129297971725464
[32m[20221124 21:27:20 @pendulum_agent.py:312][0m Update time: 9.089486122131348
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:27:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:27:21 @pendulum_agent.py:317][0m Evaluation time: 1.1732959747314453
[32m[20221124 21:27:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:27:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:27:21 @pendulum_agent.py:289][0m Total time: 310.62915992736816
[32m[20221124 21:27:21 @pendulum_agent.py:291][0m 1050000 total steps have happened
[32m[20221124 21:27:21 @pendulum_agent.py:281][0m #------------------------ Iteration 21 --------------------------#
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:27:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:27:26 @pendulum_agent.py:307][0m Sample time: 4.515446901321411
[32m[20221124 21:27:35 @pendulum_agent.py:312][0m Update time: 9.58899998664856
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:27:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:27:36 @pendulum_agent.py:317][0m Evaluation time: 0.5710229873657227
[32m[20221124 21:27:36 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:27:36 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:27:36 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:27:36 @pendulum_agent.py:289][0m Total time: 325.5869870185852
[32m[20221124 21:27:36 @pendulum_agent.py:291][0m 1100000 total steps have happened
[32m[20221124 21:27:36 @pendulum_agent.py:281][0m #------------------------ Iteration 22 --------------------------#
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:27:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:27:40 @pendulum_agent.py:307][0m Sample time: 3.8567967414855957
[32m[20221124 21:27:49 @pendulum_agent.py:312][0m Update time: 9.587045192718506
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:27:50 @pendulum_agent.py:317][0m Evaluation time: 0.8442208766937256
[32m[20221124 21:27:51 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:27:51 @pendulum_agent.py:289][0m Total time: 340.1868100166321
[32m[20221124 21:27:51 @pendulum_agent.py:291][0m 1150000 total steps have happened
[32m[20221124 21:27:51 @pendulum_agent.py:281][0m #------------------------ Iteration 23 --------------------------#
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:27:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:27:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:27:54 @pendulum_agent.py:307][0m Sample time: 3.3408188819885254
[32m[20221124 21:28:04 @pendulum_agent.py:312][0m Update time: 9.765578031539917
[32m[20221124 21:28:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:28:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:28:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:28:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:28:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:28:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:28:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:28:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:28:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:28:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:28:05 @pendulum_agent.py:317][0m Evaluation time: 1.2202491760253906
[32m[20221124 21:28:05 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:28:05 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:28:05 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:28:05 @pendulum_agent.py:289][0m Total time: 354.77693700790405
[32m[20221124 21:28:05 @pendulum_agent.py:291][0m 1200000 total steps have happened
[32m[20221124 21:28:05 @pendulum_agent.py:281][0m #------------------------ Iteration 24 --------------------------#
[32m[20221124 21:28:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:28:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:28:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:28:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:28:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:28:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:28:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:28:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:28:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:28:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:28:08 @pendulum_agent.py:307][0m Sample time: 3.280567169189453
[32m[20221124 21:28:18 @pendulum_agent.py:312][0m Update time: 9.534197807312012
[32m[20221124 21:28:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:28:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:28:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:28:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:28:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:28:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:28:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:28:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:28:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:28:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:28:19 @pendulum_agent.py:317][0m Evaluation time: 1.0602238178253174
[32m[20221124 21:28:19 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:28:19 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:28:19 @pendulum_agent.py:289][0m Total time: 368.9332981109619
[32m[20221124 21:28:19 @pendulum_agent.py:291][0m 1250000 total steps have happened
[32m[20221124 21:28:19 @pendulum_agent.py:281][0m #------------------------ Iteration 25 --------------------------#
[32m[20221124 21:28:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.0
[32m[20221124 21:28:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.4
[32m[20221124 21:28:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 10.4
[32m[20221124 21:28:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.8
[32m[20221124 21:28:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.6
[32m[20221124 21:28:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.8
[32m[20221124 21:28:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.2
[32m[20221124 21:28:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.8
[32m[20221124 21:28:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.8
[32m[20221124 21:28:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.6
[32m[20221124 21:28:23 @pendulum_agent.py:307][0m Sample time: 3.224950075149536
[32m[20221124 21:28:32 @pendulum_agent.py:312][0m Update time: 9.873448133468628
[32m[20221124 21:28:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:28:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:28:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:28:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:28:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:28:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:28:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:28:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:28:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:28:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:28:33 @pendulum_agent.py:317][0m Evaluation time: 1.056750774383545
[32m[20221124 21:28:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.24
[32m[20221124 21:28:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:28:34 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:28:34 @pendulum_agent.py:289][0m Total time: 383.37384605407715
[32m[20221124 21:28:34 @pendulum_agent.py:291][0m 1300000 total steps have happened
[32m[20221124 21:28:34 @pendulum_agent.py:281][0m #------------------------ Iteration 26 --------------------------#
[32m[20221124 21:28:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.4
[32m[20221124 21:28:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.4
[32m[20221124 21:28:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.4
[32m[20221124 21:28:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 9.4
[32m[20221124 21:28:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.4
[32m[20221124 21:28:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.2
[32m[20221124 21:28:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.0
[32m[20221124 21:28:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.6
[32m[20221124 21:28:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.2
[32m[20221124 21:28:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.0
[32m[20221124 21:28:37 @pendulum_agent.py:307][0m Sample time: 3.697685956954956
[32m[20221124 21:28:47 @pendulum_agent.py:312][0m Update time: 9.396236181259155
[32m[20221124 21:28:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:28:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:28:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:28:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:28:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:28:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:28:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:28:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:28:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:28:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:28:48 @pendulum_agent.py:317][0m Evaluation time: 0.747053861618042
[32m[20221124 21:28:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.8
[32m[20221124 21:28:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:28:48 @pendulum_agent.py:289][0m Total time: 397.4812881946564
[32m[20221124 21:28:48 @pendulum_agent.py:291][0m 1350000 total steps have happened
[32m[20221124 21:28:48 @pendulum_agent.py:281][0m #------------------------ Iteration 27 --------------------------#
[32m[20221124 21:28:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:28:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:28:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:28:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:28:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:28:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:28:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:28:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:28:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:28:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:28:52 @pendulum_agent.py:307][0m Sample time: 3.7757251262664795
[32m[20221124 21:29:01 @pendulum_agent.py:312][0m Update time: 9.506715059280396
[32m[20221124 21:29:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:29:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:29:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:29:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:29:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:29:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:29:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:29:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:29:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:29:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:29:02 @pendulum_agent.py:317][0m Evaluation time: 0.5916528701782227
[32m[20221124 21:29:02 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:29:02 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:29:02 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:29:02 @pendulum_agent.py:289][0m Total time: 411.6653389930725
[32m[20221124 21:29:02 @pendulum_agent.py:291][0m 1400000 total steps have happened
[32m[20221124 21:29:02 @pendulum_agent.py:281][0m #------------------------ Iteration 28 --------------------------#
[32m[20221124 21:29:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:29:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:29:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:29:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:29:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:29:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:29:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:29:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:29:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:29:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:29:06 @pendulum_agent.py:307][0m Sample time: 3.820484161376953
[32m[20221124 21:29:16 @pendulum_agent.py:312][0m Update time: 9.877405881881714
[32m[20221124 21:29:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:29:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:29:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:29:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:29:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:29:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:29:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:29:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:29:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:29:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:29:16 @pendulum_agent.py:317][0m Evaluation time: 0.6315782070159912
[32m[20221124 21:29:17 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:29:17 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:29:17 @pendulum_agent.py:289][0m Total time: 426.31037998199463
[32m[20221124 21:29:17 @pendulum_agent.py:291][0m 1450000 total steps have happened
[32m[20221124 21:29:17 @pendulum_agent.py:281][0m #------------------------ Iteration 29 --------------------------#
[32m[20221124 21:29:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:29:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:29:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:29:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:29:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:29:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:29:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:29:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:29:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:29:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:29:21 @pendulum_agent.py:307][0m Sample time: 3.894568920135498
[32m[20221124 21:29:31 @pendulum_agent.py:312][0m Update time: 10.14386773109436
[32m[20221124 21:29:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:29:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:29:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:29:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:29:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:29:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:29:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:29:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:29:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:29:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:29:31 @pendulum_agent.py:317][0m Evaluation time: 0.6206490993499756
[32m[20221124 21:29:32 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:29:32 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:29:32 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:29:32 @pendulum_agent.py:289][0m Total time: 441.29428005218506
[32m[20221124 21:29:32 @pendulum_agent.py:291][0m 1500000 total steps have happened
[32m[20221124 21:29:32 @pendulum_agent.py:281][0m #------------------------ Iteration 30 --------------------------#
[32m[20221124 21:29:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:29:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:29:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:29:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:29:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:29:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:29:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:29:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:29:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:29:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:29:36 @pendulum_agent.py:307][0m Sample time: 3.898723840713501
[32m[20221124 21:29:45 @pendulum_agent.py:312][0m Update time: 9.424090147018433
[32m[20221124 21:29:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:29:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:29:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:29:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:29:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:29:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:29:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:29:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:29:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:29:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:29:46 @pendulum_agent.py:317][0m Evaluation time: 0.586245059967041
[32m[20221124 21:29:46 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:29:46 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:29:46 @pendulum_agent.py:289][0m Total time: 455.4994878768921
[32m[20221124 21:29:46 @pendulum_agent.py:291][0m 1550000 total steps have happened
[32m[20221124 21:29:46 @pendulum_agent.py:281][0m #------------------------ Iteration 31 --------------------------#
[32m[20221124 21:29:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:29:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:29:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:29:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:29:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:29:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:29:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:29:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:29:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:29:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:29:50 @pendulum_agent.py:307][0m Sample time: 3.780207872390747
[32m[20221124 21:29:59 @pendulum_agent.py:312][0m Update time: 9.131843090057373
[32m[20221124 21:29:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:29:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:29:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:29:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:29:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:29:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:29:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:29:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:29:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:29:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:30:00 @pendulum_agent.py:317][0m Evaluation time: 0.6960608959197998
[32m[20221124 21:30:00 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:30:00 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:30:00 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:30:00 @pendulum_agent.py:289][0m Total time: 469.38794684410095
[32m[20221124 21:30:00 @pendulum_agent.py:291][0m 1600000 total steps have happened
[32m[20221124 21:30:00 @pendulum_agent.py:281][0m #------------------------ Iteration 32 --------------------------#
[32m[20221124 21:30:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:30:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:30:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:30:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:30:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:30:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:30:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:30:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:30:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:30:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:30:03 @pendulum_agent.py:307][0m Sample time: 3.5498650074005127
[32m[20221124 21:30:13 @pendulum_agent.py:312][0m Update time: 9.764956951141357
[32m[20221124 21:30:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:30:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:30:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:30:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:30:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:30:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:30:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:30:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:30:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:30:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:30:14 @pendulum_agent.py:317][0m Evaluation time: 0.852121114730835
[32m[20221124 21:30:14 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:30:14 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:30:14 @pendulum_agent.py:289][0m Total time: 483.8256721496582
[32m[20221124 21:30:14 @pendulum_agent.py:291][0m 1650000 total steps have happened
[32m[20221124 21:30:14 @pendulum_agent.py:281][0m #------------------------ Iteration 33 --------------------------#
[32m[20221124 21:30:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.8
[32m[20221124 21:30:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.0
[32m[20221124 21:30:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.0
[32m[20221124 21:30:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.8
[32m[20221124 21:30:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.8
[32m[20221124 21:30:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.8
[32m[20221124 21:30:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.2
[32m[20221124 21:30:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.0
[32m[20221124 21:30:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.6
[32m[20221124 21:30:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.6
[32m[20221124 21:30:18 @pendulum_agent.py:307][0m Sample time: 3.378756046295166
[32m[20221124 21:30:28 @pendulum_agent.py:312][0m Update time: 10.664669036865234
[32m[20221124 21:30:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:30:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:30:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:30:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:30:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:30:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:30:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:30:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:30:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:30:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:30:29 @pendulum_agent.py:317][0m Evaluation time: 1.1571929454803467
[32m[20221124 21:30:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.86
[32m[20221124 21:30:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:30:30 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:30:30 @pendulum_agent.py:289][0m Total time: 499.31257796287537
[32m[20221124 21:30:30 @pendulum_agent.py:291][0m 1700000 total steps have happened
[32m[20221124 21:30:30 @pendulum_agent.py:281][0m #------------------------ Iteration 34 --------------------------#
[32m[20221124 21:30:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:30:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:30:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:30:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:30:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:30:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:30:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:30:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:30:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:30:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:30:33 @pendulum_agent.py:307][0m Sample time: 3.356398820877075
[32m[20221124 21:30:43 @pendulum_agent.py:312][0m Update time: 9.789437294006348
[32m[20221124 21:30:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:30:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:30:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:30:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:30:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:30:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:30:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:30:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:30:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:30:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:30:44 @pendulum_agent.py:317][0m Evaluation time: 1.040663719177246
[32m[20221124 21:30:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:30:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:30:44 @pendulum_agent.py:289][0m Total time: 513.783399105072
[32m[20221124 21:30:44 @pendulum_agent.py:291][0m 1750000 total steps have happened
[32m[20221124 21:30:44 @pendulum_agent.py:281][0m #------------------------ Iteration 35 --------------------------#
[32m[20221124 21:30:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:30:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:30:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:30:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:30:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:30:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:30:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:30:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:30:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:30:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:30:48 @pendulum_agent.py:307][0m Sample time: 3.7886500358581543
[32m[20221124 21:30:57 @pendulum_agent.py:312][0m Update time: 8.92848801612854
[32m[20221124 21:30:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:30:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:30:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:30:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:30:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:30:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:30:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:30:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:30:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:30:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:30:58 @pendulum_agent.py:317][0m Evaluation time: 0.7211110591888428
[32m[20221124 21:30:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:30:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:30:58 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:30:58 @pendulum_agent.py:289][0m Total time: 527.4961578845978
[32m[20221124 21:30:58 @pendulum_agent.py:291][0m 1800000 total steps have happened
[32m[20221124 21:30:58 @pendulum_agent.py:281][0m #------------------------ Iteration 36 --------------------------#
[32m[20221124 21:30:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.8
[32m[20221124 21:30:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.8
[32m[20221124 21:30:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.6
[32m[20221124 21:30:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1.0
[32m[20221124 21:30:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.8
[32m[20221124 21:30:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.6
[32m[20221124 21:30:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.6
[32m[20221124 21:30:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.6
[32m[20221124 21:30:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.6
[32m[20221124 21:30:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.8
[32m[20221124 21:31:02 @pendulum_agent.py:307][0m Sample time: 3.6579091548919678
[32m[20221124 21:31:12 @pendulum_agent.py:312][0m Update time: 10.177146911621094
[32m[20221124 21:31:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:31:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:31:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:31:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:31:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:31:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:31:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:31:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:31:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:31:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:31:13 @pendulum_agent.py:317][0m Evaluation time: 0.9764721393585205
[32m[20221124 21:31:13 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.72
[32m[20221124 21:31:13 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:31:13 @pendulum_agent.py:289][0m Total time: 542.5876178741455
[32m[20221124 21:31:13 @pendulum_agent.py:291][0m 1850000 total steps have happened
[32m[20221124 21:31:13 @pendulum_agent.py:281][0m #------------------------ Iteration 37 --------------------------#
[32m[20221124 21:31:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:31:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:31:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:31:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:31:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:31:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:31:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:31:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:31:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:31:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:31:17 @pendulum_agent.py:307][0m Sample time: 3.901870012283325
[32m[20221124 21:31:26 @pendulum_agent.py:312][0m Update time: 9.536020040512085
[32m[20221124 21:31:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:31:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:31:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:31:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:31:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:31:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:31:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:31:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:31:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:31:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:31:27 @pendulum_agent.py:317][0m Evaluation time: 0.5734708309173584
[32m[20221124 21:31:27 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:31:27 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:31:27 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:31:27 @pendulum_agent.py:289][0m Total time: 556.855544090271
[32m[20221124 21:31:27 @pendulum_agent.py:291][0m 1900000 total steps have happened
[32m[20221124 21:31:27 @pendulum_agent.py:281][0m #------------------------ Iteration 38 --------------------------#
[32m[20221124 21:31:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:31:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:31:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:31:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:31:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:31:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:31:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:31:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:31:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:31:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:31:31 @pendulum_agent.py:307][0m Sample time: 3.6580989360809326
[32m[20221124 21:31:40 @pendulum_agent.py:312][0m Update time: 9.055569171905518
[32m[20221124 21:31:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 18.0
[32m[20221124 21:31:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 18.0
[32m[20221124 21:31:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 18.0
[32m[20221124 21:31:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 18.0
[32m[20221124 21:31:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 18.0
[32m[20221124 21:31:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 18.0
[32m[20221124 21:31:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 18.0
[32m[20221124 21:31:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 18.0
[32m[20221124 21:31:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 18.0
[32m[20221124 21:31:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 18.0
[32m[20221124 21:31:41 @pendulum_agent.py:317][0m Evaluation time: 0.8317828178405762
[32m[20221124 21:31:41 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:31:41 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:31:41 @pendulum_agent.py:289][0m Total time: 570.6846690177917
[32m[20221124 21:31:41 @pendulum_agent.py:291][0m 1950000 total steps have happened
[32m[20221124 21:31:41 @pendulum_agent.py:281][0m #------------------------ Iteration 39 --------------------------#
[32m[20221124 21:31:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:31:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:31:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:31:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:31:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:31:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:31:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:31:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:31:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:31:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:31:44 @pendulum_agent.py:307][0m Sample time: 3.3029723167419434
[32m[20221124 21:31:54 @pendulum_agent.py:312][0m Update time: 9.782249927520752
[32m[20221124 21:31:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:31:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:31:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:31:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:31:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:31:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:31:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:31:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:31:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:31:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:31:55 @pendulum_agent.py:317][0m Evaluation time: 0.9901039600372314
[32m[20221124 21:31:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:31:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:31:55 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:31:55 @pendulum_agent.py:289][0m Total time: 585.0478990077972
[32m[20221124 21:31:55 @pendulum_agent.py:291][0m 2000000 total steps have happened
[32m[20221124 21:31:55 @pendulum_agent.py:281][0m #------------------------ Iteration 40 --------------------------#
[32m[20221124 21:31:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:31:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:31:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:31:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:31:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:31:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:31:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:31:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:31:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:31:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:31:59 @pendulum_agent.py:307][0m Sample time: 3.688840866088867
[32m[20221124 21:32:09 @pendulum_agent.py:312][0m Update time: 10.19024395942688
[32m[20221124 21:32:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:32:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:32:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:32:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:32:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:32:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:32:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:32:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:32:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:32:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:32:10 @pendulum_agent.py:317][0m Evaluation time: 0.9801802635192871
[32m[20221124 21:32:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:32:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:32:11 @pendulum_agent.py:289][0m Total time: 600.1999621391296
[32m[20221124 21:32:11 @pendulum_agent.py:291][0m 2050000 total steps have happened
[32m[20221124 21:32:11 @pendulum_agent.py:281][0m #------------------------ Iteration 41 --------------------------#
[32m[20221124 21:32:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:32:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:32:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:32:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:32:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:32:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:32:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:32:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:32:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:32:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:32:14 @pendulum_agent.py:307][0m Sample time: 3.795872926712036
[32m[20221124 21:32:23 @pendulum_agent.py:312][0m Update time: 9.05089020729065
[32m[20221124 21:32:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:32:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:32:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:32:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:32:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:32:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:32:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:32:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:32:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:32:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:32:24 @pendulum_agent.py:317][0m Evaluation time: 0.7214469909667969
[32m[20221124 21:32:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:32:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:32:24 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:32:24 @pendulum_agent.py:289][0m Total time: 614.0406670570374
[32m[20221124 21:32:24 @pendulum_agent.py:291][0m 2100000 total steps have happened
[32m[20221124 21:32:24 @pendulum_agent.py:281][0m #------------------------ Iteration 42 --------------------------#
[32m[20221124 21:32:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:32:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:32:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:32:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:32:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:32:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:32:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:32:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:32:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:32:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:32:28 @pendulum_agent.py:307][0m Sample time: 3.6356518268585205
[32m[20221124 21:32:37 @pendulum_agent.py:312][0m Update time: 9.260179042816162
[32m[20221124 21:32:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:32:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:32:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:32:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:32:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:32:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:32:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:32:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:32:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:32:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:32:38 @pendulum_agent.py:317][0m Evaluation time: 0.9772231578826904
[32m[20221124 21:32:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:32:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:32:39 @pendulum_agent.py:289][0m Total time: 628.2073130607605
[32m[20221124 21:32:39 @pendulum_agent.py:291][0m 2150000 total steps have happened
[32m[20221124 21:32:39 @pendulum_agent.py:281][0m #------------------------ Iteration 43 --------------------------#
[32m[20221124 21:32:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:32:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:32:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:32:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:32:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:32:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:32:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:32:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:32:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:32:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:32:42 @pendulum_agent.py:307][0m Sample time: 3.7167179584503174
[32m[20221124 21:32:51 @pendulum_agent.py:312][0m Update time: 9.104412078857422
[32m[20221124 21:32:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:32:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:32:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:32:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:32:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:32:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:32:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:32:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:32:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:32:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:32:52 @pendulum_agent.py:317][0m Evaluation time: 0.6997790336608887
[32m[20221124 21:32:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:32:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:32:52 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:32:52 @pendulum_agent.py:289][0m Total time: 641.9925270080566
[32m[20221124 21:32:52 @pendulum_agent.py:291][0m 2200000 total steps have happened
[32m[20221124 21:32:52 @pendulum_agent.py:281][0m #------------------------ Iteration 44 --------------------------#
[32m[20221124 21:32:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:32:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:32:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:32:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:32:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:32:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:32:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:32:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:32:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:32:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:32:56 @pendulum_agent.py:307][0m Sample time: 3.5168230533599854
[32m[20221124 21:33:05 @pendulum_agent.py:312][0m Update time: 9.449268817901611
[32m[20221124 21:33:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:33:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:33:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:33:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:33:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:33:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:33:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:33:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:33:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:33:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:33:06 @pendulum_agent.py:317][0m Evaluation time: 0.7189891338348389
[32m[20221124 21:33:06 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:33:06 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:33:06 @pendulum_agent.py:289][0m Total time: 655.9449779987335
[32m[20221124 21:33:06 @pendulum_agent.py:291][0m 2250000 total steps have happened
[32m[20221124 21:33:06 @pendulum_agent.py:281][0m #------------------------ Iteration 45 --------------------------#
[32m[20221124 21:33:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:33:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:33:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:33:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:33:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:33:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:33:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:33:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:33:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:33:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:33:10 @pendulum_agent.py:307][0m Sample time: 3.5732131004333496
[32m[20221124 21:33:19 @pendulum_agent.py:312][0m Update time: 9.179502010345459
[32m[20221124 21:33:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:33:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:33:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:33:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:33:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:33:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:33:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:33:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:33:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:33:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:33:20 @pendulum_agent.py:317][0m Evaluation time: 0.692314863204956
[32m[20221124 21:33:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:33:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:33:20 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:33:20 @pendulum_agent.py:289][0m Total time: 669.6639521121979
[32m[20221124 21:33:20 @pendulum_agent.py:291][0m 2300000 total steps have happened
[32m[20221124 21:33:20 @pendulum_agent.py:281][0m #------------------------ Iteration 46 --------------------------#
[32m[20221124 21:33:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:33:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:33:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:33:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:33:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:33:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:33:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:33:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:33:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:33:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:33:24 @pendulum_agent.py:307][0m Sample time: 3.7671101093292236
[32m[20221124 21:33:33 @pendulum_agent.py:312][0m Update time: 9.527987003326416
[32m[20221124 21:33:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 22.0
[32m[20221124 21:33:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 22.0
[32m[20221124 21:33:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 22.0
[32m[20221124 21:33:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 22.0
[32m[20221124 21:33:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 22.0
[32m[20221124 21:33:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 22.0
[32m[20221124 21:33:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 22.0
[32m[20221124 21:33:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 22.0
[32m[20221124 21:33:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 22.0
[32m[20221124 21:33:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 22.0
[32m[20221124 21:33:34 @pendulum_agent.py:317][0m Evaluation time: 0.5785009860992432
[32m[20221124 21:33:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:33:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:33:34 @pendulum_agent.py:289][0m Total time: 683.838583946228
[32m[20221124 21:33:34 @pendulum_agent.py:291][0m 2350000 total steps have happened
[32m[20221124 21:33:34 @pendulum_agent.py:281][0m #------------------------ Iteration 47 --------------------------#
[32m[20221124 21:33:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:33:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:33:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:33:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:33:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:33:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:33:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:33:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:33:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:33:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:33:38 @pendulum_agent.py:307][0m Sample time: 3.645253896713257
[32m[20221124 21:33:47 @pendulum_agent.py:312][0m Update time: 9.06046986579895
[32m[20221124 21:33:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:33:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:33:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:33:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:33:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:33:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:33:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:33:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:33:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:33:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:33:48 @pendulum_agent.py:317][0m Evaluation time: 0.8183140754699707
[32m[20221124 21:33:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:33:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:33:48 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:33:48 @pendulum_agent.py:289][0m Total time: 697.6400120258331
[32m[20221124 21:33:48 @pendulum_agent.py:291][0m 2400000 total steps have happened
[32m[20221124 21:33:48 @pendulum_agent.py:281][0m #------------------------ Iteration 48 --------------------------#
[32m[20221124 21:33:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.4
[32m[20221124 21:33:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.0
[32m[20221124 21:33:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.8
[32m[20221124 21:33:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.4
[32m[20221124 21:33:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.2
[32m[20221124 21:33:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.6
[32m[20221124 21:33:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.2
[32m[20221124 21:33:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.6
[32m[20221124 21:33:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.6
[32m[20221124 21:33:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.4
[32m[20221124 21:33:52 @pendulum_agent.py:307][0m Sample time: 3.5777835845947266
[32m[20221124 21:34:01 @pendulum_agent.py:312][0m Update time: 9.117879152297974
[32m[20221124 21:34:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:34:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:34:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:34:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:34:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:34:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:34:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:34:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:34:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:34:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:34:02 @pendulum_agent.py:317][0m Evaluation time: 1.6379859447479248
[32m[20221124 21:34:03 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.62
[32m[20221124 21:34:03 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:34:03 @pendulum_agent.py:289][0m Total time: 712.2949738502502
[32m[20221124 21:34:03 @pendulum_agent.py:291][0m 2450000 total steps have happened
[32m[20221124 21:34:03 @pendulum_agent.py:281][0m #------------------------ Iteration 49 --------------------------#
[32m[20221124 21:34:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:34:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:34:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:34:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:34:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:34:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:34:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:34:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:34:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:34:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:34:06 @pendulum_agent.py:307][0m Sample time: 3.802722930908203
[32m[20221124 21:34:16 @pendulum_agent.py:312][0m Update time: 9.180073022842407
[32m[20221124 21:34:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:34:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:34:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:34:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:34:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:34:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:34:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:34:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:34:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:34:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:34:16 @pendulum_agent.py:317][0m Evaluation time: 0.716562032699585
[32m[20221124 21:34:17 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:34:17 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:34:17 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:34:17 @pendulum_agent.py:289][0m Total time: 726.2784931659698
[32m[20221124 21:34:17 @pendulum_agent.py:291][0m 2500000 total steps have happened
[32m[20221124 21:34:17 @pendulum_agent.py:281][0m #------------------------ Iteration 50 --------------------------#
[32m[20221124 21:34:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:34:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:34:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:34:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:34:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:34:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:34:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:34:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:34:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:34:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:34:21 @pendulum_agent.py:307][0m Sample time: 3.8761701583862305
[32m[20221124 21:34:30 @pendulum_agent.py:312][0m Update time: 9.530772924423218
[32m[20221124 21:34:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:34:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:34:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:34:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:34:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:34:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:34:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:34:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:34:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:34:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:34:31 @pendulum_agent.py:317][0m Evaluation time: 0.586899995803833
[32m[20221124 21:34:31 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:34:31 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:34:31 @pendulum_agent.py:289][0m Total time: 740.5685911178589
[32m[20221124 21:34:31 @pendulum_agent.py:291][0m 2550000 total steps have happened
[32m[20221124 21:34:31 @pendulum_agent.py:281][0m #------------------------ Iteration 51 --------------------------#
[32m[20221124 21:34:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:34:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:34:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:34:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:34:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:34:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:34:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:34:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:34:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:34:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:34:35 @pendulum_agent.py:307][0m Sample time: 3.7966158390045166
[32m[20221124 21:34:44 @pendulum_agent.py:312][0m Update time: 9.281903266906738
[32m[20221124 21:34:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:34:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:34:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:34:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:34:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:34:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:34:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:34:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:34:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:34:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:34:45 @pendulum_agent.py:317][0m Evaluation time: 1.0101077556610107
[32m[20221124 21:34:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:34:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:34:45 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:34:45 @pendulum_agent.py:289][0m Total time: 754.9388148784637
[32m[20221124 21:34:45 @pendulum_agent.py:291][0m 2600000 total steps have happened
[32m[20221124 21:34:45 @pendulum_agent.py:281][0m #------------------------ Iteration 52 --------------------------#
[32m[20221124 21:34:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:34:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:34:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:34:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:34:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:34:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:34:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:34:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:34:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:34:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:34:49 @pendulum_agent.py:307][0m Sample time: 3.764072895050049
[32m[20221124 21:34:58 @pendulum_agent.py:312][0m Update time: 9.008870840072632
[32m[20221124 21:34:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:34:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:34:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:34:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:34:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:34:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:34:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:34:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:34:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:34:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:34:59 @pendulum_agent.py:317][0m Evaluation time: 0.8347682952880859
[32m[20221124 21:34:59 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:34:59 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:34:59 @pendulum_agent.py:289][0m Total time: 768.8267800807953
[32m[20221124 21:34:59 @pendulum_agent.py:291][0m 2650000 total steps have happened
[32m[20221124 21:34:59 @pendulum_agent.py:281][0m #------------------------ Iteration 53 --------------------------#
[32m[20221124 21:35:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:35:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:35:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:35:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:35:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:35:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:35:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:35:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:35:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:35:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:35:03 @pendulum_agent.py:307][0m Sample time: 3.6008141040802
[32m[20221124 21:35:14 @pendulum_agent.py:312][0m Update time: 11.24836802482605
[32m[20221124 21:35:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:35:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:35:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:35:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:35:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:35:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:35:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:35:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:35:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:35:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:35:15 @pendulum_agent.py:317][0m Evaluation time: 0.5814988613128662
[32m[20221124 21:35:15 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:35:15 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:35:15 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:35:15 @pendulum_agent.py:289][0m Total time: 784.5433461666107
[32m[20221124 21:35:15 @pendulum_agent.py:291][0m 2700000 total steps have happened
[32m[20221124 21:35:15 @pendulum_agent.py:281][0m #------------------------ Iteration 54 --------------------------#
[32m[20221124 21:35:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.8
[32m[20221124 21:35:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.2
[32m[20221124 21:35:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.2
[32m[20221124 21:35:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.4
[32m[20221124 21:35:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.0
[32m[20221124 21:35:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.6
[32m[20221124 21:35:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.0
[32m[20221124 21:35:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.2
[32m[20221124 21:35:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.4
[32m[20221124 21:35:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.0
[32m[20221124 21:35:19 @pendulum_agent.py:307][0m Sample time: 3.794955015182495
[32m[20221124 21:35:29 @pendulum_agent.py:312][0m Update time: 9.904352903366089
[32m[20221124 21:35:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:35:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:35:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:35:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:35:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:35:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:35:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:35:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:35:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:35:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:35:29 @pendulum_agent.py:317][0m Evaluation time: 0.7166748046875
[32m[20221124 21:35:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.88
[32m[20221124 21:35:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:35:30 @pendulum_agent.py:289][0m Total time: 799.2476320266724
[32m[20221124 21:35:30 @pendulum_agent.py:291][0m 2750000 total steps have happened
[32m[20221124 21:35:30 @pendulum_agent.py:281][0m #------------------------ Iteration 55 --------------------------#
[32m[20221124 21:35:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.0
[32m[20221124 21:35:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.2
[32m[20221124 21:35:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.6
[32m[20221124 21:35:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.2
[32m[20221124 21:35:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.0
[32m[20221124 21:35:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.2
[32m[20221124 21:35:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.8
[32m[20221124 21:35:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.6
[32m[20221124 21:35:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.2
[32m[20221124 21:35:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.4
[32m[20221124 21:35:33 @pendulum_agent.py:307][0m Sample time: 3.8474223613739014
[32m[20221124 21:35:43 @pendulum_agent.py:312][0m Update time: 9.917707920074463
[32m[20221124 21:35:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 23.0
[32m[20221124 21:35:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 23.0
[32m[20221124 21:35:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 23.0
[32m[20221124 21:35:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 23.0
[32m[20221124 21:35:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 23.0
[32m[20221124 21:35:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 23.0
[32m[20221124 21:35:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 23.0
[32m[20221124 21:35:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 23.0
[32m[20221124 21:35:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 23.0
[32m[20221124 21:35:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 23.0
[32m[20221124 21:35:44 @pendulum_agent.py:317][0m Evaluation time: 0.5727529525756836
[32m[20221124 21:35:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.42
[32m[20221124 21:35:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:35:44 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:35:44 @pendulum_agent.py:289][0m Total time: 813.8814809322357
[32m[20221124 21:35:44 @pendulum_agent.py:291][0m 2800000 total steps have happened
[32m[20221124 21:35:44 @pendulum_agent.py:281][0m #------------------------ Iteration 56 --------------------------#
[32m[20221124 21:35:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:35:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.6
[32m[20221124 21:35:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:35:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.6
[32m[20221124 21:35:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:35:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:35:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:35:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:35:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:35:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:35:48 @pendulum_agent.py:307][0m Sample time: 3.7166409492492676
[32m[20221124 21:35:58 @pendulum_agent.py:312][0m Update time: 10.425473928451538
[32m[20221124 21:35:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:35:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:35:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:35:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:35:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:35:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:35:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:35:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:35:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:35:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:35:59 @pendulum_agent.py:317][0m Evaluation time: 0.8404941558837891
[32m[20221124 21:36:00 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.12
[32m[20221124 21:36:00 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:36:00 @pendulum_agent.py:289][0m Total time: 829.1464087963104
[32m[20221124 21:36:00 @pendulum_agent.py:291][0m 2850000 total steps have happened
[32m[20221124 21:36:00 @pendulum_agent.py:281][0m #------------------------ Iteration 57 --------------------------#
[32m[20221124 21:36:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:36:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:36:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:36:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:36:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:36:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:36:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:36:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:36:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:36:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:36:03 @pendulum_agent.py:307][0m Sample time: 3.2974278926849365
[32m[20221124 21:36:12 @pendulum_agent.py:312][0m Update time: 8.98940110206604
[32m[20221124 21:36:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:36:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:36:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:36:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:36:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:36:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:36:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:36:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:36:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:36:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:36:13 @pendulum_agent.py:317][0m Evaluation time: 1.0400028228759766
[32m[20221124 21:36:13 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:36:13 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:36:13 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:36:13 @pendulum_agent.py:289][0m Total time: 842.7436981201172
[32m[20221124 21:36:13 @pendulum_agent.py:291][0m 2900000 total steps have happened
[32m[20221124 21:36:13 @pendulum_agent.py:281][0m #------------------------ Iteration 58 --------------------------#
[32m[20221124 21:36:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.2
[32m[20221124 21:36:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.8
[32m[20221124 21:36:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1.6
[32m[20221124 21:36:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.6
[32m[20221124 21:36:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.8
[32m[20221124 21:36:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.2
[32m[20221124 21:36:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.2
[32m[20221124 21:36:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.8
[32m[20221124 21:36:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.0
[32m[20221124 21:36:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.4
[32m[20221124 21:36:17 @pendulum_agent.py:307][0m Sample time: 3.4765729904174805
[32m[20221124 21:36:26 @pendulum_agent.py:312][0m Update time: 9.71616792678833
[32m[20221124 21:36:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:36:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:36:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:36:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:36:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:36:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:36:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:36:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:36:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:36:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:36:28 @pendulum_agent.py:317][0m Evaluation time: 1.2030279636383057
[32m[20221124 21:36:28 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.06
[32m[20221124 21:36:28 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:36:28 @pendulum_agent.py:289][0m Total time: 857.4444961547852
[32m[20221124 21:36:28 @pendulum_agent.py:291][0m 2950000 total steps have happened
[32m[20221124 21:36:28 @pendulum_agent.py:281][0m #------------------------ Iteration 59 --------------------------#
[32m[20221124 21:36:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:36:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:36:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:36:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:36:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:36:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:36:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:36:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:36:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:36:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:36:31 @pendulum_agent.py:307][0m Sample time: 3.5265748500823975
[32m[20221124 21:36:42 @pendulum_agent.py:312][0m Update time: 10.44790005683899
[32m[20221124 21:36:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:36:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:36:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:36:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:36:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:36:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:36:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:36:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:36:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:36:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:36:44 @pendulum_agent.py:317][0m Evaluation time: 1.762361764907837
[32m[20221124 21:36:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:36:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:36:44 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:36:44 @pendulum_agent.py:289][0m Total time: 873.4920330047607
[32m[20221124 21:36:44 @pendulum_agent.py:291][0m 3000000 total steps have happened
[32m[20221124 21:36:44 @pendulum_agent.py:281][0m #------------------------ Iteration 60 --------------------------#
[32m[20221124 21:36:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:36:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:36:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:36:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:36:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:36:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:36:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:36:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:36:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:36:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:36:48 @pendulum_agent.py:307][0m Sample time: 3.8735430240631104
[32m[20221124 21:36:57 @pendulum_agent.py:312][0m Update time: 9.127097845077515
[32m[20221124 21:36:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:36:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:36:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:36:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:36:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:36:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:36:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:36:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:36:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:36:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:36:58 @pendulum_agent.py:317][0m Evaluation time: 1.0060398578643799
[32m[20221124 21:36:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:36:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:36:58 @pendulum_agent.py:289][0m Total time: 887.7961781024933
[32m[20221124 21:36:58 @pendulum_agent.py:291][0m 3050000 total steps have happened
[32m[20221124 21:36:58 @pendulum_agent.py:281][0m #------------------------ Iteration 61 --------------------------#
[32m[20221124 21:36:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:36:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:36:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:36:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:36:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:36:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:36:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:36:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:36:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:36:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:37:02 @pendulum_agent.py:307][0m Sample time: 3.9135100841522217
[32m[20221124 21:37:11 @pendulum_agent.py:312][0m Update time: 8.921622037887573
[32m[20221124 21:37:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:37:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:37:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:37:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:37:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:37:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:37:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:37:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:37:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:37:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:37:12 @pendulum_agent.py:317][0m Evaluation time: 1.0128138065338135
[32m[20221124 21:37:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:37:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:37:12 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:37:12 @pendulum_agent.py:289][0m Total time: 901.942458152771
[32m[20221124 21:37:12 @pendulum_agent.py:291][0m 3100000 total steps have happened
[32m[20221124 21:37:12 @pendulum_agent.py:281][0m #------------------------ Iteration 62 --------------------------#
[32m[20221124 21:37:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:37:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:37:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:37:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:37:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:37:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:37:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:37:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:37:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:37:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:37:16 @pendulum_agent.py:307][0m Sample time: 3.8335788249969482
[32m[20221124 21:37:25 @pendulum_agent.py:312][0m Update time: 8.965004205703735
[32m[20221124 21:37:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:37:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:37:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:37:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:37:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:37:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:37:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:37:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:37:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:37:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:37:26 @pendulum_agent.py:317][0m Evaluation time: 0.6962907314300537
[32m[20221124 21:37:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:37:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:37:26 @pendulum_agent.py:289][0m Total time: 915.7445948123932
[32m[20221124 21:37:26 @pendulum_agent.py:291][0m 3150000 total steps have happened
[32m[20221124 21:37:26 @pendulum_agent.py:281][0m #------------------------ Iteration 63 --------------------------#
[32m[20221124 21:37:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:37:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:37:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:37:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:37:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:37:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:37:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:37:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:37:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:37:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:37:30 @pendulum_agent.py:307][0m Sample time: 3.9636070728302
[32m[20221124 21:37:39 @pendulum_agent.py:312][0m Update time: 9.167653799057007
[32m[20221124 21:37:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:37:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:37:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:37:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:37:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:37:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:37:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:37:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:37:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:37:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:37:40 @pendulum_agent.py:317][0m Evaluation time: 0.582282304763794
[32m[20221124 21:37:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:37:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:37:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:37:40 @pendulum_agent.py:289][0m Total time: 929.7440528869629
[32m[20221124 21:37:40 @pendulum_agent.py:291][0m 3200000 total steps have happened
[32m[20221124 21:37:40 @pendulum_agent.py:281][0m #------------------------ Iteration 64 --------------------------#
[32m[20221124 21:37:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:37:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:37:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:37:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:37:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:37:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:37:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:37:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:37:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:37:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:37:44 @pendulum_agent.py:307][0m Sample time: 3.7256720066070557
[32m[20221124 21:37:54 @pendulum_agent.py:312][0m Update time: 10.274749994277954
[32m[20221124 21:37:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:37:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:37:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:37:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:37:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:37:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:37:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:37:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:37:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:37:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:37:55 @pendulum_agent.py:317][0m Evaluation time: 0.7109010219573975
[32m[20221124 21:37:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:37:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:37:55 @pendulum_agent.py:289][0m Total time: 944.7355630397797
[32m[20221124 21:37:55 @pendulum_agent.py:291][0m 3250000 total steps have happened
[32m[20221124 21:37:55 @pendulum_agent.py:281][0m #------------------------ Iteration 65 --------------------------#
[32m[20221124 21:37:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:37:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:37:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:37:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:37:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:37:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:37:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:37:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:37:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:37:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:37:59 @pendulum_agent.py:307][0m Sample time: 3.6770219802856445
[32m[20221124 21:38:08 @pendulum_agent.py:312][0m Update time: 9.04118824005127
[32m[20221124 21:38:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:38:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:38:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:38:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:38:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:38:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:38:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:38:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:38:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:38:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:38:09 @pendulum_agent.py:317][0m Evaluation time: 0.6798839569091797
[32m[20221124 21:38:09 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:38:09 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:38:09 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:38:09 @pendulum_agent.py:289][0m Total time: 958.4079358577728
[32m[20221124 21:38:09 @pendulum_agent.py:291][0m 3300000 total steps have happened
[32m[20221124 21:38:09 @pendulum_agent.py:281][0m #------------------------ Iteration 66 --------------------------#
[32m[20221124 21:38:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.8
[32m[20221124 21:38:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.2
[32m[20221124 21:38:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1.6
[32m[20221124 21:38:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.2
[32m[20221124 21:38:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.8
[32m[20221124 21:38:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.6
[32m[20221124 21:38:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.2
[32m[20221124 21:38:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 19.6
[32m[20221124 21:38:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 11.2
[32m[20221124 21:38:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.2
[32m[20221124 21:38:12 @pendulum_agent.py:307][0m Sample time: 3.678819179534912
[32m[20221124 21:38:22 @pendulum_agent.py:312][0m Update time: 9.896719932556152
[32m[20221124 21:38:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:38:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:38:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:38:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:38:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:38:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:38:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:38:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:38:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:38:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:38:23 @pendulum_agent.py:317][0m Evaluation time: 0.7076637744903564
[32m[20221124 21:38:23 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.44
[32m[20221124 21:38:23 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:38:23 @pendulum_agent.py:289][0m Total time: 972.9839239120483
[32m[20221124 21:38:23 @pendulum_agent.py:291][0m 3350000 total steps have happened
[32m[20221124 21:38:23 @pendulum_agent.py:281][0m #------------------------ Iteration 67 --------------------------#
[32m[20221124 21:38:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:38:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:38:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:38:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:38:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:38:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:38:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:38:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:38:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:38:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:38:27 @pendulum_agent.py:307][0m Sample time: 3.6433041095733643
[32m[20221124 21:38:36 @pendulum_agent.py:312][0m Update time: 9.018610954284668
[32m[20221124 21:38:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:38:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:38:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:38:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:38:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:38:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:38:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:38:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:38:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:38:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:38:37 @pendulum_agent.py:317][0m Evaluation time: 0.5789279937744141
[32m[20221124 21:38:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:38:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:38:37 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:38:37 @pendulum_agent.py:289][0m Total time: 986.520555973053
[32m[20221124 21:38:37 @pendulum_agent.py:291][0m 3400000 total steps have happened
[32m[20221124 21:38:37 @pendulum_agent.py:281][0m #------------------------ Iteration 68 --------------------------#
[32m[20221124 21:38:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:38:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:38:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:38:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:38:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:38:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:38:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:38:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:38:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:38:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:38:41 @pendulum_agent.py:307][0m Sample time: 3.695383071899414
[32m[20221124 21:38:50 @pendulum_agent.py:312][0m Update time: 9.482008934020996
[32m[20221124 21:38:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:38:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:38:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:38:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:38:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:38:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:38:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:38:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:38:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:38:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:38:51 @pendulum_agent.py:317][0m Evaluation time: 0.8169710636138916
[32m[20221124 21:38:51 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:38:51 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:38:51 @pendulum_agent.py:289][0m Total time: 1000.8218870162964
[32m[20221124 21:38:51 @pendulum_agent.py:291][0m 3450000 total steps have happened
[32m[20221124 21:38:51 @pendulum_agent.py:281][0m #------------------------ Iteration 69 --------------------------#
[32m[20221124 21:38:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:38:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:38:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:38:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:38:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:38:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:38:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:38:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:38:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:38:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:38:55 @pendulum_agent.py:307][0m Sample time: 3.2892868518829346
[32m[20221124 21:39:03 @pendulum_agent.py:312][0m Update time: 8.884452104568481
[32m[20221124 21:39:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:39:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:39:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:39:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:39:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:39:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:39:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:39:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:39:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:39:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:39:04 @pendulum_agent.py:317][0m Evaluation time: 1.039780855178833
[32m[20221124 21:39:05 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:39:05 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:39:05 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:39:05 @pendulum_agent.py:289][0m Total time: 1014.312952041626
[32m[20221124 21:39:05 @pendulum_agent.py:291][0m 3500000 total steps have happened
[32m[20221124 21:39:05 @pendulum_agent.py:281][0m #------------------------ Iteration 70 --------------------------#
[32m[20221124 21:39:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:39:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:39:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:39:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:39:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:39:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:39:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:39:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:39:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:39:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:39:08 @pendulum_agent.py:307][0m Sample time: 3.4728031158447266
[32m[20221124 21:39:18 @pendulum_agent.py:312][0m Update time: 9.424304962158203
[32m[20221124 21:39:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:39:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:39:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:39:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:39:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:39:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:39:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:39:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:39:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:39:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:39:19 @pendulum_agent.py:317][0m Evaluation time: 1.1757478713989258
[32m[20221124 21:39:19 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:39:19 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:39:19 @pendulum_agent.py:289][0m Total time: 1028.6972301006317
[32m[20221124 21:39:19 @pendulum_agent.py:291][0m 3550000 total steps have happened
[32m[20221124 21:39:19 @pendulum_agent.py:281][0m #------------------------ Iteration 71 --------------------------#
[32m[20221124 21:39:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:39:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:39:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:39:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:39:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:39:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:39:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:39:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:39:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:39:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:39:22 @pendulum_agent.py:307][0m Sample time: 3.203157901763916
[32m[20221124 21:39:33 @pendulum_agent.py:312][0m Update time: 10.659363269805908
[32m[20221124 21:39:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:39:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:39:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:39:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:39:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:39:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:39:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:39:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:39:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:39:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:39:34 @pendulum_agent.py:317][0m Evaluation time: 1.0490038394927979
[32m[20221124 21:39:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:39:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:39:34 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:39:34 @pendulum_agent.py:289][0m Total time: 1043.8803970813751
[32m[20221124 21:39:34 @pendulum_agent.py:291][0m 3600000 total steps have happened
[32m[20221124 21:39:34 @pendulum_agent.py:281][0m #------------------------ Iteration 72 --------------------------#
[32m[20221124 21:39:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:39:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:39:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:39:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:39:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:39:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:39:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:39:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:39:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:39:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:39:38 @pendulum_agent.py:307][0m Sample time: 3.9318180084228516
[32m[20221124 21:39:49 @pendulum_agent.py:312][0m Update time: 11.233380794525146
[32m[20221124 21:39:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:39:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:39:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:39:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:39:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:39:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:39:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:39:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:39:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:39:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:39:50 @pendulum_agent.py:317][0m Evaluation time: 0.7278001308441162
[32m[20221124 21:39:50 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:39:50 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:39:50 @pendulum_agent.py:289][0m Total time: 1060.0572669506073
[32m[20221124 21:39:50 @pendulum_agent.py:291][0m 3650000 total steps have happened
[32m[20221124 21:39:50 @pendulum_agent.py:281][0m #------------------------ Iteration 73 --------------------------#
[32m[20221124 21:39:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:39:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:39:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:39:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:39:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:39:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:39:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:39:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:39:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:39:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:39:54 @pendulum_agent.py:307][0m Sample time: 3.797415018081665
[32m[20221124 21:40:05 @pendulum_agent.py:312][0m Update time: 10.714592933654785
[32m[20221124 21:40:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.0
[32m[20221124 21:40:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.0
[32m[20221124 21:40:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.0
[32m[20221124 21:40:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.0
[32m[20221124 21:40:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.0
[32m[20221124 21:40:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.0
[32m[20221124 21:40:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.0
[32m[20221124 21:40:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.0
[32m[20221124 21:40:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.0
[32m[20221124 21:40:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.0
[32m[20221124 21:40:06 @pendulum_agent.py:317][0m Evaluation time: 0.7232229709625244
[32m[20221124 21:40:06 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:40:06 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:40:06 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:40:06 @pendulum_agent.py:289][0m Total time: 1075.5848350524902
[32m[20221124 21:40:06 @pendulum_agent.py:291][0m 3700000 total steps have happened
[32m[20221124 21:40:06 @pendulum_agent.py:281][0m #------------------------ Iteration 74 --------------------------#
[32m[20221124 21:40:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:40:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:40:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:40:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:40:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:40:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:40:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:40:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:40:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:40:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:40:10 @pendulum_agent.py:307][0m Sample time: 3.5358481407165527
[32m[20221124 21:40:19 @pendulum_agent.py:312][0m Update time: 9.231287717819214
[32m[20221124 21:40:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:40:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:40:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:40:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:40:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:40:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:40:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:40:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:40:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:40:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:40:19 @pendulum_agent.py:317][0m Evaluation time: 0.7054619789123535
[32m[20221124 21:40:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:40:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:40:20 @pendulum_agent.py:289][0m Total time: 1089.3405339717865
[32m[20221124 21:40:20 @pendulum_agent.py:291][0m 3750000 total steps have happened
[32m[20221124 21:40:20 @pendulum_agent.py:281][0m #------------------------ Iteration 75 --------------------------#
[32m[20221124 21:40:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:40:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:40:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:40:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:40:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:40:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:40:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:40:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:40:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:40:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:40:24 @pendulum_agent.py:307][0m Sample time: 3.8737473487854004
[32m[20221124 21:40:33 @pendulum_agent.py:312][0m Update time: 9.284703969955444
[32m[20221124 21:40:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:40:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:40:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:40:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:40:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:40:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:40:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:40:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:40:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:40:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:40:34 @pendulum_agent.py:317][0m Evaluation time: 0.7129647731781006
[32m[20221124 21:40:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:40:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:40:34 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:40:34 @pendulum_agent.py:289][0m Total time: 1103.5126309394836
[32m[20221124 21:40:34 @pendulum_agent.py:291][0m 3800000 total steps have happened
[32m[20221124 21:40:34 @pendulum_agent.py:281][0m #------------------------ Iteration 76 --------------------------#
[32m[20221124 21:40:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:40:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:40:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:40:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:40:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:40:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:40:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:40:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:40:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:40:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:40:38 @pendulum_agent.py:307][0m Sample time: 3.6606972217559814
[32m[20221124 21:40:49 @pendulum_agent.py:312][0m Update time: 10.98087191581726
[32m[20221124 21:40:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:40:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:40:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:40:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:40:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:40:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:40:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:40:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:40:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:40:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:40:49 @pendulum_agent.py:317][0m Evaluation time: 0.7177989482879639
[32m[20221124 21:40:50 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:40:50 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:40:50 @pendulum_agent.py:289][0m Total time: 1119.1477899551392
[32m[20221124 21:40:50 @pendulum_agent.py:291][0m 3850000 total steps have happened
[32m[20221124 21:40:50 @pendulum_agent.py:281][0m #------------------------ Iteration 77 --------------------------#
[32m[20221124 21:40:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 8.2
[32m[20221124 21:40:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.8
[32m[20221124 21:40:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.8
[32m[20221124 21:40:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.8
[32m[20221124 21:40:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.4
[32m[20221124 21:40:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.0
[32m[20221124 21:40:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.4
[32m[20221124 21:40:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.2
[32m[20221124 21:40:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.8
[32m[20221124 21:40:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.4
[32m[20221124 21:40:53 @pendulum_agent.py:307][0m Sample time: 3.8539750576019287
[32m[20221124 21:41:03 @pendulum_agent.py:312][0m Update time: 9.339606046676636
[32m[20221124 21:41:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:41:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:41:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:41:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:41:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:41:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:41:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:41:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:41:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:41:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:41:04 @pendulum_agent.py:317][0m Evaluation time: 0.998117208480835
[32m[20221124 21:41:04 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.58
[32m[20221124 21:41:04 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:41:04 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:41:04 @pendulum_agent.py:289][0m Total time: 1133.631675004959
[32m[20221124 21:41:04 @pendulum_agent.py:291][0m 3900000 total steps have happened
[32m[20221124 21:41:04 @pendulum_agent.py:281][0m #------------------------ Iteration 78 --------------------------#
[32m[20221124 21:41:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.2
[32m[20221124 21:41:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.0
[32m[20221124 21:41:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.0
[32m[20221124 21:41:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.0
[32m[20221124 21:41:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.0
[32m[20221124 21:41:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.2
[32m[20221124 21:41:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.4
[32m[20221124 21:41:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.0
[32m[20221124 21:41:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.2
[32m[20221124 21:41:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.8
[32m[20221124 21:41:08 @pendulum_agent.py:307][0m Sample time: 3.796505928039551
[32m[20221124 21:41:18 @pendulum_agent.py:312][0m Update time: 9.879794120788574
[32m[20221124 21:41:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:41:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:41:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:41:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:41:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:41:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:41:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:41:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:41:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:41:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:41:19 @pendulum_agent.py:317][0m Evaluation time: 0.8560898303985596
[32m[20221124 21:41:19 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.38
[32m[20221124 21:41:19 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:41:19 @pendulum_agent.py:289][0m Total time: 1148.4474260807037
[32m[20221124 21:41:19 @pendulum_agent.py:291][0m 3950000 total steps have happened
[32m[20221124 21:41:19 @pendulum_agent.py:281][0m #------------------------ Iteration 79 --------------------------#
[32m[20221124 21:41:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:41:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:41:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:41:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:41:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:41:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:41:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:41:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:41:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:41:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:41:22 @pendulum_agent.py:307][0m Sample time: 3.3429698944091797
[32m[20221124 21:41:31 @pendulum_agent.py:312][0m Update time: 9.261574983596802
[32m[20221124 21:41:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:41:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:41:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:41:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:41:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:41:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:41:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:41:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:41:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:41:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:41:33 @pendulum_agent.py:317][0m Evaluation time: 1.5877189636230469
[32m[20221124 21:41:33 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:41:33 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:41:33 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:41:33 @pendulum_agent.py:289][0m Total time: 1162.921117067337
[32m[20221124 21:41:33 @pendulum_agent.py:291][0m 4000000 total steps have happened
[32m[20221124 21:41:33 @pendulum_agent.py:281][0m #------------------------ Iteration 80 --------------------------#
[32m[20221124 21:41:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:41:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:41:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:41:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:41:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:41:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:41:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:41:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:41:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:41:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:41:37 @pendulum_agent.py:307][0m Sample time: 3.373520851135254
[32m[20221124 21:41:46 @pendulum_agent.py:312][0m Update time: 9.030086994171143
[32m[20221124 21:41:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:41:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:41:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:41:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:41:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:41:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:41:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:41:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:41:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:41:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:41:47 @pendulum_agent.py:317][0m Evaluation time: 1.1730070114135742
[32m[20221124 21:41:47 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:41:47 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:41:47 @pendulum_agent.py:289][0m Total time: 1176.7895488739014
[32m[20221124 21:41:47 @pendulum_agent.py:291][0m 4050000 total steps have happened
[32m[20221124 21:41:47 @pendulum_agent.py:281][0m #------------------------ Iteration 81 --------------------------#
[32m[20221124 21:41:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:41:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:41:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:41:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:41:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:41:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:41:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:41:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:41:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:41:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:41:51 @pendulum_agent.py:307][0m Sample time: 3.6740729808807373
[32m[20221124 21:42:00 @pendulum_agent.py:312][0m Update time: 9.210793018341064
[32m[20221124 21:42:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:42:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:42:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:42:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:42:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:42:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:42:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:42:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:42:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:42:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:42:01 @pendulum_agent.py:317][0m Evaluation time: 0.7195100784301758
[32m[20221124 21:42:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:42:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:42:01 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:42:01 @pendulum_agent.py:289][0m Total time: 1190.6690819263458
[32m[20221124 21:42:01 @pendulum_agent.py:291][0m 4100000 total steps have happened
[32m[20221124 21:42:01 @pendulum_agent.py:281][0m #------------------------ Iteration 82 --------------------------#
[32m[20221124 21:42:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:42:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:42:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:42:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:42:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:42:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:42:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:42:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:42:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:42:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:42:05 @pendulum_agent.py:307][0m Sample time: 3.623767137527466
[32m[20221124 21:42:14 @pendulum_agent.py:312][0m Update time: 9.586733102798462
[32m[20221124 21:42:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:42:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:42:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:42:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:42:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:42:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:42:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:42:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:42:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:42:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:42:15 @pendulum_agent.py:317][0m Evaluation time: 0.7369389533996582
[32m[20221124 21:42:15 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:42:15 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:42:15 @pendulum_agent.py:289][0m Total time: 1204.905473947525
[32m[20221124 21:42:15 @pendulum_agent.py:291][0m 4150000 total steps have happened
[32m[20221124 21:42:15 @pendulum_agent.py:281][0m #------------------------ Iteration 83 --------------------------#
[32m[20221124 21:42:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.4
[32m[20221124 21:42:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.0
[32m[20221124 21:42:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.4
[32m[20221124 21:42:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.0
[32m[20221124 21:42:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.4
[32m[20221124 21:42:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.4
[32m[20221124 21:42:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.8
[32m[20221124 21:42:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.4
[32m[20221124 21:42:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1.6
[32m[20221124 21:42:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.0
[32m[20221124 21:42:19 @pendulum_agent.py:307][0m Sample time: 3.914100170135498
[32m[20221124 21:42:28 @pendulum_agent.py:312][0m Update time: 9.14667272567749
[32m[20221124 21:42:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:42:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:42:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:42:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:42:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:42:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:42:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:42:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:42:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:42:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:42:29 @pendulum_agent.py:317][0m Evaluation time: 0.5656392574310303
[32m[20221124 21:42:29 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.04
[32m[20221124 21:42:29 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:42:29 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:42:29 @pendulum_agent.py:289][0m Total time: 1218.8133590221405
[32m[20221124 21:42:29 @pendulum_agent.py:291][0m 4200000 total steps have happened
[32m[20221124 21:42:29 @pendulum_agent.py:281][0m #------------------------ Iteration 84 --------------------------#
[32m[20221124 21:42:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:42:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:42:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:42:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:42:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:42:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:42:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:42:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:42:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:42:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:42:33 @pendulum_agent.py:307][0m Sample time: 3.689481019973755
[32m[20221124 21:42:44 @pendulum_agent.py:312][0m Update time: 11.304314851760864
[32m[20221124 21:42:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:42:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:42:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:42:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:42:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:42:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:42:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:42:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:42:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:42:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:42:45 @pendulum_agent.py:317][0m Evaluation time: 0.828192949295044
[32m[20221124 21:42:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:42:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:42:45 @pendulum_agent.py:289][0m Total time: 1234.9236347675323
[32m[20221124 21:42:45 @pendulum_agent.py:291][0m 4250000 total steps have happened
[32m[20221124 21:42:45 @pendulum_agent.py:281][0m #------------------------ Iteration 85 --------------------------#
[32m[20221124 21:42:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:42:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:42:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:42:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:42:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:42:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:42:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:42:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:42:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:42:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:42:49 @pendulum_agent.py:307][0m Sample time: 3.474181890487671
[32m[20221124 21:42:59 @pendulum_agent.py:312][0m Update time: 9.997176170349121
[32m[20221124 21:42:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:42:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:42:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:42:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:42:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:42:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:42:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:42:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:42:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:42:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:43:00 @pendulum_agent.py:317][0m Evaluation time: 1.0267210006713867
[32m[20221124 21:43:00 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:43:00 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:43:00 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:43:00 @pendulum_agent.py:289][0m Total time: 1249.7098758220673
[32m[20221124 21:43:00 @pendulum_agent.py:291][0m 4300000 total steps have happened
[32m[20221124 21:43:00 @pendulum_agent.py:281][0m #------------------------ Iteration 86 --------------------------#
[32m[20221124 21:43:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1.6
[32m[20221124 21:43:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.4
[32m[20221124 21:43:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.6
[32m[20221124 21:43:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.6
[32m[20221124 21:43:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1.6
[32m[20221124 21:43:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.6
[32m[20221124 21:43:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.2
[32m[20221124 21:43:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.6
[32m[20221124 21:43:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.2
[32m[20221124 21:43:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.8
[32m[20221124 21:43:04 @pendulum_agent.py:307][0m Sample time: 3.6298701763153076
[32m[20221124 21:43:13 @pendulum_agent.py:312][0m Update time: 8.992691993713379
[32m[20221124 21:43:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:43:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:43:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:43:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:43:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:43:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:43:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:43:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:43:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:43:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:43:13 @pendulum_agent.py:317][0m Evaluation time: 0.7172131538391113
[32m[20221124 21:43:14 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.32
[32m[20221124 21:43:14 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:43:14 @pendulum_agent.py:289][0m Total time: 1263.3256990909576
[32m[20221124 21:43:14 @pendulum_agent.py:291][0m 4350000 total steps have happened
[32m[20221124 21:43:14 @pendulum_agent.py:281][0m #------------------------ Iteration 87 --------------------------#
[32m[20221124 21:43:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:43:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:43:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:43:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:43:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:43:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:43:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:43:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:43:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:43:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:43:17 @pendulum_agent.py:307][0m Sample time: 3.6102211475372314
[32m[20221124 21:43:27 @pendulum_agent.py:312][0m Update time: 10.031975746154785
[32m[20221124 21:43:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:43:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:43:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:43:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:43:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:43:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:43:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:43:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:43:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:43:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:43:28 @pendulum_agent.py:317][0m Evaluation time: 0.5851771831512451
[32m[20221124 21:43:28 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:43:28 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:43:28 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:43:28 @pendulum_agent.py:289][0m Total time: 1277.8442931175232
[32m[20221124 21:43:28 @pendulum_agent.py:291][0m 4400000 total steps have happened
[32m[20221124 21:43:28 @pendulum_agent.py:281][0m #------------------------ Iteration 88 --------------------------#
[32m[20221124 21:43:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:43:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:43:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:43:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:43:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:43:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:43:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:43:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:43:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:43:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:43:32 @pendulum_agent.py:307][0m Sample time: 3.794975757598877
[32m[20221124 21:43:41 @pendulum_agent.py:312][0m Update time: 8.816315174102783
[32m[20221124 21:43:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:43:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:43:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:43:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:43:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:43:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:43:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:43:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:43:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:43:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:43:42 @pendulum_agent.py:317][0m Evaluation time: 0.6981649398803711
[32m[20221124 21:43:42 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:43:42 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:43:42 @pendulum_agent.py:289][0m Total time: 1291.4556720256805
[32m[20221124 21:43:42 @pendulum_agent.py:291][0m 4450000 total steps have happened
[32m[20221124 21:43:42 @pendulum_agent.py:281][0m #------------------------ Iteration 89 --------------------------#
[32m[20221124 21:43:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:43:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:43:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:43:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:43:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:43:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:43:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:43:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:43:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:43:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:43:46 @pendulum_agent.py:307][0m Sample time: 3.727910280227661
[32m[20221124 21:43:55 @pendulum_agent.py:312][0m Update time: 9.183894634246826
[32m[20221124 21:43:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:43:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:43:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:43:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:43:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:43:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:43:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:43:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:43:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:43:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:43:55 @pendulum_agent.py:317][0m Evaluation time: 0.7252652645111084
[32m[20221124 21:43:56 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:43:56 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:43:56 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:43:56 @pendulum_agent.py:289][0m Total time: 1305.400859117508
[32m[20221124 21:43:56 @pendulum_agent.py:291][0m 4500000 total steps have happened
[32m[20221124 21:43:56 @pendulum_agent.py:281][0m #------------------------ Iteration 90 --------------------------#
[32m[20221124 21:43:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:43:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:43:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:43:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:43:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:43:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:43:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:43:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:43:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:43:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:43:59 @pendulum_agent.py:307][0m Sample time: 3.6081721782684326
[32m[20221124 21:44:10 @pendulum_agent.py:312][0m Update time: 10.99141812324524
[32m[20221124 21:44:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:44:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:44:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:44:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:44:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:44:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:44:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:44:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:44:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:44:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:44:11 @pendulum_agent.py:317][0m Evaluation time: 0.9827427864074707
[32m[20221124 21:44:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:44:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:44:12 @pendulum_agent.py:289][0m Total time: 1321.2768120765686
[32m[20221124 21:44:12 @pendulum_agent.py:291][0m 4550000 total steps have happened
[32m[20221124 21:44:12 @pendulum_agent.py:281][0m #------------------------ Iteration 91 --------------------------#
[32m[20221124 21:44:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:44:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:44:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:44:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:44:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:44:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:44:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:44:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:44:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:44:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:44:15 @pendulum_agent.py:307][0m Sample time: 3.736294746398926
[32m[20221124 21:44:24 @pendulum_agent.py:312][0m Update time: 9.042823076248169
[32m[20221124 21:44:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:44:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:44:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:44:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:44:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:44:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:44:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:44:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:44:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:44:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:44:25 @pendulum_agent.py:317][0m Evaluation time: 0.6956300735473633
[32m[20221124 21:44:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:44:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:44:25 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:44:25 @pendulum_agent.py:289][0m Total time: 1335.023066997528
[32m[20221124 21:44:25 @pendulum_agent.py:291][0m 4600000 total steps have happened
[32m[20221124 21:44:25 @pendulum_agent.py:281][0m #------------------------ Iteration 92 --------------------------#
[32m[20221124 21:44:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:44:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:44:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:44:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:44:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:44:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:44:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:44:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:44:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:44:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:44:29 @pendulum_agent.py:307][0m Sample time: 3.709489345550537
[32m[20221124 21:44:38 @pendulum_agent.py:312][0m Update time: 9.102922916412354
[32m[20221124 21:44:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:44:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:44:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:44:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:44:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:44:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:44:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:44:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:44:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:44:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:44:39 @pendulum_agent.py:317][0m Evaluation time: 0.6769647598266602
[32m[20221124 21:44:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:44:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:44:39 @pendulum_agent.py:289][0m Total time: 1348.7998571395874
[32m[20221124 21:44:39 @pendulum_agent.py:291][0m 4650000 total steps have happened
[32m[20221124 21:44:39 @pendulum_agent.py:281][0m #------------------------ Iteration 93 --------------------------#
[32m[20221124 21:44:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.0
[32m[20221124 21:44:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.4
[32m[20221124 21:44:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.2
[32m[20221124 21:44:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.2
[32m[20221124 21:44:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 7.2
[32m[20221124 21:44:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.0
[32m[20221124 21:44:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.0
[32m[20221124 21:44:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.8
[32m[20221124 21:44:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.6
[32m[20221124 21:44:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.4
[32m[20221124 21:44:43 @pendulum_agent.py:307][0m Sample time: 3.4280803203582764
[32m[20221124 21:44:52 @pendulum_agent.py:312][0m Update time: 9.638497591018677
[32m[20221124 21:44:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:44:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:44:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:44:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:44:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:44:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:44:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:44:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:44:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:44:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:44:53 @pendulum_agent.py:317][0m Evaluation time: 0.9230961799621582
[32m[20221124 21:44:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.58
[32m[20221124 21:44:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:44:53 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:44:53 @pendulum_agent.py:289][0m Total time: 1363.0626468658447
[32m[20221124 21:44:53 @pendulum_agent.py:291][0m 4700000 total steps have happened
[32m[20221124 21:44:53 @pendulum_agent.py:281][0m #------------------------ Iteration 94 --------------------------#
[32m[20221124 21:44:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.8
[32m[20221124 21:44:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 17.6
[32m[20221124 21:44:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.6
[32m[20221124 21:44:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.0
[32m[20221124 21:44:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 11.8
[32m[20221124 21:44:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 8.2
[32m[20221124 21:44:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 12.4
[32m[20221124 21:44:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 8.8
[32m[20221124 21:44:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 9.8
[32m[20221124 21:44:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.2
[32m[20221124 21:44:57 @pendulum_agent.py:307][0m Sample time: 3.302863121032715
[32m[20221124 21:45:06 @pendulum_agent.py:312][0m Update time: 9.097994089126587
[32m[20221124 21:45:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:45:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:45:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:45:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:45:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:45:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:45:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:45:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:45:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:45:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:45:08 @pendulum_agent.py:317][0m Evaluation time: 1.7235820293426514
[32m[20221124 21:45:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 9.72
[32m[20221124 21:45:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:45:08 @pendulum_agent.py:289][0m Total time: 1377.4774718284607
[32m[20221124 21:45:08 @pendulum_agent.py:291][0m 4750000 total steps have happened
[32m[20221124 21:45:08 @pendulum_agent.py:281][0m #------------------------ Iteration 95 --------------------------#
[32m[20221124 21:45:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:45:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:45:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:45:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:45:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:45:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:45:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:45:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:45:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:45:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:45:12 @pendulum_agent.py:307][0m Sample time: 3.801156997680664
[32m[20221124 21:45:21 @pendulum_agent.py:312][0m Update time: 9.278942108154297
[32m[20221124 21:45:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:45:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:45:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:45:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:45:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:45:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:45:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:45:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:45:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:45:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:45:22 @pendulum_agent.py:317][0m Evaluation time: 0.7169859409332275
[32m[20221124 21:45:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:45:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:45:22 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:45:22 @pendulum_agent.py:289][0m Total time: 1391.5498399734497
[32m[20221124 21:45:22 @pendulum_agent.py:291][0m 4800000 total steps have happened
[32m[20221124 21:45:22 @pendulum_agent.py:281][0m #------------------------ Iteration 96 --------------------------#
[32m[20221124 21:45:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:45:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:45:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:45:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:45:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:45:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:45:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:45:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:45:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:45:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:45:26 @pendulum_agent.py:307][0m Sample time: 3.6431398391723633
[32m[20221124 21:45:36 @pendulum_agent.py:312][0m Update time: 10.77104115486145
[32m[20221124 21:45:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:45:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:45:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:45:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:45:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:45:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:45:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:45:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:45:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:45:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:45:37 @pendulum_agent.py:317][0m Evaluation time: 0.7026669979095459
[32m[20221124 21:45:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:45:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:45:37 @pendulum_agent.py:289][0m Total time: 1406.9383227825165
[32m[20221124 21:45:37 @pendulum_agent.py:291][0m 4850000 total steps have happened
[32m[20221124 21:45:37 @pendulum_agent.py:281][0m #------------------------ Iteration 97 --------------------------#
[32m[20221124 21:45:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:45:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:45:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:45:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:45:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:45:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:45:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:45:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:45:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:45:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:45:41 @pendulum_agent.py:307][0m Sample time: 3.7010819911956787
[32m[20221124 21:45:51 @pendulum_agent.py:312][0m Update time: 9.523406982421875
[32m[20221124 21:45:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:45:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:45:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:45:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:45:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:45:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:45:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:45:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:45:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:45:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:45:51 @pendulum_agent.py:317][0m Evaluation time: 0.6969540119171143
[32m[20221124 21:45:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:45:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:45:52 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:45:52 @pendulum_agent.py:289][0m Total time: 1421.143210887909
[32m[20221124 21:45:52 @pendulum_agent.py:291][0m 4900000 total steps have happened
[32m[20221124 21:45:52 @pendulum_agent.py:281][0m #------------------------ Iteration 98 --------------------------#
[32m[20221124 21:45:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:45:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:45:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:45:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:45:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:45:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:45:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:45:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:45:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:45:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:45:55 @pendulum_agent.py:307][0m Sample time: 3.563871145248413
[32m[20221124 21:46:06 @pendulum_agent.py:312][0m Update time: 11.04004693031311
[32m[20221124 21:46:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:46:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:46:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:46:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:46:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:46:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:46:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:46:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:46:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:46:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:46:07 @pendulum_agent.py:317][0m Evaluation time: 0.8414878845214844
[32m[20221124 21:46:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:46:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:46:07 @pendulum_agent.py:289][0m Total time: 1436.8835802078247
[32m[20221124 21:46:07 @pendulum_agent.py:291][0m 4950000 total steps have happened
[32m[20221124 21:46:07 @pendulum_agent.py:281][0m #------------------------ Iteration 99 --------------------------#
[32m[20221124 21:46:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:46:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:46:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:46:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:46:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:46:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:46:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:46:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:46:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:46:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:46:11 @pendulum_agent.py:307][0m Sample time: 3.6183102130889893
[32m[20221124 21:46:21 @pendulum_agent.py:312][0m Update time: 10.016390800476074
[32m[20221124 21:46:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:46:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:46:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:46:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:46:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:46:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:46:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:46:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:46:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:46:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:46:22 @pendulum_agent.py:317][0m Evaluation time: 0.8442072868347168
[32m[20221124 21:46:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:46:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:46:22 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:46:22 @pendulum_agent.py:289][0m Total time: 1451.6849219799042
[32m[20221124 21:46:22 @pendulum_agent.py:291][0m 5000000 total steps have happened
[32m[20221124 21:46:22 @pendulum_agent.py:281][0m #------------------------ Iteration 100 --------------------------#
[32m[20221124 21:46:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:46:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:46:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:46:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:46:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:46:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:46:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:46:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:46:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:46:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:46:26 @pendulum_agent.py:307][0m Sample time: 3.684134006500244
[32m[20221124 21:46:35 @pendulum_agent.py:312][0m Update time: 9.19625186920166
[32m[20221124 21:46:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:46:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:46:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:46:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:46:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:46:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:46:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:46:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:46:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:46:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:46:36 @pendulum_agent.py:317][0m Evaluation time: 0.7221171855926514
[32m[20221124 21:46:36 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:46:36 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:46:36 @pendulum_agent.py:289][0m Total time: 1465.5484619140625
[32m[20221124 21:46:36 @pendulum_agent.py:291][0m 5050000 total steps have happened
[32m[20221124 21:46:36 @pendulum_agent.py:281][0m #------------------------ Iteration 101 --------------------------#
[32m[20221124 21:46:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.0
[32m[20221124 21:46:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.0
[32m[20221124 21:46:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.2
[32m[20221124 21:46:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.8
[32m[20221124 21:46:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.6
[32m[20221124 21:46:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.8
[32m[20221124 21:46:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.6
[32m[20221124 21:46:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.0
[32m[20221124 21:46:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.8
[32m[20221124 21:46:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.8
[32m[20221124 21:46:40 @pendulum_agent.py:307][0m Sample time: 3.595296859741211
[32m[20221124 21:46:49 @pendulum_agent.py:312][0m Update time: 9.309555053710938
[32m[20221124 21:46:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:46:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:46:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:46:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:46:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:46:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:46:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:46:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:46:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:46:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:46:50 @pendulum_agent.py:317][0m Evaluation time: 0.7238991260528564
[32m[20221124 21:46:50 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.26
[32m[20221124 21:46:50 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:46:50 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:46:50 @pendulum_agent.py:289][0m Total time: 1479.4522709846497
[32m[20221124 21:46:50 @pendulum_agent.py:291][0m 5100000 total steps have happened
[32m[20221124 21:46:50 @pendulum_agent.py:281][0m #------------------------ Iteration 102 --------------------------#
[32m[20221124 21:46:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:46:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:46:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:46:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:46:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:46:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:46:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:46:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:46:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:46:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:46:53 @pendulum_agent.py:307][0m Sample time: 3.4986631870269775
[32m[20221124 21:47:03 @pendulum_agent.py:312][0m Update time: 9.522656679153442
[32m[20221124 21:47:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:47:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:47:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:47:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:47:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:47:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:47:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:47:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:47:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:47:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:47:04 @pendulum_agent.py:317][0m Evaluation time: 0.8415801525115967
[32m[20221124 21:47:04 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:47:04 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:47:04 @pendulum_agent.py:289][0m Total time: 1493.5998950004578
[32m[20221124 21:47:04 @pendulum_agent.py:291][0m 5150000 total steps have happened
[32m[20221124 21:47:04 @pendulum_agent.py:281][0m #------------------------ Iteration 103 --------------------------#
[32m[20221124 21:47:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:47:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:47:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:47:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:47:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:47:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:47:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:47:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:47:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:47:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:47:07 @pendulum_agent.py:307][0m Sample time: 3.5001158714294434
[32m[20221124 21:47:17 @pendulum_agent.py:312][0m Update time: 9.99266791343689
[32m[20221124 21:47:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:47:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:47:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:47:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:47:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:47:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:47:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:47:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:47:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:47:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:47:19 @pendulum_agent.py:317][0m Evaluation time: 1.0231590270996094
[32m[20221124 21:47:19 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:47:19 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:47:19 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:47:19 @pendulum_agent.py:289][0m Total time: 1508.4076688289642
[32m[20221124 21:47:19 @pendulum_agent.py:291][0m 5200000 total steps have happened
[32m[20221124 21:47:19 @pendulum_agent.py:281][0m #------------------------ Iteration 104 --------------------------#
[32m[20221124 21:47:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:47:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:47:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:47:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:47:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:47:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:47:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:47:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:47:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:47:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:47:22 @pendulum_agent.py:307][0m Sample time: 3.2928249835968018
[32m[20221124 21:47:31 @pendulum_agent.py:312][0m Update time: 8.775059223175049
[32m[20221124 21:47:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:47:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:47:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:47:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:47:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:47:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:47:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:47:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:47:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:47:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:47:32 @pendulum_agent.py:317][0m Evaluation time: 1.1701979637145996
[32m[20221124 21:47:32 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:47:32 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:47:32 @pendulum_agent.py:289][0m Total time: 1521.9224529266357
[32m[20221124 21:47:32 @pendulum_agent.py:291][0m 5250000 total steps have happened
[32m[20221124 21:47:32 @pendulum_agent.py:281][0m #------------------------ Iteration 105 --------------------------#
[32m[20221124 21:47:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:47:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:47:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:47:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:47:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:47:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:47:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:47:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:47:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:47:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:47:36 @pendulum_agent.py:307][0m Sample time: 3.334550142288208
[32m[20221124 21:47:46 @pendulum_agent.py:312][0m Update time: 10.632643938064575
[32m[20221124 21:47:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:47:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:47:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:47:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:47:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:47:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:47:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:47:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:47:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:47:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:47:48 @pendulum_agent.py:317][0m Evaluation time: 1.8608672618865967
[32m[20221124 21:47:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:47:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:47:48 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:47:48 @pendulum_agent.py:289][0m Total time: 1538.0559799671173
[32m[20221124 21:47:48 @pendulum_agent.py:291][0m 5300000 total steps have happened
[32m[20221124 21:47:48 @pendulum_agent.py:281][0m #------------------------ Iteration 106 --------------------------#
[32m[20221124 21:47:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.6
[32m[20221124 21:47:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.0
[32m[20221124 21:47:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.6
[32m[20221124 21:47:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.2
[32m[20221124 21:47:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.2
[32m[20221124 21:47:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.4
[32m[20221124 21:47:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.2
[32m[20221124 21:47:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.4
[32m[20221124 21:47:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.2
[32m[20221124 21:47:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.0
[32m[20221124 21:47:52 @pendulum_agent.py:307][0m Sample time: 3.523059129714966
[32m[20221124 21:48:01 @pendulum_agent.py:312][0m Update time: 9.11023497581482
[32m[20221124 21:48:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:48:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:48:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:48:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:48:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:48:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:48:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:48:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:48:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:48:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:48:02 @pendulum_agent.py:317][0m Evaluation time: 0.708855152130127
[32m[20221124 21:48:02 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.08
[32m[20221124 21:48:02 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:48:02 @pendulum_agent.py:289][0m Total time: 1551.6680538654327
[32m[20221124 21:48:02 @pendulum_agent.py:291][0m 5350000 total steps have happened
[32m[20221124 21:48:02 @pendulum_agent.py:281][0m #------------------------ Iteration 107 --------------------------#
[32m[20221124 21:48:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:48:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:48:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:48:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:48:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:48:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:48:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:48:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:48:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:48:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:48:06 @pendulum_agent.py:307][0m Sample time: 3.638502836227417
[32m[20221124 21:48:16 @pendulum_agent.py:312][0m Update time: 10.148905992507935
[32m[20221124 21:48:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:48:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:48:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:48:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:48:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:48:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:48:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:48:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:48:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:48:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:48:17 @pendulum_agent.py:317][0m Evaluation time: 0.9779341220855713
[32m[20221124 21:48:17 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:48:17 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:48:17 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:48:17 @pendulum_agent.py:289][0m Total time: 1566.720067024231
[32m[20221124 21:48:17 @pendulum_agent.py:291][0m 5400000 total steps have happened
[32m[20221124 21:48:17 @pendulum_agent.py:281][0m #------------------------ Iteration 108 --------------------------#
[32m[20221124 21:48:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:48:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:48:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:48:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:48:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:48:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:48:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:48:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:48:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:48:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:48:21 @pendulum_agent.py:307][0m Sample time: 3.8483262062072754
[32m[20221124 21:48:31 @pendulum_agent.py:312][0m Update time: 9.68099570274353
[32m[20221124 21:48:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:48:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:48:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:48:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:48:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:48:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:48:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:48:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:48:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:48:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:48:32 @pendulum_agent.py:317][0m Evaluation time: 0.9374990463256836
[32m[20221124 21:48:32 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:48:32 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:48:32 @pendulum_agent.py:289][0m Total time: 1581.4601080417633
[32m[20221124 21:48:32 @pendulum_agent.py:291][0m 5450000 total steps have happened
[32m[20221124 21:48:32 @pendulum_agent.py:281][0m #------------------------ Iteration 109 --------------------------#
[32m[20221124 21:48:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.2
[32m[20221124 21:48:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.4
[32m[20221124 21:48:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.2
[32m[20221124 21:48:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.0
[32m[20221124 21:48:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.4
[32m[20221124 21:48:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.6
[32m[20221124 21:48:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.8
[32m[20221124 21:48:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.8
[32m[20221124 21:48:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.0
[32m[20221124 21:48:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.8
[32m[20221124 21:48:36 @pendulum_agent.py:307][0m Sample time: 3.907011032104492
[32m[20221124 21:48:45 @pendulum_agent.py:312][0m Update time: 9.159074783325195
[32m[20221124 21:48:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:48:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:48:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:48:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:48:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:48:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:48:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:48:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:48:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:48:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:48:46 @pendulum_agent.py:317][0m Evaluation time: 0.7107081413269043
[32m[20221124 21:48:46 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.22
[32m[20221124 21:48:46 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:48:46 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:48:46 @pendulum_agent.py:289][0m Total time: 1595.5102961063385
[32m[20221124 21:48:46 @pendulum_agent.py:291][0m 5500000 total steps have happened
[32m[20221124 21:48:46 @pendulum_agent.py:281][0m #------------------------ Iteration 110 --------------------------#
[32m[20221124 21:48:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:48:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:48:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:48:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:48:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:48:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:48:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:48:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:48:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:48:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:48:49 @pendulum_agent.py:307][0m Sample time: 3.5376739501953125
[32m[20221124 21:48:58 @pendulum_agent.py:312][0m Update time: 9.024073362350464
[32m[20221124 21:48:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:48:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:48:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:48:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:48:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:48:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:48:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:48:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:48:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:48:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:48:59 @pendulum_agent.py:317][0m Evaluation time: 0.582758903503418
[32m[20221124 21:48:59 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:48:59 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:48:59 @pendulum_agent.py:289][0m Total time: 1608.9345939159393
[32m[20221124 21:48:59 @pendulum_agent.py:291][0m 5550000 total steps have happened
[32m[20221124 21:48:59 @pendulum_agent.py:281][0m #------------------------ Iteration 111 --------------------------#
[32m[20221124 21:49:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:49:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:49:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:49:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:49:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:49:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:49:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:49:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:49:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:49:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:49:03 @pendulum_agent.py:307][0m Sample time: 3.764234781265259
[32m[20221124 21:49:12 @pendulum_agent.py:312][0m Update time: 9.141946077346802
[32m[20221124 21:49:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:49:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:49:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:49:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:49:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:49:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:49:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:49:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:49:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:49:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:49:13 @pendulum_agent.py:317][0m Evaluation time: 0.5698988437652588
[32m[20221124 21:49:13 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:49:13 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:49:13 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:49:13 @pendulum_agent.py:289][0m Total time: 1622.7051520347595
[32m[20221124 21:49:13 @pendulum_agent.py:291][0m 5600000 total steps have happened
[32m[20221124 21:49:13 @pendulum_agent.py:281][0m #------------------------ Iteration 112 --------------------------#
[32m[20221124 21:49:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:49:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:49:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:49:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:49:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:49:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:49:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:49:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:49:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:49:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:49:17 @pendulum_agent.py:307][0m Sample time: 3.7747139930725098
[32m[20221124 21:49:26 @pendulum_agent.py:312][0m Update time: 9.357164144515991
[32m[20221124 21:49:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:49:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:49:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:49:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:49:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:49:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:49:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:49:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:49:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:49:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:49:27 @pendulum_agent.py:317][0m Evaluation time: 0.5739951133728027
[32m[20221124 21:49:27 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:49:27 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:49:27 @pendulum_agent.py:289][0m Total time: 1636.7128870487213
[32m[20221124 21:49:27 @pendulum_agent.py:291][0m 5650000 total steps have happened
[32m[20221124 21:49:27 @pendulum_agent.py:281][0m #------------------------ Iteration 113 --------------------------#
[32m[20221124 21:49:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:49:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:49:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:49:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:49:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:49:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:49:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:49:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:49:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:49:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:49:31 @pendulum_agent.py:307][0m Sample time: 3.872252941131592
[32m[20221124 21:49:41 @pendulum_agent.py:312][0m Update time: 9.562994956970215
[32m[20221124 21:49:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:49:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:49:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:49:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:49:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:49:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:49:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:49:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:49:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:49:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:49:41 @pendulum_agent.py:317][0m Evaluation time: 0.7078812122344971
[32m[20221124 21:49:42 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:49:42 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:49:42 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:49:42 @pendulum_agent.py:289][0m Total time: 1651.15305685997
[32m[20221124 21:49:42 @pendulum_agent.py:291][0m 5700000 total steps have happened
[32m[20221124 21:49:42 @pendulum_agent.py:281][0m #------------------------ Iteration 114 --------------------------#
[32m[20221124 21:49:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:49:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:49:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:49:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:49:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:49:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:49:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:49:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:49:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:49:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:49:45 @pendulum_agent.py:307][0m Sample time: 3.4907310009002686
[32m[20221124 21:49:54 @pendulum_agent.py:312][0m Update time: 8.956190347671509
[32m[20221124 21:49:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:49:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:49:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:49:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:49:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:49:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:49:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:49:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:49:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:49:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:49:55 @pendulum_agent.py:317][0m Evaluation time: 0.8347787857055664
[32m[20221124 21:49:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:49:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:49:55 @pendulum_agent.py:289][0m Total time: 1664.7265141010284
[32m[20221124 21:49:55 @pendulum_agent.py:291][0m 5750000 total steps have happened
[32m[20221124 21:49:55 @pendulum_agent.py:281][0m #------------------------ Iteration 115 --------------------------#
[32m[20221124 21:49:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.2
[32m[20221124 21:49:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.6
[32m[20221124 21:49:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.2
[32m[20221124 21:49:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.2
[32m[20221124 21:49:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.4
[32m[20221124 21:49:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.6
[32m[20221124 21:49:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.2
[32m[20221124 21:49:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.4
[32m[20221124 21:49:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.8
[32m[20221124 21:49:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.2
[32m[20221124 21:49:58 @pendulum_agent.py:307][0m Sample time: 3.3168230056762695
[32m[20221124 21:50:09 @pendulum_agent.py:312][0m Update time: 10.229343175888062
[32m[20221124 21:50:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:50:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:50:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:50:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:50:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:50:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:50:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:50:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:50:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:50:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:50:10 @pendulum_agent.py:317][0m Evaluation time: 1.0201771259307861
[32m[20221124 21:50:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.98
[32m[20221124 21:50:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:50:10 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:50:10 @pendulum_agent.py:289][0m Total time: 1679.5847227573395
[32m[20221124 21:50:10 @pendulum_agent.py:291][0m 5800000 total steps have happened
[32m[20221124 21:50:10 @pendulum_agent.py:281][0m #------------------------ Iteration 116 --------------------------#
[32m[20221124 21:50:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:50:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:50:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:50:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:50:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:50:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:50:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:50:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:50:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:50:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:50:13 @pendulum_agent.py:307][0m Sample time: 3.4887919425964355
[32m[20221124 21:50:22 @pendulum_agent.py:312][0m Update time: 8.712260246276855
[32m[20221124 21:50:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:50:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:50:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:50:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:50:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:50:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:50:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:50:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:50:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:50:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:50:23 @pendulum_agent.py:317][0m Evaluation time: 1.1726007461547852
[32m[20221124 21:50:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:50:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:50:24 @pendulum_agent.py:289][0m Total time: 1693.2346448898315
[32m[20221124 21:50:24 @pendulum_agent.py:291][0m 5850000 total steps have happened
[32m[20221124 21:50:24 @pendulum_agent.py:281][0m #------------------------ Iteration 117 --------------------------#
[32m[20221124 21:50:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:50:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:50:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:50:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:50:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:50:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:50:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:50:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:50:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:50:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:50:27 @pendulum_agent.py:307][0m Sample time: 3.32552433013916
[32m[20221124 21:50:36 @pendulum_agent.py:312][0m Update time: 8.927059888839722
[32m[20221124 21:50:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:50:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:50:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:50:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:50:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:50:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:50:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:50:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:50:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:50:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:50:37 @pendulum_agent.py:317][0m Evaluation time: 1.166038990020752
[32m[20221124 21:50:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:50:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:50:37 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:50:37 @pendulum_agent.py:289][0m Total time: 1706.9492259025574
[32m[20221124 21:50:37 @pendulum_agent.py:291][0m 5900000 total steps have happened
[32m[20221124 21:50:37 @pendulum_agent.py:281][0m #------------------------ Iteration 118 --------------------------#
[32m[20221124 21:50:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:50:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:50:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:50:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:50:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:50:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:50:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:50:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:50:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:50:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:50:41 @pendulum_agent.py:307][0m Sample time: 3.6637392044067383
[32m[20221124 21:50:51 @pendulum_agent.py:312][0m Update time: 9.949732780456543
[32m[20221124 21:50:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:50:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:50:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:50:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:50:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:50:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:50:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:50:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:50:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:50:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:50:52 @pendulum_agent.py:317][0m Evaluation time: 0.7039151191711426
[32m[20221124 21:50:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:50:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:50:52 @pendulum_agent.py:289][0m Total time: 1721.5578479766846
[32m[20221124 21:50:52 @pendulum_agent.py:291][0m 5950000 total steps have happened
[32m[20221124 21:50:52 @pendulum_agent.py:281][0m #------------------------ Iteration 119 --------------------------#
[32m[20221124 21:50:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:50:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:50:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:50:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:50:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:50:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:50:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:50:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:50:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:50:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:50:56 @pendulum_agent.py:307][0m Sample time: 3.615924835205078
[32m[20221124 21:51:05 @pendulum_agent.py:312][0m Update time: 9.126816987991333
[32m[20221124 21:51:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:51:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:51:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:51:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:51:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:51:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:51:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:51:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:51:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:51:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:51:05 @pendulum_agent.py:317][0m Evaluation time: 0.7200541496276855
[32m[20221124 21:51:06 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:51:06 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:51:06 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:51:06 @pendulum_agent.py:289][0m Total time: 1735.316372871399
[32m[20221124 21:51:06 @pendulum_agent.py:291][0m 6000000 total steps have happened
[32m[20221124 21:51:06 @pendulum_agent.py:281][0m #------------------------ Iteration 120 --------------------------#
[32m[20221124 21:51:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.8
[32m[20221124 21:51:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.0
[32m[20221124 21:51:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.4
[32m[20221124 21:51:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.8
[32m[20221124 21:51:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.6
[32m[20221124 21:51:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.4
[32m[20221124 21:51:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.8
[32m[20221124 21:51:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.8
[32m[20221124 21:51:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.8
[32m[20221124 21:51:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.0
[32m[20221124 21:51:09 @pendulum_agent.py:307][0m Sample time: 3.5238120555877686
[32m[20221124 21:51:19 @pendulum_agent.py:312][0m Update time: 9.610973834991455
[32m[20221124 21:51:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:51:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:51:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:51:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:51:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:51:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:51:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:51:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:51:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:51:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:51:20 @pendulum_agent.py:317][0m Evaluation time: 0.7120890617370605
[32m[20221124 21:51:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.24
[32m[20221124 21:51:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:51:20 @pendulum_agent.py:289][0m Total time: 1749.4297268390656
[32m[20221124 21:51:20 @pendulum_agent.py:291][0m 6050000 total steps have happened
[32m[20221124 21:51:20 @pendulum_agent.py:281][0m #------------------------ Iteration 121 --------------------------#
[32m[20221124 21:51:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.2
[32m[20221124 21:51:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.2
[32m[20221124 21:51:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.6
[32m[20221124 21:51:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.4
[32m[20221124 21:51:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.8
[32m[20221124 21:51:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.6
[32m[20221124 21:51:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.4
[32m[20221124 21:51:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.2
[32m[20221124 21:51:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.6
[32m[20221124 21:51:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.8
[32m[20221124 21:51:24 @pendulum_agent.py:307][0m Sample time: 3.8142788410186768
[32m[20221124 21:51:33 @pendulum_agent.py:312][0m Update time: 9.204416990280151
[32m[20221124 21:51:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:51:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:51:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:51:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:51:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:51:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:51:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:51:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:51:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:51:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:51:33 @pendulum_agent.py:317][0m Evaluation time: 0.5810601711273193
[32m[20221124 21:51:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.58
[32m[20221124 21:51:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:51:34 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:51:34 @pendulum_agent.py:289][0m Total time: 1763.3319458961487
[32m[20221124 21:51:34 @pendulum_agent.py:291][0m 6100000 total steps have happened
[32m[20221124 21:51:34 @pendulum_agent.py:281][0m #------------------------ Iteration 122 --------------------------#
[32m[20221124 21:51:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:51:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:51:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:51:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:51:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:51:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:51:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:51:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:51:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:51:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:51:38 @pendulum_agent.py:307][0m Sample time: 3.7831311225891113
[32m[20221124 21:51:47 @pendulum_agent.py:312][0m Update time: 9.332860946655273
[32m[20221124 21:51:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:51:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:51:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:51:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:51:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:51:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:51:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:51:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:51:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:51:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:51:48 @pendulum_agent.py:317][0m Evaluation time: 0.7301230430603027
[32m[20221124 21:51:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:51:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:51:48 @pendulum_agent.py:289][0m Total time: 1777.4674091339111
[32m[20221124 21:51:48 @pendulum_agent.py:291][0m 6150000 total steps have happened
[32m[20221124 21:51:48 @pendulum_agent.py:281][0m #------------------------ Iteration 123 --------------------------#
[32m[20221124 21:51:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:51:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:51:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:51:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:51:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:51:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:51:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:51:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:51:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:51:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:51:51 @pendulum_agent.py:307][0m Sample time: 3.5818161964416504
[32m[20221124 21:52:02 @pendulum_agent.py:312][0m Update time: 10.082682847976685
[32m[20221124 21:52:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:52:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:52:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:52:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:52:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:52:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:52:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:52:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:52:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:52:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:52:02 @pendulum_agent.py:317][0m Evaluation time: 0.703233003616333
[32m[20221124 21:52:03 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:52:03 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:52:03 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:52:03 @pendulum_agent.py:289][0m Total time: 1792.1151111125946
[32m[20221124 21:52:03 @pendulum_agent.py:291][0m 6200000 total steps have happened
[32m[20221124 21:52:03 @pendulum_agent.py:281][0m #------------------------ Iteration 124 --------------------------#
[32m[20221124 21:52:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:52:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:52:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:52:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:52:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:52:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:52:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:52:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:52:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:52:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:52:06 @pendulum_agent.py:307][0m Sample time: 3.601902723312378
[32m[20221124 21:52:15 @pendulum_agent.py:312][0m Update time: 9.119171142578125
[32m[20221124 21:52:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:52:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:52:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:52:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:52:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:52:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:52:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:52:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:52:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:52:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:52:16 @pendulum_agent.py:317][0m Evaluation time: 0.8387918472290039
[32m[20221124 21:52:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:52:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:52:16 @pendulum_agent.py:289][0m Total time: 1805.964527130127
[32m[20221124 21:52:16 @pendulum_agent.py:291][0m 6250000 total steps have happened
[32m[20221124 21:52:16 @pendulum_agent.py:281][0m #------------------------ Iteration 125 --------------------------#
[32m[20221124 21:52:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:52:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:52:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:52:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:52:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:52:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:52:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:52:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:52:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:52:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:52:20 @pendulum_agent.py:307][0m Sample time: 3.4161150455474854
[32m[20221124 21:52:30 @pendulum_agent.py:312][0m Update time: 9.749129056930542
[32m[20221124 21:52:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:52:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:52:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:52:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:52:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:52:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:52:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:52:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:52:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:52:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:52:31 @pendulum_agent.py:317][0m Evaluation time: 1.0509240627288818
[32m[20221124 21:52:31 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:52:31 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:52:31 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:52:31 @pendulum_agent.py:289][0m Total time: 1820.4595911502838
[32m[20221124 21:52:31 @pendulum_agent.py:291][0m 6300000 total steps have happened
[32m[20221124 21:52:31 @pendulum_agent.py:281][0m #------------------------ Iteration 126 --------------------------#
[32m[20221124 21:52:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:52:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:52:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:52:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:52:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:52:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:52:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:52:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:52:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:52:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:52:34 @pendulum_agent.py:307][0m Sample time: 3.2346231937408447
[32m[20221124 21:52:44 @pendulum_agent.py:312][0m Update time: 9.490769863128662
[32m[20221124 21:52:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:52:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:52:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:52:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:52:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:52:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:52:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:52:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:52:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:52:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:52:45 @pendulum_agent.py:317][0m Evaluation time: 1.0487101078033447
[32m[20221124 21:52:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:52:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:52:45 @pendulum_agent.py:289][0m Total time: 1834.5085139274597
[32m[20221124 21:52:45 @pendulum_agent.py:291][0m 6350000 total steps have happened
[32m[20221124 21:52:45 @pendulum_agent.py:281][0m #------------------------ Iteration 127 --------------------------#
[32m[20221124 21:52:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:52:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:52:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:52:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:52:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:52:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:52:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:52:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:52:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:52:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:52:49 @pendulum_agent.py:307][0m Sample time: 3.6376662254333496
[32m[20221124 21:52:58 @pendulum_agent.py:312][0m Update time: 9.479734897613525
[32m[20221124 21:52:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:52:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:52:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:52:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:52:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:52:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:52:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:52:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:52:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:52:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:52:59 @pendulum_agent.py:317][0m Evaluation time: 0.6971461772918701
[32m[20221124 21:52:59 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:52:59 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:52:59 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:52:59 @pendulum_agent.py:289][0m Total time: 1848.5968589782715
[32m[20221124 21:52:59 @pendulum_agent.py:291][0m 6400000 total steps have happened
[32m[20221124 21:52:59 @pendulum_agent.py:281][0m #------------------------ Iteration 128 --------------------------#
[32m[20221124 21:53:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:53:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:53:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:53:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:53:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:53:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:53:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:53:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:53:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:53:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:53:03 @pendulum_agent.py:307][0m Sample time: 3.6433610916137695
[32m[20221124 21:53:12 @pendulum_agent.py:312][0m Update time: 9.5625479221344
[32m[20221124 21:53:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:53:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:53:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:53:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:53:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:53:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:53:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:53:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:53:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:53:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:53:13 @pendulum_agent.py:317][0m Evaluation time: 0.7207858562469482
[32m[20221124 21:53:13 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:53:13 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:53:13 @pendulum_agent.py:289][0m Total time: 1862.8241920471191
[32m[20221124 21:53:13 @pendulum_agent.py:291][0m 6450000 total steps have happened
[32m[20221124 21:53:13 @pendulum_agent.py:281][0m #------------------------ Iteration 129 --------------------------#
[32m[20221124 21:53:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:53:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:53:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:53:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:53:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:53:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:53:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:53:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:53:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:53:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:53:17 @pendulum_agent.py:307][0m Sample time: 3.8256330490112305
[32m[20221124 21:53:27 @pendulum_agent.py:312][0m Update time: 9.625786066055298
[32m[20221124 21:53:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:53:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:53:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:53:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:53:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:53:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:53:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:53:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:53:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:53:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:53:27 @pendulum_agent.py:317][0m Evaluation time: 0.5802850723266602
[32m[20221124 21:53:28 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:53:28 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:53:28 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:53:28 @pendulum_agent.py:289][0m Total time: 1877.1545169353485
[32m[20221124 21:53:28 @pendulum_agent.py:291][0m 6500000 total steps have happened
[32m[20221124 21:53:28 @pendulum_agent.py:281][0m #------------------------ Iteration 130 --------------------------#
[32m[20221124 21:53:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.0
[32m[20221124 21:53:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.4
[32m[20221124 21:53:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.0
[32m[20221124 21:53:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.0
[32m[20221124 21:53:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.2
[32m[20221124 21:53:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.0
[32m[20221124 21:53:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.0
[32m[20221124 21:53:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.4
[32m[20221124 21:53:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.2
[32m[20221124 21:53:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.8
[32m[20221124 21:53:31 @pendulum_agent.py:307][0m Sample time: 3.6873648166656494
[32m[20221124 21:53:42 @pendulum_agent.py:312][0m Update time: 10.484968900680542
[32m[20221124 21:53:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:53:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:53:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:53:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:53:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:53:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:53:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:53:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:53:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:53:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:53:43 @pendulum_agent.py:317][0m Evaluation time: 0.8307271003723145
[32m[20221124 21:53:43 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.3
[32m[20221124 21:53:43 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:53:43 @pendulum_agent.py:289][0m Total time: 1892.4445350170135
[32m[20221124 21:53:43 @pendulum_agent.py:291][0m 6550000 total steps have happened
[32m[20221124 21:53:43 @pendulum_agent.py:281][0m #------------------------ Iteration 131 --------------------------#
[32m[20221124 21:53:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:53:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:53:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:53:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:53:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:53:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:53:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:53:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:53:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:53:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:53:46 @pendulum_agent.py:307][0m Sample time: 3.499452829360962
[32m[20221124 21:53:56 @pendulum_agent.py:312][0m Update time: 9.441231966018677
[32m[20221124 21:53:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:53:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:53:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:53:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:53:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:53:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:53:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:53:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:53:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:53:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:53:57 @pendulum_agent.py:317][0m Evaluation time: 1.0270471572875977
[32m[20221124 21:53:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:53:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:53:57 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:53:57 @pendulum_agent.py:289][0m Total time: 1906.6923561096191
[32m[20221124 21:53:57 @pendulum_agent.py:291][0m 6600000 total steps have happened
[32m[20221124 21:53:57 @pendulum_agent.py:281][0m #------------------------ Iteration 132 --------------------------#
[32m[20221124 21:53:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:53:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:53:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:53:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:53:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:53:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:53:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:53:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:53:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:53:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:54:01 @pendulum_agent.py:307][0m Sample time: 3.625138998031616
[32m[20221124 21:54:10 @pendulum_agent.py:312][0m Update time: 8.889604091644287
[32m[20221124 21:54:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:54:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:54:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:54:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:54:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:54:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:54:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:54:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:54:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:54:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:54:10 @pendulum_agent.py:317][0m Evaluation time: 0.7318689823150635
[32m[20221124 21:54:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:54:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:54:11 @pendulum_agent.py:289][0m Total time: 1920.2147209644318
[32m[20221124 21:54:11 @pendulum_agent.py:291][0m 6650000 total steps have happened
[32m[20221124 21:54:11 @pendulum_agent.py:281][0m #------------------------ Iteration 133 --------------------------#
[32m[20221124 21:54:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:54:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:54:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:54:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:54:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:54:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:54:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:54:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:54:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:54:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:54:14 @pendulum_agent.py:307][0m Sample time: 3.604200839996338
[32m[20221124 21:54:24 @pendulum_agent.py:312][0m Update time: 9.70949411392212
[32m[20221124 21:54:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:54:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:54:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:54:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:54:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:54:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:54:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:54:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:54:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:54:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:54:25 @pendulum_agent.py:317][0m Evaluation time: 0.5924837589263916
[32m[20221124 21:54:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:54:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:54:25 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:54:25 @pendulum_agent.py:289][0m Total time: 1934.4169461727142
[32m[20221124 21:54:25 @pendulum_agent.py:291][0m 6700000 total steps have happened
[32m[20221124 21:54:25 @pendulum_agent.py:281][0m #------------------------ Iteration 134 --------------------------#
[32m[20221124 21:54:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:54:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:54:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:54:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:54:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:54:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:54:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:54:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:54:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:54:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:54:29 @pendulum_agent.py:307][0m Sample time: 3.761561870574951
[32m[20221124 21:54:39 @pendulum_agent.py:312][0m Update time: 10.657181978225708
[32m[20221124 21:54:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:54:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:54:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:54:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:54:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:54:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:54:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:54:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:54:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:54:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:54:40 @pendulum_agent.py:317][0m Evaluation time: 0.6924099922180176
[32m[20221124 21:54:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:54:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:54:40 @pendulum_agent.py:289][0m Total time: 1949.8310599327087
[32m[20221124 21:54:40 @pendulum_agent.py:291][0m 6750000 total steps have happened
[32m[20221124 21:54:40 @pendulum_agent.py:281][0m #------------------------ Iteration 135 --------------------------#
[32m[20221124 21:54:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:54:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:54:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:54:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:54:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:54:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:54:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:54:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:54:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:54:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:54:44 @pendulum_agent.py:307][0m Sample time: 3.7988839149475098
[32m[20221124 21:54:54 @pendulum_agent.py:312][0m Update time: 10.376890897750854
[32m[20221124 21:54:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:54:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:54:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:54:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:54:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:54:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:54:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:54:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:54:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:54:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:54:55 @pendulum_agent.py:317][0m Evaluation time: 0.7037792205810547
[32m[20221124 21:54:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:54:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:54:55 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:54:55 @pendulum_agent.py:289][0m Total time: 1964.9957511425018
[32m[20221124 21:54:55 @pendulum_agent.py:291][0m 6800000 total steps have happened
[32m[20221124 21:54:55 @pendulum_agent.py:281][0m #------------------------ Iteration 136 --------------------------#
[32m[20221124 21:54:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:54:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:54:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:54:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:54:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:54:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:54:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:54:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:54:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:54:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:54:59 @pendulum_agent.py:307][0m Sample time: 3.6051998138427734
[32m[20221124 21:55:08 @pendulum_agent.py:312][0m Update time: 9.268304109573364
[32m[20221124 21:55:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:55:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:55:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:55:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:55:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:55:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:55:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:55:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:55:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:55:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:55:09 @pendulum_agent.py:317][0m Evaluation time: 0.9333100318908691
[32m[20221124 21:55:09 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:55:09 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:55:09 @pendulum_agent.py:289][0m Total time: 1979.083419084549
[32m[20221124 21:55:09 @pendulum_agent.py:291][0m 6850000 total steps have happened
[32m[20221124 21:55:09 @pendulum_agent.py:281][0m #------------------------ Iteration 137 --------------------------#
[32m[20221124 21:55:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:55:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:55:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:55:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:55:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:55:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:55:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:55:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:55:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:55:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:55:13 @pendulum_agent.py:307][0m Sample time: 3.679733991622925
[32m[20221124 21:55:23 @pendulum_agent.py:312][0m Update time: 9.432394981384277
[32m[20221124 21:55:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:55:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:55:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:55:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:55:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:55:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:55:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:55:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:55:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:55:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:55:23 @pendulum_agent.py:317][0m Evaluation time: 0.6999297142028809
[32m[20221124 21:55:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:55:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:55:24 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:55:24 @pendulum_agent.py:289][0m Total time: 1993.185646057129
[32m[20221124 21:55:24 @pendulum_agent.py:291][0m 6900000 total steps have happened
[32m[20221124 21:55:24 @pendulum_agent.py:281][0m #------------------------ Iteration 138 --------------------------#
[32m[20221124 21:55:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:55:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:55:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:55:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:55:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:55:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:55:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:55:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:55:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:55:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:55:27 @pendulum_agent.py:307][0m Sample time: 3.7130651473999023
[32m[20221124 21:55:37 @pendulum_agent.py:312][0m Update time: 10.0835599899292
[32m[20221124 21:55:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:55:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:55:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:55:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:55:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:55:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:55:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:55:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:55:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:55:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:55:38 @pendulum_agent.py:317][0m Evaluation time: 0.677034854888916
[32m[20221124 21:55:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:55:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:55:38 @pendulum_agent.py:289][0m Total time: 2007.957946062088
[32m[20221124 21:55:38 @pendulum_agent.py:291][0m 6950000 total steps have happened
[32m[20221124 21:55:38 @pendulum_agent.py:281][0m #------------------------ Iteration 139 --------------------------#
[32m[20221124 21:55:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:55:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:55:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:55:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:55:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:55:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:55:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:55:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:55:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:55:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:55:42 @pendulum_agent.py:307][0m Sample time: 3.433948278427124
[32m[20221124 21:55:51 @pendulum_agent.py:312][0m Update time: 9.313687086105347
[32m[20221124 21:55:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:55:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:55:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:55:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:55:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:55:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:55:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:55:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:55:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:55:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:55:52 @pendulum_agent.py:317][0m Evaluation time: 0.925560712814331
[32m[20221124 21:55:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:55:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:55:52 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:55:52 @pendulum_agent.py:289][0m Total time: 2021.8982260227203
[32m[20221124 21:55:52 @pendulum_agent.py:291][0m 7000000 total steps have happened
[32m[20221124 21:55:52 @pendulum_agent.py:281][0m #------------------------ Iteration 140 --------------------------#
[32m[20221124 21:55:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:55:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:55:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:55:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:55:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:55:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:55:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:55:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:55:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:55:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:55:56 @pendulum_agent.py:307][0m Sample time: 3.3113980293273926
[32m[20221124 21:56:06 @pendulum_agent.py:312][0m Update time: 10.790215969085693
[32m[20221124 21:56:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:56:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:56:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:56:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:56:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:56:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:56:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:56:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:56:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:56:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:56:08 @pendulum_agent.py:317][0m Evaluation time: 1.6858980655670166
[32m[20221124 21:56:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:56:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:56:08 @pendulum_agent.py:289][0m Total time: 2037.9867260456085
[32m[20221124 21:56:08 @pendulum_agent.py:291][0m 7050000 total steps have happened
[32m[20221124 21:56:08 @pendulum_agent.py:281][0m #------------------------ Iteration 141 --------------------------#
[32m[20221124 21:56:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:56:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:56:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:56:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:56:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:56:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:56:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:56:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:56:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:56:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:56:12 @pendulum_agent.py:307][0m Sample time: 3.8010668754577637
[32m[20221124 21:56:21 @pendulum_agent.py:312][0m Update time: 9.16507625579834
[32m[20221124 21:56:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:56:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:56:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:56:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:56:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:56:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:56:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:56:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:56:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:56:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:56:22 @pendulum_agent.py:317][0m Evaluation time: 0.7269246578216553
[32m[20221124 21:56:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:56:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:56:22 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:56:22 @pendulum_agent.py:289][0m Total time: 2051.955904006958
[32m[20221124 21:56:22 @pendulum_agent.py:291][0m 7100000 total steps have happened
[32m[20221124 21:56:22 @pendulum_agent.py:281][0m #------------------------ Iteration 142 --------------------------#
[32m[20221124 21:56:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:56:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:56:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:56:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:56:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:56:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:56:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:56:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:56:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:56:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:56:26 @pendulum_agent.py:307][0m Sample time: 3.6533219814300537
[32m[20221124 21:56:36 @pendulum_agent.py:312][0m Update time: 10.123075008392334
[32m[20221124 21:56:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:56:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:56:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:56:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:56:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:56:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:56:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:56:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:56:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:56:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:56:37 @pendulum_agent.py:317][0m Evaluation time: 0.8887369632720947
[32m[20221124 21:56:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:56:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:56:37 @pendulum_agent.py:289][0m Total time: 2067.0225100517273
[32m[20221124 21:56:37 @pendulum_agent.py:291][0m 7150000 total steps have happened
[32m[20221124 21:56:37 @pendulum_agent.py:281][0m #------------------------ Iteration 143 --------------------------#
[32m[20221124 21:56:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:56:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:56:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:56:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:56:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:56:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:56:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:56:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:56:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:56:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:56:42 @pendulum_agent.py:307][0m Sample time: 4.584430932998657
[32m[20221124 21:56:51 @pendulum_agent.py:312][0m Update time: 9.093830108642578
[32m[20221124 21:56:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:56:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:56:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:56:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:56:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:56:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:56:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:56:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:56:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:56:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:56:52 @pendulum_agent.py:317][0m Evaluation time: 0.7061090469360352
[32m[20221124 21:56:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:56:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:56:52 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:56:52 @pendulum_agent.py:289][0m Total time: 2081.677103996277
[32m[20221124 21:56:52 @pendulum_agent.py:291][0m 7200000 total steps have happened
[32m[20221124 21:56:52 @pendulum_agent.py:281][0m #------------------------ Iteration 144 --------------------------#
[32m[20221124 21:56:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.8
[32m[20221124 21:56:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.4
[32m[20221124 21:56:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.6
[32m[20221124 21:56:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.6
[32m[20221124 21:56:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.2
[32m[20221124 21:56:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.4
[32m[20221124 21:56:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.8
[32m[20221124 21:56:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.8
[32m[20221124 21:56:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.0
[32m[20221124 21:56:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.4
[32m[20221124 21:56:56 @pendulum_agent.py:307][0m Sample time: 3.5272791385650635
[32m[20221124 21:57:05 @pendulum_agent.py:312][0m Update time: 9.702733039855957
[32m[20221124 21:57:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:57:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:57:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:57:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:57:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:57:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:57:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:57:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:57:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:57:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:57:06 @pendulum_agent.py:317][0m Evaluation time: 0.8046667575836182
[32m[20221124 21:57:06 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.3
[32m[20221124 21:57:06 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:57:06 @pendulum_agent.py:289][0m Total time: 2095.970010995865
[32m[20221124 21:57:06 @pendulum_agent.py:291][0m 7250000 total steps have happened
[32m[20221124 21:57:06 @pendulum_agent.py:281][0m #------------------------ Iteration 145 --------------------------#
[32m[20221124 21:57:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.8
[32m[20221124 21:57:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.4
[32m[20221124 21:57:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.2
[32m[20221124 21:57:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.0
[32m[20221124 21:57:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.4
[32m[20221124 21:57:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.6
[32m[20221124 21:57:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.8
[32m[20221124 21:57:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.4
[32m[20221124 21:57:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.0
[32m[20221124 21:57:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.2
[32m[20221124 21:57:10 @pendulum_agent.py:307][0m Sample time: 3.6515469551086426
[32m[20221124 21:57:19 @pendulum_agent.py:312][0m Update time: 9.253461122512817
[32m[20221124 21:57:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:57:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:57:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:57:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:57:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:57:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:57:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:57:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:57:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:57:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:57:20 @pendulum_agent.py:317][0m Evaluation time: 0.7192680835723877
[32m[20221124 21:57:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.18
[32m[20221124 21:57:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:57:20 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:57:20 @pendulum_agent.py:289][0m Total time: 2109.8575739860535
[32m[20221124 21:57:20 @pendulum_agent.py:291][0m 7300000 total steps have happened
[32m[20221124 21:57:20 @pendulum_agent.py:281][0m #------------------------ Iteration 146 --------------------------#
[32m[20221124 21:57:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:57:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:57:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:57:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:57:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:57:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:57:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:57:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:57:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:57:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:57:24 @pendulum_agent.py:307][0m Sample time: 3.7894508838653564
[32m[20221124 21:57:33 @pendulum_agent.py:312][0m Update time: 9.139045000076294
[32m[20221124 21:57:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:57:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:57:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:57:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:57:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:57:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:57:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:57:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:57:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:57:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:57:34 @pendulum_agent.py:317][0m Evaluation time: 0.7174928188323975
[32m[20221124 21:57:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:57:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:57:34 @pendulum_agent.py:289][0m Total time: 2123.768967151642
[32m[20221124 21:57:34 @pendulum_agent.py:291][0m 7350000 total steps have happened
[32m[20221124 21:57:34 @pendulum_agent.py:281][0m #------------------------ Iteration 147 --------------------------#
[32m[20221124 21:57:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:57:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:57:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:57:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:57:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:57:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:57:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:57:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:57:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:57:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:57:38 @pendulum_agent.py:307][0m Sample time: 3.5745012760162354
[32m[20221124 21:57:47 @pendulum_agent.py:312][0m Update time: 9.153552770614624
[32m[20221124 21:57:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:57:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:57:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:57:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:57:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:57:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:57:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:57:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:57:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:57:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:57:48 @pendulum_agent.py:317][0m Evaluation time: 0.7032623291015625
[32m[20221124 21:57:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:57:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:57:48 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:57:48 @pendulum_agent.py:289][0m Total time: 2137.4907701015472
[32m[20221124 21:57:48 @pendulum_agent.py:291][0m 7400000 total steps have happened
[32m[20221124 21:57:48 @pendulum_agent.py:281][0m #------------------------ Iteration 148 --------------------------#
[32m[20221124 21:57:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:57:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:57:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:57:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:57:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:57:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:57:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:57:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:57:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:57:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:57:51 @pendulum_agent.py:307][0m Sample time: 3.536742925643921
[32m[20221124 21:58:01 @pendulum_agent.py:312][0m Update time: 9.09977912902832
[32m[20221124 21:58:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:58:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:58:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:58:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:58:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:58:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:58:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:58:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:58:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:58:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:58:01 @pendulum_agent.py:317][0m Evaluation time: 0.8238358497619629
[32m[20221124 21:58:02 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:58:02 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:58:02 @pendulum_agent.py:289][0m Total time: 2151.223037004471
[32m[20221124 21:58:02 @pendulum_agent.py:291][0m 7450000 total steps have happened
[32m[20221124 21:58:02 @pendulum_agent.py:281][0m #------------------------ Iteration 149 --------------------------#
[32m[20221124 21:58:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.2
[32m[20221124 21:58:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.0
[32m[20221124 21:58:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:58:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.4
[32m[20221124 21:58:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.2
[32m[20221124 21:58:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.0
[32m[20221124 21:58:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.0
[32m[20221124 21:58:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:58:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.8
[32m[20221124 21:58:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.8
[32m[20221124 21:58:05 @pendulum_agent.py:307][0m Sample time: 3.43196702003479
[32m[20221124 21:58:14 @pendulum_agent.py:312][0m Update time: 9.038215160369873
[32m[20221124 21:58:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:58:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:58:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:58:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:58:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:58:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:58:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:58:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:58:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:58:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:58:15 @pendulum_agent.py:317][0m Evaluation time: 1.040125846862793
[32m[20221124 21:58:15 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.34
[32m[20221124 21:58:15 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:58:15 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:58:15 @pendulum_agent.py:289][0m Total time: 2165.013221025467
[32m[20221124 21:58:15 @pendulum_agent.py:291][0m 7500000 total steps have happened
[32m[20221124 21:58:15 @pendulum_agent.py:281][0m #------------------------ Iteration 150 --------------------------#
[32m[20221124 21:58:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:58:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:58:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:58:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:58:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:58:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:58:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:58:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:58:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:58:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:58:19 @pendulum_agent.py:307][0m Sample time: 3.292465925216675
[32m[20221124 21:58:28 @pendulum_agent.py:312][0m Update time: 8.868251085281372
[32m[20221124 21:58:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:58:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:58:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:58:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:58:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:58:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:58:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:58:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:58:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:58:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:58:29 @pendulum_agent.py:317][0m Evaluation time: 1.1594769954681396
[32m[20221124 21:58:29 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:58:29 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:58:29 @pendulum_agent.py:289][0m Total time: 2178.6001460552216
[32m[20221124 21:58:29 @pendulum_agent.py:291][0m 7550000 total steps have happened
[32m[20221124 21:58:29 @pendulum_agent.py:281][0m #------------------------ Iteration 151 --------------------------#
[32m[20221124 21:58:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:58:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:58:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:58:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:58:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:58:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:58:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:58:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:58:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:58:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:58:32 @pendulum_agent.py:307][0m Sample time: 3.332805871963501
[32m[20221124 21:58:41 @pendulum_agent.py:312][0m Update time: 8.909090995788574
[32m[20221124 21:58:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:58:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:58:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:58:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:58:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:58:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:58:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:58:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:58:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:58:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:58:43 @pendulum_agent.py:317][0m Evaluation time: 1.837334156036377
[32m[20221124 21:58:43 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:58:43 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:58:43 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:58:43 @pendulum_agent.py:289][0m Total time: 2192.957690000534
[32m[20221124 21:58:43 @pendulum_agent.py:291][0m 7600000 total steps have happened
[32m[20221124 21:58:43 @pendulum_agent.py:281][0m #------------------------ Iteration 152 --------------------------#
[32m[20221124 21:58:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:58:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:58:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:58:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:58:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:58:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:58:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:58:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:58:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:58:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:58:47 @pendulum_agent.py:307][0m Sample time: 3.529733180999756
[32m[20221124 21:58:56 @pendulum_agent.py:312][0m Update time: 8.992263793945312
[32m[20221124 21:58:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:58:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:58:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:58:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:58:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:58:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:58:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:58:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:58:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:58:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:58:57 @pendulum_agent.py:317][0m Evaluation time: 0.6969091892242432
[32m[20221124 21:58:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:58:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:58:57 @pendulum_agent.py:289][0m Total time: 2206.4430990219116
[32m[20221124 21:58:57 @pendulum_agent.py:291][0m 7650000 total steps have happened
[32m[20221124 21:58:57 @pendulum_agent.py:281][0m #------------------------ Iteration 153 --------------------------#
[32m[20221124 21:58:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:58:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:58:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:58:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:58:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.6
[32m[20221124 21:58:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:58:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:58:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:58:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 7.4
[32m[20221124 21:58:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.6
[32m[20221124 21:59:01 @pendulum_agent.py:307][0m Sample time: 3.679922103881836
[32m[20221124 21:59:09 @pendulum_agent.py:312][0m Update time: 8.904579877853394
[32m[20221124 21:59:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:59:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:59:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:59:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:59:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:59:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:59:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:59:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:59:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:59:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:59:10 @pendulum_agent.py:317][0m Evaluation time: 0.9497861862182617
[32m[20221124 21:59:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 1.96
[32m[20221124 21:59:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:59:11 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:59:11 @pendulum_agent.py:289][0m Total time: 2220.2461018562317
[32m[20221124 21:59:11 @pendulum_agent.py:291][0m 7700000 total steps have happened
[32m[20221124 21:59:11 @pendulum_agent.py:281][0m #------------------------ Iteration 154 --------------------------#
[32m[20221124 21:59:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:59:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:59:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:59:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:59:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:59:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:59:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:59:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:59:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:59:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:59:15 @pendulum_agent.py:307][0m Sample time: 3.870573043823242
[32m[20221124 21:59:23 @pendulum_agent.py:312][0m Update time: 8.817318201065063
[32m[20221124 21:59:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:59:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:59:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:59:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:59:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:59:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:59:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:59:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:59:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:59:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:59:24 @pendulum_agent.py:317][0m Evaluation time: 0.9390218257904053
[32m[20221124 21:59:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:59:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:59:25 @pendulum_agent.py:289][0m Total time: 2234.142855167389
[32m[20221124 21:59:25 @pendulum_agent.py:291][0m 7750000 total steps have happened
[32m[20221124 21:59:25 @pendulum_agent.py:281][0m #------------------------ Iteration 155 --------------------------#
[32m[20221124 21:59:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:59:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:59:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:59:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:59:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:59:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:59:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:59:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:59:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:59:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:59:29 @pendulum_agent.py:307][0m Sample time: 3.9777917861938477
[32m[20221124 21:59:38 @pendulum_agent.py:312][0m Update time: 9.115308046340942
[32m[20221124 21:59:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:59:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:59:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:59:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:59:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:59:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:59:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:59:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:59:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:59:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:59:38 @pendulum_agent.py:317][0m Evaluation time: 0.694655179977417
[32m[20221124 21:59:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:59:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:59:39 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:59:39 @pendulum_agent.py:289][0m Total time: 2248.228049993515
[32m[20221124 21:59:39 @pendulum_agent.py:291][0m 7800000 total steps have happened
[32m[20221124 21:59:39 @pendulum_agent.py:281][0m #------------------------ Iteration 156 --------------------------#
[32m[20221124 21:59:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:59:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:59:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:59:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:59:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:59:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:59:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:59:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:59:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:59:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:59:42 @pendulum_agent.py:307][0m Sample time: 3.5324838161468506
[32m[20221124 21:59:51 @pendulum_agent.py:312][0m Update time: 9.04645299911499
[32m[20221124 21:59:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:59:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:59:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:59:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:59:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:59:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:59:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:59:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:59:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:59:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:59:52 @pendulum_agent.py:317][0m Evaluation time: 0.5777230262756348
[32m[20221124 21:59:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:59:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:59:52 @pendulum_agent.py:289][0m Total time: 2261.6809258461
[32m[20221124 21:59:52 @pendulum_agent.py:291][0m 7850000 total steps have happened
[32m[20221124 21:59:52 @pendulum_agent.py:281][0m #------------------------ Iteration 157 --------------------------#
[32m[20221124 21:59:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:59:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:59:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:59:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:59:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:59:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:59:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:59:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:59:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:59:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:59:56 @pendulum_agent.py:307][0m Sample time: 3.8184597492218018
[32m[20221124 22:00:05 @pendulum_agent.py:312][0m Update time: 9.03149700164795
[32m[20221124 22:00:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:00:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:00:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:00:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:00:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:00:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:00:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:00:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:00:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:00:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:00:06 @pendulum_agent.py:317][0m Evaluation time: 0.6678290367126465
[32m[20221124 22:00:06 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:00:06 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:00:06 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:00:06 @pendulum_agent.py:289][0m Total time: 2275.495483160019
[32m[20221124 22:00:06 @pendulum_agent.py:291][0m 7900000 total steps have happened
[32m[20221124 22:00:06 @pendulum_agent.py:281][0m #------------------------ Iteration 158 --------------------------#
[32m[20221124 22:00:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:00:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:00:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:00:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:00:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:00:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:00:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:00:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:00:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:00:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:00:10 @pendulum_agent.py:307][0m Sample time: 3.8645360469818115
[32m[20221124 22:00:19 @pendulum_agent.py:312][0m Update time: 9.053174018859863
[32m[20221124 22:00:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:00:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:00:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:00:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:00:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:00:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:00:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:00:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:00:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:00:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:00:19 @pendulum_agent.py:317][0m Evaluation time: 0.5736739635467529
[32m[20221124 22:00:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:00:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:00:20 @pendulum_agent.py:289][0m Total time: 2289.2954380512238
[32m[20221124 22:00:20 @pendulum_agent.py:291][0m 7950000 total steps have happened
[32m[20221124 22:00:20 @pendulum_agent.py:281][0m #------------------------ Iteration 159 --------------------------#
[32m[20221124 22:00:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.8
[32m[20221124 22:00:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.2
[32m[20221124 22:00:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.8
[32m[20221124 22:00:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.4
[32m[20221124 22:00:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.4
[32m[20221124 22:00:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.2
[32m[20221124 22:00:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.4
[32m[20221124 22:00:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.2
[32m[20221124 22:00:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.2
[32m[20221124 22:00:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.0
[32m[20221124 22:00:24 @pendulum_agent.py:307][0m Sample time: 3.8637619018554688
[32m[20221124 22:00:38 @pendulum_agent.py:312][0m Update time: 14.033324003219604
[32m[20221124 22:00:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:00:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:00:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:00:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:00:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:00:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:00:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:00:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:00:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:00:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:00:38 @pendulum_agent.py:317][0m Evaluation time: 0.6823689937591553
[32m[20221124 22:00:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.76
[32m[20221124 22:00:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:00:39 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:00:39 @pendulum_agent.py:289][0m Total time: 2308.156536102295
[32m[20221124 22:00:39 @pendulum_agent.py:291][0m 8000000 total steps have happened
[32m[20221124 22:00:39 @pendulum_agent.py:281][0m #------------------------ Iteration 160 --------------------------#
[32m[20221124 22:00:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:00:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:00:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:00:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:00:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:00:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:00:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:00:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:00:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:00:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:00:42 @pendulum_agent.py:307][0m Sample time: 3.5610270500183105
[32m[20221124 22:00:51 @pendulum_agent.py:312][0m Update time: 8.98792290687561
[32m[20221124 22:00:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 25.0
[32m[20221124 22:00:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 25.0
[32m[20221124 22:00:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 25.0
[32m[20221124 22:00:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 25.0
[32m[20221124 22:00:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 25.0
[32m[20221124 22:00:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 25.0
[32m[20221124 22:00:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 25.0
[32m[20221124 22:00:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 25.0
[32m[20221124 22:00:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 25.0
[32m[20221124 22:00:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 25.0
[32m[20221124 22:00:52 @pendulum_agent.py:317][0m Evaluation time: 0.831791877746582
[32m[20221124 22:00:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:00:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:00:52 @pendulum_agent.py:289][0m Total time: 2321.8337671756744
[32m[20221124 22:00:52 @pendulum_agent.py:291][0m 8050000 total steps have happened
[32m[20221124 22:00:52 @pendulum_agent.py:281][0m #------------------------ Iteration 161 --------------------------#
[32m[20221124 22:00:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:00:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:00:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:00:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:00:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:00:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:00:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:00:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:00:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:00:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:00:56 @pendulum_agent.py:307][0m Sample time: 3.3187990188598633
[32m[20221124 22:01:04 @pendulum_agent.py:312][0m Update time: 8.932515144348145
[32m[20221124 22:01:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:01:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:01:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:01:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:01:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:01:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:01:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:01:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:01:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:01:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:01:06 @pendulum_agent.py:317][0m Evaluation time: 1.040280818939209
[32m[20221124 22:01:06 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:01:06 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:01:06 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:01:06 @pendulum_agent.py:289][0m Total time: 2335.400228023529
[32m[20221124 22:01:06 @pendulum_agent.py:291][0m 8100000 total steps have happened
[32m[20221124 22:01:06 @pendulum_agent.py:281][0m #------------------------ Iteration 162 --------------------------#
[32m[20221124 22:01:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:01:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:01:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:01:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:01:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:01:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:01:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:01:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:01:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:01:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:01:09 @pendulum_agent.py:307][0m Sample time: 3.452077865600586
[32m[20221124 22:01:24 @pendulum_agent.py:312][0m Update time: 14.366636991500854
[32m[20221124 22:01:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:01:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:01:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:01:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:01:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:01:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:01:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:01:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:01:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:01:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:01:25 @pendulum_agent.py:317][0m Evaluation time: 1.1366090774536133
[32m[20221124 22:01:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:01:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:01:25 @pendulum_agent.py:289][0m Total time: 2354.6261291503906
[32m[20221124 22:01:25 @pendulum_agent.py:291][0m 8150000 total steps have happened
[32m[20221124 22:01:25 @pendulum_agent.py:281][0m #------------------------ Iteration 163 --------------------------#
[32m[20221124 22:01:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:01:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:01:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:01:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:01:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:01:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:01:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:01:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:01:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:01:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:01:28 @pendulum_agent.py:307][0m Sample time: 3.338593006134033
[32m[20221124 22:01:53 @pendulum_agent.py:312][0m Update time: 24.339004278182983
[32m[20221124 22:01:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:01:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:01:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:01:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:01:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:01:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:01:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:01:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:01:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:01:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:01:54 @pendulum_agent.py:317][0m Evaluation time: 1.1479098796844482
[32m[20221124 22:01:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:01:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:01:54 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:01:54 @pendulum_agent.py:289][0m Total time: 2383.7132709026337
[32m[20221124 22:01:54 @pendulum_agent.py:291][0m 8200000 total steps have happened
[32m[20221124 22:01:54 @pendulum_agent.py:281][0m #------------------------ Iteration 164 --------------------------#
[32m[20221124 22:01:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.6
[32m[20221124 22:01:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.4
[32m[20221124 22:01:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.6
[32m[20221124 22:01:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.6
[32m[20221124 22:01:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.6
[32m[20221124 22:01:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.4
[32m[20221124 22:01:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.6
[32m[20221124 22:01:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.6
[32m[20221124 22:01:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.6
[32m[20221124 22:01:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.6
[32m[20221124 22:01:58 @pendulum_agent.py:307][0m Sample time: 3.6716461181640625
[32m[20221124 22:02:07 @pendulum_agent.py:312][0m Update time: 9.10108494758606
[32m[20221124 22:02:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:02:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:02:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:02:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:02:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:02:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:02:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:02:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:02:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:02:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:02:08 @pendulum_agent.py:317][0m Evaluation time: 0.6895859241485596
[32m[20221124 22:02:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.56
[32m[20221124 22:02:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:02:08 @pendulum_agent.py:289][0m Total time: 2397.458920955658
[32m[20221124 22:02:08 @pendulum_agent.py:291][0m 8250000 total steps have happened
[32m[20221124 22:02:08 @pendulum_agent.py:281][0m #------------------------ Iteration 165 --------------------------#
[32m[20221124 22:02:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:02:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:02:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:02:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:02:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:02:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:02:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:02:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:02:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:02:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:02:12 @pendulum_agent.py:307][0m Sample time: 3.6566262245178223
[32m[20221124 22:02:25 @pendulum_agent.py:312][0m Update time: 13.225429058074951
[32m[20221124 22:02:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:02:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:02:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:02:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:02:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:02:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:02:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:02:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:02:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:02:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:02:25 @pendulum_agent.py:317][0m Evaluation time: 0.7004847526550293
[32m[20221124 22:02:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:02:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:02:26 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:02:26 @pendulum_agent.py:289][0m Total time: 2415.322818994522
[32m[20221124 22:02:26 @pendulum_agent.py:291][0m 8300000 total steps have happened
[32m[20221124 22:02:26 @pendulum_agent.py:281][0m #------------------------ Iteration 166 --------------------------#
[32m[20221124 22:02:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:02:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:02:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:02:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:02:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:02:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:02:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:02:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:02:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:02:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:02:29 @pendulum_agent.py:307][0m Sample time: 3.4941301345825195
[32m[20221124 22:02:55 @pendulum_agent.py:312][0m Update time: 26.094993829727173
[32m[20221124 22:02:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:02:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:02:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:02:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:02:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:02:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:02:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:02:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:02:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:02:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:02:56 @pendulum_agent.py:317][0m Evaluation time: 0.6894650459289551
[32m[20221124 22:02:56 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:02:56 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:02:56 @pendulum_agent.py:289][0m Total time: 2445.870798110962
[32m[20221124 22:02:56 @pendulum_agent.py:291][0m 8350000 total steps have happened
[32m[20221124 22:02:56 @pendulum_agent.py:281][0m #------------------------ Iteration 167 --------------------------#
[32m[20221124 22:02:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:02:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:02:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:02:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:02:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:02:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:02:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:02:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:02:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:02:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:03:00 @pendulum_agent.py:307][0m Sample time: 3.80623197555542
[32m[20221124 22:03:09 @pendulum_agent.py:312][0m Update time: 8.971905946731567
[32m[20221124 22:03:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:03:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:03:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:03:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:03:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:03:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:03:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:03:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:03:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:03:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:03:10 @pendulum_agent.py:317][0m Evaluation time: 0.5571320056915283
[32m[20221124 22:03:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:03:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:03:10 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:03:10 @pendulum_agent.py:289][0m Total time: 2459.494289159775
[32m[20221124 22:03:10 @pendulum_agent.py:291][0m 8400000 total steps have happened
[32m[20221124 22:03:10 @pendulum_agent.py:281][0m #------------------------ Iteration 168 --------------------------#
[32m[20221124 22:03:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.8
[32m[20221124 22:03:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.6
[32m[20221124 22:03:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.2
[32m[20221124 22:03:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.0
[32m[20221124 22:03:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.6
[32m[20221124 22:03:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.4
[32m[20221124 22:03:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.0
[32m[20221124 22:03:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.0
[32m[20221124 22:03:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.6
[32m[20221124 22:03:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.0
[32m[20221124 22:03:14 @pendulum_agent.py:307][0m Sample time: 3.741086006164551
[32m[20221124 22:03:23 @pendulum_agent.py:312][0m Update time: 8.977483034133911
[32m[20221124 22:03:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:03:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:03:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:03:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:03:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:03:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:03:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:03:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:03:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:03:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:03:23 @pendulum_agent.py:317][0m Evaluation time: 0.7140460014343262
[32m[20221124 22:03:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.82
[32m[20221124 22:03:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:03:24 @pendulum_agent.py:289][0m Total time: 2473.2054510116577
[32m[20221124 22:03:24 @pendulum_agent.py:291][0m 8450000 total steps have happened
[32m[20221124 22:03:24 @pendulum_agent.py:281][0m #------------------------ Iteration 169 --------------------------#
[32m[20221124 22:03:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:03:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:03:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:03:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:03:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:03:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:03:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:03:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:03:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:03:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:03:27 @pendulum_agent.py:307][0m Sample time: 3.6253252029418945
[32m[20221124 22:03:36 @pendulum_agent.py:312][0m Update time: 8.965374946594238
[32m[20221124 22:03:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:03:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:03:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:03:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:03:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:03:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:03:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:03:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:03:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:03:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:03:37 @pendulum_agent.py:317][0m Evaluation time: 0.7059569358825684
[32m[20221124 22:03:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:03:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:03:37 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:03:37 @pendulum_agent.py:289][0m Total time: 2486.768854856491
[32m[20221124 22:03:37 @pendulum_agent.py:291][0m 8500000 total steps have happened
[32m[20221124 22:03:37 @pendulum_agent.py:281][0m #------------------------ Iteration 170 --------------------------#
[32m[20221124 22:03:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:03:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:03:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:03:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:03:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:03:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:03:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:03:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:03:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:03:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:03:41 @pendulum_agent.py:307][0m Sample time: 3.6315858364105225
[32m[20221124 22:03:50 @pendulum_agent.py:312][0m Update time: 8.914369106292725
[32m[20221124 22:03:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:03:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:03:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:03:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:03:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:03:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:03:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:03:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:03:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:03:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:03:51 @pendulum_agent.py:317][0m Evaluation time: 0.8439640998840332
[32m[20221124 22:03:51 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:03:51 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:03:51 @pendulum_agent.py:289][0m Total time: 2500.4509291648865
[32m[20221124 22:03:51 @pendulum_agent.py:291][0m 8550000 total steps have happened
[32m[20221124 22:03:51 @pendulum_agent.py:281][0m #------------------------ Iteration 171 --------------------------#
[32m[20221124 22:03:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:03:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:03:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:03:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:03:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:03:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:03:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:03:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:03:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:03:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:03:54 @pendulum_agent.py:307][0m Sample time: 3.289931058883667
[32m[20221124 22:04:23 @pendulum_agent.py:312][0m Update time: 28.619590282440186
[32m[20221124 22:04:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:04:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:04:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:04:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:04:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:04:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:04:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:04:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:04:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:04:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:04:24 @pendulum_agent.py:317][0m Evaluation time: 1.0435099601745605
[32m[20221124 22:04:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:04:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:04:24 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:04:24 @pendulum_agent.py:289][0m Total time: 2533.6820662021637
[32m[20221124 22:04:24 @pendulum_agent.py:291][0m 8600000 total steps have happened
[32m[20221124 22:04:24 @pendulum_agent.py:281][0m #------------------------ Iteration 172 --------------------------#
[32m[20221124 22:04:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:04:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:04:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:04:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:04:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:04:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:04:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:04:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:04:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:04:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:04:27 @pendulum_agent.py:307][0m Sample time: 3.340963125228882
[32m[20221124 22:04:36 @pendulum_agent.py:312][0m Update time: 9.008954048156738
[32m[20221124 22:04:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:04:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:04:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:04:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:04:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:04:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:04:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:04:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:04:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:04:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:04:37 @pendulum_agent.py:317][0m Evaluation time: 1.0402588844299316
[32m[20221124 22:04:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:04:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:04:38 @pendulum_agent.py:289][0m Total time: 2547.3404788970947
[32m[20221124 22:04:38 @pendulum_agent.py:291][0m 8650000 total steps have happened
[32m[20221124 22:04:38 @pendulum_agent.py:281][0m #------------------------ Iteration 173 --------------------------#
[32m[20221124 22:04:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:04:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:04:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:04:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:04:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:04:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:04:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:04:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:04:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:04:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:04:41 @pendulum_agent.py:307][0m Sample time: 3.65061092376709
[32m[20221124 22:04:57 @pendulum_agent.py:312][0m Update time: 15.38386082649231
[32m[20221124 22:04:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:04:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:04:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:04:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:04:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:04:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:04:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:04:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:04:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:04:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:04:57 @pendulum_agent.py:317][0m Evaluation time: 0.7175602912902832
[32m[20221124 22:04:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:04:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:04:58 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:04:58 @pendulum_agent.py:289][0m Total time: 2567.3737111091614
[32m[20221124 22:04:58 @pendulum_agent.py:291][0m 8700000 total steps have happened
[32m[20221124 22:04:58 @pendulum_agent.py:281][0m #------------------------ Iteration 174 --------------------------#
[32m[20221124 22:04:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.0
[32m[20221124 22:04:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.0
[32m[20221124 22:04:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.6
[32m[20221124 22:04:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.6
[32m[20221124 22:04:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.2
[32m[20221124 22:04:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.4
[32m[20221124 22:04:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.4
[32m[20221124 22:04:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.4
[32m[20221124 22:04:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.8
[32m[20221124 22:04:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.8
[32m[20221124 22:05:01 @pendulum_agent.py:307][0m Sample time: 3.6650571823120117
[32m[20221124 22:05:21 @pendulum_agent.py:312][0m Update time: 19.742695808410645
[32m[20221124 22:05:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:05:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:05:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:05:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:05:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:05:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:05:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:05:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:05:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:05:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:05:22 @pendulum_agent.py:317][0m Evaluation time: 0.7186141014099121
[32m[20221124 22:05:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.22
[32m[20221124 22:05:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:05:22 @pendulum_agent.py:289][0m Total time: 2591.777421951294
[32m[20221124 22:05:22 @pendulum_agent.py:291][0m 8750000 total steps have happened
[32m[20221124 22:05:22 @pendulum_agent.py:281][0m #------------------------ Iteration 175 --------------------------#
[32m[20221124 22:05:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:05:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:05:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:05:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:05:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:05:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:05:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:05:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:05:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:05:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:05:26 @pendulum_agent.py:307][0m Sample time: 3.8196468353271484
[32m[20221124 22:05:39 @pendulum_agent.py:312][0m Update time: 12.848712921142578
[32m[20221124 22:05:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:05:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:05:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:05:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:05:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:05:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:05:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:05:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:05:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:05:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:05:39 @pendulum_agent.py:317][0m Evaluation time: 0.5685379505157471
[32m[20221124 22:05:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:05:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:05:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:05:40 @pendulum_agent.py:289][0m Total time: 2609.3013842105865
[32m[20221124 22:05:40 @pendulum_agent.py:291][0m 8800000 total steps have happened
[32m[20221124 22:05:40 @pendulum_agent.py:281][0m #------------------------ Iteration 176 --------------------------#
[32m[20221124 22:05:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:05:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:05:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:05:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:05:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:05:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:05:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:05:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:05:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:05:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:05:43 @pendulum_agent.py:307][0m Sample time: 3.676642894744873
[32m[20221124 22:05:54 @pendulum_agent.py:312][0m Update time: 10.142398118972778
[32m[20221124 22:05:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:05:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:05:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:05:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:05:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:05:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:05:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:05:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:05:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:05:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:05:54 @pendulum_agent.py:317][0m Evaluation time: 0.8299808502197266
[32m[20221124 22:05:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:05:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:05:55 @pendulum_agent.py:289][0m Total time: 2624.2287950515747
[32m[20221124 22:05:55 @pendulum_agent.py:291][0m 8850000 total steps have happened
[32m[20221124 22:05:55 @pendulum_agent.py:281][0m #------------------------ Iteration 177 --------------------------#
[32m[20221124 22:05:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:05:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:05:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:05:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:05:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:05:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:05:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:05:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:05:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:05:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:05:58 @pendulum_agent.py:307][0m Sample time: 3.5236032009124756
[32m[20221124 22:06:17 @pendulum_agent.py:312][0m Update time: 18.886677980422974
[32m[20221124 22:06:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:06:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:06:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:06:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:06:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:06:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:06:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:06:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:06:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:06:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:06:18 @pendulum_agent.py:317][0m Evaluation time: 1.0210046768188477
[32m[20221124 22:06:18 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:06:18 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:06:18 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:06:18 @pendulum_agent.py:289][0m Total time: 2647.940637111664
[32m[20221124 22:06:18 @pendulum_agent.py:291][0m 8900000 total steps have happened
[32m[20221124 22:06:18 @pendulum_agent.py:281][0m #------------------------ Iteration 178 --------------------------#
[32m[20221124 22:06:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.0
[32m[20221124 22:06:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.4
[32m[20221124 22:06:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.0
[32m[20221124 22:06:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.6
[32m[20221124 22:06:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.2
[32m[20221124 22:06:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.2
[32m[20221124 22:06:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.8
[32m[20221124 22:06:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.2
[32m[20221124 22:06:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.8
[32m[20221124 22:06:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.8
[32m[20221124 22:06:22 @pendulum_agent.py:307][0m Sample time: 3.5963029861450195
[32m[20221124 22:06:35 @pendulum_agent.py:312][0m Update time: 13.294697046279907
[32m[20221124 22:06:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:06:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:06:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:06:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:06:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:06:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:06:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:06:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:06:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:06:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:06:36 @pendulum_agent.py:317][0m Evaluation time: 0.7053079605102539
[32m[20221124 22:06:36 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.1
[32m[20221124 22:06:36 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:06:36 @pendulum_agent.py:289][0m Total time: 2665.806463956833
[32m[20221124 22:06:36 @pendulum_agent.py:291][0m 8950000 total steps have happened
[32m[20221124 22:06:36 @pendulum_agent.py:281][0m #------------------------ Iteration 179 --------------------------#
[32m[20221124 22:06:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:06:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:06:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:06:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:06:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:06:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:06:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:06:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:06:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:06:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:06:40 @pendulum_agent.py:307][0m Sample time: 3.754209041595459
[32m[20221124 22:06:49 @pendulum_agent.py:312][0m Update time: 8.932168960571289
[32m[20221124 22:06:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:06:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:06:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:06:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:06:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:06:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:06:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:06:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:06:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:06:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:06:49 @pendulum_agent.py:317][0m Evaluation time: 0.5721521377563477
[32m[20221124 22:06:50 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:06:50 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:06:50 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:06:50 @pendulum_agent.py:289][0m Total time: 2679.3665478229523
[32m[20221124 22:06:50 @pendulum_agent.py:291][0m 9000000 total steps have happened
[32m[20221124 22:06:50 @pendulum_agent.py:281][0m #------------------------ Iteration 180 --------------------------#
[32m[20221124 22:06:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.2
[32m[20221124 22:06:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.4
[32m[20221124 22:06:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.2
[32m[20221124 22:06:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.2
[32m[20221124 22:06:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.4
[32m[20221124 22:06:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.6
[32m[20221124 22:06:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.4
[32m[20221124 22:06:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.8
[32m[20221124 22:06:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.2
[32m[20221124 22:06:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.2
[32m[20221124 22:06:54 @pendulum_agent.py:307][0m Sample time: 3.753666877746582
[32m[20221124 22:07:02 @pendulum_agent.py:312][0m Update time: 8.76504898071289
[32m[20221124 22:07:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:07:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:07:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:07:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:07:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:07:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:07:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:07:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:07:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:07:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:07:03 @pendulum_agent.py:317][0m Evaluation time: 0.7019219398498535
[32m[20221124 22:07:03 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.36
[32m[20221124 22:07:03 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:07:03 @pendulum_agent.py:289][0m Total time: 2692.864063978195
[32m[20221124 22:07:03 @pendulum_agent.py:291][0m 9050000 total steps have happened
[32m[20221124 22:07:03 @pendulum_agent.py:281][0m #------------------------ Iteration 181 --------------------------#
[32m[20221124 22:07:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:07:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:07:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:07:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:07:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:07:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:07:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:07:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:07:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:07:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:07:07 @pendulum_agent.py:307][0m Sample time: 3.7740509510040283
[32m[20221124 22:07:16 @pendulum_agent.py:312][0m Update time: 8.944860935211182
[32m[20221124 22:07:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:07:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:07:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:07:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:07:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:07:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:07:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:07:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:07:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:07:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:07:17 @pendulum_agent.py:317][0m Evaluation time: 0.714911937713623
[32m[20221124 22:07:17 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:07:17 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:07:17 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:07:17 @pendulum_agent.py:289][0m Total time: 2706.581981897354
[32m[20221124 22:07:17 @pendulum_agent.py:291][0m 9100000 total steps have happened
[32m[20221124 22:07:17 @pendulum_agent.py:281][0m #------------------------ Iteration 182 --------------------------#
[32m[20221124 22:07:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:07:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:07:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:07:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:07:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:07:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:07:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:07:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:07:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:07:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:07:21 @pendulum_agent.py:307][0m Sample time: 3.7261910438537598
[32m[20221124 22:07:30 @pendulum_agent.py:312][0m Update time: 8.829981088638306
[32m[20221124 22:07:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:07:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:07:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:07:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:07:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:07:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:07:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:07:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:07:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:07:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:07:30 @pendulum_agent.py:317][0m Evaluation time: 0.9375789165496826
[32m[20221124 22:07:31 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:07:31 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:07:31 @pendulum_agent.py:289][0m Total time: 2720.360347032547
[32m[20221124 22:07:31 @pendulum_agent.py:291][0m 9150000 total steps have happened
[32m[20221124 22:07:31 @pendulum_agent.py:281][0m #------------------------ Iteration 183 --------------------------#
[32m[20221124 22:07:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.6
[32m[20221124 22:07:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.0
[32m[20221124 22:07:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.4
[32m[20221124 22:07:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.4
[32m[20221124 22:07:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.0
[32m[20221124 22:07:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.2
[32m[20221124 22:07:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.2
[32m[20221124 22:07:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.6
[32m[20221124 22:07:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.0
[32m[20221124 22:07:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.6
[32m[20221124 22:07:34 @pendulum_agent.py:307][0m Sample time: 3.7236781120300293
[32m[20221124 22:07:43 @pendulum_agent.py:312][0m Update time: 8.903247117996216
[32m[20221124 22:07:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 19.0
[32m[20221124 22:07:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 19.0
[32m[20221124 22:07:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 19.0
[32m[20221124 22:07:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 19.0
[32m[20221124 22:07:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 19.0
[32m[20221124 22:07:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 19.0
[32m[20221124 22:07:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 19.0
[32m[20221124 22:07:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 19.0
[32m[20221124 22:07:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 19.0
[32m[20221124 22:07:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 19.0
[32m[20221124 22:07:44 @pendulum_agent.py:317][0m Evaluation time: 0.6950838565826416
[32m[20221124 22:07:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.9
[32m[20221124 22:07:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:07:44 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:07:44 @pendulum_agent.py:289][0m Total time: 2733.9582529067993
[32m[20221124 22:07:44 @pendulum_agent.py:291][0m 9200000 total steps have happened
[32m[20221124 22:07:44 @pendulum_agent.py:281][0m #------------------------ Iteration 184 --------------------------#
[32m[20221124 22:07:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:07:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:07:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:07:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:07:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:07:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:07:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:07:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:07:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:07:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:07:48 @pendulum_agent.py:307][0m Sample time: 3.6048409938812256
[32m[20221124 22:07:59 @pendulum_agent.py:312][0m Update time: 10.883908033370972
[32m[20221124 22:07:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:07:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:07:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:07:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:07:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:07:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:07:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:07:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:07:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:07:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:08:00 @pendulum_agent.py:317][0m Evaluation time: 0.691065788269043
[32m[20221124 22:08:00 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:08:00 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:08:00 @pendulum_agent.py:289][0m Total time: 2749.4341979026794
[32m[20221124 22:08:00 @pendulum_agent.py:291][0m 9250000 total steps have happened
[32m[20221124 22:08:00 @pendulum_agent.py:281][0m #------------------------ Iteration 185 --------------------------#
[32m[20221124 22:08:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:08:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:08:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:08:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:08:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:08:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:08:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:08:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:08:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:08:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:08:03 @pendulum_agent.py:307][0m Sample time: 3.4379591941833496
[32m[20221124 22:08:33 @pendulum_agent.py:312][0m Update time: 29.61881375312805
[32m[20221124 22:08:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:08:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:08:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:08:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:08:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:08:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:08:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:08:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:08:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:08:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:08:34 @pendulum_agent.py:317][0m Evaluation time: 0.9261820316314697
[32m[20221124 22:08:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:08:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:08:34 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:08:34 @pendulum_agent.py:289][0m Total time: 2783.6906549930573
[32m[20221124 22:08:34 @pendulum_agent.py:291][0m 9300000 total steps have happened
[32m[20221124 22:08:34 @pendulum_agent.py:281][0m #------------------------ Iteration 186 --------------------------#
[32m[20221124 22:08:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:08:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:08:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:08:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:08:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:08:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:08:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:08:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:08:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:08:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:08:37 @pendulum_agent.py:307][0m Sample time: 3.2862448692321777
[32m[20221124 22:08:46 @pendulum_agent.py:312][0m Update time: 8.995283126831055
[32m[20221124 22:08:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:08:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:08:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:08:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:08:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:08:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:08:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:08:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:08:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:08:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:08:48 @pendulum_agent.py:317][0m Evaluation time: 1.6522929668426514
[32m[20221124 22:08:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:08:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:08:48 @pendulum_agent.py:289][0m Total time: 2797.919783115387
[32m[20221124 22:08:48 @pendulum_agent.py:291][0m 9350000 total steps have happened
[32m[20221124 22:08:48 @pendulum_agent.py:281][0m #------------------------ Iteration 187 --------------------------#
[32m[20221124 22:08:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:08:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:08:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:08:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:08:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:08:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:08:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:08:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:08:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:08:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:08:52 @pendulum_agent.py:307][0m Sample time: 3.8657000064849854
[32m[20221124 22:09:09 @pendulum_agent.py:312][0m Update time: 16.922126054763794
[32m[20221124 22:09:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:09:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:09:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:09:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:09:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:09:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:09:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:09:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:09:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:09:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:09:10 @pendulum_agent.py:317][0m Evaluation time: 0.712526798248291
[32m[20221124 22:09:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:09:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:09:10 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:09:10 @pendulum_agent.py:289][0m Total time: 2819.696912050247
[32m[20221124 22:09:10 @pendulum_agent.py:291][0m 9400000 total steps have happened
[32m[20221124 22:09:10 @pendulum_agent.py:281][0m #------------------------ Iteration 188 --------------------------#
[32m[20221124 22:09:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:09:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:09:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:09:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:09:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:09:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:09:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:09:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:09:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:09:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:09:14 @pendulum_agent.py:307][0m Sample time: 3.615342140197754
[32m[20221124 22:09:28 @pendulum_agent.py:312][0m Update time: 14.40599274635315
[32m[20221124 22:09:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:09:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:09:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:09:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:09:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:09:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:09:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:09:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:09:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:09:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:09:29 @pendulum_agent.py:317][0m Evaluation time: 0.6971609592437744
[32m[20221124 22:09:29 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:09:29 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:09:29 @pendulum_agent.py:289][0m Total time: 2838.683629989624
[32m[20221124 22:09:29 @pendulum_agent.py:291][0m 9450000 total steps have happened
[32m[20221124 22:09:29 @pendulum_agent.py:281][0m #------------------------ Iteration 189 --------------------------#
[32m[20221124 22:09:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.2
[32m[20221124 22:09:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.0
[32m[20221124 22:09:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.2
[32m[20221124 22:09:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.0
[32m[20221124 22:09:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.0
[32m[20221124 22:09:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1.2
[32m[20221124 22:09:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1.2
[32m[20221124 22:09:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1.2
[32m[20221124 22:09:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.0
[32m[20221124 22:09:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.2
[32m[20221124 22:09:33 @pendulum_agent.py:307][0m Sample time: 3.725990056991577
[32m[20221124 22:09:42 @pendulum_agent.py:312][0m Update time: 8.90025806427002
[32m[20221124 22:09:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:09:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:09:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:09:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:09:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:09:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:09:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:09:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:09:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:09:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:09:42 @pendulum_agent.py:317][0m Evaluation time: 0.7094831466674805
[32m[20221124 22:09:43 @pendulum_agent.py:285][0m Average TRAINING episode reward: 1.12
[32m[20221124 22:09:43 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:09:43 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:09:43 @pendulum_agent.py:289][0m Total time: 2852.290004014969
[32m[20221124 22:09:43 @pendulum_agent.py:291][0m 9500000 total steps have happened
[32m[20221124 22:09:43 @pendulum_agent.py:281][0m #------------------------ Iteration 190 --------------------------#
[32m[20221124 22:09:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:09:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:09:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:09:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:09:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:09:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:09:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:09:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:09:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:09:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:09:46 @pendulum_agent.py:307][0m Sample time: 3.607170820236206
[32m[20221124 22:10:09 @pendulum_agent.py:312][0m Update time: 23.15366220474243
[32m[20221124 22:10:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:10:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:10:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:10:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:10:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:10:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:10:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:10:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:10:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:10:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:10:10 @pendulum_agent.py:317][0m Evaluation time: 0.7888729572296143
[32m[20221124 22:10:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:10:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:10:11 @pendulum_agent.py:289][0m Total time: 2880.1080980300903
[32m[20221124 22:10:11 @pendulum_agent.py:291][0m 9550000 total steps have happened
[32m[20221124 22:10:11 @pendulum_agent.py:281][0m #------------------------ Iteration 191 --------------------------#
[32m[20221124 22:10:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.0
[32m[20221124 22:10:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.2
[32m[20221124 22:10:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.2
[32m[20221124 22:10:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.8
[32m[20221124 22:10:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1.8
[32m[20221124 22:10:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.0
[32m[20221124 22:10:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.2
[32m[20221124 22:10:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.0
[32m[20221124 22:10:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.2
[32m[20221124 22:10:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1.8
[32m[20221124 22:10:14 @pendulum_agent.py:307][0m Sample time: 3.64424204826355
[32m[20221124 22:10:23 @pendulum_agent.py:312][0m Update time: 8.935528993606567
[32m[20221124 22:10:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:10:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:10:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:10:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:10:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:10:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:10:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:10:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:10:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:10:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:10:24 @pendulum_agent.py:317][0m Evaluation time: 0.7188999652862549
[32m[20221124 22:10:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.02
[32m[20221124 22:10:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:10:24 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:10:24 @pendulum_agent.py:289][0m Total time: 2893.674394130707
[32m[20221124 22:10:24 @pendulum_agent.py:291][0m 9600000 total steps have happened
[32m[20221124 22:10:24 @pendulum_agent.py:281][0m #------------------------ Iteration 192 --------------------------#
[32m[20221124 22:10:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:10:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:10:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:10:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:10:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:10:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:10:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:10:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:10:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:10:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:10:28 @pendulum_agent.py:307][0m Sample time: 3.7570087909698486
[32m[20221124 22:10:47 @pendulum_agent.py:312][0m Update time: 18.736421823501587
[32m[20221124 22:10:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:10:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:10:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:10:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:10:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:10:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:10:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:10:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:10:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:10:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:10:47 @pendulum_agent.py:317][0m Evaluation time: 0.7199802398681641
[32m[20221124 22:10:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:10:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:10:48 @pendulum_agent.py:289][0m Total time: 2917.176022052765
[32m[20221124 22:10:48 @pendulum_agent.py:291][0m 9650000 total steps have happened
[32m[20221124 22:10:48 @pendulum_agent.py:281][0m #------------------------ Iteration 193 --------------------------#
[32m[20221124 22:10:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:10:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:10:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:10:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:10:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:10:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:10:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:10:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:10:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:10:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:10:51 @pendulum_agent.py:307][0m Sample time: 3.6227190494537354
[32m[20221124 22:11:07 @pendulum_agent.py:312][0m Update time: 16.29921793937683
[32m[20221124 22:11:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:11:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:11:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:11:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:11:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:11:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:11:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:11:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:11:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:11:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:11:08 @pendulum_agent.py:317][0m Evaluation time: 0.7217681407928467
[32m[20221124 22:11:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:11:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:11:08 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:11:08 @pendulum_agent.py:289][0m Total time: 2938.0991621017456
[32m[20221124 22:11:08 @pendulum_agent.py:291][0m 9700000 total steps have happened
[32m[20221124 22:11:08 @pendulum_agent.py:281][0m #------------------------ Iteration 194 --------------------------#
[32m[20221124 22:11:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:11:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:11:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:11:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:11:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:11:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:11:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:11:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:11:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:11:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:11:12 @pendulum_agent.py:307][0m Sample time: 3.5842671394348145
[32m[20221124 22:11:26 @pendulum_agent.py:312][0m Update time: 14.07976508140564
[32m[20221124 22:11:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:11:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:11:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:11:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:11:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:11:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:11:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:11:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:11:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:11:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:11:27 @pendulum_agent.py:317][0m Evaluation time: 0.8197307586669922
[32m[20221124 22:11:27 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:11:27 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:11:27 @pendulum_agent.py:289][0m Total time: 2956.8558728694916
[32m[20221124 22:11:27 @pendulum_agent.py:291][0m 9750000 total steps have happened
[32m[20221124 22:11:27 @pendulum_agent.py:281][0m #------------------------ Iteration 195 --------------------------#
[32m[20221124 22:11:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:11:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:11:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:11:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:11:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:11:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:11:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:11:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:11:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:11:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:11:31 @pendulum_agent.py:307][0m Sample time: 3.4419829845428467
[32m[20221124 22:11:46 @pendulum_agent.py:312][0m Update time: 15.288005113601685
[32m[20221124 22:11:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:11:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:11:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:11:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:11:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:11:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:11:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:11:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:11:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:11:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:11:47 @pendulum_agent.py:317][0m Evaluation time: 1.0525641441345215
[32m[20221124 22:11:47 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:11:47 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:11:47 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:11:47 @pendulum_agent.py:289][0m Total time: 2976.915561914444
[32m[20221124 22:11:47 @pendulum_agent.py:291][0m 9800000 total steps have happened
[32m[20221124 22:11:47 @pendulum_agent.py:281][0m #------------------------ Iteration 196 --------------------------#
[32m[20221124 22:11:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:11:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:11:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:11:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:11:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:11:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:11:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:11:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:11:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:11:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:11:51 @pendulum_agent.py:307][0m Sample time: 3.343330144882202
[32m[20221124 22:11:59 @pendulum_agent.py:312][0m Update time: 8.729941844940186
[32m[20221124 22:12:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:12:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:12:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:12:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:12:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:12:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:12:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:12:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:12:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:12:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:12:01 @pendulum_agent.py:317][0m Evaluation time: 1.1690850257873535
[32m[20221124 22:12:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:12:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:12:01 @pendulum_agent.py:289][0m Total time: 2990.4282059669495
[32m[20221124 22:12:01 @pendulum_agent.py:291][0m 9850000 total steps have happened
[32m[20221124 22:12:01 @pendulum_agent.py:281][0m #------------------------ Iteration 197 --------------------------#
[32m[20221124 22:12:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:12:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:12:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:12:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:12:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:12:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:12:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:12:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:12:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:12:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:12:04 @pendulum_agent.py:307][0m Sample time: 3.4244680404663086
[32m[20221124 22:12:13 @pendulum_agent.py:312][0m Update time: 8.778076887130737
[32m[20221124 22:12:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:12:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:12:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:12:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:12:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:12:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:12:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:12:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:12:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:12:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:12:15 @pendulum_agent.py:317][0m Evaluation time: 1.8032171726226807
[32m[20221124 22:12:15 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:12:15 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:12:15 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:12:15 @pendulum_agent.py:289][0m Total time: 3004.7307708263397
[32m[20221124 22:12:15 @pendulum_agent.py:291][0m 9900000 total steps have happened
[32m[20221124 22:12:15 @pendulum_agent.py:281][0m #------------------------ Iteration 198 --------------------------#
[32m[20221124 22:12:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:12:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:12:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:12:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:12:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:12:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:12:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:12:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:12:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:12:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:12:19 @pendulum_agent.py:307][0m Sample time: 3.562870979309082
[32m[20221124 22:12:28 @pendulum_agent.py:312][0m Update time: 8.91075325012207
[32m[20221124 22:12:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:12:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:12:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:12:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:12:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:12:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:12:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:12:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:12:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:12:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:12:28 @pendulum_agent.py:317][0m Evaluation time: 0.7146248817443848
[32m[20221124 22:12:29 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:12:29 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:12:29 @pendulum_agent.py:289][0m Total time: 3018.2006981372833
[32m[20221124 22:12:29 @pendulum_agent.py:291][0m 9950000 total steps have happened
[32m[20221124 22:12:29 @pendulum_agent.py:281][0m #------------------------ Iteration 199 --------------------------#
[32m[20221124 22:12:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:12:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:12:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:12:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:12:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:12:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:12:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:12:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:12:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:12:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:12:32 @pendulum_agent.py:307][0m Sample time: 3.7413887977600098
[32m[20221124 22:12:41 @pendulum_agent.py:312][0m Update time: 8.957293033599854
[32m[20221124 22:12:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:12:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:12:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:12:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:12:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:12:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:12:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:12:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:12:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:12:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:12:42 @pendulum_agent.py:317][0m Evaluation time: 0.9641599655151367
[32m[20221124 22:12:43 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:12:43 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:12:43 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:12:43 @pendulum_agent.py:289][0m Total time: 3032.149087905884
[32m[20221124 22:12:43 @pendulum_agent.py:291][0m 10000000 total steps have happened
[32m[20221124 22:12:43 @pendulum_agent.py:281][0m #------------------------ Iteration 200 --------------------------#
[32m[20221124 22:12:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.8
[32m[20221124 22:12:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.6
[32m[20221124 22:12:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.0
[32m[20221124 22:12:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1.8
[32m[20221124 22:12:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.2
[32m[20221124 22:12:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1.8
[32m[20221124 22:12:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.2
[32m[20221124 22:12:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.4
[32m[20221124 22:12:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.2
[32m[20221124 22:12:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.0
[32m[20221124 22:12:46 @pendulum_agent.py:307][0m Sample time: 3.87555193901062
[32m[20221124 22:13:01 @pendulum_agent.py:312][0m Update time: 14.106373071670532
[32m[20221124 22:13:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:13:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:13:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:13:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:13:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:13:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:13:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:13:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:13:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:13:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:13:01 @pendulum_agent.py:317][0m Evaluation time: 0.9345870018005371
[32m[20221124 22:13:02 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.1
[32m[20221124 22:13:02 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:13:02 @pendulum_agent.py:289][0m Total time: 3051.337419986725
[32m[20221124 22:13:02 @pendulum_agent.py:291][0m 10050000 total steps have happened
[32m[20221124 22:13:02 @pendulum_agent.py:281][0m #------------------------ Iteration 201 --------------------------#
[32m[20221124 22:13:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.0
[32m[20221124 22:13:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.0
[32m[20221124 22:13:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.4
[32m[20221124 22:13:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.8
[32m[20221124 22:13:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.2
[32m[20221124 22:13:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.8
[32m[20221124 22:13:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.0
[32m[20221124 22:13:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.2
[32m[20221124 22:13:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.4
[32m[20221124 22:13:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.8
[32m[20221124 22:13:06 @pendulum_agent.py:307][0m Sample time: 3.928579092025757
[32m[20221124 22:13:25 @pendulum_agent.py:312][0m Update time: 19.21772289276123
[32m[20221124 22:13:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:13:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:13:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:13:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:13:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:13:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:13:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:13:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:13:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:13:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:13:26 @pendulum_agent.py:317][0m Evaluation time: 0.7064080238342285
[32m[20221124 22:13:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.46
[32m[20221124 22:13:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:13:26 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:13:26 @pendulum_agent.py:289][0m Total time: 3075.4879179000854
[32m[20221124 22:13:26 @pendulum_agent.py:291][0m 10100000 total steps have happened
[32m[20221124 22:13:26 @pendulum_agent.py:281][0m #------------------------ Iteration 202 --------------------------#
[32m[20221124 22:13:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:13:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:13:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:13:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:13:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:13:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:13:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:13:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:13:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:13:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:13:29 @pendulum_agent.py:307][0m Sample time: 3.523258924484253
[32m[20221124 22:13:38 @pendulum_agent.py:312][0m Update time: 8.956233024597168
[32m[20221124 22:13:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:13:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:13:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:13:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:13:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:13:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:13:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:13:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:13:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:13:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:13:39 @pendulum_agent.py:317][0m Evaluation time: 0.5828180313110352
[32m[20221124 22:13:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:13:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:13:39 @pendulum_agent.py:289][0m Total time: 3088.850128173828
[32m[20221124 22:13:39 @pendulum_agent.py:291][0m 10150000 total steps have happened
[32m[20221124 22:13:39 @pendulum_agent.py:281][0m #------------------------ Iteration 203 --------------------------#
[32m[20221124 22:13:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.0
[32m[20221124 22:13:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.6
[32m[20221124 22:13:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 11.4
[32m[20221124 22:13:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.2
[32m[20221124 22:13:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.8
[32m[20221124 22:13:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.6
[32m[20221124 22:13:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.6
[32m[20221124 22:13:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.0
[32m[20221124 22:13:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.8
[32m[20221124 22:13:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.8
[32m[20221124 22:13:43 @pendulum_agent.py:307][0m Sample time: 3.779594898223877
[32m[20221124 22:13:58 @pendulum_agent.py:312][0m Update time: 14.692511081695557
[32m[20221124 22:13:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:13:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:13:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:13:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:13:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:13:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:13:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:13:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:13:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:13:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:13:58 @pendulum_agent.py:317][0m Evaluation time: 0.5676729679107666
[32m[20221124 22:13:59 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.88
[32m[20221124 22:13:59 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:13:59 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:13:59 @pendulum_agent.py:289][0m Total time: 3108.197009086609
[32m[20221124 22:13:59 @pendulum_agent.py:291][0m 10200000 total steps have happened
[32m[20221124 22:13:59 @pendulum_agent.py:281][0m #------------------------ Iteration 204 --------------------------#
[32m[20221124 22:13:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:13:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:13:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:13:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:13:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:13:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:13:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:13:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:13:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:13:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:14:02 @pendulum_agent.py:307][0m Sample time: 3.729457139968872
[32m[20221124 22:14:11 @pendulum_agent.py:312][0m Update time: 8.930307149887085
[32m[20221124 22:14:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:14:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:14:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:14:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:14:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:14:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:14:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:14:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:14:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:14:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:14:12 @pendulum_agent.py:317][0m Evaluation time: 0.5866520404815674
[32m[20221124 22:14:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:14:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:14:12 @pendulum_agent.py:289][0m Total time: 3121.7425479888916
[32m[20221124 22:14:12 @pendulum_agent.py:291][0m 10250000 total steps have happened
[32m[20221124 22:14:12 @pendulum_agent.py:281][0m #------------------------ Iteration 205 --------------------------#
[32m[20221124 22:14:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:14:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:14:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:14:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:14:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:14:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:14:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:14:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:14:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:14:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:14:16 @pendulum_agent.py:307][0m Sample time: 3.898216962814331
[32m[20221124 22:14:36 @pendulum_agent.py:312][0m Update time: 19.720119953155518
[32m[20221124 22:14:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:14:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:14:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:14:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:14:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:14:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:14:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:14:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:14:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:14:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:14:36 @pendulum_agent.py:317][0m Evaluation time: 0.6849348545074463
[32m[20221124 22:14:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:14:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:14:37 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:14:37 @pendulum_agent.py:289][0m Total time: 3146.3251419067383
[32m[20221124 22:14:37 @pendulum_agent.py:291][0m 10300000 total steps have happened
[32m[20221124 22:14:37 @pendulum_agent.py:281][0m #------------------------ Iteration 206 --------------------------#
[32m[20221124 22:14:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 9.4
[32m[20221124 22:14:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 8.4
[32m[20221124 22:14:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 7.6
[32m[20221124 22:14:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.2
[32m[20221124 22:14:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 9.4
[32m[20221124 22:14:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 7.4
[32m[20221124 22:14:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 10.8
[32m[20221124 22:14:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.2
[32m[20221124 22:14:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.0
[32m[20221124 22:14:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 7.6
[32m[20221124 22:14:40 @pendulum_agent.py:307][0m Sample time: 3.534152030944824
[32m[20221124 22:14:49 @pendulum_agent.py:312][0m Update time: 9.2202889919281
[32m[20221124 22:14:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 7.0
[32m[20221124 22:14:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.0
[32m[20221124 22:14:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 7.0
[32m[20221124 22:14:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 7.0
[32m[20221124 22:14:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.0
[32m[20221124 22:14:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.0
[32m[20221124 22:14:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.0
[32m[20221124 22:14:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.0
[32m[20221124 22:14:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 7.0
[32m[20221124 22:14:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 7.0
[32m[20221124 22:14:50 @pendulum_agent.py:317][0m Evaluation time: 0.8117921352386475
[32m[20221124 22:14:51 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.9
[32m[20221124 22:14:51 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:14:51 @pendulum_agent.py:289][0m Total time: 3160.170916080475
[32m[20221124 22:14:51 @pendulum_agent.py:291][0m 10350000 total steps have happened
[32m[20221124 22:14:51 @pendulum_agent.py:281][0m #------------------------ Iteration 207 --------------------------#
[32m[20221124 22:14:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:14:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:14:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:14:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:14:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:14:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:14:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:14:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:14:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:14:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:14:54 @pendulum_agent.py:307][0m Sample time: 3.298996925354004
[32m[20221124 22:15:03 @pendulum_agent.py:312][0m Update time: 8.902276039123535
[32m[20221124 22:15:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:15:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:15:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:15:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:15:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:15:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:15:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:15:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:15:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:15:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:15:04 @pendulum_agent.py:317][0m Evaluation time: 1.0286688804626465
[32m[20221124 22:15:04 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:15:04 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:15:04 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:15:04 @pendulum_agent.py:289][0m Total time: 3173.680153131485
[32m[20221124 22:15:04 @pendulum_agent.py:291][0m 10400000 total steps have happened
[32m[20221124 22:15:04 @pendulum_agent.py:281][0m #------------------------ Iteration 208 --------------------------#
[32m[20221124 22:15:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.8
[32m[20221124 22:15:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.2
[32m[20221124 22:15:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.2
[32m[20221124 22:15:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.6
[32m[20221124 22:15:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.6
[32m[20221124 22:15:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.8
[32m[20221124 22:15:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.2
[32m[20221124 22:15:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.6
[32m[20221124 22:15:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.0
[32m[20221124 22:15:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.2
[32m[20221124 22:15:08 @pendulum_agent.py:307][0m Sample time: 3.541987895965576
[32m[20221124 22:15:16 @pendulum_agent.py:312][0m Update time: 8.810637950897217
[32m[20221124 22:15:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 9.0
[32m[20221124 22:15:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 9.0
[32m[20221124 22:15:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 9.0
[32m[20221124 22:15:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 9.0
[32m[20221124 22:15:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 9.0
[32m[20221124 22:15:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 9.0
[32m[20221124 22:15:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 9.0
[32m[20221124 22:15:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 9.0
[32m[20221124 22:15:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 9.0
[32m[20221124 22:15:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 9.0
[32m[20221124 22:15:18 @pendulum_agent.py:317][0m Evaluation time: 1.1605782508850098
[32m[20221124 22:15:18 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.82
[32m[20221124 22:15:18 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:15:18 @pendulum_agent.py:289][0m Total time: 3187.4717860221863
[32m[20221124 22:15:18 @pendulum_agent.py:291][0m 10450000 total steps have happened
[32m[20221124 22:15:18 @pendulum_agent.py:281][0m #------------------------ Iteration 209 --------------------------#
[32m[20221124 22:15:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:15:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:15:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:15:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:15:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:15:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:15:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:15:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:15:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:15:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:15:21 @pendulum_agent.py:307][0m Sample time: 3.3654799461364746
[32m[20221124 22:15:30 @pendulum_agent.py:312][0m Update time: 8.752447843551636
[32m[20221124 22:15:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:15:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:15:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:15:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:15:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:15:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:15:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:15:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:15:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:15:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:15:31 @pendulum_agent.py:317][0m Evaluation time: 1.145200252532959
[32m[20221124 22:15:31 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:15:31 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:15:31 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:15:31 @pendulum_agent.py:289][0m Total time: 3201.012279987335
[32m[20221124 22:15:31 @pendulum_agent.py:291][0m 10500000 total steps have happened
[32m[20221124 22:15:31 @pendulum_agent.py:281][0m #------------------------ Iteration 210 --------------------------#
[32m[20221124 22:15:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:15:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:15:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:15:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:15:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:15:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:15:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:15:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:15:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:15:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:15:35 @pendulum_agent.py:307][0m Sample time: 3.672380208969116
[32m[20221124 22:15:44 @pendulum_agent.py:312][0m Update time: 8.875179052352905
[32m[20221124 22:15:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:15:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:15:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:15:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:15:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:15:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:15:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:15:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:15:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:15:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:15:45 @pendulum_agent.py:317][0m Evaluation time: 0.7068066596984863
[32m[20221124 22:15:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:15:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:15:45 @pendulum_agent.py:289][0m Total time: 3214.5436651706696
[32m[20221124 22:15:45 @pendulum_agent.py:291][0m 10550000 total steps have happened
[32m[20221124 22:15:45 @pendulum_agent.py:281][0m #------------------------ Iteration 211 --------------------------#
[32m[20221124 22:15:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:15:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:15:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:15:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:15:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:15:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:15:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:15:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:15:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:15:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:15:49 @pendulum_agent.py:307][0m Sample time: 3.6826510429382324
[32m[20221124 22:15:58 @pendulum_agent.py:312][0m Update time: 8.908776044845581
[32m[20221124 22:15:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.0
[32m[20221124 22:15:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.0
[32m[20221124 22:15:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.0
[32m[20221124 22:15:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.0
[32m[20221124 22:15:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.0
[32m[20221124 22:15:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.0
[32m[20221124 22:15:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.0
[32m[20221124 22:15:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.0
[32m[20221124 22:15:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.0
[32m[20221124 22:15:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.0
[32m[20221124 22:15:58 @pendulum_agent.py:317][0m Evaluation time: 0.7145640850067139
[32m[20221124 22:15:59 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:15:59 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:15:59 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:15:59 @pendulum_agent.py:289][0m Total time: 3228.1343500614166
[32m[20221124 22:15:59 @pendulum_agent.py:291][0m 10600000 total steps have happened
[32m[20221124 22:15:59 @pendulum_agent.py:281][0m #------------------------ Iteration 212 --------------------------#
[32m[20221124 22:15:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:15:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:15:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:15:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:15:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:15:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:15:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:15:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:15:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:15:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:16:02 @pendulum_agent.py:307][0m Sample time: 3.600046157836914
[32m[20221124 22:16:16 @pendulum_agent.py:312][0m Update time: 13.39230990409851
[32m[20221124 22:16:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:16:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:16:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:16:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:16:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:16:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:16:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:16:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:16:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:16:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:16:16 @pendulum_agent.py:317][0m Evaluation time: 0.6979739665985107
[32m[20221124 22:16:17 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:16:17 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:16:17 @pendulum_agent.py:289][0m Total time: 3246.109526872635
[32m[20221124 22:16:17 @pendulum_agent.py:291][0m 10650000 total steps have happened
[32m[20221124 22:16:17 @pendulum_agent.py:281][0m #------------------------ Iteration 213 --------------------------#
[32m[20221124 22:16:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:16:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:16:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:16:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:16:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:16:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:16:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:16:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:16:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:16:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:16:20 @pendulum_agent.py:307][0m Sample time: 3.8326730728149414
[32m[20221124 22:16:29 @pendulum_agent.py:312][0m Update time: 8.875546932220459
[32m[20221124 22:16:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:16:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:16:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:16:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:16:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:16:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:16:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:16:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:16:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:16:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:16:30 @pendulum_agent.py:317][0m Evaluation time: 0.5774087905883789
[32m[20221124 22:16:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:16:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:16:30 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:16:30 @pendulum_agent.py:289][0m Total time: 3259.706729888916
[32m[20221124 22:16:30 @pendulum_agent.py:291][0m 10700000 total steps have happened
[32m[20221124 22:16:30 @pendulum_agent.py:281][0m #------------------------ Iteration 214 --------------------------#
[32m[20221124 22:16:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.4
[32m[20221124 22:16:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.2
[32m[20221124 22:16:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.6
[32m[20221124 22:16:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.6
[32m[20221124 22:16:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.6
[32m[20221124 22:16:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.4
[32m[20221124 22:16:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.8
[32m[20221124 22:16:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.8
[32m[20221124 22:16:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.2
[32m[20221124 22:16:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.2
[32m[20221124 22:16:34 @pendulum_agent.py:307][0m Sample time: 3.7829790115356445
[32m[20221124 22:16:55 @pendulum_agent.py:312][0m Update time: 20.918411016464233
[32m[20221124 22:16:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:16:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:16:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:16:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:16:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:16:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:16:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:16:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:16:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:16:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:16:56 @pendulum_agent.py:317][0m Evaluation time: 0.7053451538085938
[32m[20221124 22:16:56 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.98
[32m[20221124 22:16:56 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:16:56 @pendulum_agent.py:289][0m Total time: 3285.4034428596497
[32m[20221124 22:16:56 @pendulum_agent.py:291][0m 10750000 total steps have happened
[32m[20221124 22:16:56 @pendulum_agent.py:281][0m #------------------------ Iteration 215 --------------------------#
[32m[20221124 22:16:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:16:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:16:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:16:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:16:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:16:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:16:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:16:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:16:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:16:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:16:59 @pendulum_agent.py:307][0m Sample time: 3.6090497970581055
[32m[20221124 22:17:08 @pendulum_agent.py:312][0m Update time: 8.971270322799683
[32m[20221124 22:17:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 16.0
[32m[20221124 22:17:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 16.0
[32m[20221124 22:17:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 16.0
[32m[20221124 22:17:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 16.0
[32m[20221124 22:17:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 16.0
[32m[20221124 22:17:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 16.0
[32m[20221124 22:17:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 16.0
[32m[20221124 22:17:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 16.0
[32m[20221124 22:17:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 16.0
[32m[20221124 22:17:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 16.0
[32m[20221124 22:17:09 @pendulum_agent.py:317][0m Evaluation time: 0.703021764755249
[32m[20221124 22:17:09 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:17:09 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:17:09 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:17:09 @pendulum_agent.py:289][0m Total time: 3298.9641268253326
[32m[20221124 22:17:09 @pendulum_agent.py:291][0m 10800000 total steps have happened
[32m[20221124 22:17:09 @pendulum_agent.py:281][0m #------------------------ Iteration 216 --------------------------#
[32m[20221124 22:17:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:17:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:17:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:17:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:17:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:17:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:17:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:17:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:17:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:17:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:17:13 @pendulum_agent.py:307][0m Sample time: 3.555867910385132
[32m[20221124 22:17:22 @pendulum_agent.py:312][0m Update time: 9.010583877563477
[32m[20221124 22:17:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:17:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:17:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:17:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:17:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:17:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:17:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:17:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:17:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:17:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:17:23 @pendulum_agent.py:317][0m Evaluation time: 0.8449130058288574
[32m[20221124 22:17:23 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:17:23 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:17:23 @pendulum_agent.py:289][0m Total time: 3312.661700963974
[32m[20221124 22:17:23 @pendulum_agent.py:291][0m 10850000 total steps have happened
[32m[20221124 22:17:23 @pendulum_agent.py:281][0m #------------------------ Iteration 217 --------------------------#
[32m[20221124 22:17:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.0
[32m[20221124 22:17:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.2
[32m[20221124 22:17:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.2
[32m[20221124 22:17:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.2
[32m[20221124 22:17:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.0
[32m[20221124 22:17:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.8
[32m[20221124 22:17:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.0
[32m[20221124 22:17:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.4
[32m[20221124 22:17:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.4
[32m[20221124 22:17:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.6
[32m[20221124 22:17:26 @pendulum_agent.py:307][0m Sample time: 3.3274099826812744
[32m[20221124 22:17:39 @pendulum_agent.py:312][0m Update time: 12.338052034378052
[32m[20221124 22:17:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.0
[32m[20221124 22:17:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.0
[32m[20221124 22:17:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.0
[32m[20221124 22:17:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.0
[32m[20221124 22:17:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.0
[32m[20221124 22:17:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.0
[32m[20221124 22:17:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.0
[32m[20221124 22:17:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.0
[32m[20221124 22:17:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.0
[32m[20221124 22:17:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.0
[32m[20221124 22:17:40 @pendulum_agent.py:317][0m Evaluation time: 1.045557975769043
[32m[20221124 22:17:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.18
[32m[20221124 22:17:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:17:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:17:40 @pendulum_agent.py:289][0m Total time: 3329.653561115265
[32m[20221124 22:17:40 @pendulum_agent.py:291][0m 10900000 total steps have happened
[32m[20221124 22:17:40 @pendulum_agent.py:281][0m #------------------------ Iteration 218 --------------------------#
[32m[20221124 22:17:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:17:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:17:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:17:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:17:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:17:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:17:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:17:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:17:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:17:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:17:43 @pendulum_agent.py:307][0m Sample time: 3.270273208618164
[32m[20221124 22:18:10 @pendulum_agent.py:312][0m Update time: 26.310325860977173
[32m[20221124 22:18:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:18:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:18:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:18:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:18:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:18:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:18:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:18:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:18:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:18:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:18:11 @pendulum_agent.py:317][0m Evaluation time: 1.0308890342712402
[32m[20221124 22:18:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:18:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:18:11 @pendulum_agent.py:289][0m Total time: 3360.5511951446533
[32m[20221124 22:18:11 @pendulum_agent.py:291][0m 10950000 total steps have happened
[32m[20221124 22:18:11 @pendulum_agent.py:281][0m #------------------------ Iteration 219 --------------------------#
[32m[20221124 22:18:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:18:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:18:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:18:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:18:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:18:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:18:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:18:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:18:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:18:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:18:15 @pendulum_agent.py:307][0m Sample time: 3.6227071285247803
[32m[20221124 22:18:36 @pendulum_agent.py:312][0m Update time: 21.82652997970581
[32m[20221124 22:18:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:18:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:18:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:18:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:18:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:18:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:18:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:18:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:18:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:18:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:18:37 @pendulum_agent.py:317][0m Evaluation time: 0.7063350677490234
[32m[20221124 22:18:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:18:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:18:37 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:18:37 @pendulum_agent.py:289][0m Total time: 3386.9782881736755
[32m[20221124 22:18:37 @pendulum_agent.py:291][0m 11000000 total steps have happened
[32m[20221124 22:18:37 @pendulum_agent.py:281][0m #------------------------ Iteration 220 --------------------------#
[32m[20221124 22:18:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:18:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:18:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:18:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:18:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:18:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:18:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:18:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:18:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:18:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:18:41 @pendulum_agent.py:307][0m Sample time: 3.647963047027588
[32m[20221124 22:18:50 @pendulum_agent.py:312][0m Update time: 8.898507118225098
[32m[20221124 22:18:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:18:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:18:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:18:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:18:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:18:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:18:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:18:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:18:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:18:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:18:51 @pendulum_agent.py:317][0m Evaluation time: 0.7057907581329346
[32m[20221124 22:18:51 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:18:51 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:18:51 @pendulum_agent.py:289][0m Total time: 3400.507634162903
[32m[20221124 22:18:51 @pendulum_agent.py:291][0m 11050000 total steps have happened
[32m[20221124 22:18:51 @pendulum_agent.py:281][0m #------------------------ Iteration 221 --------------------------#
[32m[20221124 22:18:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.8
[32m[20221124 22:18:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.0
[32m[20221124 22:18:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.2
[32m[20221124 22:18:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 13.0
[32m[20221124 22:18:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.2
[32m[20221124 22:18:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.4
[32m[20221124 22:18:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.2
[32m[20221124 22:18:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.6
[32m[20221124 22:18:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.2
[32m[20221124 22:18:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.2
[32m[20221124 22:18:55 @pendulum_agent.py:307][0m Sample time: 3.8517298698425293
[32m[20221124 22:19:19 @pendulum_agent.py:312][0m Update time: 24.017664909362793
[32m[20221124 22:19:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:19:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:19:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:19:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:19:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:19:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:19:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:19:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:19:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:19:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:19:19 @pendulum_agent.py:317][0m Evaluation time: 0.5751602649688721
[32m[20221124 22:19:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.48
[32m[20221124 22:19:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:19:20 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:19:20 @pendulum_agent.py:289][0m Total time: 3429.247220993042
[32m[20221124 22:19:20 @pendulum_agent.py:291][0m 11100000 total steps have happened
[32m[20221124 22:19:20 @pendulum_agent.py:281][0m #------------------------ Iteration 222 --------------------------#
[32m[20221124 22:19:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:19:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:19:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:19:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:19:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:19:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:19:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:19:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:19:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:19:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:19:23 @pendulum_agent.py:307][0m Sample time: 3.6590561866760254
[32m[20221124 22:19:37 @pendulum_agent.py:312][0m Update time: 13.97152590751648
[32m[20221124 22:19:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:19:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:19:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:19:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:19:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:19:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:19:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:19:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:19:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:19:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:19:38 @pendulum_agent.py:317][0m Evaluation time: 0.8190581798553467
[32m[20221124 22:19:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:19:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:19:38 @pendulum_agent.py:289][0m Total time: 3447.981791973114
[32m[20221124 22:19:38 @pendulum_agent.py:291][0m 11150000 total steps have happened
[32m[20221124 22:19:38 @pendulum_agent.py:281][0m #------------------------ Iteration 223 --------------------------#
[32m[20221124 22:19:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:19:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:19:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:19:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:19:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:19:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:19:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:19:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:19:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:19:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:19:42 @pendulum_agent.py:307][0m Sample time: 3.440793037414551
[32m[20221124 22:19:56 @pendulum_agent.py:312][0m Update time: 14.505048990249634
[32m[20221124 22:19:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:19:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:19:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:19:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:19:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:19:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:19:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:19:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:19:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:19:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:19:57 @pendulum_agent.py:317][0m Evaluation time: 1.0166282653808594
[32m[20221124 22:19:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:19:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:19:58 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:19:58 @pendulum_agent.py:289][0m Total time: 3467.2244789600372
[32m[20221124 22:19:58 @pendulum_agent.py:291][0m 11200000 total steps have happened
[32m[20221124 22:19:58 @pendulum_agent.py:281][0m #------------------------ Iteration 224 --------------------------#
[32m[20221124 22:19:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:19:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:19:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:19:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:19:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:19:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:19:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:19:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:19:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:19:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:20:01 @pendulum_agent.py:307][0m Sample time: 3.620450019836426
[32m[20221124 22:20:17 @pendulum_agent.py:312][0m Update time: 15.344151973724365
[32m[20221124 22:20:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:20:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:20:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:20:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:20:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:20:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:20:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:20:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:20:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:20:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:20:17 @pendulum_agent.py:317][0m Evaluation time: 0.706190824508667
[32m[20221124 22:20:18 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:20:18 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:20:18 @pendulum_agent.py:289][0m Total time: 3487.182309150696
[32m[20221124 22:20:18 @pendulum_agent.py:291][0m 11250000 total steps have happened
[32m[20221124 22:20:18 @pendulum_agent.py:281][0m #------------------------ Iteration 225 --------------------------#
[32m[20221124 22:20:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:20:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:20:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:20:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:20:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:20:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:20:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:20:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:20:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:20:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:20:21 @pendulum_agent.py:307][0m Sample time: 3.6240038871765137
[32m[20221124 22:20:30 @pendulum_agent.py:312][0m Update time: 9.014003276824951
[32m[20221124 22:20:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:20:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:20:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:20:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:20:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:20:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:20:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:20:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:20:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:20:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:20:31 @pendulum_agent.py:317][0m Evaluation time: 0.5805668830871582
[32m[20221124 22:20:31 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:20:31 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:20:31 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:20:31 @pendulum_agent.py:289][0m Total time: 3500.702542066574
[32m[20221124 22:20:31 @pendulum_agent.py:291][0m 11300000 total steps have happened
[32m[20221124 22:20:31 @pendulum_agent.py:281][0m #------------------------ Iteration 226 --------------------------#
[32m[20221124 22:20:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.0
[32m[20221124 22:20:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.2
[32m[20221124 22:20:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.0
[32m[20221124 22:20:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.4
[32m[20221124 22:20:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.2
[32m[20221124 22:20:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.6
[32m[20221124 22:20:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.6
[32m[20221124 22:20:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.0
[32m[20221124 22:20:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.0
[32m[20221124 22:20:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.6
[32m[20221124 22:20:35 @pendulum_agent.py:307][0m Sample time: 3.776887893676758
[32m[20221124 22:20:45 @pendulum_agent.py:312][0m Update time: 10.541415929794312
[32m[20221124 22:20:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:20:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:20:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:20:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:20:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:20:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:20:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:20:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:20:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:20:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:20:46 @pendulum_agent.py:317][0m Evaluation time: 0.6979930400848389
[32m[20221124 22:20:46 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.36
[32m[20221124 22:20:46 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:20:46 @pendulum_agent.py:289][0m Total time: 3516.0305910110474
[32m[20221124 22:20:46 @pendulum_agent.py:291][0m 11350000 total steps have happened
[32m[20221124 22:20:46 @pendulum_agent.py:281][0m #------------------------ Iteration 227 --------------------------#
[32m[20221124 22:20:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:20:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:20:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:20:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:20:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:20:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:20:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:20:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:20:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:20:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:20:50 @pendulum_agent.py:307][0m Sample time: 3.7321672439575195
[32m[20221124 22:21:11 @pendulum_agent.py:312][0m Update time: 21.3153018951416
[32m[20221124 22:21:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:21:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:21:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:21:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:21:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:21:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:21:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:21:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:21:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:21:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:21:12 @pendulum_agent.py:317][0m Evaluation time: 0.6957077980041504
[32m[20221124 22:21:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:21:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:21:12 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:21:12 @pendulum_agent.py:289][0m Total time: 3542.0472350120544
[32m[20221124 22:21:12 @pendulum_agent.py:291][0m 11400000 total steps have happened
[32m[20221124 22:21:12 @pendulum_agent.py:281][0m #------------------------ Iteration 228 --------------------------#
[32m[20221124 22:21:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:21:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:21:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:21:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:21:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:21:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:21:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:21:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:21:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:21:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:21:16 @pendulum_agent.py:307][0m Sample time: 3.5787010192871094
[32m[20221124 22:21:25 @pendulum_agent.py:312][0m Update time: 8.930408000946045
[32m[20221124 22:21:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:21:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:21:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:21:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:21:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:21:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:21:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:21:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:21:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:21:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:21:26 @pendulum_agent.py:317][0m Evaluation time: 0.903878927230835
[32m[20221124 22:21:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:21:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:21:26 @pendulum_agent.py:289][0m Total time: 3555.7486588954926
[32m[20221124 22:21:26 @pendulum_agent.py:291][0m 11450000 total steps have happened
[32m[20221124 22:21:26 @pendulum_agent.py:281][0m #------------------------ Iteration 229 --------------------------#
[32m[20221124 22:21:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 12.4
[32m[20221124 22:21:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.8
[32m[20221124 22:21:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 10.0
[32m[20221124 22:21:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 15.6
[32m[20221124 22:21:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.0
[32m[20221124 22:21:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.4
[32m[20221124 22:21:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.8
[32m[20221124 22:21:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.4
[32m[20221124 22:21:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 11.0
[32m[20221124 22:21:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.6
[32m[20221124 22:21:30 @pendulum_agent.py:307][0m Sample time: 3.7154829502105713
[32m[20221124 22:21:39 @pendulum_agent.py:312][0m Update time: 8.94800090789795
[32m[20221124 22:21:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:21:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:21:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:21:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:21:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:21:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:21:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:21:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:21:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:21:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:21:39 @pendulum_agent.py:317][0m Evaluation time: 0.6738131046295166
[32m[20221124 22:21:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.5
[32m[20221124 22:21:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:21:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:21:40 @pendulum_agent.py:289][0m Total time: 3569.349856853485
[32m[20221124 22:21:40 @pendulum_agent.py:291][0m 11500000 total steps have happened
[32m[20221124 22:21:40 @pendulum_agent.py:281][0m #------------------------ Iteration 230 --------------------------#
[32m[20221124 22:21:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:21:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:21:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:21:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:21:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:21:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:21:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:21:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:21:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:21:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:21:43 @pendulum_agent.py:307][0m Sample time: 3.7187860012054443
[32m[20221124 22:22:03 @pendulum_agent.py:312][0m Update time: 19.873053073883057
[32m[20221124 22:22:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:22:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:22:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:22:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:22:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:22:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:22:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:22:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:22:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:22:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:22:04 @pendulum_agent.py:317][0m Evaluation time: 0.6839888095855713
[32m[20221124 22:22:04 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:22:04 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:22:04 @pendulum_agent.py:289][0m Total time: 3593.9255199432373
[32m[20221124 22:22:04 @pendulum_agent.py:291][0m 11550000 total steps have happened
[32m[20221124 22:22:04 @pendulum_agent.py:281][0m #------------------------ Iteration 231 --------------------------#
[32m[20221124 22:22:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:22:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:22:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:22:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:22:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:22:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:22:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:22:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:22:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:22:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:22:08 @pendulum_agent.py:307][0m Sample time: 3.4107141494750977
[32m[20221124 22:22:21 @pendulum_agent.py:312][0m Update time: 13.100260972976685
[32m[20221124 22:22:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:22:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:22:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:22:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:22:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:22:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:22:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:22:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:22:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:22:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:22:22 @pendulum_agent.py:317][0m Evaluation time: 0.9139750003814697
[32m[20221124 22:22:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:22:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:22:22 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:22:22 @pendulum_agent.py:289][0m Total time: 3611.615860939026
[32m[20221124 22:22:22 @pendulum_agent.py:291][0m 11600000 total steps have happened
[32m[20221124 22:22:22 @pendulum_agent.py:281][0m #------------------------ Iteration 232 --------------------------#
[32m[20221124 22:22:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:22:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:22:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:22:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:22:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:22:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:22:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:22:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:22:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:22:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:22:25 @pendulum_agent.py:307][0m Sample time: 3.2852609157562256
[32m[20221124 22:22:40 @pendulum_agent.py:312][0m Update time: 15.067811965942383
[32m[20221124 22:22:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:22:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:22:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:22:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:22:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:22:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:22:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:22:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:22:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:22:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:22:42 @pendulum_agent.py:317][0m Evaluation time: 1.6441941261291504
[32m[20221124 22:22:42 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:22:42 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:22:42 @pendulum_agent.py:289][0m Total time: 3631.9030051231384
[32m[20221124 22:22:42 @pendulum_agent.py:291][0m 11650000 total steps have happened
[32m[20221124 22:22:42 @pendulum_agent.py:281][0m #------------------------ Iteration 233 --------------------------#
[32m[20221124 22:22:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.2
[32m[20221124 22:22:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.4
[32m[20221124 22:22:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.0
[32m[20221124 22:22:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.0
[32m[20221124 22:22:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.8
[32m[20221124 22:22:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.4
[32m[20221124 22:22:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.8
[32m[20221124 22:22:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.8
[32m[20221124 22:22:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.8
[32m[20221124 22:22:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.8
[32m[20221124 22:22:46 @pendulum_agent.py:307][0m Sample time: 3.794861078262329
[32m[20221124 22:22:55 @pendulum_agent.py:312][0m Update time: 8.881139993667603
[32m[20221124 22:22:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:22:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:22:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:22:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:22:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:22:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:22:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:22:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:22:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:22:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:22:56 @pendulum_agent.py:317][0m Evaluation time: 0.7098989486694336
[32m[20221124 22:22:56 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.4
[32m[20221124 22:22:56 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:22:56 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:22:56 @pendulum_agent.py:289][0m Total time: 3645.5608949661255
[32m[20221124 22:22:56 @pendulum_agent.py:291][0m 11700000 total steps have happened
[32m[20221124 22:22:56 @pendulum_agent.py:281][0m #------------------------ Iteration 234 --------------------------#
[32m[20221124 22:22:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:22:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:22:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:22:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:22:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:22:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:22:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:22:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:22:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:22:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:23:00 @pendulum_agent.py:307][0m Sample time: 3.638136863708496
[32m[20221124 22:23:14 @pendulum_agent.py:312][0m Update time: 14.860100030899048
[32m[20221124 22:23:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:23:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:23:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:23:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:23:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:23:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:23:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:23:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:23:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:23:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:23:15 @pendulum_agent.py:317][0m Evaluation time: 0.6990189552307129
[32m[20221124 22:23:15 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:23:15 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:23:15 @pendulum_agent.py:289][0m Total time: 3665.034791946411
[32m[20221124 22:23:15 @pendulum_agent.py:291][0m 11750000 total steps have happened
[32m[20221124 22:23:15 @pendulum_agent.py:281][0m #------------------------ Iteration 235 --------------------------#
[32m[20221124 22:23:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:23:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:23:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:23:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:23:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:23:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:23:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:23:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:23:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:23:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:23:19 @pendulum_agent.py:307][0m Sample time: 3.737196683883667
[32m[20221124 22:23:34 @pendulum_agent.py:312][0m Update time: 14.829623222351074
[32m[20221124 22:23:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:23:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:23:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:23:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:23:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:23:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:23:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:23:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:23:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:23:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:23:35 @pendulum_agent.py:317][0m Evaluation time: 0.7006659507751465
[32m[20221124 22:23:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:23:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:23:35 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:23:35 @pendulum_agent.py:289][0m Total time: 3684.5855889320374
[32m[20221124 22:23:35 @pendulum_agent.py:291][0m 11800000 total steps have happened
[32m[20221124 22:23:35 @pendulum_agent.py:281][0m #------------------------ Iteration 236 --------------------------#
[32m[20221124 22:23:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:23:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:23:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:23:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:23:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:23:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:23:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:23:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:23:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:23:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:23:38 @pendulum_agent.py:307][0m Sample time: 3.5004899501800537
[32m[20221124 22:23:47 @pendulum_agent.py:312][0m Update time: 8.820913791656494
[32m[20221124 22:23:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:23:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:23:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:23:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:23:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:23:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:23:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:23:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:23:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:23:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:23:48 @pendulum_agent.py:317][0m Evaluation time: 0.8102593421936035
[32m[20221124 22:23:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:23:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:23:48 @pendulum_agent.py:289][0m Total time: 3697.9906191825867
[32m[20221124 22:23:48 @pendulum_agent.py:291][0m 11850000 total steps have happened
[32m[20221124 22:23:48 @pendulum_agent.py:281][0m #------------------------ Iteration 237 --------------------------#
[32m[20221124 22:23:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:23:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:23:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:23:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:23:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:23:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:23:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:23:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:23:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:23:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:23:52 @pendulum_agent.py:307][0m Sample time: 3.746351957321167
[32m[20221124 22:24:26 @pendulum_agent.py:312][0m Update time: 33.637523889541626
[32m[20221124 22:24:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:24:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:24:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:24:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:24:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:24:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:24:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:24:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:24:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:24:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:24:26 @pendulum_agent.py:317][0m Evaluation time: 0.680901050567627
[32m[20221124 22:24:27 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:24:27 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:24:27 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:24:27 @pendulum_agent.py:289][0m Total time: 3736.3245129585266
[32m[20221124 22:24:27 @pendulum_agent.py:291][0m 11900000 total steps have happened
[32m[20221124 22:24:27 @pendulum_agent.py:281][0m #------------------------ Iteration 238 --------------------------#
[32m[20221124 22:24:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:24:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:24:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:24:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:24:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:24:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:24:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:24:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:24:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:24:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:24:30 @pendulum_agent.py:307][0m Sample time: 3.7689919471740723
[32m[20221124 22:24:46 @pendulum_agent.py:312][0m Update time: 15.177558898925781
[32m[20221124 22:24:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:24:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:24:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:24:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:24:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:24:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:24:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:24:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:24:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:24:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:24:46 @pendulum_agent.py:317][0m Evaluation time: 0.7108070850372314
[32m[20221124 22:24:47 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:24:47 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:24:47 @pendulum_agent.py:289][0m Total time: 3756.2644760608673
[32m[20221124 22:24:47 @pendulum_agent.py:291][0m 11950000 total steps have happened
[32m[20221124 22:24:47 @pendulum_agent.py:281][0m #------------------------ Iteration 239 --------------------------#
[32m[20221124 22:24:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:24:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:24:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:24:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:24:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:24:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:24:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:24:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:24:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:24:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:24:50 @pendulum_agent.py:307][0m Sample time: 3.587930917739868
[32m[20221124 22:24:59 @pendulum_agent.py:312][0m Update time: 8.925551176071167
[32m[20221124 22:24:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:24:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:24:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:24:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:24:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:24:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:24:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:24:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:24:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:24:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:25:00 @pendulum_agent.py:317][0m Evaluation time: 0.6954519748687744
[32m[20221124 22:25:00 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:25:00 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:25:00 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:25:00 @pendulum_agent.py:289][0m Total time: 3769.757547855377
[32m[20221124 22:25:00 @pendulum_agent.py:291][0m 12000000 total steps have happened
[32m[20221124 22:25:00 @pendulum_agent.py:281][0m #------------------------ Iteration 240 --------------------------#
[32m[20221124 22:25:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:25:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:25:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:25:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:25:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:25:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:25:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:25:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:25:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:25:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:25:04 @pendulum_agent.py:307][0m Sample time: 3.4559710025787354
[32m[20221124 22:25:13 @pendulum_agent.py:312][0m Update time: 8.930602073669434
[32m[20221124 22:25:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:25:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:25:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:25:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:25:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:25:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:25:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:25:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:25:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:25:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:25:13 @pendulum_agent.py:317][0m Evaluation time: 0.8377888202667236
[32m[20221124 22:25:14 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:25:14 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:25:14 @pendulum_agent.py:289][0m Total time: 3783.263197183609
[32m[20221124 22:25:14 @pendulum_agent.py:291][0m 12050000 total steps have happened
[32m[20221124 22:25:14 @pendulum_agent.py:281][0m #------------------------ Iteration 241 --------------------------#
[32m[20221124 22:25:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:25:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:25:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:25:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:25:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:25:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:25:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:25:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:25:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:25:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:25:17 @pendulum_agent.py:307][0m Sample time: 3.4509360790252686
[32m[20221124 22:25:26 @pendulum_agent.py:312][0m Update time: 8.847576141357422
[32m[20221124 22:25:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:25:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:25:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:25:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:25:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:25:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:25:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:25:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:25:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:25:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:25:27 @pendulum_agent.py:317][0m Evaluation time: 1.0281610488891602
[32m[20221124 22:25:27 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:25:27 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:25:27 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:25:27 @pendulum_agent.py:289][0m Total time: 3796.880213022232
[32m[20221124 22:25:27 @pendulum_agent.py:291][0m 12100000 total steps have happened
[32m[20221124 22:25:27 @pendulum_agent.py:281][0m #------------------------ Iteration 242 --------------------------#
[32m[20221124 22:25:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:25:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:25:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:25:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:25:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:25:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:25:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:25:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:25:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:25:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:25:31 @pendulum_agent.py:307][0m Sample time: 3.345783233642578
[32m[20221124 22:25:39 @pendulum_agent.py:312][0m Update time: 8.749683856964111
[32m[20221124 22:25:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:25:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:25:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:25:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:25:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:25:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:25:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:25:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:25:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:25:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:25:41 @pendulum_agent.py:317][0m Evaluation time: 1.1599550247192383
[32m[20221124 22:25:41 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:25:41 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:25:41 @pendulum_agent.py:289][0m Total time: 3810.4063580036163
[32m[20221124 22:25:41 @pendulum_agent.py:291][0m 12150000 total steps have happened
[32m[20221124 22:25:41 @pendulum_agent.py:281][0m #------------------------ Iteration 243 --------------------------#
[32m[20221124 22:25:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:25:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:25:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:25:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:25:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:25:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:25:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:25:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:25:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:25:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:25:44 @pendulum_agent.py:307][0m Sample time: 3.3527982234954834
[32m[20221124 22:25:53 @pendulum_agent.py:312][0m Update time: 8.740906715393066
[32m[20221124 22:25:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:25:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:25:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:25:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:25:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:25:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:25:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:25:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:25:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:25:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:25:55 @pendulum_agent.py:317][0m Evaluation time: 1.8173532485961914
[32m[20221124 22:25:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:25:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:25:55 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:25:55 @pendulum_agent.py:289][0m Total time: 3824.6182379722595
[32m[20221124 22:25:55 @pendulum_agent.py:291][0m 12200000 total steps have happened
[32m[20221124 22:25:55 @pendulum_agent.py:281][0m #------------------------ Iteration 244 --------------------------#
[32m[20221124 22:25:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:25:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:25:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:25:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:25:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:25:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:25:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:25:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:25:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:25:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:25:59 @pendulum_agent.py:307][0m Sample time: 3.5422611236572266
[32m[20221124 22:26:07 @pendulum_agent.py:312][0m Update time: 8.807675838470459
[32m[20221124 22:26:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:26:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:26:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:26:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:26:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:26:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:26:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:26:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:26:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:26:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:26:08 @pendulum_agent.py:317][0m Evaluation time: 0.7015700340270996
[32m[20221124 22:26:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:26:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:26:08 @pendulum_agent.py:289][0m Total time: 3837.9554789066315
[32m[20221124 22:26:08 @pendulum_agent.py:291][0m 12250000 total steps have happened
[32m[20221124 22:26:08 @pendulum_agent.py:281][0m #------------------------ Iteration 245 --------------------------#
[32m[20221124 22:26:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:26:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:26:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:26:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:26:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:26:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:26:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:26:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:26:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:26:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:26:12 @pendulum_agent.py:307][0m Sample time: 3.6450603008270264
[32m[20221124 22:26:21 @pendulum_agent.py:312][0m Update time: 8.635827779769897
[32m[20221124 22:26:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:26:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:26:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:26:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:26:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:26:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:26:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:26:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:26:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:26:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:26:22 @pendulum_agent.py:317][0m Evaluation time: 0.9665849208831787
[32m[20221124 22:26:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:26:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:26:22 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:26:22 @pendulum_agent.py:289][0m Total time: 3851.4856429100037
[32m[20221124 22:26:22 @pendulum_agent.py:291][0m 12300000 total steps have happened
[32m[20221124 22:26:22 @pendulum_agent.py:281][0m #------------------------ Iteration 246 --------------------------#
[32m[20221124 22:26:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:26:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:26:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:26:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:26:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:26:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:26:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:26:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:26:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:26:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:26:26 @pendulum_agent.py:307][0m Sample time: 3.828187942504883
[32m[20221124 22:26:34 @pendulum_agent.py:312][0m Update time: 8.622400999069214
[32m[20221124 22:26:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 41.0
[32m[20221124 22:26:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 41.0
[32m[20221124 22:26:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 41.0
[32m[20221124 22:26:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 41.0
[32m[20221124 22:26:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 41.0
[32m[20221124 22:26:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 41.0
[32m[20221124 22:26:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 41.0
[32m[20221124 22:26:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 41.0
[32m[20221124 22:26:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 41.0
[32m[20221124 22:26:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 41.0
[32m[20221124 22:26:35 @pendulum_agent.py:317][0m Evaluation time: 0.9172132015228271
[32m[20221124 22:26:36 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:26:36 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:26:36 @pendulum_agent.py:289][0m Total time: 3865.112972974777
[32m[20221124 22:26:36 @pendulum_agent.py:291][0m 12350000 total steps have happened
[32m[20221124 22:26:36 @pendulum_agent.py:281][0m #------------------------ Iteration 247 --------------------------#
[32m[20221124 22:26:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:26:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:26:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:26:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:26:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:26:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:26:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:26:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:26:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:26:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:26:39 @pendulum_agent.py:307][0m Sample time: 3.8886361122131348
[32m[20221124 22:26:56 @pendulum_agent.py:312][0m Update time: 16.812427043914795
[32m[20221124 22:26:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:26:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:26:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:26:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:26:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:26:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:26:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:26:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:26:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:26:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:26:57 @pendulum_agent.py:317][0m Evaluation time: 0.7111408710479736
[32m[20221124 22:26:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:26:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:26:57 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:26:57 @pendulum_agent.py:289][0m Total time: 3886.8137838840485
[32m[20221124 22:26:57 @pendulum_agent.py:291][0m 12400000 total steps have happened
[32m[20221124 22:26:57 @pendulum_agent.py:281][0m #------------------------ Iteration 248 --------------------------#
[32m[20221124 22:26:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:26:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:26:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:26:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:26:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:26:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:26:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:26:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:26:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:26:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:27:01 @pendulum_agent.py:307][0m Sample time: 3.5597310066223145
[32m[20221124 22:27:10 @pendulum_agent.py:312][0m Update time: 8.802042961120605
[32m[20221124 22:27:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:27:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:27:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:27:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:27:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:27:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:27:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:27:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:27:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:27:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:27:10 @pendulum_agent.py:317][0m Evaluation time: 0.590001106262207
[32m[20221124 22:27:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:27:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:27:10 @pendulum_agent.py:289][0m Total time: 3900.0606729984283
[32m[20221124 22:27:10 @pendulum_agent.py:291][0m 12450000 total steps have happened
[32m[20221124 22:27:10 @pendulum_agent.py:281][0m #------------------------ Iteration 249 --------------------------#
[32m[20221124 22:27:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 10.2
[32m[20221124 22:27:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.2
[32m[20221124 22:27:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.4
[32m[20221124 22:27:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.2
[32m[20221124 22:27:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.4
[32m[20221124 22:27:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 7.2
[32m[20221124 22:27:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.2
[32m[20221124 22:27:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.6
[32m[20221124 22:27:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.0
[32m[20221124 22:27:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.2
[32m[20221124 22:27:14 @pendulum_agent.py:307][0m Sample time: 3.7837531566619873
[32m[20221124 22:27:25 @pendulum_agent.py:312][0m Update time: 10.874484062194824
[32m[20221124 22:27:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:27:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:27:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:27:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:27:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:27:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:27:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:27:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:27:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:27:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:27:26 @pendulum_agent.py:317][0m Evaluation time: 0.5705528259277344
[32m[20221124 22:27:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.96
[32m[20221124 22:27:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:27:26 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:27:26 @pendulum_agent.py:289][0m Total time: 3915.592045068741
[32m[20221124 22:27:26 @pendulum_agent.py:291][0m 12500000 total steps have happened
[32m[20221124 22:27:26 @pendulum_agent.py:281][0m #------------------------ Iteration 250 --------------------------#
[32m[20221124 22:27:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.2
[32m[20221124 22:27:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 17.6
[32m[20221124 22:27:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 7.0
[32m[20221124 22:27:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 10.0
[32m[20221124 22:27:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 13.0
[32m[20221124 22:27:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.6
[32m[20221124 22:27:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 9.8
[32m[20221124 22:27:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 9.2
[32m[20221124 22:27:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 8.4
[32m[20221124 22:27:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 9.2
[32m[20221124 22:27:30 @pendulum_agent.py:307][0m Sample time: 3.7706639766693115
[32m[20221124 22:27:39 @pendulum_agent.py:312][0m Update time: 8.811285018920898
[32m[20221124 22:27:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:27:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:27:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:27:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:27:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:27:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:27:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:27:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:27:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:27:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:27:39 @pendulum_agent.py:317][0m Evaluation time: 0.5811808109283447
[32m[20221124 22:27:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 9.6
[32m[20221124 22:27:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:27:39 @pendulum_agent.py:289][0m Total time: 3929.063684940338
[32m[20221124 22:27:39 @pendulum_agent.py:291][0m 12550000 total steps have happened
[32m[20221124 22:27:39 @pendulum_agent.py:281][0m #------------------------ Iteration 251 --------------------------#
[32m[20221124 22:27:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:27:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:27:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:27:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:27:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:27:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:27:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:27:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:27:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:27:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:27:43 @pendulum_agent.py:307][0m Sample time: 3.868802070617676
[32m[20221124 22:27:57 @pendulum_agent.py:312][0m Update time: 14.015727758407593
[32m[20221124 22:27:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:27:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:27:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:27:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:27:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:27:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:27:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:27:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:27:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:27:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:27:58 @pendulum_agent.py:317][0m Evaluation time: 0.6824190616607666
[32m[20221124 22:27:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:27:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:27:58 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:27:58 @pendulum_agent.py:289][0m Total time: 3947.9135410785675
[32m[20221124 22:27:58 @pendulum_agent.py:291][0m 12600000 total steps have happened
[32m[20221124 22:27:58 @pendulum_agent.py:281][0m #------------------------ Iteration 252 --------------------------#
[32m[20221124 22:27:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.8
[32m[20221124 22:27:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 10.0
[32m[20221124 22:27:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.4
[32m[20221124 22:27:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.2
[32m[20221124 22:27:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 15.8
[32m[20221124 22:27:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.2
[32m[20221124 22:27:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.6
[32m[20221124 22:27:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.4
[32m[20221124 22:27:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.0
[32m[20221124 22:27:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.6
[32m[20221124 22:28:02 @pendulum_agent.py:307][0m Sample time: 3.5293211936950684
[32m[20221124 22:28:11 @pendulum_agent.py:312][0m Update time: 8.892087936401367
[32m[20221124 22:28:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:28:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:28:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:28:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:28:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:28:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:28:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:28:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:28:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:28:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:28:12 @pendulum_agent.py:317][0m Evaluation time: 0.8433351516723633
[32m[20221124 22:28:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.5
[32m[20221124 22:28:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:28:12 @pendulum_agent.py:289][0m Total time: 3961.475687980652
[32m[20221124 22:28:12 @pendulum_agent.py:291][0m 12650000 total steps have happened
[32m[20221124 22:28:12 @pendulum_agent.py:281][0m #------------------------ Iteration 253 --------------------------#
[32m[20221124 22:28:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:28:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:28:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:28:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:28:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:28:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:28:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:28:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:28:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:28:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:28:15 @pendulum_agent.py:307][0m Sample time: 3.297938823699951
[32m[20221124 22:28:34 @pendulum_agent.py:312][0m Update time: 18.989037036895752
[32m[20221124 22:28:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:28:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:28:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:28:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:28:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:28:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:28:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:28:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:28:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:28:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:28:35 @pendulum_agent.py:317][0m Evaluation time: 1.022165060043335
[32m[20221124 22:28:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:28:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:28:35 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:28:35 @pendulum_agent.py:289][0m Total time: 3985.058751821518
[32m[20221124 22:28:35 @pendulum_agent.py:291][0m 12700000 total steps have happened
[32m[20221124 22:28:35 @pendulum_agent.py:281][0m #------------------------ Iteration 254 --------------------------#
[32m[20221124 22:28:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:28:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:28:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:28:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:28:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:28:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:28:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:28:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:28:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:28:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:28:39 @pendulum_agent.py:307][0m Sample time: 3.540883779525757
[32m[20221124 22:28:48 @pendulum_agent.py:312][0m Update time: 8.898490905761719
[32m[20221124 22:28:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:28:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:28:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:28:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:28:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:28:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:28:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:28:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:28:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:28:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:28:49 @pendulum_agent.py:317][0m Evaluation time: 1.2325351238250732
[32m[20221124 22:28:49 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:28:49 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:28:49 @pendulum_agent.py:289][0m Total time: 3999.0149099826813
[32m[20221124 22:28:49 @pendulum_agent.py:291][0m 12750000 total steps have happened
[32m[20221124 22:28:49 @pendulum_agent.py:281][0m #------------------------ Iteration 255 --------------------------#
[32m[20221124 22:28:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:28:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:28:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:28:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:28:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:28:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:28:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:28:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:28:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:28:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:28:53 @pendulum_agent.py:307][0m Sample time: 3.5190529823303223
[32m[20221124 22:29:02 @pendulum_agent.py:312][0m Update time: 9.020484209060669
[32m[20221124 22:29:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:29:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:29:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:29:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:29:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:29:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:29:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:29:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:29:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:29:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:29:03 @pendulum_agent.py:317][0m Evaluation time: 1.2749619483947754
[32m[20221124 22:29:04 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:29:04 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:29:04 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:29:04 @pendulum_agent.py:289][0m Total time: 4013.136432170868
[32m[20221124 22:29:04 @pendulum_agent.py:291][0m 12800000 total steps have happened
[32m[20221124 22:29:04 @pendulum_agent.py:281][0m #------------------------ Iteration 256 --------------------------#
[32m[20221124 22:29:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:29:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:29:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:29:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:29:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:29:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:29:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:29:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:29:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:29:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:29:08 @pendulum_agent.py:307][0m Sample time: 3.9972991943359375
[32m[20221124 22:29:17 @pendulum_agent.py:312][0m Update time: 9.865103721618652
[32m[20221124 22:29:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:29:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:29:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:29:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:29:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:29:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:29:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:29:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:29:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:29:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:29:18 @pendulum_agent.py:317][0m Evaluation time: 0.8600692749023438
[32m[20221124 22:29:19 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:29:19 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:29:19 @pendulum_agent.py:289][0m Total time: 4028.2659409046173
[32m[20221124 22:29:19 @pendulum_agent.py:291][0m 12850000 total steps have happened
[32m[20221124 22:29:19 @pendulum_agent.py:281][0m #------------------------ Iteration 257 --------------------------#
[32m[20221124 22:29:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:29:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:29:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:29:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:29:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:29:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:29:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:29:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:29:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:29:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:29:23 @pendulum_agent.py:307][0m Sample time: 4.476202964782715
[32m[20221124 22:29:33 @pendulum_agent.py:312][0m Update time: 9.820069074630737
[32m[20221124 22:29:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:29:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:29:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:29:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:29:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:29:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:29:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:29:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:29:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:29:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:29:34 @pendulum_agent.py:317][0m Evaluation time: 0.7958760261535645
[32m[20221124 22:29:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:29:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:29:34 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:29:34 @pendulum_agent.py:289][0m Total time: 4043.677164077759
[32m[20221124 22:29:34 @pendulum_agent.py:291][0m 12900000 total steps have happened
[32m[20221124 22:29:34 @pendulum_agent.py:281][0m #------------------------ Iteration 258 --------------------------#
[32m[20221124 22:29:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:29:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:29:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:29:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:29:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:29:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:29:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:29:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:29:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:29:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:29:38 @pendulum_agent.py:307][0m Sample time: 3.963574171066284
[32m[20221124 22:29:48 @pendulum_agent.py:312][0m Update time: 9.614863872528076
[32m[20221124 22:29:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:29:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:29:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:29:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:29:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:29:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:29:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:29:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:29:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:29:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:29:48 @pendulum_agent.py:317][0m Evaluation time: 0.7481949329376221
[32m[20221124 22:29:49 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:29:49 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:29:49 @pendulum_agent.py:289][0m Total time: 4058.298315048218
[32m[20221124 22:29:49 @pendulum_agent.py:291][0m 12950000 total steps have happened
[32m[20221124 22:29:49 @pendulum_agent.py:281][0m #------------------------ Iteration 259 --------------------------#
[32m[20221124 22:29:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.2
[32m[20221124 22:29:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.8
[32m[20221124 22:29:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.2
[32m[20221124 22:29:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.8
[32m[20221124 22:29:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.6
[32m[20221124 22:29:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.8
[32m[20221124 22:29:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.4
[32m[20221124 22:29:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.2
[32m[20221124 22:29:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.8
[32m[20221124 22:29:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.2
[32m[20221124 22:29:53 @pendulum_agent.py:307][0m Sample time: 4.099247932434082
[32m[20221124 22:30:02 @pendulum_agent.py:312][0m Update time: 9.386842966079712
[32m[20221124 22:30:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 14.0
[32m[20221124 22:30:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 14.0
[32m[20221124 22:30:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 14.0
[32m[20221124 22:30:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 14.0
[32m[20221124 22:30:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 14.0
[32m[20221124 22:30:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 14.0
[32m[20221124 22:30:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 14.0
[32m[20221124 22:30:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 14.0
[32m[20221124 22:30:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 14.0
[32m[20221124 22:30:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 14.0
[32m[20221124 22:30:03 @pendulum_agent.py:317][0m Evaluation time: 0.6400282382965088
[32m[20221124 22:30:03 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.4
[32m[20221124 22:30:03 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:30:03 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:30:03 @pendulum_agent.py:289][0m Total time: 4072.735363960266
[32m[20221124 22:30:03 @pendulum_agent.py:291][0m 13000000 total steps have happened
[32m[20221124 22:30:03 @pendulum_agent.py:281][0m #------------------------ Iteration 260 --------------------------#
[32m[20221124 22:30:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:30:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:30:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:30:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:30:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:30:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:30:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:30:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:30:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:30:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:30:07 @pendulum_agent.py:307][0m Sample time: 4.0190019607543945
[32m[20221124 22:30:17 @pendulum_agent.py:312][0m Update time: 9.771762132644653
[32m[20221124 22:30:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:30:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:30:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:30:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:30:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:30:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:30:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:30:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:30:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:30:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:30:18 @pendulum_agent.py:317][0m Evaluation time: 0.7542581558227539
[32m[20221124 22:30:18 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:30:18 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:30:18 @pendulum_agent.py:289][0m Total time: 4087.564754962921
[32m[20221124 22:30:18 @pendulum_agent.py:291][0m 13050000 total steps have happened
[32m[20221124 22:30:18 @pendulum_agent.py:281][0m #------------------------ Iteration 261 --------------------------#
[32m[20221124 22:30:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:30:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:30:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:30:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:30:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:30:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:30:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:30:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:30:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:30:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:30:22 @pendulum_agent.py:307][0m Sample time: 3.7285730838775635
[32m[20221124 22:30:31 @pendulum_agent.py:312][0m Update time: 9.18541693687439
[32m[20221124 22:30:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:30:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:30:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:30:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:30:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:30:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:30:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:30:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:30:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:30:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:30:32 @pendulum_agent.py:317][0m Evaluation time: 0.8138859272003174
[32m[20221124 22:30:32 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:30:32 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:30:32 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:30:32 @pendulum_agent.py:289][0m Total time: 4101.64658498764
[32m[20221124 22:30:32 @pendulum_agent.py:291][0m 13100000 total steps have happened
[32m[20221124 22:30:32 @pendulum_agent.py:281][0m #------------------------ Iteration 262 --------------------------#
[32m[20221124 22:30:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:30:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:30:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:30:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:30:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:30:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:30:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:30:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:30:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:30:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:30:36 @pendulum_agent.py:307][0m Sample time: 3.9157118797302246
[32m[20221124 22:30:45 @pendulum_agent.py:312][0m Update time: 9.373311996459961
[32m[20221124 22:30:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:30:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:30:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:30:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:30:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:30:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:30:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:30:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:30:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:30:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:30:46 @pendulum_agent.py:317][0m Evaluation time: 0.8930540084838867
[32m[20221124 22:30:47 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:30:47 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:30:47 @pendulum_agent.py:289][0m Total time: 4116.109470844269
[32m[20221124 22:30:47 @pendulum_agent.py:291][0m 13150000 total steps have happened
[32m[20221124 22:30:47 @pendulum_agent.py:281][0m #------------------------ Iteration 263 --------------------------#
[32m[20221124 22:30:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 9.2
[32m[20221124 22:30:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.2
[32m[20221124 22:30:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.6
[32m[20221124 22:30:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.8
[32m[20221124 22:30:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.4
[32m[20221124 22:30:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.6
[32m[20221124 22:30:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.0
[32m[20221124 22:30:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.6
[32m[20221124 22:30:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.4
[32m[20221124 22:30:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.8
[32m[20221124 22:30:50 @pendulum_agent.py:307][0m Sample time: 3.477537155151367
[32m[20221124 22:31:00 @pendulum_agent.py:312][0m Update time: 9.615808963775635
[32m[20221124 22:31:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:31:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:31:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:31:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:31:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:31:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:31:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:31:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:31:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:31:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:31:01 @pendulum_agent.py:317][0m Evaluation time: 1.1240029335021973
[32m[20221124 22:31:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.86
[32m[20221124 22:31:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:31:01 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:31:01 @pendulum_agent.py:289][0m Total time: 4130.635215997696
[32m[20221124 22:31:01 @pendulum_agent.py:291][0m 13200000 total steps have happened
[32m[20221124 22:31:01 @pendulum_agent.py:281][0m #------------------------ Iteration 264 --------------------------#
[32m[20221124 22:31:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:31:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:31:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:31:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:31:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:31:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:31:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:31:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:31:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:31:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:31:04 @pendulum_agent.py:307][0m Sample time: 3.4334659576416016
[32m[20221124 22:31:14 @pendulum_agent.py:312][0m Update time: 9.80196213722229
[32m[20221124 22:31:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:31:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:31:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:31:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:31:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:31:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:31:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:31:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:31:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:31:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:31:15 @pendulum_agent.py:317][0m Evaluation time: 1.0878148078918457
[32m[20221124 22:31:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:31:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:31:16 @pendulum_agent.py:289][0m Total time: 4145.260194063187
[32m[20221124 22:31:16 @pendulum_agent.py:291][0m 13250000 total steps have happened
[32m[20221124 22:31:16 @pendulum_agent.py:281][0m #------------------------ Iteration 265 --------------------------#
[32m[20221124 22:31:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:31:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:31:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:31:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:31:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:31:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:31:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:31:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:31:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:31:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:31:19 @pendulum_agent.py:307][0m Sample time: 3.784421920776367
[32m[20221124 22:31:29 @pendulum_agent.py:312][0m Update time: 9.825326919555664
[32m[20221124 22:31:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:31:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:31:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:31:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:31:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:31:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:31:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:31:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:31:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:31:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:31:30 @pendulum_agent.py:317][0m Evaluation time: 0.7979059219360352
[32m[20221124 22:31:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:31:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:31:30 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:31:30 @pendulum_agent.py:289][0m Total time: 4159.9654240608215
[32m[20221124 22:31:30 @pendulum_agent.py:291][0m 13300000 total steps have happened
[32m[20221124 22:31:30 @pendulum_agent.py:281][0m #------------------------ Iteration 266 --------------------------#
[32m[20221124 22:31:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:31:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:31:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:31:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:31:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:31:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:31:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:31:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:31:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:31:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:31:34 @pendulum_agent.py:307][0m Sample time: 3.686753988265991
[32m[20221124 22:31:43 @pendulum_agent.py:312][0m Update time: 8.930217981338501
[32m[20221124 22:31:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:31:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:31:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:31:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:31:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:31:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:31:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:31:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:31:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:31:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:31:44 @pendulum_agent.py:317][0m Evaluation time: 0.7843892574310303
[32m[20221124 22:31:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:31:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:31:44 @pendulum_agent.py:289][0m Total time: 4173.666438102722
[32m[20221124 22:31:44 @pendulum_agent.py:291][0m 13350000 total steps have happened
[32m[20221124 22:31:44 @pendulum_agent.py:281][0m #------------------------ Iteration 267 --------------------------#
[32m[20221124 22:31:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:31:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:31:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:31:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:31:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:31:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:31:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:31:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:31:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:31:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:31:48 @pendulum_agent.py:307][0m Sample time: 3.9334568977355957
[32m[20221124 22:31:58 @pendulum_agent.py:312][0m Update time: 9.906961917877197
[32m[20221124 22:31:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:31:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:31:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:31:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:31:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:31:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:31:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:31:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:31:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:31:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:31:59 @pendulum_agent.py:317][0m Evaluation time: 0.6050059795379639
[32m[20221124 22:31:59 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:31:59 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:31:59 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:31:59 @pendulum_agent.py:289][0m Total time: 4188.405837059021
[32m[20221124 22:31:59 @pendulum_agent.py:291][0m 13400000 total steps have happened
[32m[20221124 22:31:59 @pendulum_agent.py:281][0m #------------------------ Iteration 268 --------------------------#
[32m[20221124 22:32:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:32:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:32:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:32:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:32:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:32:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:32:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:32:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:32:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:32:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:32:03 @pendulum_agent.py:307][0m Sample time: 3.7170348167419434
[32m[20221124 22:32:12 @pendulum_agent.py:312][0m Update time: 9.1286461353302
[32m[20221124 22:32:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:32:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:32:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:32:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:32:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:32:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:32:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:32:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:32:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:32:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:32:13 @pendulum_agent.py:317][0m Evaluation time: 1.0054149627685547
[32m[20221124 22:32:13 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:32:13 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:32:13 @pendulum_agent.py:289][0m Total time: 4202.5269548892975
[32m[20221124 22:32:13 @pendulum_agent.py:291][0m 13450000 total steps have happened
[32m[20221124 22:32:13 @pendulum_agent.py:281][0m #------------------------ Iteration 269 --------------------------#
[32m[20221124 22:32:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:32:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:32:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:32:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:32:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:32:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:32:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:32:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:32:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:32:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:32:17 @pendulum_agent.py:307][0m Sample time: 3.8998923301696777
[32m[20221124 22:32:26 @pendulum_agent.py:312][0m Update time: 9.09168791770935
[32m[20221124 22:32:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:32:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:32:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:32:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:32:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:32:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:32:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:32:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:32:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:32:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:32:27 @pendulum_agent.py:317][0m Evaluation time: 1.1377830505371094
[32m[20221124 22:32:27 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:32:27 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:32:27 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:32:27 @pendulum_agent.py:289][0m Total time: 4216.947865009308
[32m[20221124 22:32:27 @pendulum_agent.py:291][0m 13500000 total steps have happened
[32m[20221124 22:32:27 @pendulum_agent.py:281][0m #------------------------ Iteration 270 --------------------------#
[32m[20221124 22:32:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:32:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:32:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:32:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:32:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:32:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:32:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:32:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:32:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:32:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:32:31 @pendulum_agent.py:307][0m Sample time: 3.6993699073791504
[32m[20221124 22:32:41 @pendulum_agent.py:312][0m Update time: 9.593754291534424
[32m[20221124 22:32:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:32:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:32:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:32:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:32:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:32:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:32:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:32:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:32:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:32:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:32:41 @pendulum_agent.py:317][0m Evaluation time: 0.7974240779876709
[32m[20221124 22:32:42 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:32:42 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:32:42 @pendulum_agent.py:289][0m Total time: 4231.341956138611
[32m[20221124 22:32:42 @pendulum_agent.py:291][0m 13550000 total steps have happened
[32m[20221124 22:32:42 @pendulum_agent.py:281][0m #------------------------ Iteration 271 --------------------------#
[32m[20221124 22:32:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:32:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:32:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:32:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:32:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:32:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:32:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:32:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:32:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:32:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:32:46 @pendulum_agent.py:307][0m Sample time: 3.857335090637207
[32m[20221124 22:32:55 @pendulum_agent.py:312][0m Update time: 8.94930386543274
[32m[20221124 22:32:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:32:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:32:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:32:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:32:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:32:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:32:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:32:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:32:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:32:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:32:55 @pendulum_agent.py:317][0m Evaluation time: 0.6290040016174316
[32m[20221124 22:32:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:32:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:32:55 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:32:55 @pendulum_agent.py:289][0m Total time: 4245.078045845032
[32m[20221124 22:32:55 @pendulum_agent.py:291][0m 13600000 total steps have happened
[32m[20221124 22:32:55 @pendulum_agent.py:281][0m #------------------------ Iteration 272 --------------------------#
[32m[20221124 22:32:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:32:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:32:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:32:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:32:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:32:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:32:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:32:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:32:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:32:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:32:59 @pendulum_agent.py:307][0m Sample time: 3.9056320190429688
[32m[20221124 22:33:08 @pendulum_agent.py:312][0m Update time: 8.736443996429443
[32m[20221124 22:33:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:33:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:33:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:33:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:33:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:33:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:33:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:33:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:33:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:33:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:33:09 @pendulum_agent.py:317][0m Evaluation time: 0.7575697898864746
[32m[20221124 22:33:09 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:33:09 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:33:09 @pendulum_agent.py:289][0m Total time: 4258.807893037796
[32m[20221124 22:33:09 @pendulum_agent.py:291][0m 13650000 total steps have happened
[32m[20221124 22:33:09 @pendulum_agent.py:281][0m #------------------------ Iteration 273 --------------------------#
[32m[20221124 22:33:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:33:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:33:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:33:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:33:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:33:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:33:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:33:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:33:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:33:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:33:13 @pendulum_agent.py:307][0m Sample time: 4.161831855773926
[32m[20221124 22:33:23 @pendulum_agent.py:312][0m Update time: 9.832520008087158
[32m[20221124 22:33:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:33:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:33:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:33:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:33:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:33:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:33:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:33:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:33:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:33:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:33:24 @pendulum_agent.py:317][0m Evaluation time: 0.7556972503662109
[32m[20221124 22:33:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:33:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:33:24 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:33:24 @pendulum_agent.py:289][0m Total time: 4273.868526935577
[32m[20221124 22:33:24 @pendulum_agent.py:291][0m 13700000 total steps have happened
[32m[20221124 22:33:24 @pendulum_agent.py:281][0m #------------------------ Iteration 274 --------------------------#
[32m[20221124 22:33:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:33:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:33:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:33:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:33:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:33:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:33:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:33:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:33:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:33:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:33:28 @pendulum_agent.py:307][0m Sample time: 3.6801459789276123
[32m[20221124 22:33:38 @pendulum_agent.py:312][0m Update time: 10.420773029327393
[32m[20221124 22:33:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:33:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:33:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:33:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:33:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:33:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:33:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:33:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:33:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:33:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:33:39 @pendulum_agent.py:317][0m Evaluation time: 1.0632750988006592
[32m[20221124 22:33:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:33:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:33:40 @pendulum_agent.py:289][0m Total time: 4289.351088047028
[32m[20221124 22:33:40 @pendulum_agent.py:291][0m 13750000 total steps have happened
[32m[20221124 22:33:40 @pendulum_agent.py:281][0m #------------------------ Iteration 275 --------------------------#
[32m[20221124 22:33:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 12.4
[32m[20221124 22:33:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 8.2
[32m[20221124 22:33:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.8
[32m[20221124 22:33:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.2
[32m[20221124 22:33:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.2
[32m[20221124 22:33:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.6
[32m[20221124 22:33:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.2
[32m[20221124 22:33:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.2
[32m[20221124 22:33:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.0
[32m[20221124 22:33:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 10.2
[32m[20221124 22:33:44 @pendulum_agent.py:307][0m Sample time: 3.87746000289917
[32m[20221124 22:33:53 @pendulum_agent.py:312][0m Update time: 9.187412977218628
[32m[20221124 22:33:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:33:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:33:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:33:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:33:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:33:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:33:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:33:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:33:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:33:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:33:54 @pendulum_agent.py:317][0m Evaluation time: 0.7414929866790771
[32m[20221124 22:33:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.2
[32m[20221124 22:33:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:33:54 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:33:54 @pendulum_agent.py:289][0m Total time: 4303.428684949875
[32m[20221124 22:33:54 @pendulum_agent.py:291][0m 13800000 total steps have happened
[32m[20221124 22:33:54 @pendulum_agent.py:281][0m #------------------------ Iteration 276 --------------------------#
[32m[20221124 22:33:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:33:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:33:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:33:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:33:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:33:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:33:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:33:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:33:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:33:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:33:58 @pendulum_agent.py:307][0m Sample time: 3.836332082748413
[32m[20221124 22:34:07 @pendulum_agent.py:312][0m Update time: 8.89916205406189
[32m[20221124 22:34:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:34:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:34:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:34:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:34:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:34:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:34:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:34:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:34:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:34:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:34:07 @pendulum_agent.py:317][0m Evaluation time: 0.7043859958648682
[32m[20221124 22:34:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:34:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:34:08 @pendulum_agent.py:289][0m Total time: 4317.139391899109
[32m[20221124 22:34:08 @pendulum_agent.py:291][0m 13850000 total steps have happened
[32m[20221124 22:34:08 @pendulum_agent.py:281][0m #------------------------ Iteration 277 --------------------------#
[32m[20221124 22:34:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.6
[32m[20221124 22:34:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 8.8
[32m[20221124 22:34:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.0
[32m[20221124 22:34:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.2
[32m[20221124 22:34:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 11.0
[32m[20221124 22:34:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 9.2
[32m[20221124 22:34:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 9.2
[32m[20221124 22:34:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.6
[32m[20221124 22:34:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.2
[32m[20221124 22:34:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.2
[32m[20221124 22:34:11 @pendulum_agent.py:307][0m Sample time: 3.4722979068756104
[32m[20221124 22:34:21 @pendulum_agent.py:312][0m Update time: 9.527392148971558
[32m[20221124 22:34:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:34:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:34:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:34:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:34:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:34:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:34:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:34:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:34:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:34:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:34:22 @pendulum_agent.py:317][0m Evaluation time: 1.022961139678955
[32m[20221124 22:34:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.4
[32m[20221124 22:34:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:34:22 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:34:22 @pendulum_agent.py:289][0m Total time: 4331.4614861011505
[32m[20221124 22:34:22 @pendulum_agent.py:291][0m 13900000 total steps have happened
[32m[20221124 22:34:22 @pendulum_agent.py:281][0m #------------------------ Iteration 278 --------------------------#
[32m[20221124 22:34:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:34:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:34:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:34:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:34:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:34:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:34:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:34:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:34:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:34:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:34:25 @pendulum_agent.py:307][0m Sample time: 3.3964829444885254
[32m[20221124 22:34:34 @pendulum_agent.py:312][0m Update time: 8.845091104507446
[32m[20221124 22:34:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:34:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:34:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:34:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:34:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:34:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:34:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:34:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:34:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:34:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:34:36 @pendulum_agent.py:317][0m Evaluation time: 1.7914330959320068
[32m[20221124 22:34:36 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:34:36 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:34:36 @pendulum_agent.py:289][0m Total time: 4345.8001101017
[32m[20221124 22:34:36 @pendulum_agent.py:291][0m 13950000 total steps have happened
[32m[20221124 22:34:36 @pendulum_agent.py:281][0m #------------------------ Iteration 279 --------------------------#
[32m[20221124 22:34:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:34:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:34:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:34:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:34:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:34:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:34:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:34:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:34:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:34:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:34:40 @pendulum_agent.py:307][0m Sample time: 3.837723970413208
[32m[20221124 22:34:49 @pendulum_agent.py:312][0m Update time: 9.00753402709961
[32m[20221124 22:34:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:34:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:34:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:34:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:34:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:34:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:34:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:34:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:34:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:34:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:34:50 @pendulum_agent.py:317][0m Evaluation time: 0.7279369831085205
[32m[20221124 22:34:50 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:34:50 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:34:50 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:34:50 @pendulum_agent.py:289][0m Total time: 4359.644849061966
[32m[20221124 22:34:50 @pendulum_agent.py:291][0m 14000000 total steps have happened
[32m[20221124 22:34:50 @pendulum_agent.py:281][0m #------------------------ Iteration 280 --------------------------#
[32m[20221124 22:34:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.6
[32m[20221124 22:34:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.0
[32m[20221124 22:34:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.0
[32m[20221124 22:34:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.2
[32m[20221124 22:34:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.2
[32m[20221124 22:34:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.8
[32m[20221124 22:34:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.6
[32m[20221124 22:34:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.4
[32m[20221124 22:34:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.2
[32m[20221124 22:34:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.0
[32m[20221124 22:34:54 @pendulum_agent.py:307][0m Sample time: 3.791055202484131
[32m[20221124 22:35:03 @pendulum_agent.py:312][0m Update time: 9.66904592514038
[32m[20221124 22:35:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:35:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:35:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:35:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:35:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:35:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:35:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:35:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:35:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:35:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:35:04 @pendulum_agent.py:317][0m Evaluation time: 0.7953481674194336
[32m[20221124 22:35:05 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.1
[32m[20221124 22:35:05 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:35:05 @pendulum_agent.py:289][0m Total time: 4374.186976909637
[32m[20221124 22:35:05 @pendulum_agent.py:291][0m 14050000 total steps have happened
[32m[20221124 22:35:05 @pendulum_agent.py:281][0m #------------------------ Iteration 281 --------------------------#
[32m[20221124 22:35:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:35:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:35:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:35:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:35:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:35:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:35:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:35:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:35:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:35:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:35:09 @pendulum_agent.py:307][0m Sample time: 3.9370367527008057
[32m[20221124 22:35:18 @pendulum_agent.py:312][0m Update time: 9.001526117324829
[32m[20221124 22:35:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:35:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:35:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:35:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:35:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:35:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:35:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:35:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:35:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:35:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:35:18 @pendulum_agent.py:317][0m Evaluation time: 0.7798759937286377
[32m[20221124 22:35:19 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:35:19 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:35:19 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:35:19 @pendulum_agent.py:289][0m Total time: 4388.183233976364
[32m[20221124 22:35:19 @pendulum_agent.py:291][0m 14100000 total steps have happened
[32m[20221124 22:35:19 @pendulum_agent.py:281][0m #------------------------ Iteration 282 --------------------------#
[32m[20221124 22:35:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.2
[32m[20221124 22:35:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 11.0
[32m[20221124 22:35:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.0
[32m[20221124 22:35:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.6
[32m[20221124 22:35:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.0
[32m[20221124 22:35:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.4
[32m[20221124 22:35:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.0
[32m[20221124 22:35:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.2
[32m[20221124 22:35:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.4
[32m[20221124 22:35:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.6
[32m[20221124 22:35:22 @pendulum_agent.py:307][0m Sample time: 3.6004080772399902
[32m[20221124 22:35:31 @pendulum_agent.py:312][0m Update time: 9.083026885986328
[32m[20221124 22:35:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:35:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:35:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:35:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:35:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:35:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:35:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:35:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:35:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:35:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:35:32 @pendulum_agent.py:317][0m Evaluation time: 0.8404989242553711
[32m[20221124 22:35:32 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.04
[32m[20221124 22:35:32 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:35:32 @pendulum_agent.py:289][0m Total time: 4402.000946760178
[32m[20221124 22:35:32 @pendulum_agent.py:291][0m 14150000 total steps have happened
[32m[20221124 22:35:32 @pendulum_agent.py:281][0m #------------------------ Iteration 283 --------------------------#
[32m[20221124 22:35:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:35:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:35:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:35:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:35:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:35:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:35:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:35:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:35:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:35:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:35:36 @pendulum_agent.py:307][0m Sample time: 3.88911509513855
[32m[20221124 22:35:45 @pendulum_agent.py:312][0m Update time: 8.808201789855957
[32m[20221124 22:35:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:35:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:35:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:35:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:35:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:35:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:35:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:35:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:35:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:35:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:35:46 @pendulum_agent.py:317][0m Evaluation time: 0.7354092597961426
[32m[20221124 22:35:46 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:35:46 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:35:46 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:35:46 @pendulum_agent.py:289][0m Total time: 4415.734541893005
[32m[20221124 22:35:46 @pendulum_agent.py:291][0m 14200000 total steps have happened
[32m[20221124 22:35:46 @pendulum_agent.py:281][0m #------------------------ Iteration 284 --------------------------#
[32m[20221124 22:35:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.8
[32m[20221124 22:35:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.2
[32m[20221124 22:35:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.6
[32m[20221124 22:35:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.2
[32m[20221124 22:35:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.0
[32m[20221124 22:35:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.0
[32m[20221124 22:35:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.0
[32m[20221124 22:35:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.4
[32m[20221124 22:35:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.8
[32m[20221124 22:35:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.0
[32m[20221124 22:35:50 @pendulum_agent.py:307][0m Sample time: 3.9052958488464355
[32m[20221124 22:35:59 @pendulum_agent.py:312][0m Update time: 9.200524091720581
[32m[20221124 22:35:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 9.0
[32m[20221124 22:35:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 9.0
[32m[20221124 22:35:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 9.0
[32m[20221124 22:35:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 9.0
[32m[20221124 22:35:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 9.0
[32m[20221124 22:36:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 9.0
[32m[20221124 22:36:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 9.0
[32m[20221124 22:36:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 9.0
[32m[20221124 22:36:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 9.0
[32m[20221124 22:36:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 9.0
[32m[20221124 22:36:00 @pendulum_agent.py:317][0m Evaluation time: 0.8559091091156006
[32m[20221124 22:36:00 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.3
[32m[20221124 22:36:00 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:36:00 @pendulum_agent.py:289][0m Total time: 4429.963005781174
[32m[20221124 22:36:00 @pendulum_agent.py:291][0m 14250000 total steps have happened
[32m[20221124 22:36:00 @pendulum_agent.py:281][0m #------------------------ Iteration 285 --------------------------#
[32m[20221124 22:36:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:36:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:36:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:36:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:36:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:36:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:36:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:36:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:36:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:36:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:36:04 @pendulum_agent.py:307][0m Sample time: 3.80761981010437
[32m[20221124 22:36:14 @pendulum_agent.py:312][0m Update time: 10.082731008529663
[32m[20221124 22:36:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:36:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:36:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:36:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:36:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:36:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:36:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:36:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:36:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:36:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:36:15 @pendulum_agent.py:317][0m Evaluation time: 0.8241360187530518
[32m[20221124 22:36:15 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:36:15 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:36:15 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:36:15 @pendulum_agent.py:289][0m Total time: 4445.034727096558
[32m[20221124 22:36:15 @pendulum_agent.py:291][0m 14300000 total steps have happened
[32m[20221124 22:36:15 @pendulum_agent.py:281][0m #------------------------ Iteration 286 --------------------------#
[32m[20221124 22:36:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:36:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:36:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:36:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:36:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:36:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:36:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:36:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:36:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:36:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:36:19 @pendulum_agent.py:307][0m Sample time: 3.7206153869628906
[32m[20221124 22:36:28 @pendulum_agent.py:312][0m Update time: 9.205055952072144
[32m[20221124 22:36:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:36:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:36:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:36:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:36:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:36:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:36:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:36:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:36:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:36:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:36:29 @pendulum_agent.py:317][0m Evaluation time: 0.9277529716491699
[32m[20221124 22:36:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:36:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:36:30 @pendulum_agent.py:289][0m Total time: 4459.184907913208
[32m[20221124 22:36:30 @pendulum_agent.py:291][0m 14350000 total steps have happened
[32m[20221124 22:36:30 @pendulum_agent.py:281][0m #------------------------ Iteration 287 --------------------------#
[32m[20221124 22:36:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:36:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:36:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:36:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:36:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:36:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:36:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:36:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:36:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:36:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:36:33 @pendulum_agent.py:307][0m Sample time: 3.536720037460327
[32m[20221124 22:36:43 @pendulum_agent.py:312][0m Update time: 9.798588991165161
[32m[20221124 22:36:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:36:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:36:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:36:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:36:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:36:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:36:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:36:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:36:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:36:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:36:44 @pendulum_agent.py:317][0m Evaluation time: 1.2907638549804688
[32m[20221124 22:36:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:36:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:36:45 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:36:45 @pendulum_agent.py:289][0m Total time: 4474.183504104614
[32m[20221124 22:36:45 @pendulum_agent.py:291][0m 14400000 total steps have happened
[32m[20221124 22:36:45 @pendulum_agent.py:281][0m #------------------------ Iteration 288 --------------------------#
[32m[20221124 22:36:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:36:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:36:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:36:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:36:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:36:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:36:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:36:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:36:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:36:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:36:48 @pendulum_agent.py:307][0m Sample time: 3.518925189971924
[32m[20221124 22:36:58 @pendulum_agent.py:312][0m Update time: 9.62130880355835
[32m[20221124 22:36:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 30.0
[32m[20221124 22:36:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 30.0
[32m[20221124 22:36:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 30.0
[32m[20221124 22:36:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 30.0
[32m[20221124 22:36:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 30.0
[32m[20221124 22:36:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 30.0
[32m[20221124 22:36:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 30.0
[32m[20221124 22:36:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 30.0
[32m[20221124 22:36:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 30.0
[32m[20221124 22:36:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 30.0
[32m[20221124 22:36:59 @pendulum_agent.py:317][0m Evaluation time: 1.354473352432251
[32m[20221124 22:36:59 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:36:59 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:36:59 @pendulum_agent.py:289][0m Total time: 4488.992112159729
[32m[20221124 22:36:59 @pendulum_agent.py:291][0m 14450000 total steps have happened
[32m[20221124 22:36:59 @pendulum_agent.py:281][0m #------------------------ Iteration 289 --------------------------#
[32m[20221124 22:37:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:37:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:37:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:37:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:37:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:37:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:37:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:37:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:37:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:37:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:37:03 @pendulum_agent.py:307][0m Sample time: 3.478358030319214
[32m[20221124 22:37:12 @pendulum_agent.py:312][0m Update time: 9.27550482749939
[32m[20221124 22:37:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:37:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:37:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:37:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:37:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:37:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:37:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:37:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:37:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:37:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:37:14 @pendulum_agent.py:317][0m Evaluation time: 2.0218920707702637
[32m[20221124 22:37:14 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:37:14 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:37:14 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:37:14 @pendulum_agent.py:289][0m Total time: 4504.083311080933
[32m[20221124 22:37:14 @pendulum_agent.py:291][0m 14500000 total steps have happened
[32m[20221124 22:37:14 @pendulum_agent.py:281][0m #------------------------ Iteration 290 --------------------------#
[32m[20221124 22:37:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:37:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:37:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:37:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:37:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:37:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:37:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:37:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:37:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:37:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:37:18 @pendulum_agent.py:307][0m Sample time: 3.790714979171753
[32m[20221124 22:37:28 @pendulum_agent.py:312][0m Update time: 9.787463188171387
[32m[20221124 22:37:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:37:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:37:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:37:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:37:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:37:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:37:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:37:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:37:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:37:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:37:29 @pendulum_agent.py:317][0m Evaluation time: 0.8035430908203125
[32m[20221124 22:37:29 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:37:29 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:37:29 @pendulum_agent.py:289][0m Total time: 4518.79528594017
[32m[20221124 22:37:29 @pendulum_agent.py:291][0m 14550000 total steps have happened
[32m[20221124 22:37:29 @pendulum_agent.py:281][0m #------------------------ Iteration 291 --------------------------#
[32m[20221124 22:37:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:37:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:37:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:37:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:37:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:37:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:37:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:37:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:37:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:37:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:37:33 @pendulum_agent.py:307][0m Sample time: 4.202615022659302
[32m[20221124 22:37:43 @pendulum_agent.py:312][0m Update time: 9.17834186553955
[32m[20221124 22:37:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:37:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:37:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:37:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:37:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:37:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:37:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:37:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:37:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:37:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:37:44 @pendulum_agent.py:317][0m Evaluation time: 1.065122127532959
[32m[20221124 22:37:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:37:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:37:44 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:37:44 @pendulum_agent.py:289][0m Total time: 4533.530956029892
[32m[20221124 22:37:44 @pendulum_agent.py:291][0m 14600000 total steps have happened
[32m[20221124 22:37:44 @pendulum_agent.py:281][0m #------------------------ Iteration 292 --------------------------#
[32m[20221124 22:37:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 7.2
[32m[20221124 22:37:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.6
[32m[20221124 22:37:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.6
[32m[20221124 22:37:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 22.2
[32m[20221124 22:37:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.2
[32m[20221124 22:37:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.8
[32m[20221124 22:37:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.8
[32m[20221124 22:37:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.0
[32m[20221124 22:37:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.6
[32m[20221124 22:37:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.0
[32m[20221124 22:37:48 @pendulum_agent.py:307][0m Sample time: 4.255648136138916
[32m[20221124 22:37:57 @pendulum_agent.py:312][0m Update time: 9.256580114364624
[32m[20221124 22:37:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:37:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:37:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:37:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:37:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:37:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:37:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:37:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:37:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:37:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:37:59 @pendulum_agent.py:317][0m Evaluation time: 1.1256699562072754
[32m[20221124 22:37:59 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.4
[32m[20221124 22:37:59 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:37:59 @pendulum_agent.py:289][0m Total time: 4548.459675073624
[32m[20221124 22:37:59 @pendulum_agent.py:291][0m 14650000 total steps have happened
[32m[20221124 22:37:59 @pendulum_agent.py:281][0m #------------------------ Iteration 293 --------------------------#
[32m[20221124 22:38:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:38:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:38:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:38:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:38:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:38:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:38:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:38:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:38:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:38:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:38:03 @pendulum_agent.py:307][0m Sample time: 3.957794189453125
[32m[20221124 22:38:12 @pendulum_agent.py:312][0m Update time: 9.499168634414673
[32m[20221124 22:38:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:38:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:38:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:38:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:38:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:38:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:38:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:38:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:38:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:38:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:38:13 @pendulum_agent.py:317][0m Evaluation time: 0.8157501220703125
[32m[20221124 22:38:13 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:38:13 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:38:13 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:38:13 @pendulum_agent.py:289][0m Total time: 4563.055965900421
[32m[20221124 22:38:13 @pendulum_agent.py:291][0m 14700000 total steps have happened
[32m[20221124 22:38:13 @pendulum_agent.py:281][0m #------------------------ Iteration 294 --------------------------#
[32m[20221124 22:38:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:38:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:38:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:38:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:38:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:38:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:38:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:38:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:38:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:38:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:38:17 @pendulum_agent.py:307][0m Sample time: 3.772082805633545
[32m[20221124 22:38:28 @pendulum_agent.py:312][0m Update time: 10.304810047149658
[32m[20221124 22:38:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:38:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:38:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:38:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:38:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:38:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:38:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:38:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:38:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:38:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:38:28 @pendulum_agent.py:317][0m Evaluation time: 0.6385869979858398
[32m[20221124 22:38:28 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:38:28 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:38:28 @pendulum_agent.py:289][0m Total time: 4578.085533857346
[32m[20221124 22:38:28 @pendulum_agent.py:291][0m 14750000 total steps have happened
[32m[20221124 22:38:28 @pendulum_agent.py:281][0m #------------------------ Iteration 295 --------------------------#
[32m[20221124 22:38:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:38:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:38:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:38:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:38:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:38:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:38:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:38:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:38:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:38:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:38:33 @pendulum_agent.py:307][0m Sample time: 4.1696789264678955
[32m[20221124 22:38:42 @pendulum_agent.py:312][0m Update time: 9.476861953735352
[32m[20221124 22:38:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:38:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:38:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:38:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:38:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:38:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:38:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:38:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:38:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:38:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:38:43 @pendulum_agent.py:317][0m Evaluation time: 0.6386711597442627
[32m[20221124 22:38:43 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:38:43 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:38:43 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:38:43 @pendulum_agent.py:289][0m Total time: 4592.66685795784
[32m[20221124 22:38:43 @pendulum_agent.py:291][0m 14800000 total steps have happened
[32m[20221124 22:38:43 @pendulum_agent.py:281][0m #------------------------ Iteration 296 --------------------------#
[32m[20221124 22:38:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:38:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:38:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:38:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:38:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:38:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:38:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:38:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:38:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:38:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:38:47 @pendulum_agent.py:307][0m Sample time: 3.9977428913116455
[32m[20221124 22:38:56 @pendulum_agent.py:312][0m Update time: 8.841016054153442
[32m[20221124 22:38:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:38:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:38:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:38:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:38:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:38:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:38:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:38:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:38:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:38:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:38:56 @pendulum_agent.py:317][0m Evaluation time: 0.5852909088134766
[32m[20221124 22:38:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:38:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:38:57 @pendulum_agent.py:289][0m Total time: 4606.37762093544
[32m[20221124 22:38:57 @pendulum_agent.py:291][0m 14850000 total steps have happened
[32m[20221124 22:38:57 @pendulum_agent.py:281][0m #------------------------ Iteration 297 --------------------------#
[32m[20221124 22:38:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:38:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:38:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:38:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:38:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:38:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:38:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:38:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:38:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:38:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:39:01 @pendulum_agent.py:307][0m Sample time: 3.965252161026001
[32m[20221124 22:39:10 @pendulum_agent.py:312][0m Update time: 9.203782796859741
[32m[20221124 22:39:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:39:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:39:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:39:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:39:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:39:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:39:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:39:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:39:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:39:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:39:11 @pendulum_agent.py:317][0m Evaluation time: 0.7133660316467285
[32m[20221124 22:39:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:39:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:39:11 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:39:11 @pendulum_agent.py:289][0m Total time: 4620.560796022415
[32m[20221124 22:39:11 @pendulum_agent.py:291][0m 14900000 total steps have happened
[32m[20221124 22:39:11 @pendulum_agent.py:281][0m #------------------------ Iteration 298 --------------------------#
[32m[20221124 22:39:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:39:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:39:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:39:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:39:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:39:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:39:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:39:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:39:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:39:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:39:15 @pendulum_agent.py:307][0m Sample time: 3.5706799030303955
[32m[20221124 22:39:24 @pendulum_agent.py:312][0m Update time: 9.648317098617554
[32m[20221124 22:39:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:39:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:39:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:39:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:39:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:39:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:39:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:39:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:39:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:39:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:39:25 @pendulum_agent.py:317][0m Evaluation time: 0.8399720191955566
[32m[20221124 22:39:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:39:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:39:25 @pendulum_agent.py:289][0m Total time: 4634.907205104828
[32m[20221124 22:39:25 @pendulum_agent.py:291][0m 14950000 total steps have happened
[32m[20221124 22:39:25 @pendulum_agent.py:281][0m #------------------------ Iteration 299 --------------------------#
[32m[20221124 22:39:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:39:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:39:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:39:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:39:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:39:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:39:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:39:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:39:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:39:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:39:29 @pendulum_agent.py:307][0m Sample time: 3.4175798892974854
[32m[20221124 22:39:38 @pendulum_agent.py:312][0m Update time: 9.678053855895996
[32m[20221124 22:39:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:39:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:39:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:39:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:39:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:39:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:39:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:39:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:39:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:39:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:39:39 @pendulum_agent.py:317][0m Evaluation time: 1.1008031368255615
[32m[20221124 22:39:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:39:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:39:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:39:40 @pendulum_agent.py:289][0m Total time: 4649.400013923645
[32m[20221124 22:39:40 @pendulum_agent.py:291][0m 15000000 total steps have happened
[32m[20221124 22:39:40 @pendulum_agent.py:281][0m #------------------------ Iteration 300 --------------------------#
[32m[20221124 22:39:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:39:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:39:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:39:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:39:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:39:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:39:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:39:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:39:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:39:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:39:43 @pendulum_agent.py:307][0m Sample time: 3.5827338695526123
[32m[20221124 22:39:53 @pendulum_agent.py:312][0m Update time: 9.310542106628418
[32m[20221124 22:39:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:39:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:39:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:39:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:39:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:39:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:39:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:39:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:39:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:39:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:39:54 @pendulum_agent.py:317][0m Evaluation time: 1.1608710289001465
[32m[20221124 22:39:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:39:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:39:54 @pendulum_agent.py:289][0m Total time: 4663.739835977554
[32m[20221124 22:39:54 @pendulum_agent.py:291][0m 15050000 total steps have happened
[32m[20221124 22:39:54 @pendulum_agent.py:281][0m #------------------------ Iteration 301 --------------------------#
[32m[20221124 22:39:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:39:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:39:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:39:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:39:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:39:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:39:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:39:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:39:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:39:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:39:58 @pendulum_agent.py:307][0m Sample time: 3.468942880630493
[32m[20221124 22:40:06 @pendulum_agent.py:312][0m Update time: 8.85262393951416
[32m[20221124 22:40:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:40:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:40:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:40:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:40:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:40:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:40:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:40:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:40:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:40:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:40:08 @pendulum_agent.py:317][0m Evaluation time: 1.1922571659088135
[32m[20221124 22:40:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:40:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:40:08 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:40:08 @pendulum_agent.py:289][0m Total time: 4677.566213130951
[32m[20221124 22:40:08 @pendulum_agent.py:291][0m 15100000 total steps have happened
[32m[20221124 22:40:08 @pendulum_agent.py:281][0m #------------------------ Iteration 302 --------------------------#
[32m[20221124 22:40:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:40:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:40:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:40:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:40:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:40:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:40:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:40:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:40:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:40:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:40:12 @pendulum_agent.py:307][0m Sample time: 3.636815071105957
[32m[20221124 22:40:20 @pendulum_agent.py:312][0m Update time: 8.90156865119934
[32m[20221124 22:40:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:40:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:40:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:40:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:40:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:40:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:40:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:40:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:40:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:40:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:40:21 @pendulum_agent.py:317][0m Evaluation time: 0.6986610889434814
[32m[20221124 22:40:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:40:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:40:21 @pendulum_agent.py:289][0m Total time: 4691.071969985962
[32m[20221124 22:40:21 @pendulum_agent.py:291][0m 15150000 total steps have happened
[32m[20221124 22:40:21 @pendulum_agent.py:281][0m #------------------------ Iteration 303 --------------------------#
[32m[20221124 22:40:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:40:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:40:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:40:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:40:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:40:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:40:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:40:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:40:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:40:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:40:25 @pendulum_agent.py:307][0m Sample time: 3.6094601154327393
[32m[20221124 22:40:35 @pendulum_agent.py:312][0m Update time: 9.624809980392456
[32m[20221124 22:40:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:40:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:40:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:40:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:40:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:40:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:40:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:40:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:40:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:40:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:40:35 @pendulum_agent.py:317][0m Evaluation time: 0.7140328884124756
[32m[20221124 22:40:36 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:40:36 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:40:36 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:40:36 @pendulum_agent.py:289][0m Total time: 4705.301599025726
[32m[20221124 22:40:36 @pendulum_agent.py:291][0m 15200000 total steps have happened
[32m[20221124 22:40:36 @pendulum_agent.py:281][0m #------------------------ Iteration 304 --------------------------#
[32m[20221124 22:40:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:40:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:40:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:40:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:40:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:40:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:40:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:40:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:40:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:40:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:40:39 @pendulum_agent.py:307][0m Sample time: 3.5634512901306152
[32m[20221124 22:40:48 @pendulum_agent.py:312][0m Update time: 8.988808870315552
[32m[20221124 22:40:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:40:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:40:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:40:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:40:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:40:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:40:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:40:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:40:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:40:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:40:49 @pendulum_agent.py:317][0m Evaluation time: 0.7037830352783203
[32m[20221124 22:40:49 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:40:49 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:40:49 @pendulum_agent.py:289][0m Total time: 4718.834949016571
[32m[20221124 22:40:49 @pendulum_agent.py:291][0m 15250000 total steps have happened
[32m[20221124 22:40:49 @pendulum_agent.py:281][0m #------------------------ Iteration 305 --------------------------#
[32m[20221124 22:40:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:40:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:40:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:40:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:40:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:40:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:40:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:40:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:40:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:40:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:40:53 @pendulum_agent.py:307][0m Sample time: 3.8821959495544434
[32m[20221124 22:41:02 @pendulum_agent.py:312][0m Update time: 8.86155891418457
[32m[20221124 22:41:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:41:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:41:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:41:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:41:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:41:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:41:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:41:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:41:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:41:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:41:03 @pendulum_agent.py:317][0m Evaluation time: 0.559654951095581
[32m[20221124 22:41:03 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:41:03 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:41:03 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:41:03 @pendulum_agent.py:289][0m Total time: 4732.443125009537
[32m[20221124 22:41:03 @pendulum_agent.py:291][0m 15300000 total steps have happened
[32m[20221124 22:41:03 @pendulum_agent.py:281][0m #------------------------ Iteration 306 --------------------------#
[32m[20221124 22:41:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:41:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:41:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:41:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:41:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:41:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:41:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:41:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:41:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:41:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:41:07 @pendulum_agent.py:307][0m Sample time: 3.805738925933838
[32m[20221124 22:41:15 @pendulum_agent.py:312][0m Update time: 8.815058946609497
[32m[20221124 22:41:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:41:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:41:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:41:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:41:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:41:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:41:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:41:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:41:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:41:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:41:16 @pendulum_agent.py:317][0m Evaluation time: 0.7103230953216553
[32m[20221124 22:41:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:41:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:41:16 @pendulum_agent.py:289][0m Total time: 4746.06205201149
[32m[20221124 22:41:16 @pendulum_agent.py:291][0m 15350000 total steps have happened
[32m[20221124 22:41:16 @pendulum_agent.py:281][0m #------------------------ Iteration 307 --------------------------#
[32m[20221124 22:41:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:41:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:41:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:41:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:41:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:41:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:41:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:41:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:41:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:41:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:41:20 @pendulum_agent.py:307][0m Sample time: 3.574758768081665
[32m[20221124 22:41:31 @pendulum_agent.py:312][0m Update time: 10.807216167449951
[32m[20221124 22:41:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:41:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:41:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:41:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:41:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:41:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:41:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:41:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:41:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:41:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:41:32 @pendulum_agent.py:317][0m Evaluation time: 0.7208378314971924
[32m[20221124 22:41:32 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:41:32 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:41:32 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:41:32 @pendulum_agent.py:289][0m Total time: 4761.443567991257
[32m[20221124 22:41:32 @pendulum_agent.py:291][0m 15400000 total steps have happened
[32m[20221124 22:41:32 @pendulum_agent.py:281][0m #------------------------ Iteration 308 --------------------------#
[32m[20221124 22:41:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:41:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:41:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:41:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:41:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:41:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:41:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:41:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:41:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:41:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:41:35 @pendulum_agent.py:307][0m Sample time: 3.581278085708618
[32m[20221124 22:41:45 @pendulum_agent.py:312][0m Update time: 9.088762998580933
[32m[20221124 22:41:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:41:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:41:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:41:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:41:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:41:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:41:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:41:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:41:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:41:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:41:45 @pendulum_agent.py:317][0m Evaluation time: 0.9362277984619141
[32m[20221124 22:41:46 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:41:46 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:41:46 @pendulum_agent.py:289][0m Total time: 4775.358195781708
[32m[20221124 22:41:46 @pendulum_agent.py:291][0m 15450000 total steps have happened
[32m[20221124 22:41:46 @pendulum_agent.py:281][0m #------------------------ Iteration 309 --------------------------#
[32m[20221124 22:41:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:41:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:41:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:41:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:41:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:41:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:41:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:41:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:41:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:41:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:41:49 @pendulum_agent.py:307][0m Sample time: 3.524127960205078
[32m[20221124 22:41:58 @pendulum_agent.py:312][0m Update time: 8.956035137176514
[32m[20221124 22:41:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:41:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:41:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:41:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:41:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:41:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:41:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:41:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:41:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:41:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:41:59 @pendulum_agent.py:317][0m Evaluation time: 1.1080169677734375
[32m[20221124 22:42:00 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:42:00 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:42:00 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:42:00 @pendulum_agent.py:289][0m Total time: 4789.251533031464
[32m[20221124 22:42:00 @pendulum_agent.py:291][0m 15500000 total steps have happened
[32m[20221124 22:42:00 @pendulum_agent.py:281][0m #------------------------ Iteration 310 --------------------------#
[32m[20221124 22:42:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:42:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:42:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:42:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:42:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:42:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:42:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:42:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:42:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:42:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:42:03 @pendulum_agent.py:307][0m Sample time: 3.2021281719207764
[32m[20221124 22:42:13 @pendulum_agent.py:312][0m Update time: 9.984839916229248
[32m[20221124 22:42:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:42:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:42:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:42:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:42:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:42:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:42:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:42:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:42:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:42:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:42:14 @pendulum_agent.py:317][0m Evaluation time: 1.0787098407745361
[32m[20221124 22:42:14 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:42:14 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:42:14 @pendulum_agent.py:289][0m Total time: 4803.821889877319
[32m[20221124 22:42:14 @pendulum_agent.py:291][0m 15550000 total steps have happened
[32m[20221124 22:42:14 @pendulum_agent.py:281][0m #------------------------ Iteration 311 --------------------------#
[32m[20221124 22:42:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:42:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:42:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:42:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:42:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:42:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:42:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:42:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:42:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:42:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:42:18 @pendulum_agent.py:307][0m Sample time: 3.6844418048858643
[32m[20221124 22:42:27 @pendulum_agent.py:312][0m Update time: 9.406756162643433
[32m[20221124 22:42:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:42:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:42:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:42:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:42:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:42:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:42:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:42:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:42:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:42:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:42:28 @pendulum_agent.py:317][0m Evaluation time: 0.759394645690918
[32m[20221124 22:42:28 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:42:28 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:42:28 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:42:28 @pendulum_agent.py:289][0m Total time: 4817.961393117905
[32m[20221124 22:42:28 @pendulum_agent.py:291][0m 15600000 total steps have happened
[32m[20221124 22:42:28 @pendulum_agent.py:281][0m #------------------------ Iteration 312 --------------------------#
[32m[20221124 22:42:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:42:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:42:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:42:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:42:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:42:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:42:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:42:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:42:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:42:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:42:32 @pendulum_agent.py:307][0m Sample time: 3.750375986099243
[32m[20221124 22:42:41 @pendulum_agent.py:312][0m Update time: 8.757824182510376
[32m[20221124 22:42:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:42:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:42:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:42:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:42:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:42:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:42:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:42:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:42:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:42:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:42:42 @pendulum_agent.py:317][0m Evaluation time: 0.7846271991729736
[32m[20221124 22:42:42 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:42:42 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:42:42 @pendulum_agent.py:289][0m Total time: 4831.562045812607
[32m[20221124 22:42:42 @pendulum_agent.py:291][0m 15650000 total steps have happened
[32m[20221124 22:42:42 @pendulum_agent.py:281][0m #------------------------ Iteration 313 --------------------------#
[32m[20221124 22:42:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:42:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:42:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:42:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:42:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:42:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:42:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:42:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:42:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:42:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:42:46 @pendulum_agent.py:307][0m Sample time: 4.058097839355469
[32m[20221124 22:42:56 @pendulum_agent.py:312][0m Update time: 9.7762770652771
[32m[20221124 22:42:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:42:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:42:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:42:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:42:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:42:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:42:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:42:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:42:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:42:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:42:56 @pendulum_agent.py:317][0m Evaluation time: 0.5901660919189453
[32m[20221124 22:42:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:42:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:42:57 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:42:57 @pendulum_agent.py:289][0m Total time: 4846.296777963638
[32m[20221124 22:42:57 @pendulum_agent.py:291][0m 15700000 total steps have happened
[32m[20221124 22:42:57 @pendulum_agent.py:281][0m #------------------------ Iteration 314 --------------------------#
[32m[20221124 22:42:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.6
[32m[20221124 22:42:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1.0
[32m[20221124 22:42:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.0
[32m[20221124 22:42:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.0
[32m[20221124 22:42:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.2
[32m[20221124 22:42:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.8
[32m[20221124 22:42:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.4
[32m[20221124 22:42:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.0
[32m[20221124 22:42:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.2
[32m[20221124 22:42:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.0
[32m[20221124 22:43:01 @pendulum_agent.py:307][0m Sample time: 3.8257970809936523
[32m[20221124 22:43:10 @pendulum_agent.py:312][0m Update time: 9.516838788986206
[32m[20221124 22:43:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:43:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:43:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:43:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:43:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:43:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:43:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:43:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:43:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:43:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:43:11 @pendulum_agent.py:317][0m Evaluation time: 0.8580501079559326
[32m[20221124 22:43:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 1.42
[32m[20221124 22:43:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:43:11 @pendulum_agent.py:289][0m Total time: 4860.8086268901825
[32m[20221124 22:43:11 @pendulum_agent.py:291][0m 15750000 total steps have happened
[32m[20221124 22:43:11 @pendulum_agent.py:281][0m #------------------------ Iteration 315 --------------------------#
[32m[20221124 22:43:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.8
[32m[20221124 22:43:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.2
[32m[20221124 22:43:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.6
[32m[20221124 22:43:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.4
[32m[20221124 22:43:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.2
[32m[20221124 22:43:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.0
[32m[20221124 22:43:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.4
[32m[20221124 22:43:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.2
[32m[20221124 22:43:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.6
[32m[20221124 22:43:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.8
[32m[20221124 22:43:15 @pendulum_agent.py:307][0m Sample time: 3.666027069091797
[32m[20221124 22:43:24 @pendulum_agent.py:312][0m Update time: 9.549384832382202
[32m[20221124 22:43:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:43:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:43:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:43:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:43:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:43:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:43:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:43:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:43:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:43:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:43:26 @pendulum_agent.py:317][0m Evaluation time: 1.104362964630127
[32m[20221124 22:43:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.72
[32m[20221124 22:43:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:43:26 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:43:26 @pendulum_agent.py:289][0m Total time: 4875.437685966492
[32m[20221124 22:43:26 @pendulum_agent.py:291][0m 15800000 total steps have happened
[32m[20221124 22:43:26 @pendulum_agent.py:281][0m #------------------------ Iteration 316 --------------------------#
[32m[20221124 22:43:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:43:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:43:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:43:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:43:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:43:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:43:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:43:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:43:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:43:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:43:30 @pendulum_agent.py:307][0m Sample time: 3.887112855911255
[32m[20221124 22:43:39 @pendulum_agent.py:312][0m Update time: 9.591271162033081
[32m[20221124 22:43:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:43:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:43:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:43:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:43:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:43:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:43:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:43:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:43:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:43:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:43:40 @pendulum_agent.py:317][0m Evaluation time: 0.718878984451294
[32m[20221124 22:43:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:43:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:43:40 @pendulum_agent.py:289][0m Total time: 4889.922431945801
[32m[20221124 22:43:40 @pendulum_agent.py:291][0m 15850000 total steps have happened
[32m[20221124 22:43:40 @pendulum_agent.py:281][0m #------------------------ Iteration 317 --------------------------#
[32m[20221124 22:43:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:43:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:43:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:43:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:43:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:43:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:43:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:43:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:43:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:43:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:43:44 @pendulum_agent.py:307][0m Sample time: 3.665564775466919
[32m[20221124 22:43:53 @pendulum_agent.py:312][0m Update time: 9.067826986312866
[32m[20221124 22:43:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:43:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:43:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:43:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:43:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:43:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:43:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:43:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:43:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:43:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:43:54 @pendulum_agent.py:317][0m Evaluation time: 0.5835020542144775
[32m[20221124 22:43:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:43:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:43:54 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:43:54 @pendulum_agent.py:289][0m Total time: 4903.522499084473
[32m[20221124 22:43:54 @pendulum_agent.py:291][0m 15900000 total steps have happened
[32m[20221124 22:43:54 @pendulum_agent.py:281][0m #------------------------ Iteration 318 --------------------------#
[32m[20221124 22:43:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.8
[32m[20221124 22:43:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.2
[32m[20221124 22:43:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.8
[32m[20221124 22:43:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.0
[32m[20221124 22:43:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.2
[32m[20221124 22:43:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.2
[32m[20221124 22:43:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1.8
[32m[20221124 22:43:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.8
[32m[20221124 22:43:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.4
[32m[20221124 22:43:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.2
[32m[20221124 22:43:58 @pendulum_agent.py:307][0m Sample time: 3.793698787689209
[32m[20221124 22:44:06 @pendulum_agent.py:312][0m Update time: 8.675432205200195
[32m[20221124 22:44:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:44:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:44:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:44:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:44:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:44:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:44:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:44:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:44:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:44:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:44:07 @pendulum_agent.py:317][0m Evaluation time: 0.6940560340881348
[32m[20221124 22:44:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 1.54
[32m[20221124 22:44:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:44:07 @pendulum_agent.py:289][0m Total time: 4916.967293024063
[32m[20221124 22:44:07 @pendulum_agent.py:291][0m 15950000 total steps have happened
[32m[20221124 22:44:07 @pendulum_agent.py:281][0m #------------------------ Iteration 319 --------------------------#
[32m[20221124 22:44:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:44:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:44:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:44:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:44:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:44:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:44:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:44:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:44:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:44:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:44:11 @pendulum_agent.py:307][0m Sample time: 3.769136905670166
[32m[20221124 22:44:20 @pendulum_agent.py:312][0m Update time: 8.627379179000854
[32m[20221124 22:44:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:44:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:44:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:44:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:44:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:44:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:44:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:44:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:44:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:44:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:44:20 @pendulum_agent.py:317][0m Evaluation time: 0.7118191719055176
[32m[20221124 22:44:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:44:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:44:21 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:44:21 @pendulum_agent.py:289][0m Total time: 4930.371008872986
[32m[20221124 22:44:21 @pendulum_agent.py:291][0m 16000000 total steps have happened
[32m[20221124 22:44:21 @pendulum_agent.py:281][0m #------------------------ Iteration 320 --------------------------#
[32m[20221124 22:44:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:44:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:44:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:44:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:44:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:44:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:44:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:44:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:44:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:44:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:44:24 @pendulum_agent.py:307][0m Sample time: 3.617417097091675
[32m[20221124 22:44:34 @pendulum_agent.py:312][0m Update time: 9.249804019927979
[32m[20221124 22:44:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 55.0
[32m[20221124 22:44:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 55.0
[32m[20221124 22:44:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 55.0
[32m[20221124 22:44:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 55.0
[32m[20221124 22:44:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 55.0
[32m[20221124 22:44:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 55.0
[32m[20221124 22:44:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 55.0
[32m[20221124 22:44:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 55.0
[32m[20221124 22:44:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 55.0
[32m[20221124 22:44:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 55.0
[32m[20221124 22:44:35 @pendulum_agent.py:317][0m Evaluation time: 0.9362049102783203
[32m[20221124 22:44:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:44:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:44:35 @pendulum_agent.py:289][0m Total time: 4944.481282949448
[32m[20221124 22:44:35 @pendulum_agent.py:291][0m 16050000 total steps have happened
[32m[20221124 22:44:35 @pendulum_agent.py:281][0m #------------------------ Iteration 321 --------------------------#
[32m[20221124 22:44:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:44:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:44:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:44:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:44:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:44:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:44:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:44:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:44:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:44:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:44:39 @pendulum_agent.py:307][0m Sample time: 3.684372901916504
[32m[20221124 22:44:47 @pendulum_agent.py:312][0m Update time: 8.609775066375732
[32m[20221124 22:44:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:44:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:44:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:44:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:44:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:44:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:44:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:44:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:44:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:44:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:44:48 @pendulum_agent.py:317][0m Evaluation time: 0.7011830806732178
[32m[20221124 22:44:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:44:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:44:48 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:44:48 @pendulum_agent.py:289][0m Total time: 4957.734097003937
[32m[20221124 22:44:48 @pendulum_agent.py:291][0m 16100000 total steps have happened
[32m[20221124 22:44:48 @pendulum_agent.py:281][0m #------------------------ Iteration 322 --------------------------#
[32m[20221124 22:44:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:44:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:44:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:44:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:44:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:44:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:44:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:44:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:44:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:44:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:44:52 @pendulum_agent.py:307][0m Sample time: 3.612227201461792
[32m[20221124 22:45:02 @pendulum_agent.py:312][0m Update time: 9.902223825454712
[32m[20221124 22:45:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:45:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:45:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:45:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:45:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:45:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:45:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:45:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:45:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:45:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:45:02 @pendulum_agent.py:317][0m Evaluation time: 0.681502103805542
[32m[20221124 22:45:03 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:45:03 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:45:03 @pendulum_agent.py:289][0m Total time: 4972.218325853348
[32m[20221124 22:45:03 @pendulum_agent.py:291][0m 16150000 total steps have happened
[32m[20221124 22:45:03 @pendulum_agent.py:281][0m #------------------------ Iteration 323 --------------------------#
[32m[20221124 22:45:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:45:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:45:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:45:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:45:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:45:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:45:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:45:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:45:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:45:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:45:06 @pendulum_agent.py:307][0m Sample time: 3.3785338401794434
[32m[20221124 22:45:15 @pendulum_agent.py:312][0m Update time: 9.236629009246826
[32m[20221124 22:45:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:45:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:45:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:45:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:45:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:45:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:45:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:45:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:45:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:45:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:45:16 @pendulum_agent.py:317][0m Evaluation time: 0.946613073348999
[32m[20221124 22:45:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:45:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:45:16 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:45:16 @pendulum_agent.py:289][0m Total time: 4986.075793027878
[32m[20221124 22:45:16 @pendulum_agent.py:291][0m 16200000 total steps have happened
[32m[20221124 22:45:16 @pendulum_agent.py:281][0m #------------------------ Iteration 324 --------------------------#
[32m[20221124 22:45:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:45:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:45:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:45:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:45:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:45:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:45:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:45:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:45:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:45:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:45:20 @pendulum_agent.py:307][0m Sample time: 3.339042901992798
[32m[20221124 22:45:29 @pendulum_agent.py:312][0m Update time: 8.80603289604187
[32m[20221124 22:45:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:45:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:45:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:45:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:45:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:45:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:45:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:45:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:45:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:45:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:45:30 @pendulum_agent.py:317][0m Evaluation time: 1.704782247543335
[32m[20221124 22:45:31 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:45:31 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:45:31 @pendulum_agent.py:289][0m Total time: 5000.2388660907745
[32m[20221124 22:45:31 @pendulum_agent.py:291][0m 16250000 total steps have happened
[32m[20221124 22:45:31 @pendulum_agent.py:281][0m #------------------------ Iteration 325 --------------------------#
[32m[20221124 22:45:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.2
[32m[20221124 22:45:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1.6
[32m[20221124 22:45:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.2
[32m[20221124 22:45:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.4
[32m[20221124 22:45:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.6
[32m[20221124 22:45:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.8
[32m[20221124 22:45:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.0
[32m[20221124 22:45:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.0
[32m[20221124 22:45:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.8
[32m[20221124 22:45:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.0
[32m[20221124 22:45:34 @pendulum_agent.py:307][0m Sample time: 3.7604639530181885
[32m[20221124 22:45:43 @pendulum_agent.py:312][0m Update time: 8.898906946182251
[32m[20221124 22:45:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:45:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:45:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:45:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:45:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:45:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:45:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:45:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:45:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:45:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:45:44 @pendulum_agent.py:317][0m Evaluation time: 0.7220821380615234
[32m[20221124 22:45:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.46
[32m[20221124 22:45:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:45:44 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:45:44 @pendulum_agent.py:289][0m Total time: 5013.9039878845215
[32m[20221124 22:45:44 @pendulum_agent.py:291][0m 16300000 total steps have happened
[32m[20221124 22:45:44 @pendulum_agent.py:281][0m #------------------------ Iteration 326 --------------------------#
[32m[20221124 22:45:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:45:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:45:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:45:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:45:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:45:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:45:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:45:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:45:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:45:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:45:48 @pendulum_agent.py:307][0m Sample time: 3.6418588161468506
[32m[20221124 22:45:57 @pendulum_agent.py:312][0m Update time: 9.262230157852173
[32m[20221124 22:45:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:45:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:45:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:45:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:45:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:45:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:45:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:45:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:45:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:45:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:45:58 @pendulum_agent.py:317][0m Evaluation time: 0.7059800624847412
[32m[20221124 22:45:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:45:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:45:58 @pendulum_agent.py:289][0m Total time: 5027.786547899246
[32m[20221124 22:45:58 @pendulum_agent.py:291][0m 16350000 total steps have happened
[32m[20221124 22:45:58 @pendulum_agent.py:281][0m #------------------------ Iteration 327 --------------------------#
[32m[20221124 22:45:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:45:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:45:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:45:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:45:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:45:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:45:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:45:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:45:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:45:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:46:02 @pendulum_agent.py:307][0m Sample time: 3.841127872467041
[32m[20221124 22:46:12 @pendulum_agent.py:312][0m Update time: 10.089277982711792
[32m[20221124 22:46:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:46:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:46:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:46:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:46:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:46:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:46:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:46:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:46:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:46:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:46:13 @pendulum_agent.py:317][0m Evaluation time: 0.706934928894043
[32m[20221124 22:46:13 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:46:13 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:46:13 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:46:13 @pendulum_agent.py:289][0m Total time: 5042.70400094986
[32m[20221124 22:46:13 @pendulum_agent.py:291][0m 16400000 total steps have happened
[32m[20221124 22:46:13 @pendulum_agent.py:281][0m #------------------------ Iteration 328 --------------------------#
[32m[20221124 22:46:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:46:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:46:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:46:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:46:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:46:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:46:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:46:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:46:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:46:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:46:17 @pendulum_agent.py:307][0m Sample time: 3.5438880920410156
[32m[20221124 22:46:25 @pendulum_agent.py:312][0m Update time: 8.7409188747406
[32m[20221124 22:46:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:46:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:46:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:46:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:46:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:46:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:46:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:46:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:46:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:46:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:46:26 @pendulum_agent.py:317][0m Evaluation time: 0.8161649703979492
[32m[20221124 22:46:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:46:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:46:26 @pendulum_agent.py:289][0m Total time: 5056.082866191864
[32m[20221124 22:46:26 @pendulum_agent.py:291][0m 16450000 total steps have happened
[32m[20221124 22:46:26 @pendulum_agent.py:281][0m #------------------------ Iteration 329 --------------------------#
[32m[20221124 22:46:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:46:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:46:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:46:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:46:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:46:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:46:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:46:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:46:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:46:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:46:30 @pendulum_agent.py:307][0m Sample time: 3.6660549640655518
[32m[20221124 22:46:39 @pendulum_agent.py:312][0m Update time: 8.591247797012329
[32m[20221124 22:46:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:46:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:46:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:46:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:46:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:46:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:46:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:46:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:46:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:46:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:46:39 @pendulum_agent.py:317][0m Evaluation time: 0.7050230503082275
[32m[20221124 22:46:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:46:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:46:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:46:40 @pendulum_agent.py:289][0m Total time: 5069.322064161301
[32m[20221124 22:46:40 @pendulum_agent.py:291][0m 16500000 total steps have happened
[32m[20221124 22:46:40 @pendulum_agent.py:281][0m #------------------------ Iteration 330 --------------------------#
[32m[20221124 22:46:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:46:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:46:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:46:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:46:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:46:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:46:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:46:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:46:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:46:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:46:43 @pendulum_agent.py:307][0m Sample time: 3.7652108669281006
[32m[20221124 22:46:53 @pendulum_agent.py:312][0m Update time: 9.379514217376709
[32m[20221124 22:46:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:46:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:46:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:46:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:46:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:46:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:46:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:46:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:46:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:46:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:46:54 @pendulum_agent.py:317][0m Evaluation time: 0.7617897987365723
[32m[20221124 22:46:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:46:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:46:54 @pendulum_agent.py:289][0m Total time: 5083.512398958206
[32m[20221124 22:46:54 @pendulum_agent.py:291][0m 16550000 total steps have happened
[32m[20221124 22:46:54 @pendulum_agent.py:281][0m #------------------------ Iteration 331 --------------------------#
[32m[20221124 22:46:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:46:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:46:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:46:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:46:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:46:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:46:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:46:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:46:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:46:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:46:57 @pendulum_agent.py:307][0m Sample time: 3.583961248397827
[32m[20221124 22:47:06 @pendulum_agent.py:312][0m Update time: 8.810127019882202
[32m[20221124 22:47:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:47:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:47:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:47:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:47:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:47:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:47:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:47:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:47:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:47:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:47:07 @pendulum_agent.py:317][0m Evaluation time: 0.6929647922515869
[32m[20221124 22:47:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:47:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:47:07 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:47:07 @pendulum_agent.py:289][0m Total time: 5096.883258104324
[32m[20221124 22:47:07 @pendulum_agent.py:291][0m 16600000 total steps have happened
[32m[20221124 22:47:07 @pendulum_agent.py:281][0m #------------------------ Iteration 332 --------------------------#
[32m[20221124 22:47:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.8
[32m[20221124 22:47:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.2
[32m[20221124 22:47:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.8
[32m[20221124 22:47:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 13.8
[32m[20221124 22:47:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.2
[32m[20221124 22:47:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.0
[32m[20221124 22:47:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.2
[32m[20221124 22:47:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.8
[32m[20221124 22:47:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.8
[32m[20221124 22:47:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.6
[32m[20221124 22:47:11 @pendulum_agent.py:307][0m Sample time: 3.7473669052124023
[32m[20221124 22:47:20 @pendulum_agent.py:312][0m Update time: 9.236967325210571
[32m[20221124 22:47:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:47:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:47:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:47:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:47:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:47:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:47:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:47:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:47:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:47:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:47:21 @pendulum_agent.py:317][0m Evaluation time: 0.8406987190246582
[32m[20221124 22:47:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.62
[32m[20221124 22:47:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:47:21 @pendulum_agent.py:289][0m Total time: 5111.017035007477
[32m[20221124 22:47:21 @pendulum_agent.py:291][0m 16650000 total steps have happened
[32m[20221124 22:47:21 @pendulum_agent.py:281][0m #------------------------ Iteration 333 --------------------------#
[32m[20221124 22:47:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:47:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:47:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:47:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:47:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:47:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:47:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:47:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:47:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:47:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:47:25 @pendulum_agent.py:307][0m Sample time: 3.4313337802886963
[32m[20221124 22:47:33 @pendulum_agent.py:312][0m Update time: 8.587051153182983
[32m[20221124 22:47:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:47:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:47:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:47:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:47:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:47:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:47:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:47:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:47:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:47:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:47:34 @pendulum_agent.py:317][0m Evaluation time: 1.0181171894073486
[32m[20221124 22:47:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:47:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:47:35 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:47:35 @pendulum_agent.py:289][0m Total time: 5124.316956996918
[32m[20221124 22:47:35 @pendulum_agent.py:291][0m 16700000 total steps have happened
[32m[20221124 22:47:35 @pendulum_agent.py:281][0m #------------------------ Iteration 334 --------------------------#
[32m[20221124 22:47:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:47:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:47:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:47:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:47:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:47:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:47:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:47:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:47:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:47:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:47:38 @pendulum_agent.py:307][0m Sample time: 3.3267550468444824
[32m[20221124 22:47:47 @pendulum_agent.py:312][0m Update time: 8.615910768508911
[32m[20221124 22:47:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:47:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:47:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:47:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:47:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:47:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:47:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:47:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:47:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:47:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:47:48 @pendulum_agent.py:317][0m Evaluation time: 1.173124074935913
[32m[20221124 22:47:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:47:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:47:48 @pendulum_agent.py:289][0m Total time: 5137.7331738471985
[32m[20221124 22:47:48 @pendulum_agent.py:291][0m 16750000 total steps have happened
[32m[20221124 22:47:48 @pendulum_agent.py:281][0m #------------------------ Iteration 335 --------------------------#
[32m[20221124 22:47:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.8
[32m[20221124 22:47:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.6
[32m[20221124 22:47:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.2
[32m[20221124 22:47:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1.2
[32m[20221124 22:47:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.6
[32m[20221124 22:47:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.8
[32m[20221124 22:47:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.6
[32m[20221124 22:47:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.8
[32m[20221124 22:47:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.0
[32m[20221124 22:47:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.6
[32m[20221124 22:47:51 @pendulum_agent.py:307][0m Sample time: 3.335686206817627
[32m[20221124 22:48:00 @pendulum_agent.py:312][0m Update time: 8.82579779624939
[32m[20221124 22:48:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:48:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:48:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:48:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:48:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:48:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:48:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:48:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:48:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:48:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:48:02 @pendulum_agent.py:317][0m Evaluation time: 1.8225131034851074
[32m[20221124 22:48:02 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.92
[32m[20221124 22:48:02 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:48:02 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:48:02 @pendulum_agent.py:289][0m Total time: 5151.998378992081
[32m[20221124 22:48:02 @pendulum_agent.py:291][0m 16800000 total steps have happened
[32m[20221124 22:48:02 @pendulum_agent.py:281][0m #------------------------ Iteration 336 --------------------------#
[32m[20221124 22:48:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:48:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:48:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:48:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:48:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:48:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:48:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:48:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:48:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:48:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:48:06 @pendulum_agent.py:307][0m Sample time: 3.5477991104125977
[32m[20221124 22:48:15 @pendulum_agent.py:312][0m Update time: 8.660388946533203
[32m[20221124 22:48:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:48:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:48:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:48:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:48:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:48:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:48:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:48:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:48:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:48:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:48:15 @pendulum_agent.py:317][0m Evaluation time: 0.705435037612915
[32m[20221124 22:48:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:48:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:48:16 @pendulum_agent.py:289][0m Total time: 5165.19436788559
[32m[20221124 22:48:16 @pendulum_agent.py:291][0m 16850000 total steps have happened
[32m[20221124 22:48:16 @pendulum_agent.py:281][0m #------------------------ Iteration 337 --------------------------#
[32m[20221124 22:48:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.8
[32m[20221124 22:48:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.8
[32m[20221124 22:48:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.6
[32m[20221124 22:48:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.4
[32m[20221124 22:48:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.8
[32m[20221124 22:48:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.4
[32m[20221124 22:48:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.4
[32m[20221124 22:48:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.0
[32m[20221124 22:48:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.8
[32m[20221124 22:48:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.4
[32m[20221124 22:48:19 @pendulum_agent.py:307][0m Sample time: 3.6943609714508057
[32m[20221124 22:48:28 @pendulum_agent.py:312][0m Update time: 8.796391010284424
[32m[20221124 22:48:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:48:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:48:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:48:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:48:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:48:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:48:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:48:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:48:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:48:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:48:29 @pendulum_agent.py:317][0m Evaluation time: 0.9688160419464111
[32m[20221124 22:48:29 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.64
[32m[20221124 22:48:29 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:48:29 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:48:29 @pendulum_agent.py:289][0m Total time: 5178.940169811249
[32m[20221124 22:48:29 @pendulum_agent.py:291][0m 16900000 total steps have happened
[32m[20221124 22:48:29 @pendulum_agent.py:281][0m #------------------------ Iteration 338 --------------------------#
[32m[20221124 22:48:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:48:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:48:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:48:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:48:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:48:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:48:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:48:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:48:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:48:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:48:33 @pendulum_agent.py:307][0m Sample time: 3.838045120239258
[32m[20221124 22:48:43 @pendulum_agent.py:312][0m Update time: 9.624697923660278
[32m[20221124 22:48:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:48:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:48:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:48:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:48:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:48:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:48:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:48:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:48:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:48:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:48:44 @pendulum_agent.py:317][0m Evaluation time: 0.9346890449523926
[32m[20221124 22:48:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:48:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:48:44 @pendulum_agent.py:289][0m Total time: 5193.632472991943
[32m[20221124 22:48:44 @pendulum_agent.py:291][0m 16950000 total steps have happened
[32m[20221124 22:48:44 @pendulum_agent.py:281][0m #------------------------ Iteration 339 --------------------------#
[32m[20221124 22:48:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:48:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:48:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:48:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:48:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:48:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:48:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:48:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:48:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:48:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:48:48 @pendulum_agent.py:307][0m Sample time: 3.8725860118865967
[32m[20221124 22:48:57 @pendulum_agent.py:312][0m Update time: 9.418444156646729
[32m[20221124 22:48:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:48:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:48:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:48:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:48:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:48:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:48:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:48:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:48:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:48:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:48:58 @pendulum_agent.py:317][0m Evaluation time: 0.7024900913238525
[32m[20221124 22:48:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:48:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:48:58 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:48:58 @pendulum_agent.py:289][0m Total time: 5207.899971008301
[32m[20221124 22:48:58 @pendulum_agent.py:291][0m 17000000 total steps have happened
[32m[20221124 22:48:58 @pendulum_agent.py:281][0m #------------------------ Iteration 340 --------------------------#
[32m[20221124 22:48:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:48:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:48:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:48:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:48:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:48:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:48:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:48:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:48:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:48:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:49:02 @pendulum_agent.py:307][0m Sample time: 3.4965102672576904
[32m[20221124 22:49:11 @pendulum_agent.py:312][0m Update time: 8.897356033325195
[32m[20221124 22:49:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:49:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:49:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:49:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:49:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:49:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:49:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:49:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:49:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:49:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:49:11 @pendulum_agent.py:317][0m Evaluation time: 0.5727779865264893
[32m[20221124 22:49:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:49:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:49:12 @pendulum_agent.py:289][0m Total time: 5221.1544580459595
[32m[20221124 22:49:12 @pendulum_agent.py:291][0m 17050000 total steps have happened
[32m[20221124 22:49:12 @pendulum_agent.py:281][0m #------------------------ Iteration 341 --------------------------#
[32m[20221124 22:49:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.4
[32m[20221124 22:49:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 8.0
[32m[20221124 22:49:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.4
[32m[20221124 22:49:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.2
[32m[20221124 22:49:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.8
[32m[20221124 22:49:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.6
[32m[20221124 22:49:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.6
[32m[20221124 22:49:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.6
[32m[20221124 22:49:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 14.0
[32m[20221124 22:49:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.6
[32m[20221124 22:49:15 @pendulum_agent.py:307][0m Sample time: 3.8091681003570557
[32m[20221124 22:49:25 @pendulum_agent.py:312][0m Update time: 9.44659686088562
[32m[20221124 22:49:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:49:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:49:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:49:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:49:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:49:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:49:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:49:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:49:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:49:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:49:25 @pendulum_agent.py:317][0m Evaluation time: 0.5537302494049072
[32m[20221124 22:49:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.82
[32m[20221124 22:49:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:49:26 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:49:26 @pendulum_agent.py:289][0m Total time: 5235.254882097244
[32m[20221124 22:49:26 @pendulum_agent.py:291][0m 17100000 total steps have happened
[32m[20221124 22:49:26 @pendulum_agent.py:281][0m #------------------------ Iteration 342 --------------------------#
[32m[20221124 22:49:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:49:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:49:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:49:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:49:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:49:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:49:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:49:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:49:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:49:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:49:29 @pendulum_agent.py:307][0m Sample time: 3.725247859954834
[32m[20221124 22:49:38 @pendulum_agent.py:312][0m Update time: 8.746484994888306
[32m[20221124 22:49:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:49:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:49:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:49:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:49:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:49:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:49:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:49:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:49:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:49:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:49:39 @pendulum_agent.py:317][0m Evaluation time: 0.5786619186401367
[32m[20221124 22:49:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:49:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:49:39 @pendulum_agent.py:289][0m Total time: 5248.6029307842255
[32m[20221124 22:49:39 @pendulum_agent.py:291][0m 17150000 total steps have happened
[32m[20221124 22:49:39 @pendulum_agent.py:281][0m #------------------------ Iteration 343 --------------------------#
[32m[20221124 22:49:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:49:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:49:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:49:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:49:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:49:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:49:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:49:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:49:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:49:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:49:43 @pendulum_agent.py:307][0m Sample time: 3.8848321437835693
[32m[20221124 22:49:52 @pendulum_agent.py:312][0m Update time: 9.143016815185547
[32m[20221124 22:49:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:49:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:49:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:49:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:49:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:49:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:49:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:49:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:49:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:49:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:49:53 @pendulum_agent.py:317][0m Evaluation time: 0.688657283782959
[32m[20221124 22:49:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:49:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:49:53 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:49:53 @pendulum_agent.py:289][0m Total time: 5262.595110177994
[32m[20221124 22:49:53 @pendulum_agent.py:291][0m 17200000 total steps have happened
[32m[20221124 22:49:53 @pendulum_agent.py:281][0m #------------------------ Iteration 344 --------------------------#
[32m[20221124 22:49:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:49:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:49:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:49:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:49:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:49:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:49:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:49:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:49:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:49:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:49:57 @pendulum_agent.py:307][0m Sample time: 3.512524127960205
[32m[20221124 22:50:06 @pendulum_agent.py:312][0m Update time: 9.136345863342285
[32m[20221124 22:50:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:50:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:50:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:50:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:50:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:50:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:50:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:50:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:50:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:50:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:50:06 @pendulum_agent.py:317][0m Evaluation time: 0.8224411010742188
[32m[20221124 22:50:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:50:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:50:07 @pendulum_agent.py:289][0m Total time: 5276.344721078873
[32m[20221124 22:50:07 @pendulum_agent.py:291][0m 17250000 total steps have happened
[32m[20221124 22:50:07 @pendulum_agent.py:281][0m #------------------------ Iteration 345 --------------------------#
[32m[20221124 22:50:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:50:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:50:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:50:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:50:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:50:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:50:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:50:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:50:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:50:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:50:10 @pendulum_agent.py:307][0m Sample time: 3.2936198711395264
[32m[20221124 22:50:19 @pendulum_agent.py:312][0m Update time: 8.846350193023682
[32m[20221124 22:50:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:50:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:50:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:50:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:50:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:50:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:50:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:50:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:50:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:50:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:50:20 @pendulum_agent.py:317][0m Evaluation time: 1.05214262008667
[32m[20221124 22:50:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:50:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:50:20 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:50:20 @pendulum_agent.py:289][0m Total time: 5289.837250947952
[32m[20221124 22:50:20 @pendulum_agent.py:291][0m 17300000 total steps have happened
[32m[20221124 22:50:20 @pendulum_agent.py:281][0m #------------------------ Iteration 346 --------------------------#
[32m[20221124 22:50:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:50:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:50:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:50:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:50:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:50:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:50:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:50:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:50:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:50:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:50:24 @pendulum_agent.py:307][0m Sample time: 3.443965196609497
[32m[20221124 22:50:34 @pendulum_agent.py:312][0m Update time: 10.393771886825562
[32m[20221124 22:50:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:50:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:50:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:50:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:50:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:50:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:50:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:50:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:50:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:50:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:50:35 @pendulum_agent.py:317][0m Evaluation time: 1.1812140941619873
[32m[20221124 22:50:36 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:50:36 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:50:36 @pendulum_agent.py:289][0m Total time: 5305.142525196075
[32m[20221124 22:50:36 @pendulum_agent.py:291][0m 17350000 total steps have happened
[32m[20221124 22:50:36 @pendulum_agent.py:281][0m #------------------------ Iteration 347 --------------------------#
[32m[20221124 22:50:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:50:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:50:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:50:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:50:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:50:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:50:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:50:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:50:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:50:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:50:39 @pendulum_agent.py:307][0m Sample time: 3.3648529052734375
[32m[20221124 22:50:48 @pendulum_agent.py:312][0m Update time: 8.617894172668457
[32m[20221124 22:50:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:50:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:50:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:50:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:50:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:50:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:50:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:50:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:50:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:50:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:50:49 @pendulum_agent.py:317][0m Evaluation time: 1.1650922298431396
[32m[20221124 22:50:49 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:50:49 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:50:49 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:50:49 @pendulum_agent.py:289][0m Total time: 5318.564600944519
[32m[20221124 22:50:49 @pendulum_agent.py:291][0m 17400000 total steps have happened
[32m[20221124 22:50:49 @pendulum_agent.py:281][0m #------------------------ Iteration 348 --------------------------#
[32m[20221124 22:50:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:50:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:50:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:50:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:50:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:50:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:50:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:50:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:50:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:50:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:50:53 @pendulum_agent.py:307][0m Sample time: 3.622468948364258
[32m[20221124 22:51:01 @pendulum_agent.py:312][0m Update time: 8.82823395729065
[32m[20221124 22:51:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:51:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:51:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:51:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:51:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:51:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:51:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:51:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:51:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:51:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:51:02 @pendulum_agent.py:317][0m Evaluation time: 0.7272839546203613
[32m[20221124 22:51:02 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:51:02 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:51:02 @pendulum_agent.py:289][0m Total time: 5332.019149065018
[32m[20221124 22:51:02 @pendulum_agent.py:291][0m 17450000 total steps have happened
[32m[20221124 22:51:02 @pendulum_agent.py:281][0m #------------------------ Iteration 349 --------------------------#
[32m[20221124 22:51:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:51:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:51:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:51:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:51:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:51:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:51:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:51:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:51:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:51:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:51:06 @pendulum_agent.py:307][0m Sample time: 3.613739013671875
[32m[20221124 22:51:15 @pendulum_agent.py:312][0m Update time: 8.740036725997925
[32m[20221124 22:51:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 16.0
[32m[20221124 22:51:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 16.0
[32m[20221124 22:51:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 16.0
[32m[20221124 22:51:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 16.0
[32m[20221124 22:51:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 16.0
[32m[20221124 22:51:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 16.0
[32m[20221124 22:51:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 16.0
[32m[20221124 22:51:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 16.0
[32m[20221124 22:51:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 16.0
[32m[20221124 22:51:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 16.0
[32m[20221124 22:51:15 @pendulum_agent.py:317][0m Evaluation time: 0.72412109375
[32m[20221124 22:51:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:51:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:51:16 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:51:16 @pendulum_agent.py:289][0m Total time: 5345.3719708919525
[32m[20221124 22:51:16 @pendulum_agent.py:291][0m 17500000 total steps have happened
[32m[20221124 22:51:16 @pendulum_agent.py:281][0m #------------------------ Iteration 350 --------------------------#
[32m[20221124 22:51:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:51:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:51:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:51:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:51:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:51:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:51:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:51:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:51:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:51:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:51:19 @pendulum_agent.py:307][0m Sample time: 3.532175064086914
[32m[20221124 22:51:29 @pendulum_agent.py:312][0m Update time: 9.760663986206055
[32m[20221124 22:51:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:51:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:51:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:51:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:51:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:51:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:51:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:51:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:51:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:51:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:51:30 @pendulum_agent.py:317][0m Evaluation time: 0.7072649002075195
[32m[20221124 22:51:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:51:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:51:30 @pendulum_agent.py:289][0m Total time: 5359.670002937317
[32m[20221124 22:51:30 @pendulum_agent.py:291][0m 17550000 total steps have happened
[32m[20221124 22:51:30 @pendulum_agent.py:281][0m #------------------------ Iteration 351 --------------------------#
[32m[20221124 22:51:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:51:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:51:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:51:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:51:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:51:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:51:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:51:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:51:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:51:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:51:34 @pendulum_agent.py:307][0m Sample time: 3.8370139598846436
[32m[20221124 22:51:43 @pendulum_agent.py:312][0m Update time: 8.681179285049438
[32m[20221124 22:51:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:51:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:51:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:51:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:51:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:51:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:51:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:51:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:51:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:51:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:51:43 @pendulum_agent.py:317][0m Evaluation time: 0.5841999053955078
[32m[20221124 22:51:43 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:51:43 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:51:43 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:51:43 @pendulum_agent.py:289][0m Total time: 5373.075875043869
[32m[20221124 22:51:43 @pendulum_agent.py:291][0m 17600000 total steps have happened
[32m[20221124 22:51:43 @pendulum_agent.py:281][0m #------------------------ Iteration 352 --------------------------#
[32m[20221124 22:51:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:51:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:51:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:51:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:51:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:51:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:51:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:51:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:51:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:51:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:51:47 @pendulum_agent.py:307][0m Sample time: 3.7931149005889893
[32m[20221124 22:51:57 @pendulum_agent.py:312][0m Update time: 9.876504182815552
[32m[20221124 22:51:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:51:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:51:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:51:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:51:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:51:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:51:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:51:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:51:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:51:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:51:58 @pendulum_agent.py:317][0m Evaluation time: 0.6963949203491211
[32m[20221124 22:51:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:51:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:51:58 @pendulum_agent.py:289][0m Total time: 5387.725271940231
[32m[20221124 22:51:58 @pendulum_agent.py:291][0m 17650000 total steps have happened
[32m[20221124 22:51:58 @pendulum_agent.py:281][0m #------------------------ Iteration 353 --------------------------#
[32m[20221124 22:51:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:51:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:51:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:51:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:51:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:51:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:51:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:51:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:51:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:51:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:52:02 @pendulum_agent.py:307][0m Sample time: 3.5956127643585205
[32m[20221124 22:52:11 @pendulum_agent.py:312][0m Update time: 9.785289287567139
[32m[20221124 22:52:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:52:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:52:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:52:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:52:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:52:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:52:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:52:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:52:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:52:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:52:12 @pendulum_agent.py:317][0m Evaluation time: 0.7070229053497314
[32m[20221124 22:52:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:52:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:52:12 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:52:12 @pendulum_agent.py:289][0m Total time: 5402.095273971558
[32m[20221124 22:52:12 @pendulum_agent.py:291][0m 17700000 total steps have happened
[32m[20221124 22:52:12 @pendulum_agent.py:281][0m #------------------------ Iteration 354 --------------------------#
[32m[20221124 22:52:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:52:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:52:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:52:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:52:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:52:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:52:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:52:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:52:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:52:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:52:16 @pendulum_agent.py:307][0m Sample time: 3.624613046646118
[32m[20221124 22:52:25 @pendulum_agent.py:312][0m Update time: 8.901600122451782
[32m[20221124 22:52:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:52:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:52:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:52:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:52:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:52:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:52:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:52:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:52:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:52:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:52:26 @pendulum_agent.py:317][0m Evaluation time: 0.850337028503418
[32m[20221124 22:52:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:52:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:52:26 @pendulum_agent.py:289][0m Total time: 5415.75517988205
[32m[20221124 22:52:26 @pendulum_agent.py:291][0m 17750000 total steps have happened
[32m[20221124 22:52:26 @pendulum_agent.py:281][0m #------------------------ Iteration 355 --------------------------#
[32m[20221124 22:52:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:52:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:52:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:52:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:52:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:52:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:52:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:52:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:52:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:52:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:52:29 @pendulum_agent.py:307][0m Sample time: 3.3397440910339355
[32m[20221124 22:52:38 @pendulum_agent.py:312][0m Update time: 8.967623949050903
[32m[20221124 22:52:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:52:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:52:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:52:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:52:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:52:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:52:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:52:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:52:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:52:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:52:40 @pendulum_agent.py:317][0m Evaluation time: 1.047084093093872
[32m[20221124 22:52:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:52:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:52:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:52:40 @pendulum_agent.py:289][0m Total time: 5429.378221988678
[32m[20221124 22:52:40 @pendulum_agent.py:291][0m 17800000 total steps have happened
[32m[20221124 22:52:40 @pendulum_agent.py:281][0m #------------------------ Iteration 356 --------------------------#
[32m[20221124 22:52:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:52:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:52:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:52:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:52:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:52:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:52:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:52:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:52:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:52:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:52:43 @pendulum_agent.py:307][0m Sample time: 3.2071611881256104
[32m[20221124 22:52:52 @pendulum_agent.py:312][0m Update time: 9.179321765899658
[32m[20221124 22:52:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:52:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:52:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:52:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:52:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:52:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:52:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:52:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:52:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:52:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:52:53 @pendulum_agent.py:317][0m Evaluation time: 1.0565822124481201
[32m[20221124 22:52:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:52:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:52:54 @pendulum_agent.py:289][0m Total time: 5443.114295005798
[32m[20221124 22:52:54 @pendulum_agent.py:291][0m 17850000 total steps have happened
[32m[20221124 22:52:54 @pendulum_agent.py:281][0m #------------------------ Iteration 357 --------------------------#
[32m[20221124 22:52:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.2
[32m[20221124 22:52:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.0
[32m[20221124 22:52:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.8
[32m[20221124 22:52:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.4
[32m[20221124 22:52:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.2
[32m[20221124 22:52:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.8
[32m[20221124 22:52:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.8
[32m[20221124 22:52:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.8
[32m[20221124 22:52:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.4
[32m[20221124 22:52:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.4
[32m[20221124 22:52:57 @pendulum_agent.py:307][0m Sample time: 3.6308329105377197
[32m[20221124 22:53:06 @pendulum_agent.py:312][0m Update time: 9.144675016403198
[32m[20221124 22:53:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:53:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:53:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:53:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:53:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:53:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:53:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:53:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:53:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:53:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:53:07 @pendulum_agent.py:317][0m Evaluation time: 0.723628044128418
[32m[20221124 22:53:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.78
[32m[20221124 22:53:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:53:07 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:53:07 @pendulum_agent.py:289][0m Total time: 5456.896027088165
[32m[20221124 22:53:07 @pendulum_agent.py:291][0m 17900000 total steps have happened
[32m[20221124 22:53:07 @pendulum_agent.py:281][0m #------------------------ Iteration 358 --------------------------#
[32m[20221124 22:53:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:53:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:53:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:53:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:53:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:53:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:53:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:53:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:53:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:53:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:53:11 @pendulum_agent.py:307][0m Sample time: 3.6389918327331543
[32m[20221124 22:53:21 @pendulum_agent.py:312][0m Update time: 9.87985897064209
[32m[20221124 22:53:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:53:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:53:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:53:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:53:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:53:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:53:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:53:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:53:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:53:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:53:22 @pendulum_agent.py:317][0m Evaluation time: 0.7125780582427979
[32m[20221124 22:53:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:53:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:53:22 @pendulum_agent.py:289][0m Total time: 5471.399894952774
[32m[20221124 22:53:22 @pendulum_agent.py:291][0m 17950000 total steps have happened
[32m[20221124 22:53:22 @pendulum_agent.py:281][0m #------------------------ Iteration 359 --------------------------#
[32m[20221124 22:53:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:53:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:53:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:53:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:53:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:53:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:53:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:53:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:53:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:53:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:53:26 @pendulum_agent.py:307][0m Sample time: 3.8440420627593994
[32m[20221124 22:53:37 @pendulum_agent.py:312][0m Update time: 11.431761026382446
[32m[20221124 22:53:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:53:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:53:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:53:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:53:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:53:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:53:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:53:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:53:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:53:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:53:38 @pendulum_agent.py:317][0m Evaluation time: 0.584291934967041
[32m[20221124 22:53:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:53:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:53:38 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:53:38 @pendulum_agent.py:289][0m Total time: 5487.563853025436
[32m[20221124 22:53:38 @pendulum_agent.py:291][0m 18000000 total steps have happened
[32m[20221124 22:53:38 @pendulum_agent.py:281][0m #------------------------ Iteration 360 --------------------------#
[32m[20221124 22:53:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:53:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:53:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:53:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:53:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:53:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:53:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:53:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:53:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:53:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:53:42 @pendulum_agent.py:307][0m Sample time: 3.6290111541748047
[32m[20221124 22:53:52 @pendulum_agent.py:312][0m Update time: 10.595486879348755
[32m[20221124 22:53:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:53:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:53:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:53:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:53:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:53:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:53:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:53:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:53:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:53:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:53:53 @pendulum_agent.py:317][0m Evaluation time: 0.8498361110687256
[32m[20221124 22:53:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:53:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:53:53 @pendulum_agent.py:289][0m Total time: 5502.918825864792
[32m[20221124 22:53:53 @pendulum_agent.py:291][0m 18050000 total steps have happened
[32m[20221124 22:53:53 @pendulum_agent.py:281][0m #------------------------ Iteration 361 --------------------------#
[32m[20221124 22:53:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:53:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:53:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:53:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:53:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:53:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:53:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:53:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:53:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:53:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:53:57 @pendulum_agent.py:307][0m Sample time: 3.5363521575927734
[32m[20221124 22:54:06 @pendulum_agent.py:312][0m Update time: 9.57994794845581
[32m[20221124 22:54:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:54:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:54:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:54:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:54:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:54:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:54:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:54:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:54:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:54:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:54:07 @pendulum_agent.py:317][0m Evaluation time: 1.0258400440216064
[32m[20221124 22:54:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:54:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:54:08 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:54:08 @pendulum_agent.py:289][0m Total time: 5517.342761993408
[32m[20221124 22:54:08 @pendulum_agent.py:291][0m 18100000 total steps have happened
[32m[20221124 22:54:08 @pendulum_agent.py:281][0m #------------------------ Iteration 362 --------------------------#
[32m[20221124 22:54:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:54:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:54:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:54:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:54:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:54:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:54:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:54:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:54:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:54:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:54:11 @pendulum_agent.py:307][0m Sample time: 3.5727431774139404
[32m[20221124 22:54:20 @pendulum_agent.py:312][0m Update time: 8.842625856399536
[32m[20221124 22:54:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 21.0
[32m[20221124 22:54:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 21.0
[32m[20221124 22:54:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 21.0
[32m[20221124 22:54:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 21.0
[32m[20221124 22:54:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 21.0
[32m[20221124 22:54:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 21.0
[32m[20221124 22:54:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 21.0
[32m[20221124 22:54:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 21.0
[32m[20221124 22:54:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 21.0
[32m[20221124 22:54:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 21.0
[32m[20221124 22:54:21 @pendulum_agent.py:317][0m Evaluation time: 0.7153902053833008
[32m[20221124 22:54:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:54:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:54:21 @pendulum_agent.py:289][0m Total time: 5530.7657561302185
[32m[20221124 22:54:21 @pendulum_agent.py:291][0m 18150000 total steps have happened
[32m[20221124 22:54:21 @pendulum_agent.py:281][0m #------------------------ Iteration 363 --------------------------#
[32m[20221124 22:54:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.2
[32m[20221124 22:54:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.6
[32m[20221124 22:54:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.4
[32m[20221124 22:54:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.4
[32m[20221124 22:54:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.0
[32m[20221124 22:54:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.2
[32m[20221124 22:54:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.0
[32m[20221124 22:54:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.6
[32m[20221124 22:54:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.2
[32m[20221124 22:54:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.4
[32m[20221124 22:54:25 @pendulum_agent.py:307][0m Sample time: 3.7083210945129395
[32m[20221124 22:54:34 @pendulum_agent.py:312][0m Update time: 8.698947191238403
[32m[20221124 22:54:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:54:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:54:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:54:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:54:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:54:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:54:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:54:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:54:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:54:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:54:34 @pendulum_agent.py:317][0m Evaluation time: 0.5921719074249268
[32m[20221124 22:54:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.3
[32m[20221124 22:54:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:54:34 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:54:34 @pendulum_agent.py:289][0m Total time: 5544.074855804443
[32m[20221124 22:54:34 @pendulum_agent.py:291][0m 18200000 total steps have happened
[32m[20221124 22:54:34 @pendulum_agent.py:281][0m #------------------------ Iteration 364 --------------------------#
[32m[20221124 22:54:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:54:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:54:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:54:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:54:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:54:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:54:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:54:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:54:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:54:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:54:38 @pendulum_agent.py:307][0m Sample time: 3.7718710899353027
[32m[20221124 22:54:47 @pendulum_agent.py:312][0m Update time: 8.938537836074829
[32m[20221124 22:54:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:54:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:54:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:54:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:54:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:54:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:54:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:54:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:54:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:54:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:54:48 @pendulum_agent.py:317][0m Evaluation time: 0.6876711845397949
[32m[20221124 22:54:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:54:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:54:48 @pendulum_agent.py:289][0m Total time: 5557.762660980225
[32m[20221124 22:54:48 @pendulum_agent.py:291][0m 18250000 total steps have happened
[32m[20221124 22:54:48 @pendulum_agent.py:281][0m #------------------------ Iteration 365 --------------------------#
[32m[20221124 22:54:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:54:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:54:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:54:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:54:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:54:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:54:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:54:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:54:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:54:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:54:52 @pendulum_agent.py:307][0m Sample time: 3.640754222869873
[32m[20221124 22:55:02 @pendulum_agent.py:312][0m Update time: 9.943950891494751
[32m[20221124 22:55:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:55:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:55:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:55:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:55:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:55:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:55:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:55:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:55:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:55:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:55:02 @pendulum_agent.py:317][0m Evaluation time: 0.6988189220428467
[32m[20221124 22:55:03 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:55:03 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:55:03 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:55:03 @pendulum_agent.py:289][0m Total time: 5572.326880931854
[32m[20221124 22:55:03 @pendulum_agent.py:291][0m 18300000 total steps have happened
[32m[20221124 22:55:03 @pendulum_agent.py:281][0m #------------------------ Iteration 366 --------------------------#
[32m[20221124 22:55:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:55:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:55:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:55:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:55:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:55:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:55:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:55:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:55:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:55:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:55:06 @pendulum_agent.py:307][0m Sample time: 3.5932693481445312
[32m[20221124 22:55:15 @pendulum_agent.py:312][0m Update time: 9.127226829528809
[32m[20221124 22:55:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 24.0
[32m[20221124 22:55:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 24.0
[32m[20221124 22:55:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 24.0
[32m[20221124 22:55:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 24.0
[32m[20221124 22:55:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 24.0
[32m[20221124 22:55:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 24.0
[32m[20221124 22:55:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 24.0
[32m[20221124 22:55:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 24.0
[32m[20221124 22:55:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 24.0
[32m[20221124 22:55:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 24.0
[32m[20221124 22:55:16 @pendulum_agent.py:317][0m Evaluation time: 0.9272208213806152
[32m[20221124 22:55:17 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:55:17 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:55:17 @pendulum_agent.py:289][0m Total time: 5586.286536216736
[32m[20221124 22:55:17 @pendulum_agent.py:291][0m 18350000 total steps have happened
[32m[20221124 22:55:17 @pendulum_agent.py:281][0m #------------------------ Iteration 367 --------------------------#
[32m[20221124 22:55:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:55:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:55:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:55:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:55:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:55:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:55:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:55:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:55:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:55:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:55:20 @pendulum_agent.py:307][0m Sample time: 3.7313787937164307
[32m[20221124 22:55:29 @pendulum_agent.py:312][0m Update time: 8.879883050918579
[32m[20221124 22:55:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.0
[32m[20221124 22:55:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.0
[32m[20221124 22:55:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.0
[32m[20221124 22:55:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.0
[32m[20221124 22:55:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.0
[32m[20221124 22:55:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.0
[32m[20221124 22:55:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.0
[32m[20221124 22:55:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.0
[32m[20221124 22:55:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.0
[32m[20221124 22:55:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.0
[32m[20221124 22:55:30 @pendulum_agent.py:317][0m Evaluation time: 0.6985840797424316
[32m[20221124 22:55:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:55:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:55:30 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:55:30 @pendulum_agent.py:289][0m Total time: 5599.880352020264
[32m[20221124 22:55:30 @pendulum_agent.py:291][0m 18400000 total steps have happened
[32m[20221124 22:55:30 @pendulum_agent.py:281][0m #------------------------ Iteration 368 --------------------------#
[32m[20221124 22:55:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:55:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:55:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:55:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:55:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:55:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:55:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:55:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:55:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:55:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:55:34 @pendulum_agent.py:307][0m Sample time: 3.610076904296875
[32m[20221124 22:55:43 @pendulum_agent.py:312][0m Update time: 9.548094987869263
[32m[20221124 22:55:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:55:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:55:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:55:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:55:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:55:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:55:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:55:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:55:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:55:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:55:44 @pendulum_agent.py:317][0m Evaluation time: 0.6975560188293457
[32m[20221124 22:55:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:55:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:55:44 @pendulum_agent.py:289][0m Total time: 5614.024542808533
[32m[20221124 22:55:44 @pendulum_agent.py:291][0m 18450000 total steps have happened
[32m[20221124 22:55:44 @pendulum_agent.py:281][0m #------------------------ Iteration 369 --------------------------#
[32m[20221124 22:55:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:55:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:55:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:55:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:55:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:55:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:55:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:55:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:55:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:55:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:55:48 @pendulum_agent.py:307][0m Sample time: 3.402697801589966
[32m[20221124 22:55:57 @pendulum_agent.py:312][0m Update time: 8.861711978912354
[32m[20221124 22:55:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:55:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:55:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:55:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:55:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:55:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:55:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:55:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:55:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:55:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:55:58 @pendulum_agent.py:317][0m Evaluation time: 0.9301731586456299
[32m[20221124 22:55:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:55:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:55:58 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:55:58 @pendulum_agent.py:289][0m Total time: 5627.496855020523
[32m[20221124 22:55:58 @pendulum_agent.py:291][0m 18500000 total steps have happened
[32m[20221124 22:55:58 @pendulum_agent.py:281][0m #------------------------ Iteration 370 --------------------------#
[32m[20221124 22:55:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:55:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:55:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:55:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:55:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:55:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:55:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:55:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:55:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:55:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:56:01 @pendulum_agent.py:307][0m Sample time: 3.347228765487671
[32m[20221124 22:56:10 @pendulum_agent.py:312][0m Update time: 9.236026287078857
[32m[20221124 22:56:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:56:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:56:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:56:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:56:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:56:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:56:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:56:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:56:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:56:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:56:12 @pendulum_agent.py:317][0m Evaluation time: 1.6634469032287598
[32m[20221124 22:56:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:56:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:56:12 @pendulum_agent.py:289][0m Total time: 5642.035804033279
[32m[20221124 22:56:12 @pendulum_agent.py:291][0m 18550000 total steps have happened
[32m[20221124 22:56:12 @pendulum_agent.py:281][0m #------------------------ Iteration 371 --------------------------#
[32m[20221124 22:56:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:56:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:56:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:56:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:56:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:56:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:56:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:56:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:56:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:56:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:56:16 @pendulum_agent.py:307][0m Sample time: 3.745600938796997
[32m[20221124 22:56:25 @pendulum_agent.py:312][0m Update time: 9.213584184646606
[32m[20221124 22:56:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:56:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:56:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:56:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:56:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:56:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:56:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:56:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:56:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:56:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:56:26 @pendulum_agent.py:317][0m Evaluation time: 0.7219610214233398
[32m[20221124 22:56:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:56:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:56:26 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:56:26 @pendulum_agent.py:289][0m Total time: 5655.991746902466
[32m[20221124 22:56:26 @pendulum_agent.py:291][0m 18600000 total steps have happened
[32m[20221124 22:56:26 @pendulum_agent.py:281][0m #------------------------ Iteration 372 --------------------------#
[32m[20221124 22:56:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:56:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:56:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:56:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:56:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:56:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:56:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:56:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:56:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:56:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:56:30 @pendulum_agent.py:307][0m Sample time: 3.613474130630493
[32m[20221124 22:56:39 @pendulum_agent.py:312][0m Update time: 8.892723798751831
[32m[20221124 22:56:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:56:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:56:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:56:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:56:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:56:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:56:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:56:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:56:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:56:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:56:40 @pendulum_agent.py:317][0m Evaluation time: 0.7147531509399414
[32m[20221124 22:56:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:56:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:56:40 @pendulum_agent.py:289][0m Total time: 5669.490607976913
[32m[20221124 22:56:40 @pendulum_agent.py:291][0m 18650000 total steps have happened
[32m[20221124 22:56:40 @pendulum_agent.py:281][0m #------------------------ Iteration 373 --------------------------#
[32m[20221124 22:56:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:56:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:56:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:56:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:56:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:56:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:56:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:56:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:56:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:56:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:56:44 @pendulum_agent.py:307][0m Sample time: 3.7884600162506104
[32m[20221124 22:56:52 @pendulum_agent.py:312][0m Update time: 8.745761156082153
[32m[20221124 22:56:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:56:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:56:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:56:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:56:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:56:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:56:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:56:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:56:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:56:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:56:53 @pendulum_agent.py:317][0m Evaluation time: 0.7011010646820068
[32m[20221124 22:56:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:56:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:56:53 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:56:53 @pendulum_agent.py:289][0m Total time: 5683.0113780498505
[32m[20221124 22:56:53 @pendulum_agent.py:291][0m 18700000 total steps have happened
[32m[20221124 22:56:53 @pendulum_agent.py:281][0m #------------------------ Iteration 374 --------------------------#
[32m[20221124 22:56:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:56:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:56:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:56:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:56:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:56:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:56:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:56:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:56:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:56:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:56:57 @pendulum_agent.py:307][0m Sample time: 3.591047763824463
[32m[20221124 22:57:07 @pendulum_agent.py:312][0m Update time: 9.536062002182007
[32m[20221124 22:57:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:57:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:57:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:57:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:57:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:57:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:57:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:57:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:57:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:57:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:57:07 @pendulum_agent.py:317][0m Evaluation time: 0.8165280818939209
[32m[20221124 22:57:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:57:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:57:08 @pendulum_agent.py:289][0m Total time: 5697.247826099396
[32m[20221124 22:57:08 @pendulum_agent.py:291][0m 18750000 total steps have happened
[32m[20221124 22:57:08 @pendulum_agent.py:281][0m #------------------------ Iteration 375 --------------------------#
[32m[20221124 22:57:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:57:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:57:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:57:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:57:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:57:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:57:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:57:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:57:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:57:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:57:11 @pendulum_agent.py:307][0m Sample time: 3.66176700592041
[32m[20221124 22:57:20 @pendulum_agent.py:312][0m Update time: 9.1369309425354
[32m[20221124 22:57:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:57:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:57:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:57:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:57:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:57:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:57:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:57:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:57:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:57:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:57:21 @pendulum_agent.py:317][0m Evaluation time: 0.723034143447876
[32m[20221124 22:57:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:57:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:57:21 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:57:21 @pendulum_agent.py:289][0m Total time: 5711.052081108093
[32m[20221124 22:57:21 @pendulum_agent.py:291][0m 18800000 total steps have happened
[32m[20221124 22:57:21 @pendulum_agent.py:281][0m #------------------------ Iteration 376 --------------------------#
[32m[20221124 22:57:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:57:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:57:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:57:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:57:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:57:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:57:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:57:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:57:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:57:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:57:25 @pendulum_agent.py:307][0m Sample time: 3.7490150928497314
[32m[20221124 22:57:34 @pendulum_agent.py:312][0m Update time: 8.743128776550293
[32m[20221124 22:57:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:57:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:57:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:57:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:57:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:57:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:57:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:57:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:57:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:57:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:57:35 @pendulum_agent.py:317][0m Evaluation time: 0.723527193069458
[32m[20221124 22:57:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:57:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:57:35 @pendulum_agent.py:289][0m Total time: 5724.5567128658295
[32m[20221124 22:57:35 @pendulum_agent.py:291][0m 18850000 total steps have happened
[32m[20221124 22:57:35 @pendulum_agent.py:281][0m #------------------------ Iteration 377 --------------------------#
[32m[20221124 22:57:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.0
[32m[20221124 22:57:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.2
[32m[20221124 22:57:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.0
[32m[20221124 22:57:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.6
[32m[20221124 22:57:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 8.6
[32m[20221124 22:57:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.2
[32m[20221124 22:57:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.6
[32m[20221124 22:57:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.0
[32m[20221124 22:57:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.2
[32m[20221124 22:57:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.4
[32m[20221124 22:57:39 @pendulum_agent.py:307][0m Sample time: 3.6056108474731445
[32m[20221124 22:57:49 @pendulum_agent.py:312][0m Update time: 10.03539514541626
[32m[20221124 22:57:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 14.0
[32m[20221124 22:57:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 14.0
[32m[20221124 22:57:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 14.0
[32m[20221124 22:57:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 14.0
[32m[20221124 22:57:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 14.0
[32m[20221124 22:57:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 14.0
[32m[20221124 22:57:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 14.0
[32m[20221124 22:57:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 14.0
[32m[20221124 22:57:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 14.0
[32m[20221124 22:57:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 14.0
[32m[20221124 22:57:49 @pendulum_agent.py:317][0m Evaluation time: 0.711148738861084
[32m[20221124 22:57:50 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.88
[32m[20221124 22:57:50 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:57:50 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:57:50 @pendulum_agent.py:289][0m Total time: 5739.205389022827
[32m[20221124 22:57:50 @pendulum_agent.py:291][0m 18900000 total steps have happened
[32m[20221124 22:57:50 @pendulum_agent.py:281][0m #------------------------ Iteration 378 --------------------------#
[32m[20221124 22:57:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:57:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:57:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:57:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:57:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:57:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:57:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:57:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:57:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:57:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:57:53 @pendulum_agent.py:307][0m Sample time: 3.49069881439209
[32m[20221124 22:58:02 @pendulum_agent.py:312][0m Update time: 8.973695039749146
[32m[20221124 22:58:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:58:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:58:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:58:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:58:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:58:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:58:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:58:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:58:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:58:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:58:03 @pendulum_agent.py:317][0m Evaluation time: 0.8286190032958984
[32m[20221124 22:58:03 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:58:03 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:58:03 @pendulum_agent.py:289][0m Total time: 5752.783218860626
[32m[20221124 22:58:03 @pendulum_agent.py:291][0m 18950000 total steps have happened
[32m[20221124 22:58:03 @pendulum_agent.py:281][0m #------------------------ Iteration 379 --------------------------#
[32m[20221124 22:58:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:58:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:58:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:58:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:58:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:58:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:58:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:58:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:58:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:58:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:58:07 @pendulum_agent.py:307][0m Sample time: 3.4362590312957764
[32m[20221124 22:58:15 @pendulum_agent.py:312][0m Update time: 8.759110927581787
[32m[20221124 22:58:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:58:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:58:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:58:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:58:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:58:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:58:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:58:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:58:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:58:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:58:16 @pendulum_agent.py:317][0m Evaluation time: 1.0336720943450928
[32m[20221124 22:58:17 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:58:17 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:58:17 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:58:17 @pendulum_agent.py:289][0m Total time: 5766.305192947388
[32m[20221124 22:58:17 @pendulum_agent.py:291][0m 19000000 total steps have happened
[32m[20221124 22:58:17 @pendulum_agent.py:281][0m #------------------------ Iteration 380 --------------------------#
[32m[20221124 22:58:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:58:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:58:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:58:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:58:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:58:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:58:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:58:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:58:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:58:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:58:20 @pendulum_agent.py:307][0m Sample time: 3.3036458492279053
[32m[20221124 22:58:29 @pendulum_agent.py:312][0m Update time: 8.618592977523804
[32m[20221124 22:58:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:58:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:58:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:58:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:58:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:58:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:58:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:58:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:58:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:58:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:58:30 @pendulum_agent.py:317][0m Evaluation time: 1.1725928783416748
[32m[20221124 22:58:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:58:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:58:30 @pendulum_agent.py:289][0m Total time: 5779.686269044876
[32m[20221124 22:58:30 @pendulum_agent.py:291][0m 19050000 total steps have happened
[32m[20221124 22:58:30 @pendulum_agent.py:281][0m #------------------------ Iteration 381 --------------------------#
[32m[20221124 22:58:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 8.4
[32m[20221124 22:58:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 9.4
[32m[20221124 22:58:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.8
[32m[20221124 22:58:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 7.0
[32m[20221124 22:58:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.6
[32m[20221124 22:58:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 10.8
[32m[20221124 22:58:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 12.8
[32m[20221124 22:58:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 9.6
[32m[20221124 22:58:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 7.8
[32m[20221124 22:58:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 7.4
[32m[20221124 22:58:33 @pendulum_agent.py:307][0m Sample time: 3.385457992553711
[32m[20221124 22:58:42 @pendulum_agent.py:312][0m Update time: 8.722400903701782
[32m[20221124 22:58:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:58:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:58:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:58:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:58:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:58:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:58:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:58:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:58:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:58:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:58:44 @pendulum_agent.py:317][0m Evaluation time: 1.840569019317627
[32m[20221124 22:58:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 8.86
[32m[20221124 22:58:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:58:44 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:58:44 @pendulum_agent.py:289][0m Total time: 5793.955805778503
[32m[20221124 22:58:44 @pendulum_agent.py:291][0m 19100000 total steps have happened
[32m[20221124 22:58:44 @pendulum_agent.py:281][0m #------------------------ Iteration 382 --------------------------#
[32m[20221124 22:58:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:58:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:58:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:58:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:58:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:58:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:58:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:58:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:58:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:58:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:58:48 @pendulum_agent.py:307][0m Sample time: 3.5666699409484863
[32m[20221124 22:58:57 @pendulum_agent.py:312][0m Update time: 8.773705959320068
[32m[20221124 22:58:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:58:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:58:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:58:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:58:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:58:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:58:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:58:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:58:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:58:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:58:57 @pendulum_agent.py:317][0m Evaluation time: 0.710892915725708
[32m[20221124 22:58:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:58:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:58:58 @pendulum_agent.py:289][0m Total time: 5807.282606124878
[32m[20221124 22:58:58 @pendulum_agent.py:291][0m 19150000 total steps have happened
[32m[20221124 22:58:58 @pendulum_agent.py:281][0m #------------------------ Iteration 383 --------------------------#
[32m[20221124 22:58:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:58:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:58:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:58:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:58:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:58:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:58:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:58:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:58:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:58:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:59:01 @pendulum_agent.py:307][0m Sample time: 3.675792932510376
[32m[20221124 22:59:11 @pendulum_agent.py:312][0m Update time: 9.941149950027466
[32m[20221124 22:59:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:59:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:59:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:59:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:59:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:59:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:59:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:59:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:59:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:59:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:59:12 @pendulum_agent.py:317][0m Evaluation time: 0.9713459014892578
[32m[20221124 22:59:13 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:59:13 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:59:13 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:59:13 @pendulum_agent.py:289][0m Total time: 5822.16646194458
[32m[20221124 22:59:13 @pendulum_agent.py:291][0m 19200000 total steps have happened
[32m[20221124 22:59:13 @pendulum_agent.py:281][0m #------------------------ Iteration 384 --------------------------#
[32m[20221124 22:59:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:59:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:59:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:59:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:59:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:59:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:59:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:59:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:59:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:59:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:59:16 @pendulum_agent.py:307][0m Sample time: 3.8455379009246826
[32m[20221124 22:59:25 @pendulum_agent.py:312][0m Update time: 8.556421041488647
[32m[20221124 22:59:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:59:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:59:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:59:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:59:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:59:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:59:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:59:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:59:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:59:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:59:26 @pendulum_agent.py:317][0m Evaluation time: 0.9594268798828125
[32m[20221124 22:59:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:59:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:59:26 @pendulum_agent.py:289][0m Total time: 5835.830590963364
[32m[20221124 22:59:26 @pendulum_agent.py:291][0m 19250000 total steps have happened
[32m[20221124 22:59:26 @pendulum_agent.py:281][0m #------------------------ Iteration 385 --------------------------#
[32m[20221124 22:59:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:59:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:59:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:59:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:59:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:59:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:59:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:59:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:59:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:59:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:59:30 @pendulum_agent.py:307][0m Sample time: 3.852085828781128
[32m[20221124 22:59:39 @pendulum_agent.py:312][0m Update time: 8.587351083755493
[32m[20221124 22:59:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:59:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:59:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:59:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:59:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:59:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:59:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:59:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:59:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:59:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:59:39 @pendulum_agent.py:317][0m Evaluation time: 0.7157909870147705
[32m[20221124 22:59:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 22:59:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:59:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 22:59:40 @pendulum_agent.py:289][0m Total time: 5849.279815196991
[32m[20221124 22:59:40 @pendulum_agent.py:291][0m 19300000 total steps have happened
[32m[20221124 22:59:40 @pendulum_agent.py:281][0m #------------------------ Iteration 386 --------------------------#
[32m[20221124 22:59:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 8.0
[32m[20221124 22:59:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 8.2
[32m[20221124 22:59:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.8
[32m[20221124 22:59:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.4
[32m[20221124 22:59:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 10.0
[32m[20221124 22:59:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 9.4
[32m[20221124 22:59:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.4
[32m[20221124 22:59:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1.0
[32m[20221124 22:59:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 9.4
[32m[20221124 22:59:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 7.0
[32m[20221124 22:59:43 @pendulum_agent.py:307][0m Sample time: 3.5075340270996094
[32m[20221124 22:59:52 @pendulum_agent.py:312][0m Update time: 8.757035970687866
[32m[20221124 22:59:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:59:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:59:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:59:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:59:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:59:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:59:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:59:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:59:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:59:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:59:53 @pendulum_agent.py:317][0m Evaluation time: 0.5978279113769531
[32m[20221124 22:59:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.46
[32m[20221124 22:59:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 22:59:53 @pendulum_agent.py:289][0m Total time: 5862.435151100159
[32m[20221124 22:59:53 @pendulum_agent.py:291][0m 19350000 total steps have happened
[32m[20221124 22:59:53 @pendulum_agent.py:281][0m #------------------------ Iteration 387 --------------------------#
[32m[20221124 22:59:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 22:59:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 22:59:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 22:59:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 22:59:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 22:59:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 22:59:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 22:59:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 22:59:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 22:59:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 22:59:57 @pendulum_agent.py:307][0m Sample time: 3.7875468730926514
[32m[20221124 23:00:06 @pendulum_agent.py:312][0m Update time: 9.032824039459229
[32m[20221124 23:00:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:00:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:00:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:00:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:00:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:00:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:00:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:00:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:00:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:00:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:00:06 @pendulum_agent.py:317][0m Evaluation time: 0.591609001159668
[32m[20221124 23:00:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:00:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:00:07 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:00:07 @pendulum_agent.py:289][0m Total time: 5876.146295070648
[32m[20221124 23:00:07 @pendulum_agent.py:291][0m 19400000 total steps have happened
[32m[20221124 23:00:07 @pendulum_agent.py:281][0m #------------------------ Iteration 388 --------------------------#
[32m[20221124 23:00:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:00:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:00:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:00:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:00:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:00:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:00:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:00:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:00:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:00:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:00:10 @pendulum_agent.py:307][0m Sample time: 3.6860432624816895
[32m[20221124 23:00:19 @pendulum_agent.py:312][0m Update time: 8.787903070449829
[32m[20221124 23:00:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:00:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:00:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:00:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:00:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:00:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:00:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:00:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:00:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:00:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:00:20 @pendulum_agent.py:317][0m Evaluation time: 0.5857746601104736
[32m[20221124 23:00:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:00:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:00:20 @pendulum_agent.py:289][0m Total time: 5889.506304979324
[32m[20221124 23:00:20 @pendulum_agent.py:291][0m 19450000 total steps have happened
[32m[20221124 23:00:20 @pendulum_agent.py:281][0m #------------------------ Iteration 389 --------------------------#
[32m[20221124 23:00:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:00:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:00:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:00:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:00:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:00:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:00:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:00:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:00:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:00:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:00:24 @pendulum_agent.py:307][0m Sample time: 3.893734931945801
[32m[20221124 23:00:32 @pendulum_agent.py:312][0m Update time: 8.637447118759155
[32m[20221124 23:00:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 21.0
[32m[20221124 23:00:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 21.0
[32m[20221124 23:00:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 21.0
[32m[20221124 23:00:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 21.0
[32m[20221124 23:00:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 21.0
[32m[20221124 23:00:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 21.0
[32m[20221124 23:00:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 21.0
[32m[20221124 23:00:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 21.0
[32m[20221124 23:00:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 21.0
[32m[20221124 23:00:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 21.0
[32m[20221124 23:00:33 @pendulum_agent.py:317][0m Evaluation time: 0.7375679016113281
[32m[20221124 23:00:33 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:00:33 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:00:33 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:00:33 @pendulum_agent.py:289][0m Total time: 5903.055176973343
[32m[20221124 23:00:33 @pendulum_agent.py:291][0m 19500000 total steps have happened
[32m[20221124 23:00:33 @pendulum_agent.py:281][0m #------------------------ Iteration 390 --------------------------#
[32m[20221124 23:00:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:00:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:00:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:00:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:00:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:00:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:00:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:00:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:00:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:00:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:00:37 @pendulum_agent.py:307][0m Sample time: 3.53916597366333
[32m[20221124 23:00:46 @pendulum_agent.py:312][0m Update time: 8.87081003189087
[32m[20221124 23:00:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:00:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:00:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:00:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:00:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:00:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:00:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:00:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:00:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:00:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:00:47 @pendulum_agent.py:317][0m Evaluation time: 0.845311164855957
[32m[20221124 23:00:47 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:00:47 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:00:47 @pendulum_agent.py:289][0m Total time: 5916.580773115158
[32m[20221124 23:00:47 @pendulum_agent.py:291][0m 19550000 total steps have happened
[32m[20221124 23:00:47 @pendulum_agent.py:281][0m #------------------------ Iteration 391 --------------------------#
[32m[20221124 23:00:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1.4
[32m[20221124 23:00:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.4
[32m[20221124 23:00:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.2
[32m[20221124 23:00:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.4
[32m[20221124 23:00:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.4
[32m[20221124 23:00:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.2
[32m[20221124 23:00:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.6
[32m[20221124 23:00:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1.4
[32m[20221124 23:00:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.2
[32m[20221124 23:00:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1.8
[32m[20221124 23:00:50 @pendulum_agent.py:307][0m Sample time: 3.2671849727630615
[32m[20221124 23:01:00 @pendulum_agent.py:312][0m Update time: 9.35904312133789
[32m[20221124 23:01:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:01:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:01:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:01:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:01:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:01:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:01:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:01:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:01:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:01:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:01:01 @pendulum_agent.py:317][0m Evaluation time: 1.0200629234313965
[32m[20221124 23:01:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 1.4
[32m[20221124 23:01:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:01:01 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:01:01 @pendulum_agent.py:289][0m Total time: 5930.502128124237
[32m[20221124 23:01:01 @pendulum_agent.py:291][0m 19600000 total steps have happened
[32m[20221124 23:01:01 @pendulum_agent.py:281][0m #------------------------ Iteration 392 --------------------------#
[32m[20221124 23:01:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:01:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:01:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:01:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:01:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:01:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:01:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:01:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:01:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:01:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:01:04 @pendulum_agent.py:307][0m Sample time: 3.478776216506958
[32m[20221124 23:01:14 @pendulum_agent.py:312][0m Update time: 9.268380880355835
[32m[20221124 23:01:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:01:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:01:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:01:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:01:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:01:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:01:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:01:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:01:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:01:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:01:15 @pendulum_agent.py:317][0m Evaluation time: 1.1811158657073975
[32m[20221124 23:01:15 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:01:15 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:01:15 @pendulum_agent.py:289][0m Total time: 5944.708759069443
[32m[20221124 23:01:15 @pendulum_agent.py:291][0m 19650000 total steps have happened
[32m[20221124 23:01:15 @pendulum_agent.py:281][0m #------------------------ Iteration 393 --------------------------#
[32m[20221124 23:01:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:01:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:01:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:01:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:01:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:01:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:01:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:01:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:01:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:01:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:01:18 @pendulum_agent.py:307][0m Sample time: 3.3364291191101074
[32m[20221124 23:01:28 @pendulum_agent.py:312][0m Update time: 9.21187710762024
[32m[20221124 23:01:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:01:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:01:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:01:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:01:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:01:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:01:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:01:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:01:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:01:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:01:29 @pendulum_agent.py:317][0m Evaluation time: 1.154770851135254
[32m[20221124 23:01:29 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:01:29 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:01:29 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:01:29 @pendulum_agent.py:289][0m Total time: 5958.70861697197
[32m[20221124 23:01:29 @pendulum_agent.py:291][0m 19700000 total steps have happened
[32m[20221124 23:01:29 @pendulum_agent.py:281][0m #------------------------ Iteration 394 --------------------------#
[32m[20221124 23:01:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:01:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:01:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:01:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:01:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:01:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:01:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:01:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:01:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:01:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:01:33 @pendulum_agent.py:307][0m Sample time: 3.6413300037384033
[32m[20221124 23:01:41 @pendulum_agent.py:312][0m Update time: 8.701251983642578
[32m[20221124 23:01:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:01:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:01:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:01:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:01:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:01:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:01:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:01:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:01:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:01:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:01:42 @pendulum_agent.py:317][0m Evaluation time: 0.7247231006622314
[32m[20221124 23:01:42 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:01:42 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:01:42 @pendulum_agent.py:289][0m Total time: 5972.049856901169
[32m[20221124 23:01:42 @pendulum_agent.py:291][0m 19750000 total steps have happened
[32m[20221124 23:01:42 @pendulum_agent.py:281][0m #------------------------ Iteration 395 --------------------------#
[32m[20221124 23:01:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:01:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:01:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:01:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:01:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:01:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:01:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:01:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:01:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:01:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:01:46 @pendulum_agent.py:307][0m Sample time: 3.6647117137908936
[32m[20221124 23:01:55 @pendulum_agent.py:312][0m Update time: 8.988800048828125
[32m[20221124 23:01:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:01:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:01:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:01:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:01:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:01:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:01:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:01:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:01:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:01:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:01:56 @pendulum_agent.py:317][0m Evaluation time: 0.713238000869751
[32m[20221124 23:01:56 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:01:56 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:01:56 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:01:56 @pendulum_agent.py:289][0m Total time: 5985.7054488658905
[32m[20221124 23:01:56 @pendulum_agent.py:291][0m 19800000 total steps have happened
[32m[20221124 23:01:56 @pendulum_agent.py:281][0m #------------------------ Iteration 396 --------------------------#
[32m[20221124 23:01:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.2
[32m[20221124 23:01:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.8
[32m[20221124 23:01:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.4
[32m[20221124 23:01:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.8
[32m[20221124 23:01:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 8.0
[32m[20221124 23:01:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.0
[32m[20221124 23:01:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 9.2
[32m[20221124 23:01:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.2
[32m[20221124 23:01:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.0
[32m[20221124 23:01:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 14.8
[32m[20221124 23:02:00 @pendulum_agent.py:307][0m Sample time: 3.5070807933807373
[32m[20221124 23:02:11 @pendulum_agent.py:312][0m Update time: 11.591696977615356
[32m[20221124 23:02:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:02:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:02:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:02:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:02:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:02:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:02:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:02:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:02:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:02:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:02:12 @pendulum_agent.py:317][0m Evaluation time: 0.7594821453094482
[32m[20221124 23:02:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.44
[32m[20221124 23:02:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:02:12 @pendulum_agent.py:289][0m Total time: 6001.886962890625
[32m[20221124 23:02:12 @pendulum_agent.py:291][0m 19850000 total steps have happened
[32m[20221124 23:02:12 @pendulum_agent.py:281][0m #------------------------ Iteration 397 --------------------------#
[32m[20221124 23:02:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:02:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:02:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:02:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:02:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:02:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:02:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:02:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:02:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:02:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:02:17 @pendulum_agent.py:307][0m Sample time: 4.242753982543945
[32m[20221124 23:02:25 @pendulum_agent.py:312][0m Update time: 8.857762098312378
[32m[20221124 23:02:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:02:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:02:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:02:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:02:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:02:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:02:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:02:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:02:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:02:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:02:26 @pendulum_agent.py:317][0m Evaluation time: 0.5643436908721924
[32m[20221124 23:02:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:02:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:02:26 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:02:26 @pendulum_agent.py:289][0m Total time: 6015.848295927048
[32m[20221124 23:02:26 @pendulum_agent.py:291][0m 19900000 total steps have happened
[32m[20221124 23:02:26 @pendulum_agent.py:281][0m #------------------------ Iteration 398 --------------------------#
[32m[20221124 23:02:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:02:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:02:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:02:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:02:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:02:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:02:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:02:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:02:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:02:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:02:30 @pendulum_agent.py:307][0m Sample time: 3.873877763748169
[32m[20221124 23:02:39 @pendulum_agent.py:312][0m Update time: 9.072830200195312
[32m[20221124 23:02:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:02:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:02:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:02:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:02:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:02:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:02:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:02:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:02:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:02:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:02:40 @pendulum_agent.py:317][0m Evaluation time: 0.7017490863800049
[32m[20221124 23:02:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:02:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:02:40 @pendulum_agent.py:289][0m Total time: 6029.789714097977
[32m[20221124 23:02:40 @pendulum_agent.py:291][0m 19950000 total steps have happened
[32m[20221124 23:02:40 @pendulum_agent.py:281][0m #------------------------ Iteration 399 --------------------------#
[32m[20221124 23:02:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:02:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:02:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:02:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:02:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:02:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:02:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:02:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:02:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:02:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:02:44 @pendulum_agent.py:307][0m Sample time: 3.579244613647461
[32m[20221124 23:02:53 @pendulum_agent.py:312][0m Update time: 8.966973304748535
[32m[20221124 23:02:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:02:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:02:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:02:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:02:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:02:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:02:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:02:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:02:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:02:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:02:53 @pendulum_agent.py:317][0m Evaluation time: 0.6979358196258545
[32m[20221124 23:02:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:02:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:02:54 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:02:54 @pendulum_agent.py:289][0m Total time: 6043.325408935547
[32m[20221124 23:02:54 @pendulum_agent.py:291][0m 20000000 total steps have happened
[32m[20221124 23:02:54 @pendulum_agent.py:281][0m #------------------------ Iteration 400 --------------------------#
[32m[20221124 23:02:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1.6
[32m[20221124 23:02:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.6
[32m[20221124 23:02:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.0
[32m[20221124 23:02:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.6
[32m[20221124 23:02:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.6
[32m[20221124 23:02:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1.4
[32m[20221124 23:02:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.6
[32m[20221124 23:02:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1.6
[32m[20221124 23:02:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.4
[32m[20221124 23:02:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.0
[32m[20221124 23:02:57 @pendulum_agent.py:307][0m Sample time: 3.5686681270599365
[32m[20221124 23:03:11 @pendulum_agent.py:312][0m Update time: 13.997498989105225
[32m[20221124 23:03:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:03:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:03:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:03:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:03:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:03:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:03:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:03:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:03:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:03:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:03:12 @pendulum_agent.py:317][0m Evaluation time: 0.8381319046020508
[32m[20221124 23:03:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 1.74
[32m[20221124 23:03:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:03:12 @pendulum_agent.py:289][0m Total time: 6062.013997077942
[32m[20221124 23:03:12 @pendulum_agent.py:291][0m 20050000 total steps have happened
[32m[20221124 23:03:12 @pendulum_agent.py:281][0m #------------------------ Iteration 401 --------------------------#
[32m[20221124 23:03:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:03:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:03:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:03:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:03:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:03:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:03:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:03:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:03:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:03:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:03:16 @pendulum_agent.py:307][0m Sample time: 3.2879459857940674
[32m[20221124 23:03:24 @pendulum_agent.py:312][0m Update time: 8.79990291595459
[32m[20221124 23:03:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:03:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:03:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:03:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:03:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:03:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:03:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:03:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:03:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:03:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:03:26 @pendulum_agent.py:317][0m Evaluation time: 1.0385191440582275
[32m[20221124 23:03:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:03:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:03:26 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:03:26 @pendulum_agent.py:289][0m Total time: 6075.418287992477
[32m[20221124 23:03:26 @pendulum_agent.py:291][0m 20100000 total steps have happened
[32m[20221124 23:03:26 @pendulum_agent.py:281][0m #------------------------ Iteration 402 --------------------------#
[32m[20221124 23:03:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.2
[32m[20221124 23:03:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.6
[32m[20221124 23:03:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.2
[32m[20221124 23:03:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:03:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:03:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:03:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.2
[32m[20221124 23:03:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:03:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:03:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.2
[32m[20221124 23:03:29 @pendulum_agent.py:307][0m Sample time: 3.259644031524658
[32m[20221124 23:03:45 @pendulum_agent.py:312][0m Update time: 15.847617864608765
[32m[20221124 23:03:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:03:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:03:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:03:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:03:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:03:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:03:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:03:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:03:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:03:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:03:46 @pendulum_agent.py:317][0m Evaluation time: 1.0296509265899658
[32m[20221124 23:03:46 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.14
[32m[20221124 23:03:46 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:03:46 @pendulum_agent.py:289][0m Total time: 6095.8344078063965
[32m[20221124 23:03:46 @pendulum_agent.py:291][0m 20150000 total steps have happened
[32m[20221124 23:03:46 @pendulum_agent.py:281][0m #------------------------ Iteration 403 --------------------------#
[32m[20221124 23:03:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.6
[32m[20221124 23:03:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.6
[32m[20221124 23:03:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.4
[32m[20221124 23:03:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.4
[32m[20221124 23:03:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.4
[32m[20221124 23:03:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.2
[32m[20221124 23:03:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.2
[32m[20221124 23:03:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.4
[32m[20221124 23:03:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.4
[32m[20221124 23:03:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.2
[32m[20221124 23:03:50 @pendulum_agent.py:307][0m Sample time: 3.6471378803253174
[32m[20221124 23:04:03 @pendulum_agent.py:312][0m Update time: 12.873347282409668
[32m[20221124 23:04:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:04:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:04:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:04:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:04:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:04:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:04:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:04:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:04:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:04:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:04:03 @pendulum_agent.py:317][0m Evaluation time: 0.6995418071746826
[32m[20221124 23:04:04 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.38
[32m[20221124 23:04:04 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:04:04 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:04:04 @pendulum_agent.py:289][0m Total time: 6113.335692882538
[32m[20221124 23:04:04 @pendulum_agent.py:291][0m 20200000 total steps have happened
[32m[20221124 23:04:04 @pendulum_agent.py:281][0m #------------------------ Iteration 404 --------------------------#
[32m[20221124 23:04:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:04:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:04:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:04:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:04:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:04:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:04:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:04:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:04:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:04:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:04:07 @pendulum_agent.py:307][0m Sample time: 3.6295228004455566
[32m[20221124 23:04:18 @pendulum_agent.py:312][0m Update time: 11.03085732460022
[32m[20221124 23:04:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:04:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:04:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:04:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:04:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:04:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:04:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:04:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:04:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:04:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:04:19 @pendulum_agent.py:317][0m Evaluation time: 0.7143239974975586
[32m[20221124 23:04:19 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:04:19 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:04:19 @pendulum_agent.py:289][0m Total time: 6128.9900159835815
[32m[20221124 23:04:19 @pendulum_agent.py:291][0m 20250000 total steps have happened
[32m[20221124 23:04:19 @pendulum_agent.py:281][0m #------------------------ Iteration 405 --------------------------#
[32m[20221124 23:04:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:04:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:04:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:04:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:04:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:04:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:04:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:04:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:04:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:04:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:04:23 @pendulum_agent.py:307][0m Sample time: 3.833590030670166
[32m[20221124 23:04:37 @pendulum_agent.py:312][0m Update time: 13.779236078262329
[32m[20221124 23:04:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:04:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:04:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:04:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:04:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:04:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:04:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:04:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:04:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:04:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:04:38 @pendulum_agent.py:317][0m Evaluation time: 0.5711638927459717
[32m[20221124 23:04:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:04:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:04:38 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:04:38 @pendulum_agent.py:289][0m Total time: 6147.468399047852
[32m[20221124 23:04:38 @pendulum_agent.py:291][0m 20300000 total steps have happened
[32m[20221124 23:04:38 @pendulum_agent.py:281][0m #------------------------ Iteration 406 --------------------------#
[32m[20221124 23:04:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:04:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:04:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:04:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:04:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:04:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:04:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:04:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:04:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:04:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:04:41 @pendulum_agent.py:307][0m Sample time: 3.6280641555786133
[32m[20221124 23:04:50 @pendulum_agent.py:312][0m Update time: 8.702615976333618
[32m[20221124 23:04:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:04:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:04:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:04:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:04:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:04:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:04:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:04:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:04:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:04:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:04:51 @pendulum_agent.py:317][0m Evaluation time: 0.8394119739532471
[32m[20221124 23:04:51 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:04:51 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:04:51 @pendulum_agent.py:289][0m Total time: 6160.929646968842
[32m[20221124 23:04:51 @pendulum_agent.py:291][0m 20350000 total steps have happened
[32m[20221124 23:04:51 @pendulum_agent.py:281][0m #------------------------ Iteration 407 --------------------------#
[32m[20221124 23:04:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:04:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:04:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:04:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:04:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:04:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:04:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:04:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:04:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:04:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:04:55 @pendulum_agent.py:307][0m Sample time: 3.4831180572509766
[32m[20221124 23:05:04 @pendulum_agent.py:312][0m Update time: 9.054494857788086
[32m[20221124 23:05:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:05:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:05:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:05:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:05:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:05:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:05:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:05:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:05:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:05:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:05:05 @pendulum_agent.py:317][0m Evaluation time: 1.0222411155700684
[32m[20221124 23:05:05 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:05:05 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:05:05 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:05:05 @pendulum_agent.py:289][0m Total time: 6174.776772022247
[32m[20221124 23:05:05 @pendulum_agent.py:291][0m 20400000 total steps have happened
[32m[20221124 23:05:05 @pendulum_agent.py:281][0m #------------------------ Iteration 408 --------------------------#
[32m[20221124 23:05:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.0
[32m[20221124 23:05:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.4
[32m[20221124 23:05:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.4
[32m[20221124 23:05:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.6
[32m[20221124 23:05:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.8
[32m[20221124 23:05:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.4
[32m[20221124 23:05:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.0
[32m[20221124 23:05:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.0
[32m[20221124 23:05:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.2
[32m[20221124 23:05:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.2
[32m[20221124 23:05:09 @pendulum_agent.py:307][0m Sample time: 3.6128480434417725
[32m[20221124 23:05:19 @pendulum_agent.py:312][0m Update time: 10.161595821380615
[32m[20221124 23:05:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:05:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:05:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:05:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:05:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:05:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:05:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:05:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:05:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:05:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:05:20 @pendulum_agent.py:317][0m Evaluation time: 0.7007269859313965
[32m[20221124 23:05:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.3
[32m[20221124 23:05:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:05:20 @pendulum_agent.py:289][0m Total time: 6189.528526067734
[32m[20221124 23:05:20 @pendulum_agent.py:291][0m 20450000 total steps have happened
[32m[20221124 23:05:20 @pendulum_agent.py:281][0m #------------------------ Iteration 409 --------------------------#
[32m[20221124 23:05:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:05:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:05:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:05:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:05:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:05:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:05:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:05:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:05:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:05:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:05:24 @pendulum_agent.py:307][0m Sample time: 3.632783889770508
[32m[20221124 23:05:34 @pendulum_agent.py:312][0m Update time: 10.156548976898193
[32m[20221124 23:05:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:05:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:05:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:05:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:05:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:05:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:05:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:05:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:05:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:05:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:05:34 @pendulum_agent.py:317][0m Evaluation time: 0.6047630310058594
[32m[20221124 23:05:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:05:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:05:35 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:05:35 @pendulum_agent.py:289][0m Total time: 6204.229968070984
[32m[20221124 23:05:35 @pendulum_agent.py:291][0m 20500000 total steps have happened
[32m[20221124 23:05:35 @pendulum_agent.py:281][0m #------------------------ Iteration 410 --------------------------#
[32m[20221124 23:05:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:05:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.6
[32m[20221124 23:05:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:05:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:05:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:05:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:05:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:05:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:05:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:05:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:05:38 @pendulum_agent.py:307][0m Sample time: 3.7446649074554443
[32m[20221124 23:05:47 @pendulum_agent.py:312][0m Update time: 9.09470796585083
[32m[20221124 23:05:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:05:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:05:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:05:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:05:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:05:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:05:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:05:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:05:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:05:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:05:48 @pendulum_agent.py:317][0m Evaluation time: 0.6874711513519287
[32m[20221124 23:05:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.06
[32m[20221124 23:05:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:05:48 @pendulum_agent.py:289][0m Total time: 6218.039114952087
[32m[20221124 23:05:48 @pendulum_agent.py:291][0m 20550000 total steps have happened
[32m[20221124 23:05:48 @pendulum_agent.py:281][0m #------------------------ Iteration 411 --------------------------#
[32m[20221124 23:05:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:05:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:05:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:05:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:05:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:05:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:05:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:05:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:05:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:05:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:05:52 @pendulum_agent.py:307][0m Sample time: 3.7504220008850098
[32m[20221124 23:06:01 @pendulum_agent.py:312][0m Update time: 8.860736846923828
[32m[20221124 23:06:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:06:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:06:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:06:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:06:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:06:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:06:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:06:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:06:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:06:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:06:02 @pendulum_agent.py:317][0m Evaluation time: 0.6978030204772949
[32m[20221124 23:06:02 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:06:02 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:06:02 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:06:02 @pendulum_agent.py:289][0m Total time: 6231.650115013123
[32m[20221124 23:06:02 @pendulum_agent.py:291][0m 20600000 total steps have happened
[32m[20221124 23:06:02 @pendulum_agent.py:281][0m #------------------------ Iteration 412 --------------------------#
[32m[20221124 23:06:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:06:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:06:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:06:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:06:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:06:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:06:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:06:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:06:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:06:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:06:06 @pendulum_agent.py:307][0m Sample time: 3.6012020111083984
[32m[20221124 23:06:17 @pendulum_agent.py:312][0m Update time: 11.503254890441895
[32m[20221124 23:06:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:06:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:06:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:06:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:06:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:06:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:06:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:06:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:06:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:06:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:06:18 @pendulum_agent.py:317][0m Evaluation time: 0.9342012405395508
[32m[20221124 23:06:18 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:06:18 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:06:18 @pendulum_agent.py:289][0m Total time: 6247.978964805603
[32m[20221124 23:06:18 @pendulum_agent.py:291][0m 20650000 total steps have happened
[32m[20221124 23:06:18 @pendulum_agent.py:281][0m #------------------------ Iteration 413 --------------------------#
[32m[20221124 23:06:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:06:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:06:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:06:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:06:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:06:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:06:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:06:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:06:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:06:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:06:22 @pendulum_agent.py:307][0m Sample time: 3.708786964416504
[32m[20221124 23:06:32 @pendulum_agent.py:312][0m Update time: 10.360358953475952
[32m[20221124 23:06:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:06:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:06:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:06:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:06:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:06:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:06:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:06:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:06:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:06:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:06:33 @pendulum_agent.py:317][0m Evaluation time: 0.687518835067749
[32m[20221124 23:06:33 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:06:33 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:06:33 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:06:33 @pendulum_agent.py:289][0m Total time: 6263.028897047043
[32m[20221124 23:06:33 @pendulum_agent.py:291][0m 20700000 total steps have happened
[32m[20221124 23:06:33 @pendulum_agent.py:281][0m #------------------------ Iteration 414 --------------------------#
[32m[20221124 23:06:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:06:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:06:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:06:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:06:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:06:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:06:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:06:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:06:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:06:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:06:37 @pendulum_agent.py:307][0m Sample time: 3.632319927215576
[32m[20221124 23:06:46 @pendulum_agent.py:312][0m Update time: 9.153044939041138
[32m[20221124 23:06:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:06:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:06:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:06:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:06:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:06:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:06:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:06:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:06:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:06:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:06:47 @pendulum_agent.py:317][0m Evaluation time: 0.6668920516967773
[32m[20221124 23:06:47 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:06:47 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:06:47 @pendulum_agent.py:289][0m Total time: 6276.7851848602295
[32m[20221124 23:06:47 @pendulum_agent.py:291][0m 20750000 total steps have happened
[32m[20221124 23:06:47 @pendulum_agent.py:281][0m #------------------------ Iteration 415 --------------------------#
[32m[20221124 23:06:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:06:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:06:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:06:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:06:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:06:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:06:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:06:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:06:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:06:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:06:51 @pendulum_agent.py:307][0m Sample time: 3.522012948989868
[32m[20221124 23:06:59 @pendulum_agent.py:312][0m Update time: 8.65720820426941
[32m[20221124 23:07:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:07:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:07:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:07:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:07:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:07:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:07:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:07:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:07:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:07:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:07:00 @pendulum_agent.py:317][0m Evaluation time: 0.945371150970459
[32m[20221124 23:07:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:07:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:07:01 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:07:01 @pendulum_agent.py:289][0m Total time: 6290.186698913574
[32m[20221124 23:07:01 @pendulum_agent.py:291][0m 20800000 total steps have happened
[32m[20221124 23:07:01 @pendulum_agent.py:281][0m #------------------------ Iteration 416 --------------------------#
[32m[20221124 23:07:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.4
[32m[20221124 23:07:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.6
[32m[20221124 23:07:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 12.0
[32m[20221124 23:07:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.8
[32m[20221124 23:07:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.0
[32m[20221124 23:07:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.0
[32m[20221124 23:07:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 11.4
[32m[20221124 23:07:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 14.6
[32m[20221124 23:07:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.2
[32m[20221124 23:07:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.0
[32m[20221124 23:07:04 @pendulum_agent.py:307][0m Sample time: 3.3044328689575195
[32m[20221124 23:07:12 @pendulum_agent.py:312][0m Update time: 8.529932260513306
[32m[20221124 23:07:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:07:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:07:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:07:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:07:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:07:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:07:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:07:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:07:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:07:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:07:14 @pendulum_agent.py:317][0m Evaluation time: 1.639420986175537
[32m[20221124 23:07:14 @pendulum_agent.py:285][0m Average TRAINING episode reward: 8.1
[32m[20221124 23:07:14 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:07:14 @pendulum_agent.py:289][0m Total time: 6303.9510979652405
[32m[20221124 23:07:14 @pendulum_agent.py:291][0m 20850000 total steps have happened
[32m[20221124 23:07:14 @pendulum_agent.py:281][0m #------------------------ Iteration 417 --------------------------#
[32m[20221124 23:07:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:07:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:07:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:07:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:07:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:07:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:07:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:07:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:07:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:07:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:07:18 @pendulum_agent.py:307][0m Sample time: 3.8464388847351074
[32m[20221124 23:07:33 @pendulum_agent.py:312][0m Update time: 14.741424083709717
[32m[20221124 23:07:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:07:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:07:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:07:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:07:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:07:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:07:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:07:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:07:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:07:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:07:34 @pendulum_agent.py:317][0m Evaluation time: 0.7043700218200684
[32m[20221124 23:07:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:07:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:07:34 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:07:34 @pendulum_agent.py:289][0m Total time: 6323.527102947235
[32m[20221124 23:07:34 @pendulum_agent.py:291][0m 20900000 total steps have happened
[32m[20221124 23:07:34 @pendulum_agent.py:281][0m #------------------------ Iteration 418 --------------------------#
[32m[20221124 23:07:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:07:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:07:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:07:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:07:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:07:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:07:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:07:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:07:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:07:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:07:38 @pendulum_agent.py:307][0m Sample time: 3.609232187271118
[32m[20221124 23:07:46 @pendulum_agent.py:312][0m Update time: 8.764943838119507
[32m[20221124 23:07:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:07:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:07:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:07:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:07:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:07:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:07:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:07:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:07:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:07:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:07:47 @pendulum_agent.py:317][0m Evaluation time: 0.6891891956329346
[32m[20221124 23:07:47 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:07:47 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:07:47 @pendulum_agent.py:289][0m Total time: 6336.864235877991
[32m[20221124 23:07:47 @pendulum_agent.py:291][0m 20950000 total steps have happened
[32m[20221124 23:07:47 @pendulum_agent.py:281][0m #------------------------ Iteration 419 --------------------------#
[32m[20221124 23:07:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.8
[32m[20221124 23:07:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.4
[32m[20221124 23:07:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.8
[32m[20221124 23:07:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1.4
[32m[20221124 23:07:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.0
[32m[20221124 23:07:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.6
[32m[20221124 23:07:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1.4
[32m[20221124 23:07:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.2
[32m[20221124 23:07:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.8
[32m[20221124 23:07:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.8
[32m[20221124 23:07:51 @pendulum_agent.py:307][0m Sample time: 3.7459471225738525
[32m[20221124 23:08:00 @pendulum_agent.py:312][0m Update time: 8.751368999481201
[32m[20221124 23:08:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:08:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:08:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:08:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:08:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:08:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:08:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:08:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:08:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:08:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:08:00 @pendulum_agent.py:317][0m Evaluation time: 0.7108900547027588
[32m[20221124 23:08:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.42
[32m[20221124 23:08:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:08:01 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:08:01 @pendulum_agent.py:289][0m Total time: 6350.3608639240265
[32m[20221124 23:08:01 @pendulum_agent.py:291][0m 21000000 total steps have happened
[32m[20221124 23:08:01 @pendulum_agent.py:281][0m #------------------------ Iteration 420 --------------------------#
[32m[20221124 23:08:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:08:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:08:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:08:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:08:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:08:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:08:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:08:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:08:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:08:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:08:04 @pendulum_agent.py:307][0m Sample time: 3.564887046813965
[32m[20221124 23:08:13 @pendulum_agent.py:312][0m Update time: 8.883154392242432
[32m[20221124 23:08:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:08:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:08:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:08:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:08:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:08:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:08:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:08:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:08:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:08:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:08:14 @pendulum_agent.py:317][0m Evaluation time: 0.812842845916748
[32m[20221124 23:08:14 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:08:14 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:08:14 @pendulum_agent.py:289][0m Total time: 6363.900093078613
[32m[20221124 23:08:14 @pendulum_agent.py:291][0m 21050000 total steps have happened
[32m[20221124 23:08:14 @pendulum_agent.py:281][0m #------------------------ Iteration 421 --------------------------#
[32m[20221124 23:08:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:08:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:08:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:08:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:08:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:08:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:08:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:08:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:08:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:08:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:08:18 @pendulum_agent.py:307][0m Sample time: 3.703993797302246
[32m[20221124 23:08:27 @pendulum_agent.py:312][0m Update time: 8.653964042663574
[32m[20221124 23:08:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:08:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:08:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:08:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:08:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:08:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:08:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:08:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:08:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:08:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:08:27 @pendulum_agent.py:317][0m Evaluation time: 0.7230901718139648
[32m[20221124 23:08:28 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:08:28 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:08:28 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:08:28 @pendulum_agent.py:289][0m Total time: 6377.2567229270935
[32m[20221124 23:08:28 @pendulum_agent.py:291][0m 21100000 total steps have happened
[32m[20221124 23:08:28 @pendulum_agent.py:281][0m #------------------------ Iteration 422 --------------------------#
[32m[20221124 23:08:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:08:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:08:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:08:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:08:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:08:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:08:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:08:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:08:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:08:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:08:31 @pendulum_agent.py:307][0m Sample time: 3.8036179542541504
[32m[20221124 23:08:42 @pendulum_agent.py:312][0m Update time: 10.766031265258789
[32m[20221124 23:08:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:08:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:08:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:08:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:08:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:08:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:08:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:08:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:08:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:08:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:08:43 @pendulum_agent.py:317][0m Evaluation time: 0.719822883605957
[32m[20221124 23:08:43 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:08:43 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:08:43 @pendulum_agent.py:289][0m Total time: 6392.8359541893005
[32m[20221124 23:08:43 @pendulum_agent.py:291][0m 21150000 total steps have happened
[32m[20221124 23:08:43 @pendulum_agent.py:281][0m #------------------------ Iteration 423 --------------------------#
[32m[20221124 23:08:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:08:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:08:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:08:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:08:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:08:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:08:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:08:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:08:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:08:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:08:47 @pendulum_agent.py:307][0m Sample time: 3.6760430335998535
[32m[20221124 23:08:56 @pendulum_agent.py:312][0m Update time: 8.927122831344604
[32m[20221124 23:08:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:08:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:08:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:08:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:08:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:08:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:08:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:08:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:08:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:08:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:08:57 @pendulum_agent.py:317][0m Evaluation time: 0.6906628608703613
[32m[20221124 23:08:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:08:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:08:57 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:08:57 @pendulum_agent.py:289][0m Total time: 6406.435218811035
[32m[20221124 23:08:57 @pendulum_agent.py:291][0m 21200000 total steps have happened
[32m[20221124 23:08:57 @pendulum_agent.py:281][0m #------------------------ Iteration 424 --------------------------#
[32m[20221124 23:08:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:08:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:08:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:08:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:08:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:08:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:08:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:08:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:08:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:08:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:09:00 @pendulum_agent.py:307][0m Sample time: 3.532235622406006
[32m[20221124 23:09:37 @pendulum_agent.py:312][0m Update time: 36.741541147232056
[32m[20221124 23:09:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:09:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:09:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:09:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:09:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:09:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:09:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:09:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:09:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:09:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:09:38 @pendulum_agent.py:317][0m Evaluation time: 0.8239140510559082
[32m[20221124 23:09:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:09:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:09:38 @pendulum_agent.py:289][0m Total time: 6447.813937187195
[32m[20221124 23:09:38 @pendulum_agent.py:291][0m 21250000 total steps have happened
[32m[20221124 23:09:38 @pendulum_agent.py:281][0m #------------------------ Iteration 425 --------------------------#
[32m[20221124 23:09:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:09:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:09:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:09:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:09:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:09:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:09:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:09:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:09:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:09:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:09:42 @pendulum_agent.py:307][0m Sample time: 3.469057083129883
[32m[20221124 23:10:11 @pendulum_agent.py:312][0m Update time: 28.95215106010437
[32m[20221124 23:10:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:10:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:10:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:10:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:10:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:10:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:10:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:10:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:10:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:10:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:10:12 @pendulum_agent.py:317][0m Evaluation time: 1.0242328643798828
[32m[20221124 23:10:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:10:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:10:12 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:10:12 @pendulum_agent.py:289][0m Total time: 6481.546022176743
[32m[20221124 23:10:12 @pendulum_agent.py:291][0m 21300000 total steps have happened
[32m[20221124 23:10:12 @pendulum_agent.py:281][0m #------------------------ Iteration 426 --------------------------#
[32m[20221124 23:10:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:10:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:10:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:10:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:10:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:10:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:10:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:10:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:10:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:10:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:10:15 @pendulum_agent.py:307][0m Sample time: 3.3312530517578125
[32m[20221124 23:10:34 @pendulum_agent.py:312][0m Update time: 18.999438047409058
[32m[20221124 23:10:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:10:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:10:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:10:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:10:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:10:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:10:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:10:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:10:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:10:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:10:35 @pendulum_agent.py:317][0m Evaluation time: 1.152440071105957
[32m[20221124 23:10:36 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:10:36 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:10:36 @pendulum_agent.py:289][0m Total time: 6505.320468902588
[32m[20221124 23:10:36 @pendulum_agent.py:291][0m 21350000 total steps have happened
[32m[20221124 23:10:36 @pendulum_agent.py:281][0m #------------------------ Iteration 427 --------------------------#
[32m[20221124 23:10:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:10:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:10:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:10:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:10:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:10:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:10:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:10:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:10:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:10:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:10:39 @pendulum_agent.py:307][0m Sample time: 3.3958027362823486
[32m[20221124 23:10:49 @pendulum_agent.py:312][0m Update time: 10.36534309387207
[32m[20221124 23:10:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:10:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:10:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:10:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:10:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:10:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:10:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:10:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:10:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:10:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:10:51 @pendulum_agent.py:317][0m Evaluation time: 1.8578848838806152
[32m[20221124 23:10:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:10:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:10:52 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:10:52 @pendulum_agent.py:289][0m Total time: 6521.229304075241
[32m[20221124 23:10:52 @pendulum_agent.py:291][0m 21400000 total steps have happened
[32m[20221124 23:10:52 @pendulum_agent.py:281][0m #------------------------ Iteration 428 --------------------------#
[32m[20221124 23:10:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:10:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:10:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:10:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:10:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:10:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:10:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:10:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:10:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:10:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:10:55 @pendulum_agent.py:307][0m Sample time: 3.514876127243042
[32m[20221124 23:11:07 @pendulum_agent.py:312][0m Update time: 11.692452907562256
[32m[20221124 23:11:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:11:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:11:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:11:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:11:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:11:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:11:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:11:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:11:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:11:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:11:08 @pendulum_agent.py:317][0m Evaluation time: 0.7085611820220947
[32m[20221124 23:11:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:11:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:11:08 @pendulum_agent.py:289][0m Total time: 6537.415333986282
[32m[20221124 23:11:08 @pendulum_agent.py:291][0m 21450000 total steps have happened
[32m[20221124 23:11:08 @pendulum_agent.py:281][0m #------------------------ Iteration 429 --------------------------#
[32m[20221124 23:11:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:11:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:11:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:11:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:11:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:11:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:11:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:11:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:11:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:11:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:11:11 @pendulum_agent.py:307][0m Sample time: 3.685716152191162
[32m[20221124 23:11:21 @pendulum_agent.py:312][0m Update time: 9.72018575668335
[32m[20221124 23:11:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:11:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:11:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:11:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:11:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:11:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:11:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:11:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:11:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:11:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:11:22 @pendulum_agent.py:317][0m Evaluation time: 0.993710994720459
[32m[20221124 23:11:23 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:11:23 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:11:23 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:11:23 @pendulum_agent.py:289][0m Total time: 6552.108658790588
[32m[20221124 23:11:23 @pendulum_agent.py:291][0m 21500000 total steps have happened
[32m[20221124 23:11:23 @pendulum_agent.py:281][0m #------------------------ Iteration 430 --------------------------#
[32m[20221124 23:11:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:11:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:11:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:11:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:11:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:11:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:11:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:11:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:11:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:11:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:11:26 @pendulum_agent.py:307][0m Sample time: 3.852581262588501
[32m[20221124 23:11:36 @pendulum_agent.py:312][0m Update time: 9.223430871963501
[32m[20221124 23:11:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:11:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:11:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:11:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:11:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:11:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:11:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:11:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:11:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:11:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:11:37 @pendulum_agent.py:317][0m Evaluation time: 0.9358949661254883
[32m[20221124 23:11:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:11:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:11:37 @pendulum_agent.py:289][0m Total time: 6566.399428129196
[32m[20221124 23:11:37 @pendulum_agent.py:291][0m 21550000 total steps have happened
[32m[20221124 23:11:37 @pendulum_agent.py:281][0m #------------------------ Iteration 431 --------------------------#
[32m[20221124 23:11:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:11:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:11:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:11:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:11:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:11:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:11:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:11:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:11:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:11:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:11:41 @pendulum_agent.py:307][0m Sample time: 3.8519222736358643
[32m[20221124 23:11:50 @pendulum_agent.py:312][0m Update time: 8.874320983886719
[32m[20221124 23:11:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:11:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:11:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:11:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:11:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:11:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:11:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:11:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:11:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:11:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:11:50 @pendulum_agent.py:317][0m Evaluation time: 0.6965339183807373
[32m[20221124 23:11:50 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:11:50 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:11:50 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:11:50 @pendulum_agent.py:289][0m Total time: 6580.10538315773
[32m[20221124 23:11:50 @pendulum_agent.py:291][0m 21600000 total steps have happened
[32m[20221124 23:11:50 @pendulum_agent.py:281][0m #------------------------ Iteration 432 --------------------------#
[32m[20221124 23:11:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:11:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:11:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:11:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:11:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:11:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:11:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:11:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:11:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:11:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:11:54 @pendulum_agent.py:307][0m Sample time: 3.517475128173828
[32m[20221124 23:12:03 @pendulum_agent.py:312][0m Update time: 8.877865076065063
[32m[20221124 23:12:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:12:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:12:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:12:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:12:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:12:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:12:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:12:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:12:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:12:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:12:03 @pendulum_agent.py:317][0m Evaluation time: 0.5715420246124268
[32m[20221124 23:12:04 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:12:04 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:12:04 @pendulum_agent.py:289][0m Total time: 6593.3624811172485
[32m[20221124 23:12:04 @pendulum_agent.py:291][0m 21650000 total steps have happened
[32m[20221124 23:12:04 @pendulum_agent.py:281][0m #------------------------ Iteration 433 --------------------------#
[32m[20221124 23:12:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.8
[32m[20221124 23:12:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.4
[32m[20221124 23:12:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.8
[32m[20221124 23:12:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.6
[32m[20221124 23:12:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.8
[32m[20221124 23:12:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.6
[32m[20221124 23:12:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.8
[32m[20221124 23:12:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.8
[32m[20221124 23:12:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.8
[32m[20221124 23:12:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.0
[32m[20221124 23:12:08 @pendulum_agent.py:307][0m Sample time: 3.804412841796875
[32m[20221124 23:12:30 @pendulum_agent.py:312][0m Update time: 22.1547908782959
[32m[20221124 23:12:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:12:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:12:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:12:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:12:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:12:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:12:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:12:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:12:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:12:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:12:30 @pendulum_agent.py:317][0m Evaluation time: 0.5627822875976562
[32m[20221124 23:12:31 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.84
[32m[20221124 23:12:31 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:12:31 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:12:31 @pendulum_agent.py:289][0m Total time: 6620.188759088516
[32m[20221124 23:12:31 @pendulum_agent.py:291][0m 21700000 total steps have happened
[32m[20221124 23:12:31 @pendulum_agent.py:281][0m #------------------------ Iteration 434 --------------------------#
[32m[20221124 23:12:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:12:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:12:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:12:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:12:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:12:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:12:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:12:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:12:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:12:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:12:34 @pendulum_agent.py:307][0m Sample time: 3.7385029792785645
[32m[20221124 23:12:43 @pendulum_agent.py:312][0m Update time: 8.705849885940552
[32m[20221124 23:12:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:12:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:12:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:12:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:12:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:12:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:12:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:12:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:12:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:12:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:12:44 @pendulum_agent.py:317][0m Evaluation time: 0.570155143737793
[32m[20221124 23:12:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:12:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:12:44 @pendulum_agent.py:289][0m Total time: 6633.501760959625
[32m[20221124 23:12:44 @pendulum_agent.py:291][0m 21750000 total steps have happened
[32m[20221124 23:12:44 @pendulum_agent.py:281][0m #------------------------ Iteration 435 --------------------------#
[32m[20221124 23:12:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:12:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:12:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:12:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:12:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:12:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:12:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:12:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:12:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:12:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:12:48 @pendulum_agent.py:307][0m Sample time: 3.91483211517334
[32m[20221124 23:13:08 @pendulum_agent.py:312][0m Update time: 20.262664794921875
[32m[20221124 23:13:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:13:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:13:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:13:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:13:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:13:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:13:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:13:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:13:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:13:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:13:09 @pendulum_agent.py:317][0m Evaluation time: 0.6770219802856445
[32m[20221124 23:13:09 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:13:09 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:13:09 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:13:09 @pendulum_agent.py:289][0m Total time: 6658.634114027023
[32m[20221124 23:13:09 @pendulum_agent.py:291][0m 21800000 total steps have happened
[32m[20221124 23:13:09 @pendulum_agent.py:281][0m #------------------------ Iteration 436 --------------------------#
[32m[20221124 23:13:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 16.0
[32m[20221124 23:13:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.0
[32m[20221124 23:13:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.2
[32m[20221124 23:13:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.6
[32m[20221124 23:13:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.2
[32m[20221124 23:13:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 9.8
[32m[20221124 23:13:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 11.4
[32m[20221124 23:13:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 14.6
[32m[20221124 23:13:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.8
[32m[20221124 23:13:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.2
[32m[20221124 23:13:13 @pendulum_agent.py:307][0m Sample time: 3.5287959575653076
[32m[20221124 23:13:21 @pendulum_agent.py:312][0m Update time: 8.835674047470093
[32m[20221124 23:13:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:13:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:13:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:13:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:13:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:13:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:13:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:13:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:13:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:13:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:13:22 @pendulum_agent.py:317][0m Evaluation time: 0.8100159168243408
[32m[20221124 23:13:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 8.48
[32m[20221124 23:13:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:13:22 @pendulum_agent.py:289][0m Total time: 6672.102755069733
[32m[20221124 23:13:22 @pendulum_agent.py:291][0m 21850000 total steps have happened
[32m[20221124 23:13:22 @pendulum_agent.py:281][0m #------------------------ Iteration 437 --------------------------#
[32m[20221124 23:13:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:13:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:13:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:13:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:13:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:13:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:13:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:13:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:13:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:13:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:13:26 @pendulum_agent.py:307][0m Sample time: 3.2944040298461914
[32m[20221124 23:13:34 @pendulum_agent.py:312][0m Update time: 8.684942960739136
[32m[20221124 23:13:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:13:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:13:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:13:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:13:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:13:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:13:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:13:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:13:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:13:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:13:36 @pendulum_agent.py:317][0m Evaluation time: 1.029426097869873
[32m[20221124 23:13:36 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:13:36 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:13:36 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:13:36 @pendulum_agent.py:289][0m Total time: 6685.394243001938
[32m[20221124 23:13:36 @pendulum_agent.py:291][0m 21900000 total steps have happened
[32m[20221124 23:13:36 @pendulum_agent.py:281][0m #------------------------ Iteration 438 --------------------------#
[32m[20221124 23:13:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 8.2
[32m[20221124 23:13:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.2
[32m[20221124 23:13:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.4
[32m[20221124 23:13:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 10.2
[32m[20221124 23:13:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.0
[32m[20221124 23:13:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.2
[32m[20221124 23:13:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 11.2
[32m[20221124 23:13:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.2
[32m[20221124 23:13:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 17.0
[32m[20221124 23:13:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 9.0
[32m[20221124 23:13:39 @pendulum_agent.py:307][0m Sample time: 3.499795913696289
[32m[20221124 23:13:50 @pendulum_agent.py:312][0m Update time: 11.18262004852295
[32m[20221124 23:13:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:13:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:13:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:13:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:13:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:13:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:13:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:13:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:13:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:13:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:13:52 @pendulum_agent.py:317][0m Evaluation time: 1.1567840576171875
[32m[20221124 23:13:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 8.66
[32m[20221124 23:13:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:13:52 @pendulum_agent.py:289][0m Total time: 6701.540178060532
[32m[20221124 23:13:52 @pendulum_agent.py:291][0m 21950000 total steps have happened
[32m[20221124 23:13:52 @pendulum_agent.py:281][0m #------------------------ Iteration 439 --------------------------#
[32m[20221124 23:13:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:13:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:13:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:13:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:13:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:13:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:13:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:13:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:13:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:13:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:13:55 @pendulum_agent.py:307][0m Sample time: 3.454026937484741
[32m[20221124 23:14:04 @pendulum_agent.py:312][0m Update time: 8.80630874633789
[32m[20221124 23:14:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:14:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:14:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:14:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:14:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:14:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:14:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:14:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:14:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:14:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:14:05 @pendulum_agent.py:317][0m Evaluation time: 1.2403020858764648
[32m[20221124 23:14:06 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:14:06 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:14:06 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:14:06 @pendulum_agent.py:289][0m Total time: 6715.346922874451
[32m[20221124 23:14:06 @pendulum_agent.py:291][0m 22000000 total steps have happened
[32m[20221124 23:14:06 @pendulum_agent.py:281][0m #------------------------ Iteration 440 --------------------------#
[32m[20221124 23:14:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.6
[32m[20221124 23:14:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.0
[32m[20221124 23:14:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.0
[32m[20221124 23:14:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.4
[32m[20221124 23:14:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 12.2
[32m[20221124 23:14:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.8
[32m[20221124 23:14:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 14.2
[32m[20221124 23:14:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.6
[32m[20221124 23:14:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.6
[32m[20221124 23:14:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 13.6
[32m[20221124 23:14:10 @pendulum_agent.py:307][0m Sample time: 4.356686115264893
[32m[20221124 23:14:19 @pendulum_agent.py:312][0m Update time: 9.092771053314209
[32m[20221124 23:14:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:14:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:14:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:14:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:14:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:14:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:14:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:14:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:14:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:14:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:14:20 @pendulum_agent.py:317][0m Evaluation time: 0.7455806732177734
[32m[20221124 23:14:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.7
[32m[20221124 23:14:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:14:20 @pendulum_agent.py:289][0m Total time: 6729.85644197464
[32m[20221124 23:14:20 @pendulum_agent.py:291][0m 22050000 total steps have happened
[32m[20221124 23:14:20 @pendulum_agent.py:281][0m #------------------------ Iteration 441 --------------------------#
[32m[20221124 23:14:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:14:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:14:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:14:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:14:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:14:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:14:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:14:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:14:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:14:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:14:25 @pendulum_agent.py:307][0m Sample time: 4.293287992477417
[32m[20221124 23:14:34 @pendulum_agent.py:312][0m Update time: 9.787739753723145
[32m[20221124 23:14:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:14:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:14:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:14:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:14:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:14:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:14:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:14:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:14:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:14:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:14:35 @pendulum_agent.py:317][0m Evaluation time: 0.7463712692260742
[32m[20221124 23:14:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:14:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:14:35 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:14:35 @pendulum_agent.py:289][0m Total time: 6744.983505010605
[32m[20221124 23:14:35 @pendulum_agent.py:291][0m 22100000 total steps have happened
[32m[20221124 23:14:35 @pendulum_agent.py:281][0m #------------------------ Iteration 442 --------------------------#
[32m[20221124 23:14:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:14:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:14:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:14:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:14:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:14:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:14:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:14:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:14:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:14:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:14:39 @pendulum_agent.py:307][0m Sample time: 3.856788158416748
[32m[20221124 23:14:48 @pendulum_agent.py:312][0m Update time: 8.563076734542847
[32m[20221124 23:14:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:14:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:14:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:14:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:14:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:14:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:14:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:14:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:14:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:14:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:14:49 @pendulum_agent.py:317][0m Evaluation time: 0.705916166305542
[32m[20221124 23:14:49 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:14:49 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:14:49 @pendulum_agent.py:289][0m Total time: 6758.386217832565
[32m[20221124 23:14:49 @pendulum_agent.py:291][0m 22150000 total steps have happened
[32m[20221124 23:14:49 @pendulum_agent.py:281][0m #------------------------ Iteration 443 --------------------------#
[32m[20221124 23:14:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:14:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:14:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:14:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:14:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:14:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:14:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:14:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:14:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:14:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:14:53 @pendulum_agent.py:307][0m Sample time: 3.8346590995788574
[32m[20221124 23:15:02 @pendulum_agent.py:312][0m Update time: 9.111301898956299
[32m[20221124 23:15:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:15:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:15:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:15:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:15:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:15:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:15:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:15:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:15:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:15:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:15:02 @pendulum_agent.py:317][0m Evaluation time: 0.5775589942932129
[32m[20221124 23:15:03 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:15:03 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:15:03 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:15:03 @pendulum_agent.py:289][0m Total time: 6772.205896854401
[32m[20221124 23:15:03 @pendulum_agent.py:291][0m 22200000 total steps have happened
[32m[20221124 23:15:03 @pendulum_agent.py:281][0m #------------------------ Iteration 444 --------------------------#
[32m[20221124 23:15:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.4
[32m[20221124 23:15:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.4
[32m[20221124 23:15:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.2
[32m[20221124 23:15:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.0
[32m[20221124 23:15:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.6
[32m[20221124 23:15:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.8
[32m[20221124 23:15:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.0
[32m[20221124 23:15:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.0
[32m[20221124 23:15:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.6
[32m[20221124 23:15:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.2
[32m[20221124 23:15:06 @pendulum_agent.py:307][0m Sample time: 3.7845001220703125
[32m[20221124 23:15:15 @pendulum_agent.py:312][0m Update time: 8.802889823913574
[32m[20221124 23:15:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:15:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:15:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:15:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:15:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:15:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:15:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:15:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:15:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:15:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:15:16 @pendulum_agent.py:317][0m Evaluation time: 0.6991801261901855
[32m[20221124 23:15:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.02
[32m[20221124 23:15:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:15:16 @pendulum_agent.py:289][0m Total time: 6785.78341293335
[32m[20221124 23:15:16 @pendulum_agent.py:291][0m 22250000 total steps have happened
[32m[20221124 23:15:16 @pendulum_agent.py:281][0m #------------------------ Iteration 445 --------------------------#
[32m[20221124 23:15:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:15:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:15:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:15:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:15:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:15:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:15:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:15:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:15:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:15:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:15:20 @pendulum_agent.py:307][0m Sample time: 3.647916793823242
[32m[20221124 23:15:30 @pendulum_agent.py:312][0m Update time: 9.880835056304932
[32m[20221124 23:15:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:15:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:15:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:15:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:15:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:15:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:15:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:15:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:15:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:15:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:15:30 @pendulum_agent.py:317][0m Evaluation time: 0.7145709991455078
[32m[20221124 23:15:31 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:15:31 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:15:31 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:15:31 @pendulum_agent.py:289][0m Total time: 6800.294684171677
[32m[20221124 23:15:31 @pendulum_agent.py:291][0m 22300000 total steps have happened
[32m[20221124 23:15:31 @pendulum_agent.py:281][0m #------------------------ Iteration 446 --------------------------#
[32m[20221124 23:15:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:15:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:15:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:15:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:15:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:15:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:15:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:15:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:15:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:15:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:15:34 @pendulum_agent.py:307][0m Sample time: 3.562450885772705
[32m[20221124 23:15:43 @pendulum_agent.py:312][0m Update time: 8.967034101486206
[32m[20221124 23:15:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:15:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:15:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:15:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:15:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:15:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:15:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:15:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:15:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:15:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:15:44 @pendulum_agent.py:317][0m Evaluation time: 0.8651678562164307
[32m[20221124 23:15:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:15:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:15:44 @pendulum_agent.py:289][0m Total time: 6813.98816204071
[32m[20221124 23:15:44 @pendulum_agent.py:291][0m 22350000 total steps have happened
[32m[20221124 23:15:44 @pendulum_agent.py:281][0m #------------------------ Iteration 447 --------------------------#
[32m[20221124 23:15:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:15:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:15:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:15:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:15:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:15:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:15:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:15:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:15:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:15:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:15:48 @pendulum_agent.py:307][0m Sample time: 3.2960760593414307
[32m[20221124 23:15:58 @pendulum_agent.py:312][0m Update time: 10.167556762695312
[32m[20221124 23:15:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:15:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:15:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:15:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:15:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:15:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:15:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:15:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:15:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:15:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:15:59 @pendulum_agent.py:317][0m Evaluation time: 1.1169962882995605
[32m[20221124 23:15:59 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:15:59 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:15:59 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:15:59 @pendulum_agent.py:289][0m Total time: 6828.889479160309
[32m[20221124 23:15:59 @pendulum_agent.py:291][0m 22400000 total steps have happened
[32m[20221124 23:15:59 @pendulum_agent.py:281][0m #------------------------ Iteration 448 --------------------------#
[32m[20221124 23:16:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:16:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:16:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:16:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.2
[32m[20221124 23:16:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:16:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:16:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:16:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:16:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:16:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:16:03 @pendulum_agent.py:307][0m Sample time: 3.7024929523468018
[32m[20221124 23:16:12 @pendulum_agent.py:312][0m Update time: 9.229856014251709
[32m[20221124 23:16:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:16:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:16:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:16:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:16:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:16:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:16:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:16:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:16:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:16:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:16:13 @pendulum_agent.py:317][0m Evaluation time: 1.0818910598754883
[32m[20221124 23:16:14 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.02
[32m[20221124 23:16:14 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:16:14 @pendulum_agent.py:289][0m Total time: 6843.191561937332
[32m[20221124 23:16:14 @pendulum_agent.py:291][0m 22450000 total steps have happened
[32m[20221124 23:16:14 @pendulum_agent.py:281][0m #------------------------ Iteration 449 --------------------------#
[32m[20221124 23:16:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:16:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:16:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:16:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:16:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:16:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:16:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:16:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:16:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:16:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:16:18 @pendulum_agent.py:307][0m Sample time: 4.072734832763672
[32m[20221124 23:16:27 @pendulum_agent.py:312][0m Update time: 9.188853979110718
[32m[20221124 23:16:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:16:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:16:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:16:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:16:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:16:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:16:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:16:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:16:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:16:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:16:28 @pendulum_agent.py:317][0m Evaluation time: 0.8372330665588379
[32m[20221124 23:16:28 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:16:28 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:16:28 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:16:28 @pendulum_agent.py:289][0m Total time: 6857.606210947037
[32m[20221124 23:16:28 @pendulum_agent.py:291][0m 22500000 total steps have happened
[32m[20221124 23:16:28 @pendulum_agent.py:281][0m #------------------------ Iteration 450 --------------------------#
[32m[20221124 23:16:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:16:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:16:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:16:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:16:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:16:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:16:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:16:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:16:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:16:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:16:32 @pendulum_agent.py:307][0m Sample time: 3.915548801422119
[32m[20221124 23:16:42 @pendulum_agent.py:312][0m Update time: 9.753526210784912
[32m[20221124 23:16:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:16:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:16:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:16:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:16:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:16:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:16:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:16:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:16:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:16:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:16:43 @pendulum_agent.py:317][0m Evaluation time: 1.0066168308258057
[32m[20221124 23:16:43 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:16:43 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:16:43 @pendulum_agent.py:289][0m Total time: 6872.660650014877
[32m[20221124 23:16:43 @pendulum_agent.py:291][0m 22550000 total steps have happened
[32m[20221124 23:16:43 @pendulum_agent.py:281][0m #------------------------ Iteration 451 --------------------------#
[32m[20221124 23:16:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:16:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:16:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:16:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:16:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:16:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:16:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:16:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:16:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:16:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:16:47 @pendulum_agent.py:307][0m Sample time: 4.099500894546509
[32m[20221124 23:16:57 @pendulum_agent.py:312][0m Update time: 10.1893470287323
[32m[20221124 23:16:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:16:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:16:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:16:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:16:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:16:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:16:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:16:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:16:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:16:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:16:58 @pendulum_agent.py:317][0m Evaluation time: 0.5606729984283447
[32m[20221124 23:16:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:16:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:16:58 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:16:58 @pendulum_agent.py:289][0m Total time: 6887.7882668972015
[32m[20221124 23:16:58 @pendulum_agent.py:291][0m 22600000 total steps have happened
[32m[20221124 23:16:58 @pendulum_agent.py:281][0m #------------------------ Iteration 452 --------------------------#
[32m[20221124 23:16:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.8
[32m[20221124 23:16:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 8.6
[32m[20221124 23:16:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 9.6
[32m[20221124 23:16:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 10.4
[32m[20221124 23:16:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 12.2
[32m[20221124 23:16:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 10.6
[32m[20221124 23:16:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 8.6
[32m[20221124 23:16:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 10.4
[32m[20221124 23:16:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.4
[32m[20221124 23:16:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.0
[32m[20221124 23:17:02 @pendulum_agent.py:307][0m Sample time: 3.7012362480163574
[32m[20221124 23:17:11 @pendulum_agent.py:312][0m Update time: 9.303318738937378
[32m[20221124 23:17:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:17:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:17:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:17:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:17:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:17:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:17:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:17:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:17:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:17:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:17:12 @pendulum_agent.py:317][0m Evaluation time: 0.8660640716552734
[32m[20221124 23:17:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 9.06
[32m[20221124 23:17:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:17:12 @pendulum_agent.py:289][0m Total time: 6901.9712109565735
[32m[20221124 23:17:12 @pendulum_agent.py:291][0m 22650000 total steps have happened
[32m[20221124 23:17:12 @pendulum_agent.py:281][0m #------------------------ Iteration 453 --------------------------#
[32m[20221124 23:17:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:17:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:17:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:17:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:17:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:17:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:17:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:17:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:17:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:17:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:17:16 @pendulum_agent.py:307][0m Sample time: 3.7646710872650146
[32m[20221124 23:17:25 @pendulum_agent.py:312][0m Update time: 8.956418991088867
[32m[20221124 23:17:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:17:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:17:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:17:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:17:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:17:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:17:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:17:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:17:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:17:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:17:26 @pendulum_agent.py:317][0m Evaluation time: 1.046792984008789
[32m[20221124 23:17:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:17:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:17:26 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:17:26 @pendulum_agent.py:289][0m Total time: 6916.028964996338
[32m[20221124 23:17:26 @pendulum_agent.py:291][0m 22700000 total steps have happened
[32m[20221124 23:17:26 @pendulum_agent.py:281][0m #------------------------ Iteration 454 --------------------------#
[32m[20221124 23:17:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:17:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:17:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:17:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:17:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:17:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:17:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:17:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:17:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:17:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:17:30 @pendulum_agent.py:307][0m Sample time: 3.6750659942626953
[32m[20221124 23:17:40 @pendulum_agent.py:312][0m Update time: 9.520682096481323
[32m[20221124 23:17:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:17:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:17:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:17:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:17:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:17:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:17:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:17:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:17:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:17:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:17:40 @pendulum_agent.py:317][0m Evaluation time: 0.7227959632873535
[32m[20221124 23:17:41 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:17:41 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:17:41 @pendulum_agent.py:289][0m Total time: 6930.247732877731
[32m[20221124 23:17:41 @pendulum_agent.py:291][0m 22750000 total steps have happened
[32m[20221124 23:17:41 @pendulum_agent.py:281][0m #------------------------ Iteration 455 --------------------------#
[32m[20221124 23:17:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:17:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:17:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:17:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:17:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:17:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:17:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:17:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:17:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:17:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:17:44 @pendulum_agent.py:307][0m Sample time: 3.6656429767608643
[32m[20221124 23:17:54 @pendulum_agent.py:312][0m Update time: 10.078052043914795
[32m[20221124 23:17:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:17:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:17:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:17:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:17:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:17:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:17:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:17:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:17:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:17:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:17:55 @pendulum_agent.py:317][0m Evaluation time: 0.6703312397003174
[32m[20221124 23:17:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:17:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:17:55 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:17:55 @pendulum_agent.py:289][0m Total time: 6944.974915981293
[32m[20221124 23:17:55 @pendulum_agent.py:291][0m 22800000 total steps have happened
[32m[20221124 23:17:55 @pendulum_agent.py:281][0m #------------------------ Iteration 456 --------------------------#
[32m[20221124 23:17:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:17:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:17:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:17:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:17:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:17:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:17:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:17:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:17:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:17:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:18:00 @pendulum_agent.py:307][0m Sample time: 4.2053070068359375
[32m[20221124 23:18:09 @pendulum_agent.py:312][0m Update time: 9.398706912994385
[32m[20221124 23:18:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:18:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:18:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:18:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:18:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:18:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:18:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:18:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:18:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:18:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:18:10 @pendulum_agent.py:317][0m Evaluation time: 0.835576057434082
[32m[20221124 23:18:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:18:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:18:10 @pendulum_agent.py:289][0m Total time: 6959.736088037491
[32m[20221124 23:18:10 @pendulum_agent.py:291][0m 22850000 total steps have happened
[32m[20221124 23:18:10 @pendulum_agent.py:281][0m #------------------------ Iteration 457 --------------------------#
[32m[20221124 23:18:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:18:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:18:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:18:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:18:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:18:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:18:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:18:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:18:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:18:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:18:15 @pendulum_agent.py:307][0m Sample time: 4.442410945892334
[32m[20221124 23:18:23 @pendulum_agent.py:312][0m Update time: 8.923010110855103
[32m[20221124 23:18:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:18:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:18:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:18:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:18:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:18:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:18:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:18:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:18:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:18:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:18:24 @pendulum_agent.py:317][0m Evaluation time: 0.7774641513824463
[32m[20221124 23:18:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:18:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:18:25 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:18:25 @pendulum_agent.py:289][0m Total time: 6974.182065010071
[32m[20221124 23:18:25 @pendulum_agent.py:291][0m 22900000 total steps have happened
[32m[20221124 23:18:25 @pendulum_agent.py:281][0m #------------------------ Iteration 458 --------------------------#
[32m[20221124 23:18:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.8
[32m[20221124 23:18:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 9.0
[32m[20221124 23:18:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.2
[32m[20221124 23:18:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.6
[32m[20221124 23:18:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.6
[32m[20221124 23:18:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.0
[32m[20221124 23:18:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.6
[32m[20221124 23:18:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.4
[32m[20221124 23:18:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 24.2
[32m[20221124 23:18:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.8
[32m[20221124 23:18:28 @pendulum_agent.py:307][0m Sample time: 3.744939088821411
[32m[20221124 23:18:38 @pendulum_agent.py:312][0m Update time: 9.685637950897217
[32m[20221124 23:18:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 69.0
[32m[20221124 23:18:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 69.0
[32m[20221124 23:18:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 69.0
[32m[20221124 23:18:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 69.0
[32m[20221124 23:18:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 69.0
[32m[20221124 23:18:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 69.0
[32m[20221124 23:18:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 69.0
[32m[20221124 23:18:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 69.0
[32m[20221124 23:18:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 69.0
[32m[20221124 23:18:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 69.0
[32m[20221124 23:18:39 @pendulum_agent.py:317][0m Evaluation time: 1.0185918807983398
[32m[20221124 23:18:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 8.02
[32m[20221124 23:18:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:18:39 @pendulum_agent.py:289][0m Total time: 6988.952100992203
[32m[20221124 23:18:39 @pendulum_agent.py:291][0m 22950000 total steps have happened
[32m[20221124 23:18:39 @pendulum_agent.py:281][0m #------------------------ Iteration 459 --------------------------#
[32m[20221124 23:18:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:18:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:18:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:18:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:18:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:18:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:18:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:18:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:18:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:18:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:18:43 @pendulum_agent.py:307][0m Sample time: 3.919611692428589
[32m[20221124 23:18:53 @pendulum_agent.py:312][0m Update time: 9.403526306152344
[32m[20221124 23:18:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:18:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:18:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:18:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:18:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:18:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:18:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:18:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:18:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:18:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:18:53 @pendulum_agent.py:317][0m Evaluation time: 0.7524328231811523
[32m[20221124 23:18:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:18:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:18:54 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:18:54 @pendulum_agent.py:289][0m Total time: 7003.334041118622
[32m[20221124 23:18:54 @pendulum_agent.py:291][0m 23000000 total steps have happened
[32m[20221124 23:18:54 @pendulum_agent.py:281][0m #------------------------ Iteration 460 --------------------------#
[32m[20221124 23:18:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:18:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:18:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:18:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:18:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:18:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:18:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:18:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:18:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:18:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:18:58 @pendulum_agent.py:307][0m Sample time: 3.8724679946899414
[32m[20221124 23:19:08 @pendulum_agent.py:312][0m Update time: 9.918674945831299
[32m[20221124 23:19:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:19:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:19:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:19:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:19:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:19:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:19:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:19:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:19:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:19:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:19:08 @pendulum_agent.py:317][0m Evaluation time: 0.7239542007446289
[32m[20221124 23:19:09 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:19:09 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:19:09 @pendulum_agent.py:289][0m Total time: 7018.151711940765
[32m[20221124 23:19:09 @pendulum_agent.py:291][0m 23050000 total steps have happened
[32m[20221124 23:19:09 @pendulum_agent.py:281][0m #------------------------ Iteration 461 --------------------------#
[32m[20221124 23:19:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:19:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:19:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:19:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:19:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:19:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:19:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:19:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:19:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:19:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:19:12 @pendulum_agent.py:307][0m Sample time: 3.505405902862549
[32m[20221124 23:19:21 @pendulum_agent.py:312][0m Update time: 8.98411226272583
[32m[20221124 23:19:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:19:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:19:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:19:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:19:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:19:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:19:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:19:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:19:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:19:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:19:22 @pendulum_agent.py:317][0m Evaluation time: 1.0017669200897217
[32m[20221124 23:19:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:19:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:19:22 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:19:22 @pendulum_agent.py:289][0m Total time: 7031.941066026688
[32m[20221124 23:19:22 @pendulum_agent.py:291][0m 23100000 total steps have happened
[32m[20221124 23:19:22 @pendulum_agent.py:281][0m #------------------------ Iteration 462 --------------------------#
[32m[20221124 23:19:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:19:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:19:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:19:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:19:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:19:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:19:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:19:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:19:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:19:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:19:26 @pendulum_agent.py:307][0m Sample time: 3.438260078430176
[32m[20221124 23:19:35 @pendulum_agent.py:312][0m Update time: 9.404668092727661
[32m[20221124 23:19:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:19:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:19:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:19:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:19:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:19:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:19:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:19:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:19:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:19:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:19:37 @pendulum_agent.py:317][0m Evaluation time: 1.965641975402832
[32m[20221124 23:19:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:19:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:19:38 @pendulum_agent.py:289][0m Total time: 7047.109371185303
[32m[20221124 23:19:38 @pendulum_agent.py:291][0m 23150000 total steps have happened
[32m[20221124 23:19:38 @pendulum_agent.py:281][0m #------------------------ Iteration 463 --------------------------#
[32m[20221124 23:19:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:19:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:19:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:19:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:19:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:19:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:19:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:19:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:19:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:19:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:19:41 @pendulum_agent.py:307][0m Sample time: 3.91300892829895
[32m[20221124 23:19:51 @pendulum_agent.py:312][0m Update time: 9.139345169067383
[32m[20221124 23:19:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:19:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:19:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:19:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:19:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:19:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:19:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:19:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:19:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:19:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:19:51 @pendulum_agent.py:317][0m Evaluation time: 0.7361438274383545
[32m[20221124 23:19:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:19:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:19:52 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:19:52 @pendulum_agent.py:289][0m Total time: 7061.190289020538
[32m[20221124 23:19:52 @pendulum_agent.py:291][0m 23200000 total steps have happened
[32m[20221124 23:19:52 @pendulum_agent.py:281][0m #------------------------ Iteration 464 --------------------------#
[32m[20221124 23:19:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:19:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:19:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:19:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:19:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:19:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:19:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:19:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:19:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:19:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:19:55 @pendulum_agent.py:307][0m Sample time: 3.7705390453338623
[32m[20221124 23:20:05 @pendulum_agent.py:312][0m Update time: 9.523276805877686
[32m[20221124 23:20:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:20:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:20:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:20:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:20:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:20:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:20:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:20:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:20:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:20:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:20:06 @pendulum_agent.py:317][0m Evaluation time: 0.7688860893249512
[32m[20221124 23:20:06 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:20:06 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:20:06 @pendulum_agent.py:289][0m Total time: 7075.560620069504
[32m[20221124 23:20:06 @pendulum_agent.py:291][0m 23250000 total steps have happened
[32m[20221124 23:20:06 @pendulum_agent.py:281][0m #------------------------ Iteration 465 --------------------------#
[32m[20221124 23:20:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:20:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:20:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:20:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:20:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:20:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:20:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:20:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:20:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:20:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:20:10 @pendulum_agent.py:307][0m Sample time: 3.9529919624328613
[32m[20221124 23:20:20 @pendulum_agent.py:312][0m Update time: 10.018870115280151
[32m[20221124 23:20:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:20:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:20:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:20:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:20:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:20:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:20:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:20:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:20:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:20:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:20:21 @pendulum_agent.py:317][0m Evaluation time: 0.7372257709503174
[32m[20221124 23:20:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:20:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:20:21 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:20:21 @pendulum_agent.py:289][0m Total time: 7090.548298835754
[32m[20221124 23:20:21 @pendulum_agent.py:291][0m 23300000 total steps have happened
[32m[20221124 23:20:21 @pendulum_agent.py:281][0m #------------------------ Iteration 466 --------------------------#
[32m[20221124 23:20:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:20:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:20:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:20:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:20:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:20:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:20:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:20:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:20:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:20:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:20:25 @pendulum_agent.py:307][0m Sample time: 3.6833739280700684
[32m[20221124 23:20:34 @pendulum_agent.py:312][0m Update time: 9.621461153030396
[32m[20221124 23:20:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:20:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:20:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:20:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:20:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:20:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:20:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:20:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:20:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:20:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:20:35 @pendulum_agent.py:317][0m Evaluation time: 0.9153499603271484
[32m[20221124 23:20:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:20:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:20:35 @pendulum_agent.py:289][0m Total time: 7105.066623926163
[32m[20221124 23:20:35 @pendulum_agent.py:291][0m 23350000 total steps have happened
[32m[20221124 23:20:35 @pendulum_agent.py:281][0m #------------------------ Iteration 467 --------------------------#
[32m[20221124 23:20:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.6
[32m[20221124 23:20:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 11.2
[32m[20221124 23:20:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 10.8
[32m[20221124 23:20:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.4
[32m[20221124 23:20:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 10.4
[32m[20221124 23:20:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.6
[32m[20221124 23:20:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.0
[32m[20221124 23:20:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 10.2
[32m[20221124 23:20:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.8
[32m[20221124 23:20:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 14.4
[32m[20221124 23:20:39 @pendulum_agent.py:307][0m Sample time: 3.9624671936035156
[32m[20221124 23:20:49 @pendulum_agent.py:312][0m Update time: 9.316704988479614
[32m[20221124 23:20:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:20:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:20:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:20:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:20:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:20:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:20:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:20:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:20:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:20:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:20:50 @pendulum_agent.py:317][0m Evaluation time: 0.8170430660247803
[32m[20221124 23:20:50 @pendulum_agent.py:285][0m Average TRAINING episode reward: 8.34
[32m[20221124 23:20:50 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:20:50 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:20:50 @pendulum_agent.py:289][0m Total time: 7119.4770720005035
[32m[20221124 23:20:50 @pendulum_agent.py:291][0m 23400000 total steps have happened
[32m[20221124 23:20:50 @pendulum_agent.py:281][0m #------------------------ Iteration 468 --------------------------#
[32m[20221124 23:20:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:20:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:20:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:20:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:20:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:20:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:20:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:20:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:20:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:20:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:20:54 @pendulum_agent.py:307][0m Sample time: 4.552877902984619
[32m[20221124 23:21:04 @pendulum_agent.py:312][0m Update time: 9.553354024887085
[32m[20221124 23:21:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:21:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:21:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:21:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:21:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:21:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:21:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:21:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:21:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:21:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:21:05 @pendulum_agent.py:317][0m Evaluation time: 0.8146259784698486
[32m[20221124 23:21:05 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:21:05 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:21:05 @pendulum_agent.py:289][0m Total time: 7134.712607860565
[32m[20221124 23:21:05 @pendulum_agent.py:291][0m 23450000 total steps have happened
[32m[20221124 23:21:05 @pendulum_agent.py:281][0m #------------------------ Iteration 469 --------------------------#
[32m[20221124 23:21:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:21:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:21:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:21:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:21:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:21:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:21:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:21:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:21:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:21:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:21:09 @pendulum_agent.py:307][0m Sample time: 3.6941120624542236
[32m[20221124 23:21:18 @pendulum_agent.py:312][0m Update time: 9.439512014389038
[32m[20221124 23:21:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:21:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:21:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:21:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:21:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:21:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:21:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:21:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:21:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:21:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:21:19 @pendulum_agent.py:317][0m Evaluation time: 0.704387903213501
[32m[20221124 23:21:19 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:21:19 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:21:19 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:21:19 @pendulum_agent.py:289][0m Total time: 7148.815008878708
[32m[20221124 23:21:19 @pendulum_agent.py:291][0m 23500000 total steps have happened
[32m[20221124 23:21:19 @pendulum_agent.py:281][0m #------------------------ Iteration 470 --------------------------#
[32m[20221124 23:21:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.8
[32m[20221124 23:21:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.2
[32m[20221124 23:21:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.6
[32m[20221124 23:21:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.6
[32m[20221124 23:21:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.4
[32m[20221124 23:21:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.0
[32m[20221124 23:21:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.2
[32m[20221124 23:21:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.2
[32m[20221124 23:21:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.0
[32m[20221124 23:21:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.6
[32m[20221124 23:21:23 @pendulum_agent.py:307][0m Sample time: 3.487323045730591
[32m[20221124 23:21:33 @pendulum_agent.py:312][0m Update time: 9.804707050323486
[32m[20221124 23:21:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:21:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:21:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:21:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:21:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:21:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:21:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:21:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:21:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:21:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:21:33 @pendulum_agent.py:317][0m Evaluation time: 0.8563168048858643
[32m[20221124 23:21:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.36
[32m[20221124 23:21:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:21:34 @pendulum_agent.py:289][0m Total time: 7163.254832029343
[32m[20221124 23:21:34 @pendulum_agent.py:291][0m 23550000 total steps have happened
[32m[20221124 23:21:34 @pendulum_agent.py:281][0m #------------------------ Iteration 471 --------------------------#
[32m[20221124 23:21:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:21:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:21:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:21:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:21:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:21:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:21:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:21:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:21:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:21:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:21:37 @pendulum_agent.py:307][0m Sample time: 3.5165889263153076
[32m[20221124 23:21:47 @pendulum_agent.py:312][0m Update time: 10.03709626197815
[32m[20221124 23:21:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:21:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:21:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:21:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:21:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:21:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:21:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:21:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:21:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:21:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:21:48 @pendulum_agent.py:317][0m Evaluation time: 1.045747995376587
[32m[20221124 23:21:49 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:21:49 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:21:49 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:21:49 @pendulum_agent.py:289][0m Total time: 7178.139046192169
[32m[20221124 23:21:49 @pendulum_agent.py:291][0m 23600000 total steps have happened
[32m[20221124 23:21:49 @pendulum_agent.py:281][0m #------------------------ Iteration 472 --------------------------#
[32m[20221124 23:21:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:21:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:21:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:21:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:21:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:21:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:21:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:21:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:21:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:21:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:21:52 @pendulum_agent.py:307][0m Sample time: 3.4810619354248047
[32m[20221124 23:22:01 @pendulum_agent.py:312][0m Update time: 8.86206603050232
[32m[20221124 23:22:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:22:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:22:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:22:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:22:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:22:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:22:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:22:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:22:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:22:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:22:02 @pendulum_agent.py:317][0m Evaluation time: 1.1586120128631592
[32m[20221124 23:22:02 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:22:02 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:22:02 @pendulum_agent.py:289][0m Total time: 7191.902117967606
[32m[20221124 23:22:02 @pendulum_agent.py:291][0m 23650000 total steps have happened
[32m[20221124 23:22:02 @pendulum_agent.py:281][0m #------------------------ Iteration 473 --------------------------#
[32m[20221124 23:22:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:22:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:22:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:22:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:22:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:22:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:22:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:22:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:22:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:22:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:22:06 @pendulum_agent.py:307][0m Sample time: 3.374748945236206
[32m[20221124 23:22:14 @pendulum_agent.py:312][0m Update time: 8.709069013595581
[32m[20221124 23:22:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:22:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:22:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:22:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:22:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:22:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:22:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:22:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:22:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:22:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:22:16 @pendulum_agent.py:317][0m Evaluation time: 1.8713312149047852
[32m[20221124 23:22:17 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:22:17 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:22:17 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:22:17 @pendulum_agent.py:289][0m Total time: 7206.149886846542
[32m[20221124 23:22:17 @pendulum_agent.py:291][0m 23700000 total steps have happened
[32m[20221124 23:22:17 @pendulum_agent.py:281][0m #------------------------ Iteration 474 --------------------------#
[32m[20221124 23:22:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 12.8
[32m[20221124 23:22:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.8
[32m[20221124 23:22:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 15.2
[32m[20221124 23:22:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 13.4
[32m[20221124 23:22:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.6
[32m[20221124 23:22:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 16.4
[32m[20221124 23:22:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 12.2
[32m[20221124 23:22:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 15.6
[32m[20221124 23:22:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 15.4
[32m[20221124 23:22:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 11.6
[32m[20221124 23:22:20 @pendulum_agent.py:307][0m Sample time: 3.514794111251831
[32m[20221124 23:22:29 @pendulum_agent.py:312][0m Update time: 9.227212905883789
[32m[20221124 23:22:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:22:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:22:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:22:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:22:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:22:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:22:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:22:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:22:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:22:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:22:30 @pendulum_agent.py:317][0m Evaluation time: 0.6994740962982178
[32m[20221124 23:22:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 12.9
[32m[20221124 23:22:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:22:30 @pendulum_agent.py:289][0m Total time: 7219.86755490303
[32m[20221124 23:22:30 @pendulum_agent.py:291][0m 23750000 total steps have happened
[32m[20221124 23:22:30 @pendulum_agent.py:281][0m #------------------------ Iteration 475 --------------------------#
[32m[20221124 23:22:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:22:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:22:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:22:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:22:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:22:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:22:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:22:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:22:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:22:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:22:34 @pendulum_agent.py:307][0m Sample time: 3.666606903076172
[32m[20221124 23:22:43 @pendulum_agent.py:312][0m Update time: 8.938704013824463
[32m[20221124 23:22:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:22:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:22:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:22:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:22:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:22:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:22:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:22:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:22:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:22:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:22:44 @pendulum_agent.py:317][0m Evaluation time: 0.9343729019165039
[32m[20221124 23:22:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:22:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:22:44 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:22:44 @pendulum_agent.py:289][0m Total time: 7233.670649051666
[32m[20221124 23:22:44 @pendulum_agent.py:291][0m 23800000 total steps have happened
[32m[20221124 23:22:44 @pendulum_agent.py:281][0m #------------------------ Iteration 476 --------------------------#
[32m[20221124 23:22:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:22:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:22:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:22:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:22:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:22:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:22:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:22:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:22:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:22:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:22:48 @pendulum_agent.py:307][0m Sample time: 3.894301176071167
[32m[20221124 23:22:57 @pendulum_agent.py:312][0m Update time: 9.139349937438965
[32m[20221124 23:22:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:22:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:22:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:22:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:22:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:22:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:22:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:22:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:22:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:22:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:22:58 @pendulum_agent.py:317][0m Evaluation time: 0.973984956741333
[32m[20221124 23:22:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:22:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:22:58 @pendulum_agent.py:289][0m Total time: 7247.9851150512695
[32m[20221124 23:22:58 @pendulum_agent.py:291][0m 23850000 total steps have happened
[32m[20221124 23:22:58 @pendulum_agent.py:281][0m #------------------------ Iteration 477 --------------------------#
[32m[20221124 23:22:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:22:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:22:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:22:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:22:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:22:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:22:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:22:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:22:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:22:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:23:02 @pendulum_agent.py:307][0m Sample time: 3.910125732421875
[32m[20221124 23:23:12 @pendulum_agent.py:312][0m Update time: 9.336758136749268
[32m[20221124 23:23:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:23:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:23:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:23:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:23:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:23:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:23:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:23:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:23:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:23:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:23:12 @pendulum_agent.py:317][0m Evaluation time: 0.7065410614013672
[32m[20221124 23:23:13 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:23:13 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:23:13 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:23:13 @pendulum_agent.py:289][0m Total time: 7262.224231958389
[32m[20221124 23:23:13 @pendulum_agent.py:291][0m 23900000 total steps have happened
[32m[20221124 23:23:13 @pendulum_agent.py:281][0m #------------------------ Iteration 478 --------------------------#
[32m[20221124 23:23:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:23:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:23:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:23:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:23:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:23:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:23:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:23:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:23:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:23:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:23:16 @pendulum_agent.py:307][0m Sample time: 3.526514768600464
[32m[20221124 23:23:25 @pendulum_agent.py:312][0m Update time: 9.015727281570435
[32m[20221124 23:23:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:23:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:23:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:23:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:23:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:23:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:23:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:23:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:23:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:23:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:23:26 @pendulum_agent.py:317][0m Evaluation time: 0.5800669193267822
[32m[20221124 23:23:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:23:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:23:26 @pendulum_agent.py:289][0m Total time: 7275.621825933456
[32m[20221124 23:23:26 @pendulum_agent.py:291][0m 23950000 total steps have happened
[32m[20221124 23:23:26 @pendulum_agent.py:281][0m #------------------------ Iteration 479 --------------------------#
[32m[20221124 23:23:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:23:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:23:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:23:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:23:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:23:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:23:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:23:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:23:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:23:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:23:30 @pendulum_agent.py:307][0m Sample time: 3.7621047496795654
[32m[20221124 23:23:39 @pendulum_agent.py:312][0m Update time: 9.052479028701782
[32m[20221124 23:23:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:23:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:23:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:23:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:23:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:23:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:23:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:23:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:23:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:23:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:23:39 @pendulum_agent.py:317][0m Evaluation time: 0.5711750984191895
[32m[20221124 23:23:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:23:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:23:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:23:40 @pendulum_agent.py:289][0m Total time: 7289.309720039368
[32m[20221124 23:23:40 @pendulum_agent.py:291][0m 24000000 total steps have happened
[32m[20221124 23:23:40 @pendulum_agent.py:281][0m #------------------------ Iteration 480 --------------------------#
[32m[20221124 23:23:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 8.4
[32m[20221124 23:23:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.2
[32m[20221124 23:23:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 7.6
[32m[20221124 23:23:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.6
[32m[20221124 23:23:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.2
[32m[20221124 23:23:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.2
[32m[20221124 23:23:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.8
[32m[20221124 23:23:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.2
[32m[20221124 23:23:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 7.8
[32m[20221124 23:23:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.2
[32m[20221124 23:23:43 @pendulum_agent.py:307][0m Sample time: 3.6952037811279297
[32m[20221124 23:23:53 @pendulum_agent.py:312][0m Update time: 9.252785205841064
[32m[20221124 23:23:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:23:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:23:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:23:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:23:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:23:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:23:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:23:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:23:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:23:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:23:53 @pendulum_agent.py:317][0m Evaluation time: 0.5730147361755371
[32m[20221124 23:23:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.82
[32m[20221124 23:23:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:23:54 @pendulum_agent.py:289][0m Total time: 7303.127936840057
[32m[20221124 23:23:54 @pendulum_agent.py:291][0m 24050000 total steps have happened
[32m[20221124 23:23:54 @pendulum_agent.py:281][0m #------------------------ Iteration 481 --------------------------#
[32m[20221124 23:23:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:23:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:23:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:23:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:23:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:23:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:23:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:23:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:23:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:23:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:23:57 @pendulum_agent.py:307][0m Sample time: 3.8539557456970215
[32m[20221124 23:24:07 @pendulum_agent.py:312][0m Update time: 9.520401239395142
[32m[20221124 23:24:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:24:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:24:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:24:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:24:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:24:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:24:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:24:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:24:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:24:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:24:08 @pendulum_agent.py:317][0m Evaluation time: 0.683319091796875
[32m[20221124 23:24:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:24:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:24:08 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:24:08 @pendulum_agent.py:289][0m Total time: 7317.477178096771
[32m[20221124 23:24:08 @pendulum_agent.py:291][0m 24100000 total steps have happened
[32m[20221124 23:24:08 @pendulum_agent.py:281][0m #------------------------ Iteration 482 --------------------------#
[32m[20221124 23:24:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:24:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:24:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:24:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:24:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:24:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:24:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:24:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:24:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:24:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:24:11 @pendulum_agent.py:307][0m Sample time: 3.5314128398895264
[32m[20221124 23:24:20 @pendulum_agent.py:312][0m Update time: 8.8738431930542
[32m[20221124 23:24:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:24:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:24:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:24:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:24:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:24:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:24:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:24:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:24:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:24:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:24:21 @pendulum_agent.py:317][0m Evaluation time: 0.8178319931030273
[32m[20221124 23:24:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:24:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:24:21 @pendulum_agent.py:289][0m Total time: 7330.994985818863
[32m[20221124 23:24:21 @pendulum_agent.py:291][0m 24150000 total steps have happened
[32m[20221124 23:24:21 @pendulum_agent.py:281][0m #------------------------ Iteration 483 --------------------------#
[32m[20221124 23:24:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:24:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:24:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:24:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:24:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:24:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:24:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:24:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:24:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:24:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:24:25 @pendulum_agent.py:307][0m Sample time: 3.2685389518737793
[32m[20221124 23:24:34 @pendulum_agent.py:312][0m Update time: 8.908569097518921
[32m[20221124 23:24:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:24:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:24:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:24:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:24:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:24:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:24:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:24:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:24:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:24:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:24:35 @pendulum_agent.py:317][0m Evaluation time: 1.025669813156128
[32m[20221124 23:24:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:24:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:24:35 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:24:35 @pendulum_agent.py:289][0m Total time: 7344.463590145111
[32m[20221124 23:24:35 @pendulum_agent.py:291][0m 24200000 total steps have happened
[32m[20221124 23:24:35 @pendulum_agent.py:281][0m #------------------------ Iteration 484 --------------------------#
[32m[20221124 23:24:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:24:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:24:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:24:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:24:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:24:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:24:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:24:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:24:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:24:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:24:38 @pendulum_agent.py:307][0m Sample time: 3.5348410606384277
[32m[20221124 23:24:47 @pendulum_agent.py:312][0m Update time: 8.66235089302063
[32m[20221124 23:24:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:24:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:24:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:24:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:24:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:24:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:24:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:24:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:24:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:24:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:24:48 @pendulum_agent.py:317][0m Evaluation time: 1.1735188961029053
[32m[20221124 23:24:49 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:24:49 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:24:49 @pendulum_agent.py:289][0m Total time: 7358.110180139542
[32m[20221124 23:24:49 @pendulum_agent.py:291][0m 24250000 total steps have happened
[32m[20221124 23:24:49 @pendulum_agent.py:281][0m #------------------------ Iteration 485 --------------------------#
[32m[20221124 23:24:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:24:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:24:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:24:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:24:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:24:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:24:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:24:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:24:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:24:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:24:52 @pendulum_agent.py:307][0m Sample time: 3.344412088394165
[32m[20221124 23:25:08 @pendulum_agent.py:312][0m Update time: 15.803834676742554
[32m[20221124 23:25:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:25:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:25:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:25:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:25:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:25:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:25:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:25:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:25:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:25:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:25:09 @pendulum_agent.py:317][0m Evaluation time: 1.156562328338623
[32m[20221124 23:25:09 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:25:09 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:25:09 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:25:09 @pendulum_agent.py:289][0m Total time: 7378.686174869537
[32m[20221124 23:25:09 @pendulum_agent.py:291][0m 24300000 total steps have happened
[32m[20221124 23:25:09 @pendulum_agent.py:281][0m #------------------------ Iteration 486 --------------------------#
[32m[20221124 23:25:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:25:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:25:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:25:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:25:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:25:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:25:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:25:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:25:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:25:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:25:13 @pendulum_agent.py:307][0m Sample time: 3.6086971759796143
[32m[20221124 23:25:22 @pendulum_agent.py:312][0m Update time: 9.338636636734009
[32m[20221124 23:25:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 19.0
[32m[20221124 23:25:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 19.0
[32m[20221124 23:25:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 19.0
[32m[20221124 23:25:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 19.0
[32m[20221124 23:25:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 19.0
[32m[20221124 23:25:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 19.0
[32m[20221124 23:25:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 19.0
[32m[20221124 23:25:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 19.0
[32m[20221124 23:25:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 19.0
[32m[20221124 23:25:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 19.0
[32m[20221124 23:25:23 @pendulum_agent.py:317][0m Evaluation time: 0.7635781764984131
[32m[20221124 23:25:23 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:25:23 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:25:23 @pendulum_agent.py:289][0m Total time: 7392.728953123093
[32m[20221124 23:25:23 @pendulum_agent.py:291][0m 24350000 total steps have happened
[32m[20221124 23:25:23 @pendulum_agent.py:281][0m #------------------------ Iteration 487 --------------------------#
[32m[20221124 23:25:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:25:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:25:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:25:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:25:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:25:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:25:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:25:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:25:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:25:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:25:27 @pendulum_agent.py:307][0m Sample time: 3.8181569576263428
[32m[20221124 23:25:36 @pendulum_agent.py:312][0m Update time: 9.294334888458252
[32m[20221124 23:25:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:25:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:25:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:25:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:25:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:25:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:25:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:25:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:25:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:25:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:25:37 @pendulum_agent.py:317][0m Evaluation time: 0.7289469242095947
[32m[20221124 23:25:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:25:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:25:37 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:25:37 @pendulum_agent.py:289][0m Total time: 7406.826331138611
[32m[20221124 23:25:37 @pendulum_agent.py:291][0m 24400000 total steps have happened
[32m[20221124 23:25:37 @pendulum_agent.py:281][0m #------------------------ Iteration 488 --------------------------#
[32m[20221124 23:25:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:25:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:25:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:25:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:25:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:25:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:25:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:25:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:25:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:25:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:25:41 @pendulum_agent.py:307][0m Sample time: 3.4847590923309326
[32m[20221124 23:25:49 @pendulum_agent.py:312][0m Update time: 8.735636949539185
[32m[20221124 23:25:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:25:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:25:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:25:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:25:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:25:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:25:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:25:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:25:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:25:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:25:50 @pendulum_agent.py:317][0m Evaluation time: 0.7008559703826904
[32m[20221124 23:25:50 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:25:50 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:25:50 @pendulum_agent.py:289][0m Total time: 7420.025217056274
[32m[20221124 23:25:50 @pendulum_agent.py:291][0m 24450000 total steps have happened
[32m[20221124 23:25:50 @pendulum_agent.py:281][0m #------------------------ Iteration 489 --------------------------#
[32m[20221124 23:25:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:25:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:25:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:25:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:25:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:25:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:25:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:25:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:25:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:25:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:25:54 @pendulum_agent.py:307][0m Sample time: 3.8345208168029785
[32m[20221124 23:26:03 @pendulum_agent.py:312][0m Update time: 9.001824855804443
[32m[20221124 23:26:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:26:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:26:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:26:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:26:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:26:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:26:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:26:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:26:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:26:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:26:04 @pendulum_agent.py:317][0m Evaluation time: 0.5710201263427734
[32m[20221124 23:26:04 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:26:04 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:26:04 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:26:04 @pendulum_agent.py:289][0m Total time: 7433.728641033173
[32m[20221124 23:26:04 @pendulum_agent.py:291][0m 24500000 total steps have happened
[32m[20221124 23:26:04 @pendulum_agent.py:281][0m #------------------------ Iteration 490 --------------------------#
[32m[20221124 23:26:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:26:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:26:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:26:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:26:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:26:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:26:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:26:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:26:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:26:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:26:08 @pendulum_agent.py:307][0m Sample time: 3.721345901489258
[32m[20221124 23:26:17 @pendulum_agent.py:312][0m Update time: 8.812900066375732
[32m[20221124 23:26:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:26:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:26:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:26:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:26:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:26:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:26:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:26:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:26:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:26:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:26:17 @pendulum_agent.py:317][0m Evaluation time: 0.699531078338623
[32m[20221124 23:26:18 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:26:18 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:26:18 @pendulum_agent.py:289][0m Total time: 7447.238265037537
[32m[20221124 23:26:18 @pendulum_agent.py:291][0m 24550000 total steps have happened
[32m[20221124 23:26:18 @pendulum_agent.py:281][0m #------------------------ Iteration 491 --------------------------#
[32m[20221124 23:26:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.8
[32m[20221124 23:26:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 13.8
[32m[20221124 23:26:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.6
[32m[20221124 23:26:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 8.4
[32m[20221124 23:26:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.0
[32m[20221124 23:26:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.2
[32m[20221124 23:26:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.6
[32m[20221124 23:26:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.6
[32m[20221124 23:26:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 9.8
[32m[20221124 23:26:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.4
[32m[20221124 23:26:21 @pendulum_agent.py:307][0m Sample time: 3.5758800506591797
[32m[20221124 23:26:30 @pendulum_agent.py:312][0m Update time: 9.092439889907837
[32m[20221124 23:26:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 11.0
[32m[20221124 23:26:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 11.0
[32m[20221124 23:26:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 11.0
[32m[20221124 23:26:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 11.0
[32m[20221124 23:26:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 11.0
[32m[20221124 23:26:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 11.0
[32m[20221124 23:26:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 11.0
[32m[20221124 23:26:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 11.0
[32m[20221124 23:26:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 11.0
[32m[20221124 23:26:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 11.0
[32m[20221124 23:26:31 @pendulum_agent.py:317][0m Evaluation time: 0.6951198577880859
[32m[20221124 23:26:31 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.52
[32m[20221124 23:26:31 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:26:31 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:26:31 @pendulum_agent.py:289][0m Total time: 7460.870677947998
[32m[20221124 23:26:31 @pendulum_agent.py:291][0m 24600000 total steps have happened
[32m[20221124 23:26:31 @pendulum_agent.py:281][0m #------------------------ Iteration 492 --------------------------#
[32m[20221124 23:26:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:26:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:26:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:26:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:26:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:26:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:26:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:26:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:26:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:26:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:26:35 @pendulum_agent.py:307][0m Sample time: 3.565833330154419
[32m[20221124 23:26:44 @pendulum_agent.py:312][0m Update time: 8.949444770812988
[32m[20221124 23:26:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:26:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:26:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:26:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:26:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:26:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:26:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:26:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:26:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:26:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:26:45 @pendulum_agent.py:317][0m Evaluation time: 0.84617018699646
[32m[20221124 23:26:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:26:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:26:45 @pendulum_agent.py:289][0m Total time: 7474.507335186005
[32m[20221124 23:26:45 @pendulum_agent.py:291][0m 24650000 total steps have happened
[32m[20221124 23:26:45 @pendulum_agent.py:281][0m #------------------------ Iteration 493 --------------------------#
[32m[20221124 23:26:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.0
[32m[20221124 23:26:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 18.4
[32m[20221124 23:26:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 19.2
[32m[20221124 23:26:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 9.8
[32m[20221124 23:26:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 15.0
[32m[20221124 23:26:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 10.6
[32m[20221124 23:26:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 21.2
[32m[20221124 23:26:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 8.2
[32m[20221124 23:26:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 9.2
[32m[20221124 23:26:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 18.2
[32m[20221124 23:26:48 @pendulum_agent.py:307][0m Sample time: 3.3295059204101562
[32m[20221124 23:26:59 @pendulum_agent.py:312][0m Update time: 10.643370151519775
[32m[20221124 23:26:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:26:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:26:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:26:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:26:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:26:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:26:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:26:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:26:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:26:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:27:00 @pendulum_agent.py:317][0m Evaluation time: 1.0647709369659424
[32m[20221124 23:27:00 @pendulum_agent.py:285][0m Average TRAINING episode reward: 13.28
[32m[20221124 23:27:00 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:27:00 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:27:00 @pendulum_agent.py:289][0m Total time: 7489.819650888443
[32m[20221124 23:27:00 @pendulum_agent.py:291][0m 24700000 total steps have happened
[32m[20221124 23:27:00 @pendulum_agent.py:281][0m #------------------------ Iteration 494 --------------------------#
[32m[20221124 23:27:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:27:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:27:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:27:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:27:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:27:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:27:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:27:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:27:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:27:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:27:03 @pendulum_agent.py:307][0m Sample time: 3.217164993286133
[32m[20221124 23:27:13 @pendulum_agent.py:312][0m Update time: 9.232775926589966
[32m[20221124 23:27:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:27:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:27:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:27:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:27:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:27:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:27:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:27:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:27:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:27:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:27:14 @pendulum_agent.py:317][0m Evaluation time: 1.039499044418335
[32m[20221124 23:27:14 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:27:14 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:27:14 @pendulum_agent.py:289][0m Total time: 7503.586341142654
[32m[20221124 23:27:14 @pendulum_agent.py:291][0m 24750000 total steps have happened
[32m[20221124 23:27:14 @pendulum_agent.py:281][0m #------------------------ Iteration 495 --------------------------#
[32m[20221124 23:27:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:27:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:27:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:27:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:27:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:27:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:27:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:27:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:27:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:27:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:27:18 @pendulum_agent.py:307][0m Sample time: 3.6948258876800537
[32m[20221124 23:27:27 @pendulum_agent.py:312][0m Update time: 9.798679113388062
[32m[20221124 23:27:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:27:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:27:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:27:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:27:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:27:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:27:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:27:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:27:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:27:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:27:28 @pendulum_agent.py:317][0m Evaluation time: 0.7229909896850586
[32m[20221124 23:27:28 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:27:28 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:27:28 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:27:28 @pendulum_agent.py:289][0m Total time: 7518.080353021622
[32m[20221124 23:27:28 @pendulum_agent.py:291][0m 24800000 total steps have happened
[32m[20221124 23:27:28 @pendulum_agent.py:281][0m #------------------------ Iteration 496 --------------------------#
[32m[20221124 23:27:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:27:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:27:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:27:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:27:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:27:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:27:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:27:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:27:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:27:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:27:32 @pendulum_agent.py:307][0m Sample time: 3.6251909732818604
[32m[20221124 23:27:41 @pendulum_agent.py:312][0m Update time: 9.023431062698364
[32m[20221124 23:27:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:27:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:27:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:27:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:27:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:27:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:27:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:27:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:27:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:27:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:27:42 @pendulum_agent.py:317][0m Evaluation time: 0.7228190898895264
[32m[20221124 23:27:42 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:27:42 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:27:42 @pendulum_agent.py:289][0m Total time: 7531.732371807098
[32m[20221124 23:27:42 @pendulum_agent.py:291][0m 24850000 total steps have happened
[32m[20221124 23:27:42 @pendulum_agent.py:281][0m #------------------------ Iteration 497 --------------------------#
[32m[20221124 23:27:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:27:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:27:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:27:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:27:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:27:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:27:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:27:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:27:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:27:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:27:46 @pendulum_agent.py:307][0m Sample time: 3.8305482864379883
[32m[20221124 23:27:56 @pendulum_agent.py:312][0m Update time: 9.67777681350708
[32m[20221124 23:27:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:27:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:27:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:27:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:27:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:27:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:27:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:27:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:27:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:27:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:27:56 @pendulum_agent.py:317][0m Evaluation time: 0.572598934173584
[32m[20221124 23:27:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:27:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:27:57 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:27:57 @pendulum_agent.py:289][0m Total time: 7546.116704940796
[32m[20221124 23:27:57 @pendulum_agent.py:291][0m 24900000 total steps have happened
[32m[20221124 23:27:57 @pendulum_agent.py:281][0m #------------------------ Iteration 498 --------------------------#
[32m[20221124 23:27:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:27:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 11.2
[32m[20221124 23:27:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:27:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 9.0
[32m[20221124 23:27:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.0
[32m[20221124 23:27:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:27:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.6
[32m[20221124 23:27:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:27:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:27:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 7.0
[32m[20221124 23:28:00 @pendulum_agent.py:307][0m Sample time: 3.7071571350097656
[32m[20221124 23:28:10 @pendulum_agent.py:312][0m Update time: 9.899971961975098
[32m[20221124 23:28:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:28:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:28:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:28:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:28:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:28:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:28:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:28:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:28:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:28:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:28:11 @pendulum_agent.py:317][0m Evaluation time: 0.826833963394165
[32m[20221124 23:28:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.38
[32m[20221124 23:28:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:28:11 @pendulum_agent.py:289][0m Total time: 7560.833174943924
[32m[20221124 23:28:11 @pendulum_agent.py:291][0m 24950000 total steps have happened
[32m[20221124 23:28:11 @pendulum_agent.py:281][0m #------------------------ Iteration 499 --------------------------#
[32m[20221124 23:28:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:28:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:28:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:28:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:28:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:28:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:28:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:28:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:28:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:28:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:28:15 @pendulum_agent.py:307][0m Sample time: 3.677683115005493
[32m[20221124 23:28:25 @pendulum_agent.py:312][0m Update time: 9.670618772506714
[32m[20221124 23:28:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:28:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:28:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:28:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:28:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:28:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:28:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:28:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:28:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:28:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:28:26 @pendulum_agent.py:317][0m Evaluation time: 1.0396621227264404
[32m[20221124 23:28:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:28:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:28:26 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:28:26 @pendulum_agent.py:289][0m Total time: 7575.513247013092
[32m[20221124 23:28:26 @pendulum_agent.py:291][0m 25000000 total steps have happened
[32m[20221124 23:28:26 @pendulum_agent.py:281][0m #------------------------ Iteration 500 --------------------------#
[32m[20221124 23:28:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.4
[32m[20221124 23:28:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.8
[32m[20221124 23:28:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 7.8
[32m[20221124 23:28:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 9.0
[32m[20221124 23:28:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 12.0
[32m[20221124 23:28:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.8
[32m[20221124 23:28:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.8
[32m[20221124 23:28:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.2
[32m[20221124 23:28:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 11.4
[32m[20221124 23:28:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 7.4
[32m[20221124 23:28:30 @pendulum_agent.py:307][0m Sample time: 3.629150152206421
[32m[20221124 23:28:39 @pendulum_agent.py:312][0m Update time: 9.788988828659058
[32m[20221124 23:28:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:28:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:28:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:28:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:28:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:28:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:28:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:28:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:28:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:28:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:28:40 @pendulum_agent.py:317][0m Evaluation time: 0.7149848937988281
[32m[20221124 23:28:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.76
[32m[20221124 23:28:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:28:40 @pendulum_agent.py:289][0m Total time: 7589.917088985443
[32m[20221124 23:28:40 @pendulum_agent.py:291][0m 25050000 total steps have happened
[32m[20221124 23:28:40 @pendulum_agent.py:281][0m #------------------------ Iteration 501 --------------------------#
[32m[20221124 23:28:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:28:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:28:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:28:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:28:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:28:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:28:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:28:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:28:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:28:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:28:44 @pendulum_agent.py:307][0m Sample time: 3.608215808868408
[32m[20221124 23:28:53 @pendulum_agent.py:312][0m Update time: 9.247879266738892
[32m[20221124 23:28:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:28:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:28:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:28:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:28:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:28:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:28:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:28:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:28:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:28:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:28:54 @pendulum_agent.py:317][0m Evaluation time: 0.5986199378967285
[32m[20221124 23:28:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:28:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:28:54 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:28:54 @pendulum_agent.py:289][0m Total time: 7603.649708032608
[32m[20221124 23:28:54 @pendulum_agent.py:291][0m 25100000 total steps have happened
[32m[20221124 23:28:54 @pendulum_agent.py:281][0m #------------------------ Iteration 502 --------------------------#
[32m[20221124 23:28:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:28:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:28:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:28:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:28:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:28:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:28:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:28:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:28:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:28:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:28:58 @pendulum_agent.py:307][0m Sample time: 3.765949010848999
[32m[20221124 23:29:08 @pendulum_agent.py:312][0m Update time: 10.053414106369019
[32m[20221124 23:29:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:29:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:29:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:29:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:29:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:29:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:29:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:29:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:29:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:29:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:29:09 @pendulum_agent.py:317][0m Evaluation time: 0.7019138336181641
[32m[20221124 23:29:09 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:29:09 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:29:09 @pendulum_agent.py:289][0m Total time: 7618.47652387619
[32m[20221124 23:29:09 @pendulum_agent.py:291][0m 25150000 total steps have happened
[32m[20221124 23:29:09 @pendulum_agent.py:281][0m #------------------------ Iteration 503 --------------------------#
[32m[20221124 23:29:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.8
[32m[20221124 23:29:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.0
[32m[20221124 23:29:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.8
[32m[20221124 23:29:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 20.6
[32m[20221124 23:29:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 7.2
[32m[20221124 23:29:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 15.2
[32m[20221124 23:29:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 10.8
[32m[20221124 23:29:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.0
[32m[20221124 23:29:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 18.6
[32m[20221124 23:29:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.4
[32m[20221124 23:29:13 @pendulum_agent.py:307][0m Sample time: 3.734802722930908
[32m[20221124 23:29:23 @pendulum_agent.py:312][0m Update time: 10.046643018722534
[32m[20221124 23:29:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:29:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:29:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:29:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:29:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:29:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:29:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:29:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:29:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:29:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:29:23 @pendulum_agent.py:317][0m Evaluation time: 0.6974022388458252
[32m[20221124 23:29:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 10.74
[32m[20221124 23:29:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:29:24 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:29:24 @pendulum_agent.py:289][0m Total time: 7633.2345588207245
[32m[20221124 23:29:24 @pendulum_agent.py:291][0m 25200000 total steps have happened
[32m[20221124 23:29:24 @pendulum_agent.py:281][0m #------------------------ Iteration 504 --------------------------#
[32m[20221124 23:29:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 12.2
[32m[20221124 23:29:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 11.0
[32m[20221124 23:29:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 12.2
[32m[20221124 23:29:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.8
[32m[20221124 23:29:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.4
[32m[20221124 23:29:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 13.6
[32m[20221124 23:29:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 8.8
[32m[20221124 23:29:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.2
[32m[20221124 23:29:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.6
[32m[20221124 23:29:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.6
[32m[20221124 23:29:27 @pendulum_agent.py:307][0m Sample time: 3.584990978240967
[32m[20221124 23:29:36 @pendulum_agent.py:312][0m Update time: 8.863127946853638
[32m[20221124 23:29:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:29:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:29:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:29:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:29:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:29:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:29:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:29:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:29:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:29:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:29:37 @pendulum_agent.py:317][0m Evaluation time: 0.9342350959777832
[32m[20221124 23:29:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 8.84
[32m[20221124 23:29:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:29:37 @pendulum_agent.py:289][0m Total time: 7646.8916919231415
[32m[20221124 23:29:37 @pendulum_agent.py:291][0m 25250000 total steps have happened
[32m[20221124 23:29:37 @pendulum_agent.py:281][0m #------------------------ Iteration 505 --------------------------#
[32m[20221124 23:29:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:29:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:29:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:29:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:29:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:29:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:29:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:29:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:29:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:29:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:29:41 @pendulum_agent.py:307][0m Sample time: 3.7014379501342773
[32m[20221124 23:29:50 @pendulum_agent.py:312][0m Update time: 9.055522203445435
[32m[20221124 23:29:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:29:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:29:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:29:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:29:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:29:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:29:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:29:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:29:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:29:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:29:51 @pendulum_agent.py:317][0m Evaluation time: 0.691241979598999
[32m[20221124 23:29:51 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:29:51 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:29:51 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:29:51 @pendulum_agent.py:289][0m Total time: 7660.597260951996
[32m[20221124 23:29:51 @pendulum_agent.py:291][0m 25300000 total steps have happened
[32m[20221124 23:29:51 @pendulum_agent.py:281][0m #------------------------ Iteration 506 --------------------------#
[32m[20221124 23:29:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 9.4
[32m[20221124 23:29:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.4
[32m[20221124 23:29:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.4
[32m[20221124 23:29:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.0
[32m[20221124 23:29:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.4
[32m[20221124 23:29:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.4
[32m[20221124 23:29:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.4
[32m[20221124 23:29:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 12.2
[32m[20221124 23:29:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 11.6
[32m[20221124 23:29:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 11.2
[32m[20221124 23:29:55 @pendulum_agent.py:307][0m Sample time: 3.69635009765625
[32m[20221124 23:30:04 @pendulum_agent.py:312][0m Update time: 9.60962200164795
[32m[20221124 23:30:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:30:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:30:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:30:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:30:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:30:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:30:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:30:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:30:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:30:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:30:05 @pendulum_agent.py:317][0m Evaluation time: 0.6781668663024902
[32m[20221124 23:30:05 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.64
[32m[20221124 23:30:05 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:30:05 @pendulum_agent.py:289][0m Total time: 7674.882272005081
[32m[20221124 23:30:05 @pendulum_agent.py:291][0m 25350000 total steps have happened
[32m[20221124 23:30:05 @pendulum_agent.py:281][0m #------------------------ Iteration 507 --------------------------#
[32m[20221124 23:30:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.4
[32m[20221124 23:30:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.2
[32m[20221124 23:30:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 8.6
[32m[20221124 23:30:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.6
[32m[20221124 23:30:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.8
[32m[20221124 23:30:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.2
[32m[20221124 23:30:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.2
[32m[20221124 23:30:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.6
[32m[20221124 23:30:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.8
[32m[20221124 23:30:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.2
[32m[20221124 23:30:09 @pendulum_agent.py:307][0m Sample time: 3.416572093963623
[32m[20221124 23:30:18 @pendulum_agent.py:312][0m Update time: 8.978649854660034
[32m[20221124 23:30:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:30:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:30:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:30:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:30:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:30:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:30:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:30:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:30:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:30:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:30:19 @pendulum_agent.py:317][0m Evaluation time: 0.9279191493988037
[32m[20221124 23:30:19 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.86
[32m[20221124 23:30:19 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:30:19 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:30:19 @pendulum_agent.py:289][0m Total time: 7688.487293958664
[32m[20221124 23:30:19 @pendulum_agent.py:291][0m 25400000 total steps have happened
[32m[20221124 23:30:19 @pendulum_agent.py:281][0m #------------------------ Iteration 508 --------------------------#
[32m[20221124 23:30:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.8
[32m[20221124 23:30:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 15.2
[32m[20221124 23:30:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 17.8
[32m[20221124 23:30:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 7.6
[32m[20221124 23:30:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 12.6
[32m[20221124 23:30:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.2
[32m[20221124 23:30:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.8
[32m[20221124 23:30:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.2
[32m[20221124 23:30:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 11.8
[32m[20221124 23:30:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.8
[32m[20221124 23:30:22 @pendulum_agent.py:307][0m Sample time: 3.336738109588623
[32m[20221124 23:30:32 @pendulum_agent.py:312][0m Update time: 9.68630599975586
[32m[20221124 23:30:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:30:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:30:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:30:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:30:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:30:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:30:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:30:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:30:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:30:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:30:34 @pendulum_agent.py:317][0m Evaluation time: 1.6604089736938477
[32m[20221124 23:30:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 8.68
[32m[20221124 23:30:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:30:34 @pendulum_agent.py:289][0m Total time: 7703.45738697052
[32m[20221124 23:30:34 @pendulum_agent.py:291][0m 25450000 total steps have happened
[32m[20221124 23:30:34 @pendulum_agent.py:281][0m #------------------------ Iteration 509 --------------------------#
[32m[20221124 23:30:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:30:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:30:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:30:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:30:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:30:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:30:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:30:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:30:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:30:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:30:38 @pendulum_agent.py:307][0m Sample time: 3.8141469955444336
[32m[20221124 23:30:47 @pendulum_agent.py:312][0m Update time: 8.870017051696777
[32m[20221124 23:30:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:30:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:30:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:30:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:30:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:30:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:30:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:30:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:30:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:30:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:30:47 @pendulum_agent.py:317][0m Evaluation time: 0.7200419902801514
[32m[20221124 23:30:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:30:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:30:48 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:30:48 @pendulum_agent.py:289][0m Total time: 7717.151638031006
[32m[20221124 23:30:48 @pendulum_agent.py:291][0m 25500000 total steps have happened
[32m[20221124 23:30:48 @pendulum_agent.py:281][0m #------------------------ Iteration 510 --------------------------#
[32m[20221124 23:30:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:30:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:30:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:30:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:30:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:30:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:30:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:30:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:30:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:30:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:30:51 @pendulum_agent.py:307][0m Sample time: 3.685420036315918
[32m[20221124 23:31:01 @pendulum_agent.py:312][0m Update time: 9.598754167556763
[32m[20221124 23:31:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:31:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:31:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:31:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:31:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:31:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:31:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:31:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:31:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:31:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:31:02 @pendulum_agent.py:317][0m Evaluation time: 0.6977789402008057
[32m[20221124 23:31:02 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:31:02 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:31:02 @pendulum_agent.py:289][0m Total time: 7731.400223970413
[32m[20221124 23:31:02 @pendulum_agent.py:291][0m 25550000 total steps have happened
[32m[20221124 23:31:02 @pendulum_agent.py:281][0m #------------------------ Iteration 511 --------------------------#
[32m[20221124 23:31:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:31:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:31:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:31:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:31:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:31:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:31:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:31:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:31:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:31:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:31:06 @pendulum_agent.py:307][0m Sample time: 3.7712719440460205
[32m[20221124 23:31:15 @pendulum_agent.py:312][0m Update time: 9.079680919647217
[32m[20221124 23:31:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:31:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:31:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:31:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:31:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:31:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:31:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:31:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:31:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:31:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:31:15 @pendulum_agent.py:317][0m Evaluation time: 0.7187681198120117
[32m[20221124 23:31:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:31:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:31:16 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:31:16 @pendulum_agent.py:289][0m Total time: 7745.25081205368
[32m[20221124 23:31:16 @pendulum_agent.py:291][0m 25600000 total steps have happened
[32m[20221124 23:31:16 @pendulum_agent.py:281][0m #------------------------ Iteration 512 --------------------------#
[32m[20221124 23:31:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:31:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:31:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:31:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:31:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:31:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:31:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:31:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:31:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:31:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:31:19 @pendulum_agent.py:307][0m Sample time: 3.5891571044921875
[32m[20221124 23:31:29 @pendulum_agent.py:312][0m Update time: 9.416171073913574
[32m[20221124 23:31:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:31:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:31:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:31:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:31:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:31:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:31:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:31:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:31:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:31:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:31:29 @pendulum_agent.py:317][0m Evaluation time: 0.8415818214416504
[32m[20221124 23:31:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:31:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:31:30 @pendulum_agent.py:289][0m Total time: 7759.370402097702
[32m[20221124 23:31:30 @pendulum_agent.py:291][0m 25650000 total steps have happened
[32m[20221124 23:31:30 @pendulum_agent.py:281][0m #------------------------ Iteration 513 --------------------------#
[32m[20221124 23:31:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.4
[32m[20221124 23:31:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 9.2
[32m[20221124 23:31:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.2
[32m[20221124 23:31:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.0
[32m[20221124 23:31:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 9.4
[32m[20221124 23:31:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.6
[32m[20221124 23:31:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.4
[32m[20221124 23:31:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 7.4
[32m[20221124 23:31:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.0
[32m[20221124 23:31:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.4
[32m[20221124 23:31:33 @pendulum_agent.py:307][0m Sample time: 3.62231183052063
[32m[20221124 23:31:42 @pendulum_agent.py:312][0m Update time: 8.771190166473389
[32m[20221124 23:31:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:31:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:31:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:31:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:31:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:31:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:31:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:31:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:31:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:31:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:31:43 @pendulum_agent.py:317][0m Evaluation time: 0.694242000579834
[32m[20221124 23:31:43 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.0
[32m[20221124 23:31:43 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:31:43 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:31:43 @pendulum_agent.py:289][0m Total time: 7772.725746154785
[32m[20221124 23:31:43 @pendulum_agent.py:291][0m 25700000 total steps have happened
[32m[20221124 23:31:43 @pendulum_agent.py:281][0m #------------------------ Iteration 514 --------------------------#
[32m[20221124 23:31:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:31:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:31:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:31:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:31:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:31:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:31:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:31:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:31:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:31:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:31:47 @pendulum_agent.py:307][0m Sample time: 3.7451908588409424
[32m[20221124 23:31:56 @pendulum_agent.py:312][0m Update time: 9.118251085281372
[32m[20221124 23:31:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:31:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:31:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:31:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:31:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:31:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:31:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:31:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:31:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:31:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:31:57 @pendulum_agent.py:317][0m Evaluation time: 0.7172479629516602
[32m[20221124 23:31:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:31:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:31:57 @pendulum_agent.py:289][0m Total time: 7786.581984996796
[32m[20221124 23:31:57 @pendulum_agent.py:291][0m 25750000 total steps have happened
[32m[20221124 23:31:57 @pendulum_agent.py:281][0m #------------------------ Iteration 515 --------------------------#
[32m[20221124 23:31:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:31:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:31:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:31:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:31:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:31:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:31:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:31:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:31:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:31:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:32:01 @pendulum_agent.py:307][0m Sample time: 3.58469295501709
[32m[20221124 23:32:11 @pendulum_agent.py:312][0m Update time: 10.26291298866272
[32m[20221124 23:32:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:32:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:32:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:32:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:32:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:32:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:32:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:32:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:32:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:32:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:32:12 @pendulum_agent.py:317][0m Evaluation time: 0.7142128944396973
[32m[20221124 23:32:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:32:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:32:12 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:32:12 @pendulum_agent.py:289][0m Total time: 7801.431090831757
[32m[20221124 23:32:12 @pendulum_agent.py:291][0m 25800000 total steps have happened
[32m[20221124 23:32:12 @pendulum_agent.py:281][0m #------------------------ Iteration 516 --------------------------#
[32m[20221124 23:32:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:32:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:32:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:32:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:32:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:32:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:32:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:32:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:32:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:32:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:32:15 @pendulum_agent.py:307][0m Sample time: 3.4952151775360107
[32m[20221124 23:32:25 @pendulum_agent.py:312][0m Update time: 10.034770965576172
[32m[20221124 23:32:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:32:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:32:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:32:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:32:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:32:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:32:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:32:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:32:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:32:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:32:26 @pendulum_agent.py:317][0m Evaluation time: 0.8447678089141846
[32m[20221124 23:32:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:32:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:32:26 @pendulum_agent.py:289][0m Total time: 7816.078938961029
[32m[20221124 23:32:26 @pendulum_agent.py:291][0m 25850000 total steps have happened
[32m[20221124 23:32:26 @pendulum_agent.py:281][0m #------------------------ Iteration 517 --------------------------#
[32m[20221124 23:32:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:32:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:32:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:32:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:32:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:32:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:32:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:32:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:32:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:32:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:32:30 @pendulum_agent.py:307][0m Sample time: 3.4740591049194336
[32m[20221124 23:32:39 @pendulum_agent.py:312][0m Update time: 9.505116939544678
[32m[20221124 23:32:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.0
[32m[20221124 23:32:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.0
[32m[20221124 23:32:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.0
[32m[20221124 23:32:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.0
[32m[20221124 23:32:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.0
[32m[20221124 23:32:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.0
[32m[20221124 23:32:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.0
[32m[20221124 23:32:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.0
[32m[20221124 23:32:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.0
[32m[20221124 23:32:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.0
[32m[20221124 23:32:40 @pendulum_agent.py:317][0m Evaluation time: 1.0398759841918945
[32m[20221124 23:32:41 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:32:41 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:32:41 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:32:41 @pendulum_agent.py:289][0m Total time: 7830.3981029987335
[32m[20221124 23:32:41 @pendulum_agent.py:291][0m 25900000 total steps have happened
[32m[20221124 23:32:41 @pendulum_agent.py:281][0m #------------------------ Iteration 518 --------------------------#
[32m[20221124 23:32:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:32:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:32:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:32:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:32:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:32:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:32:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:32:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:32:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:32:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:32:44 @pendulum_agent.py:307][0m Sample time: 3.342615842819214
[32m[20221124 23:32:54 @pendulum_agent.py:312][0m Update time: 9.705955028533936
[32m[20221124 23:32:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:32:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:32:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:32:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:32:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:32:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:32:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:32:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:32:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:32:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:32:55 @pendulum_agent.py:317][0m Evaluation time: 1.1816141605377197
[32m[20221124 23:32:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:32:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:32:55 @pendulum_agent.py:289][0m Total time: 7845.005232095718
[32m[20221124 23:32:55 @pendulum_agent.py:291][0m 25950000 total steps have happened
[32m[20221124 23:32:55 @pendulum_agent.py:281][0m #------------------------ Iteration 519 --------------------------#
[32m[20221124 23:32:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:32:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:32:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:32:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:32:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:32:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:32:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:32:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:32:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:32:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:32:59 @pendulum_agent.py:307][0m Sample time: 3.5755279064178467
[32m[20221124 23:33:08 @pendulum_agent.py:312][0m Update time: 8.754299879074097
[32m[20221124 23:33:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:33:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:33:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:33:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:33:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:33:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:33:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:33:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:33:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:33:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:33:10 @pendulum_agent.py:317][0m Evaluation time: 1.864495038986206
[32m[20221124 23:33:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:33:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:33:10 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:33:10 @pendulum_agent.py:289][0m Total time: 7859.487576961517
[32m[20221124 23:33:10 @pendulum_agent.py:291][0m 26000000 total steps have happened
[32m[20221124 23:33:10 @pendulum_agent.py:281][0m #------------------------ Iteration 520 --------------------------#
[32m[20221124 23:33:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:33:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:33:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:33:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:33:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:33:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:33:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:33:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:33:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:33:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:33:13 @pendulum_agent.py:307][0m Sample time: 3.5539822578430176
[32m[20221124 23:33:23 @pendulum_agent.py:312][0m Update time: 9.838697910308838
[32m[20221124 23:33:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:33:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:33:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:33:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:33:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:33:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:33:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:33:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:33:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:33:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:33:24 @pendulum_agent.py:317][0m Evaluation time: 0.7257308959960938
[32m[20221124 23:33:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:33:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:33:24 @pendulum_agent.py:289][0m Total time: 7873.873174905777
[32m[20221124 23:33:24 @pendulum_agent.py:291][0m 26050000 total steps have happened
[32m[20221124 23:33:24 @pendulum_agent.py:281][0m #------------------------ Iteration 521 --------------------------#
[32m[20221124 23:33:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:33:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:33:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:33:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:33:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:33:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:33:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:33:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:33:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:33:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:33:28 @pendulum_agent.py:307][0m Sample time: 3.6509146690368652
[32m[20221124 23:33:36 @pendulum_agent.py:312][0m Update time: 8.465933084487915
[32m[20221124 23:33:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:33:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:33:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:33:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:33:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:33:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:33:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:33:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:33:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:33:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:33:37 @pendulum_agent.py:317][0m Evaluation time: 0.9886970520019531
[32m[20221124 23:33:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:33:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:33:38 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:33:38 @pendulum_agent.py:289][0m Total time: 7887.262508869171
[32m[20221124 23:33:38 @pendulum_agent.py:291][0m 26100000 total steps have happened
[32m[20221124 23:33:38 @pendulum_agent.py:281][0m #------------------------ Iteration 522 --------------------------#
[32m[20221124 23:33:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:33:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:33:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:33:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:33:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:33:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:33:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:33:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:33:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:33:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:33:42 @pendulum_agent.py:307][0m Sample time: 3.852489948272705
[32m[20221124 23:33:52 @pendulum_agent.py:312][0m Update time: 10.132467031478882
[32m[20221124 23:33:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:33:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:33:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:33:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:33:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:33:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:33:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:33:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:33:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:33:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:33:53 @pendulum_agent.py:317][0m Evaluation time: 0.9494500160217285
[32m[20221124 23:33:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:33:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:33:53 @pendulum_agent.py:289][0m Total time: 7902.492008924484
[32m[20221124 23:33:53 @pendulum_agent.py:291][0m 26150000 total steps have happened
[32m[20221124 23:33:53 @pendulum_agent.py:281][0m #------------------------ Iteration 523 --------------------------#
[32m[20221124 23:33:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:33:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:33:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:33:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:33:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:33:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:33:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:33:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:33:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:33:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:33:57 @pendulum_agent.py:307][0m Sample time: 3.888397693634033
[32m[20221124 23:34:06 @pendulum_agent.py:312][0m Update time: 9.126501083374023
[32m[20221124 23:34:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:34:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:34:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:34:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:34:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:34:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:34:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:34:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:34:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:34:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:34:07 @pendulum_agent.py:317][0m Evaluation time: 0.6928250789642334
[32m[20221124 23:34:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:34:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:34:07 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:34:07 @pendulum_agent.py:289][0m Total time: 7916.484135866165
[32m[20221124 23:34:07 @pendulum_agent.py:291][0m 26200000 total steps have happened
[32m[20221124 23:34:07 @pendulum_agent.py:281][0m #------------------------ Iteration 524 --------------------------#
[32m[20221124 23:34:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:34:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:34:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:34:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:34:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:34:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:34:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:34:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:34:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:34:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:34:10 @pendulum_agent.py:307][0m Sample time: 3.555478096008301
[32m[20221124 23:34:19 @pendulum_agent.py:312][0m Update time: 8.984435796737671
[32m[20221124 23:34:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:34:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:34:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:34:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:34:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:34:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:34:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:34:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:34:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:34:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:34:20 @pendulum_agent.py:317][0m Evaluation time: 0.580855131149292
[32m[20221124 23:34:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:34:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:34:20 @pendulum_agent.py:289][0m Total time: 7929.897756099701
[32m[20221124 23:34:20 @pendulum_agent.py:291][0m 26250000 total steps have happened
[32m[20221124 23:34:20 @pendulum_agent.py:281][0m #------------------------ Iteration 525 --------------------------#
[32m[20221124 23:34:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.8
[32m[20221124 23:34:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 9.2
[32m[20221124 23:34:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 10.4
[32m[20221124 23:34:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 11.6
[32m[20221124 23:34:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 15.4
[32m[20221124 23:34:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 10.4
[32m[20221124 23:34:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.4
[32m[20221124 23:34:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 9.4
[32m[20221124 23:34:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 13.0
[32m[20221124 23:34:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.2
[32m[20221124 23:34:24 @pendulum_agent.py:307][0m Sample time: 3.7379672527313232
[32m[20221124 23:34:34 @pendulum_agent.py:312][0m Update time: 9.669554948806763
[32m[20221124 23:34:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:34:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:34:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:34:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:34:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:34:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:34:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:34:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:34:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:34:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:34:34 @pendulum_agent.py:317][0m Evaluation time: 0.5883870124816895
[32m[20221124 23:34:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 9.48
[32m[20221124 23:34:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:34:35 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:34:35 @pendulum_agent.py:289][0m Total time: 7944.179827928543
[32m[20221124 23:34:35 @pendulum_agent.py:291][0m 26300000 total steps have happened
[32m[20221124 23:34:35 @pendulum_agent.py:281][0m #------------------------ Iteration 526 --------------------------#
[32m[20221124 23:34:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:34:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:34:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:34:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:34:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:34:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:34:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:34:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:34:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:34:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:34:38 @pendulum_agent.py:307][0m Sample time: 3.7301769256591797
[32m[20221124 23:34:47 @pendulum_agent.py:312][0m Update time: 9.034033060073853
[32m[20221124 23:34:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:34:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:34:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:34:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:34:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:34:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:34:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:34:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:34:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:34:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:34:48 @pendulum_agent.py:317][0m Evaluation time: 0.5804648399353027
[32m[20221124 23:34:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:34:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:34:48 @pendulum_agent.py:289][0m Total time: 7957.8230719566345
[32m[20221124 23:34:48 @pendulum_agent.py:291][0m 26350000 total steps have happened
[32m[20221124 23:34:48 @pendulum_agent.py:281][0m #------------------------ Iteration 527 --------------------------#
[32m[20221124 23:34:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:34:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:34:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:34:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:34:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:34:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:34:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:34:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:34:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:34:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:34:52 @pendulum_agent.py:307][0m Sample time: 3.868833065032959
[32m[20221124 23:35:02 @pendulum_agent.py:312][0m Update time: 10.338684797286987
[32m[20221124 23:35:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:35:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:35:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:35:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:35:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:35:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:35:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:35:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:35:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:35:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:35:03 @pendulum_agent.py:317][0m Evaluation time: 0.6747121810913086
[32m[20221124 23:35:03 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:35:03 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:35:03 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:35:03 @pendulum_agent.py:289][0m Total time: 7972.976884841919
[32m[20221124 23:35:03 @pendulum_agent.py:291][0m 26400000 total steps have happened
[32m[20221124 23:35:03 @pendulum_agent.py:281][0m #------------------------ Iteration 528 --------------------------#
[32m[20221124 23:35:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.2
[32m[20221124 23:35:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.2
[32m[20221124 23:35:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.4
[32m[20221124 23:35:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.0
[32m[20221124 23:35:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.8
[32m[20221124 23:35:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.0
[32m[20221124 23:35:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.0
[32m[20221124 23:35:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.8
[32m[20221124 23:35:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.4
[32m[20221124 23:35:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.6
[32m[20221124 23:35:07 @pendulum_agent.py:307][0m Sample time: 3.5131750106811523
[32m[20221124 23:35:16 @pendulum_agent.py:312][0m Update time: 8.784938097000122
[32m[20221124 23:35:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:35:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:35:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:35:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:35:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:35:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:35:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:35:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:35:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:35:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:35:16 @pendulum_agent.py:317][0m Evaluation time: 0.815824031829834
[32m[20221124 23:35:17 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.54
[32m[20221124 23:35:17 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:35:17 @pendulum_agent.py:289][0m Total time: 7986.379044055939
[32m[20221124 23:35:17 @pendulum_agent.py:291][0m 26450000 total steps have happened
[32m[20221124 23:35:17 @pendulum_agent.py:281][0m #------------------------ Iteration 529 --------------------------#
[32m[20221124 23:35:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:35:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:35:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:35:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:35:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:35:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:35:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:35:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:35:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:35:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:35:20 @pendulum_agent.py:307][0m Sample time: 3.296440839767456
[32m[20221124 23:35:29 @pendulum_agent.py:312][0m Update time: 8.6319580078125
[32m[20221124 23:35:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:35:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:35:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:35:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:35:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:35:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:35:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:35:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:35:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:35:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:35:30 @pendulum_agent.py:317][0m Evaluation time: 1.0221290588378906
[32m[20221124 23:35:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:35:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:35:30 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:35:30 @pendulum_agent.py:289][0m Total time: 7999.602993011475
[32m[20221124 23:35:30 @pendulum_agent.py:291][0m 26500000 total steps have happened
[32m[20221124 23:35:30 @pendulum_agent.py:281][0m #------------------------ Iteration 530 --------------------------#
[32m[20221124 23:35:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:35:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:35:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:35:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:35:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:35:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:35:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:35:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:35:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:35:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:35:34 @pendulum_agent.py:307][0m Sample time: 3.527401924133301
[32m[20221124 23:35:43 @pendulum_agent.py:312][0m Update time: 9.85185718536377
[32m[20221124 23:35:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:35:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:35:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:35:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:35:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:35:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:35:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:35:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:35:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:35:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:35:45 @pendulum_agent.py:317][0m Evaluation time: 1.1716139316558838
[32m[20221124 23:35:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:35:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:35:45 @pendulum_agent.py:289][0m Total time: 8014.445369005203
[32m[20221124 23:35:45 @pendulum_agent.py:291][0m 26550000 total steps have happened
[32m[20221124 23:35:45 @pendulum_agent.py:281][0m #------------------------ Iteration 531 --------------------------#
[32m[20221124 23:35:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:35:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:35:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:35:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:35:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:35:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:35:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:35:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:35:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:35:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:35:48 @pendulum_agent.py:307][0m Sample time: 3.293321371078491
[32m[20221124 23:35:57 @pendulum_agent.py:312][0m Update time: 8.880927801132202
[32m[20221124 23:35:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:35:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:35:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:35:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:35:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:35:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:35:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:35:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:35:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:35:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:35:58 @pendulum_agent.py:317][0m Evaluation time: 1.1701409816741943
[32m[20221124 23:35:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:35:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:35:58 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:35:58 @pendulum_agent.py:289][0m Total time: 8028.065280914307
[32m[20221124 23:35:58 @pendulum_agent.py:291][0m 26600000 total steps have happened
[32m[20221124 23:35:58 @pendulum_agent.py:281][0m #------------------------ Iteration 532 --------------------------#
[32m[20221124 23:35:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:35:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:35:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:35:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:35:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:35:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:35:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:35:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:35:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:35:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:36:02 @pendulum_agent.py:307][0m Sample time: 3.6380462646484375
[32m[20221124 23:36:11 @pendulum_agent.py:312][0m Update time: 8.77328896522522
[32m[20221124 23:36:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:36:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:36:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:36:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:36:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:36:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:36:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:36:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:36:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:36:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:36:12 @pendulum_agent.py:317][0m Evaluation time: 0.7201180458068848
[32m[20221124 23:36:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:36:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:36:12 @pendulum_agent.py:289][0m Total time: 8041.467502117157
[32m[20221124 23:36:12 @pendulum_agent.py:291][0m 26650000 total steps have happened
[32m[20221124 23:36:12 @pendulum_agent.py:281][0m #------------------------ Iteration 533 --------------------------#
[32m[20221124 23:36:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:36:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:36:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:36:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:36:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:36:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:36:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:36:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:36:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:36:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:36:16 @pendulum_agent.py:307][0m Sample time: 3.66534686088562
[32m[20221124 23:36:24 @pendulum_agent.py:312][0m Update time: 8.913158178329468
[32m[20221124 23:36:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:36:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:36:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:36:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:36:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:36:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:36:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:36:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:36:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:36:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:36:25 @pendulum_agent.py:317][0m Evaluation time: 0.7163958549499512
[32m[20221124 23:36:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:36:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:36:25 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:36:25 @pendulum_agent.py:289][0m Total time: 8055.058539867401
[32m[20221124 23:36:25 @pendulum_agent.py:291][0m 26700000 total steps have happened
[32m[20221124 23:36:25 @pendulum_agent.py:281][0m #------------------------ Iteration 534 --------------------------#
[32m[20221124 23:36:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.0
[32m[20221124 23:36:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 19.4
[32m[20221124 23:36:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 18.4
[32m[20221124 23:36:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 17.6
[32m[20221124 23:36:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.0
[32m[20221124 23:36:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 28.4
[32m[20221124 23:36:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 8.6
[32m[20221124 23:36:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.4
[32m[20221124 23:36:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 27.2
[32m[20221124 23:36:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.6
[32m[20221124 23:36:29 @pendulum_agent.py:307][0m Sample time: 3.506304979324341
[32m[20221124 23:36:38 @pendulum_agent.py:312][0m Update time: 9.009898900985718
[32m[20221124 23:36:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:36:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:36:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:36:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:36:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:36:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:36:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:36:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:36:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:36:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:36:39 @pendulum_agent.py:317][0m Evaluation time: 0.7000923156738281
[32m[20221124 23:36:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 13.16
[32m[20221124 23:36:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:36:39 @pendulum_agent.py:289][0m Total time: 8068.5729830265045
[32m[20221124 23:36:39 @pendulum_agent.py:291][0m 26750000 total steps have happened
[32m[20221124 23:36:39 @pendulum_agent.py:281][0m #------------------------ Iteration 535 --------------------------#
[32m[20221124 23:36:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:36:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:36:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:36:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:36:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:36:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:36:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:36:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:36:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:36:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:36:43 @pendulum_agent.py:307][0m Sample time: 3.841048240661621
[32m[20221124 23:36:52 @pendulum_agent.py:312][0m Update time: 8.788069725036621
[32m[20221124 23:36:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:36:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:36:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:36:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:36:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:36:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:36:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:36:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:36:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:36:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:36:52 @pendulum_agent.py:317][0m Evaluation time: 0.5699441432952881
[32m[20221124 23:36:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:36:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:36:52 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:36:52 @pendulum_agent.py:289][0m Total time: 8082.0691339969635
[32m[20221124 23:36:52 @pendulum_agent.py:291][0m 26800000 total steps have happened
[32m[20221124 23:36:52 @pendulum_agent.py:281][0m #------------------------ Iteration 536 --------------------------#
[32m[20221124 23:36:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:36:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:36:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:36:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:36:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:36:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:36:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:36:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:36:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:36:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:36:56 @pendulum_agent.py:307][0m Sample time: 3.784127950668335
[32m[20221124 23:37:05 @pendulum_agent.py:312][0m Update time: 9.184046030044556
[32m[20221124 23:37:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:37:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:37:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:37:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:37:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:37:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:37:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:37:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:37:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:37:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:37:06 @pendulum_agent.py:317][0m Evaluation time: 0.709669828414917
[32m[20221124 23:37:06 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:37:06 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:37:06 @pendulum_agent.py:289][0m Total time: 8096.036993980408
[32m[20221124 23:37:06 @pendulum_agent.py:291][0m 26850000 total steps have happened
[32m[20221124 23:37:06 @pendulum_agent.py:281][0m #------------------------ Iteration 537 --------------------------#
[32m[20221124 23:37:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 19.6
[32m[20221124 23:37:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 10.2
[32m[20221124 23:37:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 10.6
[32m[20221124 23:37:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 16.0
[32m[20221124 23:37:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 10.8
[32m[20221124 23:37:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 7.6
[32m[20221124 23:37:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 14.0
[32m[20221124 23:37:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 13.6
[32m[20221124 23:37:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 8.8
[32m[20221124 23:37:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 12.8
[32m[20221124 23:37:10 @pendulum_agent.py:307][0m Sample time: 3.601166009902954
[32m[20221124 23:37:19 @pendulum_agent.py:312][0m Update time: 8.888740062713623
[32m[20221124 23:37:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 31.0
[32m[20221124 23:37:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 31.0
[32m[20221124 23:37:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 31.0
[32m[20221124 23:37:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 31.0
[32m[20221124 23:37:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 31.0
[32m[20221124 23:37:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 31.0
[32m[20221124 23:37:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 31.0
[32m[20221124 23:37:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 31.0
[32m[20221124 23:37:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 31.0
[32m[20221124 23:37:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 31.0
[32m[20221124 23:37:20 @pendulum_agent.py:317][0m Evaluation time: 0.7104029655456543
[32m[20221124 23:37:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 12.4
[32m[20221124 23:37:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:37:20 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:37:20 @pendulum_agent.py:289][0m Total time: 8109.506858825684
[32m[20221124 23:37:20 @pendulum_agent.py:291][0m 26900000 total steps have happened
[32m[20221124 23:37:20 @pendulum_agent.py:281][0m #------------------------ Iteration 538 --------------------------#
[32m[20221124 23:37:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:37:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:37:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:37:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:37:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:37:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:37:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:37:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:37:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:37:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:37:23 @pendulum_agent.py:307][0m Sample time: 3.5356953144073486
[32m[20221124 23:37:33 @pendulum_agent.py:312][0m Update time: 9.35459566116333
[32m[20221124 23:37:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:37:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:37:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:37:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:37:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:37:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:37:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:37:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:37:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:37:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:37:34 @pendulum_agent.py:317][0m Evaluation time: 0.8251943588256836
[32m[20221124 23:37:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:37:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:37:34 @pendulum_agent.py:289][0m Total time: 8123.5055429935455
[32m[20221124 23:37:34 @pendulum_agent.py:291][0m 26950000 total steps have happened
[32m[20221124 23:37:34 @pendulum_agent.py:281][0m #------------------------ Iteration 539 --------------------------#
[32m[20221124 23:37:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:37:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:37:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:37:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:37:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:37:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:37:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:37:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:37:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:37:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:37:37 @pendulum_agent.py:307][0m Sample time: 3.298633098602295
[32m[20221124 23:37:46 @pendulum_agent.py:312][0m Update time: 9.038368940353394
[32m[20221124 23:37:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:37:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:37:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:37:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:37:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:37:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:37:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:37:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:37:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:37:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:37:47 @pendulum_agent.py:317][0m Evaluation time: 1.0487611293792725
[32m[20221124 23:37:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:37:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:37:48 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:37:48 @pendulum_agent.py:289][0m Total time: 8137.154277086258
[32m[20221124 23:37:48 @pendulum_agent.py:291][0m 27000000 total steps have happened
[32m[20221124 23:37:48 @pendulum_agent.py:281][0m #------------------------ Iteration 540 --------------------------#
[32m[20221124 23:37:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:37:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:37:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:37:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:37:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:37:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:37:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:37:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:37:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:37:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:37:51 @pendulum_agent.py:307][0m Sample time: 3.225736141204834
[32m[20221124 23:37:59 @pendulum_agent.py:312][0m Update time: 8.713953971862793
[32m[20221124 23:38:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:38:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:38:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:38:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:38:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:38:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:38:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:38:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:38:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:38:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:38:01 @pendulum_agent.py:317][0m Evaluation time: 1.0332989692687988
[32m[20221124 23:38:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:38:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:38:01 @pendulum_agent.py:289][0m Total time: 8150.396159887314
[32m[20221124 23:38:01 @pendulum_agent.py:291][0m 27050000 total steps have happened
[32m[20221124 23:38:01 @pendulum_agent.py:281][0m #------------------------ Iteration 541 --------------------------#
[32m[20221124 23:38:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:38:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:38:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:38:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:38:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:38:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:38:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:38:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:38:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:38:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:38:04 @pendulum_agent.py:307][0m Sample time: 3.595700979232788
[32m[20221124 23:38:14 @pendulum_agent.py:312][0m Update time: 9.22396206855774
[32m[20221124 23:38:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:38:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:38:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:38:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:38:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:38:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:38:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:38:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:38:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:38:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:38:14 @pendulum_agent.py:317][0m Evaluation time: 0.7192327976226807
[32m[20221124 23:38:15 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:38:15 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:38:15 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:38:15 @pendulum_agent.py:289][0m Total time: 8164.210662126541
[32m[20221124 23:38:15 @pendulum_agent.py:291][0m 27100000 total steps have happened
[32m[20221124 23:38:15 @pendulum_agent.py:281][0m #------------------------ Iteration 542 --------------------------#
[32m[20221124 23:38:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:38:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:38:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:38:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:38:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:38:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:38:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:38:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:38:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:38:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:38:18 @pendulum_agent.py:307][0m Sample time: 3.6182451248168945
[32m[20221124 23:38:27 @pendulum_agent.py:312][0m Update time: 8.51852011680603
[32m[20221124 23:38:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:38:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:38:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:38:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:38:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:38:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:38:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:38:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:38:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:38:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:38:27 @pendulum_agent.py:317][0m Evaluation time: 0.728806734085083
[32m[20221124 23:38:28 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:38:28 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:38:28 @pendulum_agent.py:289][0m Total time: 8177.359846115112
[32m[20221124 23:38:28 @pendulum_agent.py:291][0m 27150000 total steps have happened
[32m[20221124 23:38:28 @pendulum_agent.py:281][0m #------------------------ Iteration 543 --------------------------#
[32m[20221124 23:38:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:38:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:38:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:38:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:38:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:38:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:38:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:38:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:38:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:38:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:38:32 @pendulum_agent.py:307][0m Sample time: 3.825636863708496
[32m[20221124 23:38:41 @pendulum_agent.py:312][0m Update time: 9.830405235290527
[32m[20221124 23:38:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:38:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:38:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:38:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:38:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:38:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:38:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:38:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:38:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:38:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:38:42 @pendulum_agent.py:317][0m Evaluation time: 0.5843987464904785
[32m[20221124 23:38:42 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:38:42 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:38:42 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:38:42 @pendulum_agent.py:289][0m Total time: 8191.889746189117
[32m[20221124 23:38:42 @pendulum_agent.py:291][0m 27200000 total steps have happened
[32m[20221124 23:38:42 @pendulum_agent.py:281][0m #------------------------ Iteration 544 --------------------------#
[32m[20221124 23:38:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:38:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:38:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:38:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:38:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:38:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:38:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:38:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:38:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:38:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:38:46 @pendulum_agent.py:307][0m Sample time: 3.619554042816162
[32m[20221124 23:38:56 @pendulum_agent.py:312][0m Update time: 9.83207392692566
[32m[20221124 23:38:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:38:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:38:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:38:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:38:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:38:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:38:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:38:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:38:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:38:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:38:57 @pendulum_agent.py:317][0m Evaluation time: 0.8428747653961182
[32m[20221124 23:38:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:38:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:38:57 @pendulum_agent.py:289][0m Total time: 8206.458564043045
[32m[20221124 23:38:57 @pendulum_agent.py:291][0m 27250000 total steps have happened
[32m[20221124 23:38:57 @pendulum_agent.py:281][0m #------------------------ Iteration 545 --------------------------#
[32m[20221124 23:38:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:38:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:38:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:38:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:38:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:38:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:38:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:38:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:38:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:38:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:39:00 @pendulum_agent.py:307][0m Sample time: 3.4532549381256104
[32m[20221124 23:39:09 @pendulum_agent.py:312][0m Update time: 8.680992841720581
[32m[20221124 23:39:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:39:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:39:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:39:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:39:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:39:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:39:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:39:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:39:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:39:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:39:10 @pendulum_agent.py:317][0m Evaluation time: 1.0212979316711426
[32m[20221124 23:39:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:39:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:39:10 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:39:10 @pendulum_agent.py:289][0m Total time: 8219.887403011322
[32m[20221124 23:39:10 @pendulum_agent.py:291][0m 27300000 total steps have happened
[32m[20221124 23:39:10 @pendulum_agent.py:281][0m #------------------------ Iteration 546 --------------------------#
[32m[20221124 23:39:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:39:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:39:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:39:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:39:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:39:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:39:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:39:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:39:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:39:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:39:14 @pendulum_agent.py:307][0m Sample time: 3.622600793838501
[32m[20221124 23:39:23 @pendulum_agent.py:312][0m Update time: 9.22577691078186
[32m[20221124 23:39:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1000.0
[32m[20221124 23:39:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1000.0
[32m[20221124 23:39:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1000.0
[32m[20221124 23:39:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1000.0
[32m[20221124 23:39:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1000.0
[32m[20221124 23:39:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1000.0
[32m[20221124 23:39:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1000.0
[32m[20221124 23:39:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1000.0
[32m[20221124 23:39:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1000.0
[32m[20221124 23:39:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1000.0
[32m[20221124 23:39:24 @pendulum_agent.py:317][0m Evaluation time: 0.7110590934753418
[32m[20221124 23:39:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:39:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:39:24 @pendulum_agent.py:289][0m Total time: 8233.714380979538
[32m[20221124 23:39:24 @pendulum_agent.py:291][0m 27350000 total steps have happened
[32m[20221124 23:39:24 @pendulum_agent.py:281][0m #------------------------ Iteration 547 --------------------------#
[32m[20221124 23:39:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:39:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:39:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:39:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:39:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:39:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:39:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:39:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:39:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:39:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:39:28 @pendulum_agent.py:307][0m Sample time: 3.6146039962768555
[32m[20221124 23:39:38 @pendulum_agent.py:312][0m Update time: 10.629169940948486
[32m[20221124 23:39:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:39:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:39:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:39:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:39:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:39:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:39:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:39:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:39:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:39:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:39:39 @pendulum_agent.py:317][0m Evaluation time: 0.5865352153778076
[32m[20221124 23:39:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:39:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:39:39 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:39:39 @pendulum_agent.py:289][0m Total time: 8248.839399814606
[32m[20221124 23:39:39 @pendulum_agent.py:291][0m 27400000 total steps have happened
[32m[20221124 23:39:39 @pendulum_agent.py:281][0m #------------------------ Iteration 548 --------------------------#
[32m[20221124 23:39:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:39:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:39:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:39:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:39:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:39:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:39:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:39:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:39:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:39:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:39:43 @pendulum_agent.py:307][0m Sample time: 3.7560079097747803
[32m[20221124 23:39:52 @pendulum_agent.py:312][0m Update time: 8.923192262649536
[32m[20221124 23:39:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:39:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:39:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:39:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:39:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:39:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:39:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:39:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:39:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:39:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:39:53 @pendulum_agent.py:317][0m Evaluation time: 0.691864013671875
[32m[20221124 23:39:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:39:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:39:53 @pendulum_agent.py:289][0m Total time: 8262.50442481041
[32m[20221124 23:39:53 @pendulum_agent.py:291][0m 27450000 total steps have happened
[32m[20221124 23:39:53 @pendulum_agent.py:281][0m #------------------------ Iteration 549 --------------------------#
[32m[20221124 23:39:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 17.0
[32m[20221124 23:39:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.0
[32m[20221124 23:39:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.0
[32m[20221124 23:39:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.0
[32m[20221124 23:39:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 31.2
[32m[20221124 23:39:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 19.4
[32m[20221124 23:39:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 25.6
[32m[20221124 23:39:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.2
[32m[20221124 23:39:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.2
[32m[20221124 23:39:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.6
[32m[20221124 23:39:57 @pendulum_agent.py:307][0m Sample time: 3.675541877746582
[32m[20221124 23:40:06 @pendulum_agent.py:312][0m Update time: 8.979076862335205
[32m[20221124 23:40:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:40:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:40:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:40:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:40:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:40:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:40:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:40:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:40:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:40:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:40:06 @pendulum_agent.py:317][0m Evaluation time: 0.6970722675323486
[32m[20221124 23:40:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 12.12
[32m[20221124 23:40:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:40:07 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:40:07 @pendulum_agent.py:289][0m Total time: 8276.129854917526
[32m[20221124 23:40:07 @pendulum_agent.py:291][0m 27500000 total steps have happened
[32m[20221124 23:40:07 @pendulum_agent.py:281][0m #------------------------ Iteration 550 --------------------------#
[32m[20221124 23:40:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:40:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:40:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:40:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:40:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:40:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:40:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:40:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:40:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:40:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:40:10 @pendulum_agent.py:307][0m Sample time: 3.592805862426758
[32m[20221124 23:40:20 @pendulum_agent.py:312][0m Update time: 9.455205202102661
[32m[20221124 23:40:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:40:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:40:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:40:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:40:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:40:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:40:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:40:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:40:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:40:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:40:21 @pendulum_agent.py:317][0m Evaluation time: 0.9299767017364502
[32m[20221124 23:40:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:40:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:40:21 @pendulum_agent.py:289][0m Total time: 8290.394134044647
[32m[20221124 23:40:21 @pendulum_agent.py:291][0m 27550000 total steps have happened
[32m[20221124 23:40:21 @pendulum_agent.py:281][0m #------------------------ Iteration 551 --------------------------#
[32m[20221124 23:40:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:40:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:40:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:40:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:40:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:40:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:40:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:40:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:40:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:40:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:40:24 @pendulum_agent.py:307][0m Sample time: 3.657258987426758
[32m[20221124 23:40:33 @pendulum_agent.py:312][0m Update time: 8.957777976989746
[32m[20221124 23:40:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:40:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:40:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:40:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:40:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:40:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:40:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:40:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:40:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:40:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:40:34 @pendulum_agent.py:317][0m Evaluation time: 0.7042691707611084
[32m[20221124 23:40:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:40:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:40:34 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:40:34 @pendulum_agent.py:289][0m Total time: 8304.00694179535
[32m[20221124 23:40:34 @pendulum_agent.py:291][0m 27600000 total steps have happened
[32m[20221124 23:40:34 @pendulum_agent.py:281][0m #------------------------ Iteration 552 --------------------------#
[32m[20221124 23:40:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:40:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:40:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:40:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:40:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:40:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:40:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:40:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:40:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:40:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:40:38 @pendulum_agent.py:307][0m Sample time: 3.7270798683166504
[32m[20221124 23:40:47 @pendulum_agent.py:312][0m Update time: 8.932006120681763
[32m[20221124 23:40:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:40:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:40:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:40:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:40:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:40:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:40:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:40:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:40:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:40:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:40:48 @pendulum_agent.py:317][0m Evaluation time: 0.6773519515991211
[32m[20221124 23:40:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:40:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:40:48 @pendulum_agent.py:289][0m Total time: 8317.63185095787
[32m[20221124 23:40:48 @pendulum_agent.py:291][0m 27650000 total steps have happened
[32m[20221124 23:40:48 @pendulum_agent.py:281][0m #------------------------ Iteration 553 --------------------------#
[32m[20221124 23:40:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:40:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:40:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:40:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:40:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:40:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:40:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:40:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:40:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:40:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:40:51 @pendulum_agent.py:307][0m Sample time: 3.380666971206665
[32m[20221124 23:41:00 @pendulum_agent.py:312][0m Update time: 8.759581089019775
[32m[20221124 23:41:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:41:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:41:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:41:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:41:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:41:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:41:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:41:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:41:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:41:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:41:01 @pendulum_agent.py:317][0m Evaluation time: 0.9399478435516357
[32m[20221124 23:41:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:41:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:41:01 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:41:01 @pendulum_agent.py:289][0m Total time: 8330.98136806488
[32m[20221124 23:41:01 @pendulum_agent.py:291][0m 27700000 total steps have happened
[32m[20221124 23:41:01 @pendulum_agent.py:281][0m #------------------------ Iteration 554 --------------------------#
[32m[20221124 23:41:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:41:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:41:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:41:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:41:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:41:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:41:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:41:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:41:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:41:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:41:05 @pendulum_agent.py:307][0m Sample time: 3.3274660110473633
[32m[20221124 23:41:13 @pendulum_agent.py:312][0m Update time: 8.746350049972534
[32m[20221124 23:41:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:41:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:41:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:41:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:41:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:41:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:41:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:41:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:41:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:41:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:41:15 @pendulum_agent.py:317][0m Evaluation time: 1.6707589626312256
[32m[20221124 23:41:15 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:41:15 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:41:15 @pendulum_agent.py:289][0m Total time: 8345.00959610939
[32m[20221124 23:41:15 @pendulum_agent.py:291][0m 27750000 total steps have happened
[32m[20221124 23:41:15 @pendulum_agent.py:281][0m #------------------------ Iteration 555 --------------------------#
[32m[20221124 23:41:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 26.8
[32m[20221124 23:41:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 31.4
[32m[20221124 23:41:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 53.8
[32m[20221124 23:41:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 76.4
[32m[20221124 23:41:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 32.2
[32m[20221124 23:41:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 61.4
[32m[20221124 23:41:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 89.6
[32m[20221124 23:41:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 11.4
[32m[20221124 23:41:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 34.0
[32m[20221124 23:41:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 13.0
[32m[20221124 23:41:19 @pendulum_agent.py:307][0m Sample time: 3.7933218479156494
[32m[20221124 23:41:29 @pendulum_agent.py:312][0m Update time: 9.351968050003052
[32m[20221124 23:41:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:41:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:41:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:41:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:41:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:41:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:41:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:41:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:41:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:41:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:41:29 @pendulum_agent.py:317][0m Evaluation time: 0.7424631118774414
[32m[20221124 23:41:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 43.0
[32m[20221124 23:41:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:41:30 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:41:30 @pendulum_agent.py:289][0m Total time: 8359.171378135681
[32m[20221124 23:41:30 @pendulum_agent.py:291][0m 27800000 total steps have happened
[32m[20221124 23:41:30 @pendulum_agent.py:281][0m #------------------------ Iteration 556 --------------------------#
[32m[20221124 23:41:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 78.6
[32m[20221124 23:41:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 52.2
[32m[20221124 23:41:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 31.6
[32m[20221124 23:41:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 44.2
[32m[20221124 23:41:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 40.6
[32m[20221124 23:41:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 39.0
[32m[20221124 23:41:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 31.2
[32m[20221124 23:41:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 36.4
[32m[20221124 23:41:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 27.0
[32m[20221124 23:41:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 17.2
[32m[20221124 23:41:33 @pendulum_agent.py:307][0m Sample time: 3.6453609466552734
[32m[20221124 23:41:43 @pendulum_agent.py:312][0m Update time: 9.898585081100464
[32m[20221124 23:41:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:41:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:41:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:41:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:41:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:41:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:41:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:41:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:41:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:41:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:41:44 @pendulum_agent.py:317][0m Evaluation time: 0.7107980251312256
[32m[20221124 23:41:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 39.8
[32m[20221124 23:41:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:41:44 @pendulum_agent.py:289][0m Total time: 8373.698415994644
[32m[20221124 23:41:44 @pendulum_agent.py:291][0m 27850000 total steps have happened
[32m[20221124 23:41:44 @pendulum_agent.py:281][0m #------------------------ Iteration 557 --------------------------#
[32m[20221124 23:41:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:41:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:41:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:41:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:41:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:41:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:41:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:41:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:41:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:41:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:41:48 @pendulum_agent.py:307][0m Sample time: 3.8034732341766357
[32m[20221124 23:41:57 @pendulum_agent.py:312][0m Update time: 9.542839765548706
[32m[20221124 23:41:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:41:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:41:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:41:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:41:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:41:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:41:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:41:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:41:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:41:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:41:58 @pendulum_agent.py:317][0m Evaluation time: 0.7328989505767822
[32m[20221124 23:41:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:41:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:41:58 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:41:58 @pendulum_agent.py:289][0m Total time: 8388.085030078888
[32m[20221124 23:41:58 @pendulum_agent.py:291][0m 27900000 total steps have happened
[32m[20221124 23:41:58 @pendulum_agent.py:281][0m #------------------------ Iteration 558 --------------------------#
[32m[20221124 23:41:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:41:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:41:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:41:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:41:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:41:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:41:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:41:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:41:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:41:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:42:02 @pendulum_agent.py:307][0m Sample time: 3.571924924850464
[32m[20221124 23:42:11 @pendulum_agent.py:312][0m Update time: 9.022021055221558
[32m[20221124 23:42:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:42:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:42:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:42:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:42:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:42:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:42:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:42:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:42:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:42:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:42:12 @pendulum_agent.py:317][0m Evaluation time: 0.8214390277862549
[32m[20221124 23:42:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:42:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:42:12 @pendulum_agent.py:289][0m Total time: 8401.774157047272
[32m[20221124 23:42:12 @pendulum_agent.py:291][0m 27950000 total steps have happened
[32m[20221124 23:42:12 @pendulum_agent.py:281][0m #------------------------ Iteration 559 --------------------------#
[32m[20221124 23:42:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 26.6
[32m[20221124 23:42:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 21.6
[32m[20221124 23:42:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 32.6
[32m[20221124 23:42:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 18.2
[32m[20221124 23:42:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 7.4
[32m[20221124 23:42:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 32.8
[32m[20221124 23:42:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.4
[32m[20221124 23:42:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 9.0
[32m[20221124 23:42:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.0
[32m[20221124 23:42:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 8.0
[32m[20221124 23:42:16 @pendulum_agent.py:307][0m Sample time: 3.6825127601623535
[32m[20221124 23:42:25 @pendulum_agent.py:312][0m Update time: 9.182242155075073
[32m[20221124 23:42:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:42:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:42:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:42:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:42:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:42:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:42:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:42:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:42:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:42:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:42:26 @pendulum_agent.py:317][0m Evaluation time: 0.6964430809020996
[32m[20221124 23:42:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 16.76
[32m[20221124 23:42:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:42:26 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:42:26 @pendulum_agent.py:289][0m Total time: 8415.610697984695
[32m[20221124 23:42:26 @pendulum_agent.py:291][0m 28000000 total steps have happened
[32m[20221124 23:42:26 @pendulum_agent.py:281][0m #------------------------ Iteration 560 --------------------------#
[32m[20221124 23:42:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:42:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:42:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:42:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:42:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:42:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:42:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:42:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:42:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:42:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:42:30 @pendulum_agent.py:307][0m Sample time: 3.7618179321289062
[32m[20221124 23:42:40 @pendulum_agent.py:312][0m Update time: 10.608213901519775
[32m[20221124 23:42:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:42:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:42:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:42:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:42:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:42:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:42:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:42:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:42:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:42:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:42:41 @pendulum_agent.py:317][0m Evaluation time: 0.7186470031738281
[32m[20221124 23:42:41 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:42:41 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:42:41 @pendulum_agent.py:289][0m Total time: 8430.985867023468
[32m[20221124 23:42:41 @pendulum_agent.py:291][0m 28050000 total steps have happened
[32m[20221124 23:42:41 @pendulum_agent.py:281][0m #------------------------ Iteration 561 --------------------------#
[32m[20221124 23:42:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:42:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:42:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:42:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:42:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:42:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:42:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:42:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:42:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:42:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:42:45 @pendulum_agent.py:307][0m Sample time: 3.599261999130249
[32m[20221124 23:42:54 @pendulum_agent.py:312][0m Update time: 8.80480408668518
[32m[20221124 23:42:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:42:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:42:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:42:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:42:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:42:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:42:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:42:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:42:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:42:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:42:54 @pendulum_agent.py:317][0m Evaluation time: 0.7034177780151367
[32m[20221124 23:42:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:42:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:42:55 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:42:55 @pendulum_agent.py:289][0m Total time: 8444.384078979492
[32m[20221124 23:42:55 @pendulum_agent.py:291][0m 28100000 total steps have happened
[32m[20221124 23:42:55 @pendulum_agent.py:281][0m #------------------------ Iteration 562 --------------------------#
[32m[20221124 23:42:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 35.8
[32m[20221124 23:42:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 11.6
[32m[20221124 23:42:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 57.4
[32m[20221124 23:42:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 40.4
[32m[20221124 23:42:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 84.0
[32m[20221124 23:42:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 48.2
[32m[20221124 23:42:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 26.0
[32m[20221124 23:42:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 37.4
[32m[20221124 23:42:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 32.8
[32m[20221124 23:42:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 54.8
[32m[20221124 23:42:58 @pendulum_agent.py:307][0m Sample time: 3.459498167037964
[32m[20221124 23:43:08 @pendulum_agent.py:312][0m Update time: 9.495341777801514
[32m[20221124 23:43:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 994.0
[32m[20221124 23:43:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 994.0
[32m[20221124 23:43:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 994.0
[32m[20221124 23:43:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 994.0
[32m[20221124 23:43:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 994.0
[32m[20221124 23:43:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 994.0
[32m[20221124 23:43:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 994.0
[32m[20221124 23:43:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 994.0
[32m[20221124 23:43:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 994.0
[32m[20221124 23:43:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 994.0
[32m[20221124 23:43:09 @pendulum_agent.py:317][0m Evaluation time: 0.8312170505523682
[32m[20221124 23:43:09 @pendulum_agent.py:285][0m Average TRAINING episode reward: 42.84
[32m[20221124 23:43:09 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:43:09 @pendulum_agent.py:289][0m Total time: 8458.443458080292
[32m[20221124 23:43:09 @pendulum_agent.py:291][0m 28150000 total steps have happened
[32m[20221124 23:43:09 @pendulum_agent.py:281][0m #------------------------ Iteration 563 --------------------------#
[32m[20221124 23:43:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.0
[32m[20221124 23:43:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.4
[32m[20221124 23:43:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 17.0
[32m[20221124 23:43:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.4
[32m[20221124 23:43:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.4
[32m[20221124 23:43:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 11.8
[32m[20221124 23:43:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 21.4
[32m[20221124 23:43:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 12.4
[32m[20221124 23:43:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 21.4
[32m[20221124 23:43:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 10.4
[32m[20221124 23:43:12 @pendulum_agent.py:307][0m Sample time: 3.4469640254974365
[32m[20221124 23:43:21 @pendulum_agent.py:312][0m Update time: 8.896987915039062
[32m[20221124 23:43:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1000.0
[32m[20221124 23:43:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1000.0
[32m[20221124 23:43:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1000.0
[32m[20221124 23:43:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1000.0
[32m[20221124 23:43:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1000.0
[32m[20221124 23:43:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1000.0
[32m[20221124 23:43:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1000.0
[32m[20221124 23:43:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1000.0
[32m[20221124 23:43:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1000.0
[32m[20221124 23:43:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1000.0
[32m[20221124 23:43:22 @pendulum_agent.py:317][0m Evaluation time: 1.0289058685302734
[32m[20221124 23:43:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 11.06
[32m[20221124 23:43:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:43:22 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:43:22 @pendulum_agent.py:289][0m Total time: 8472.091805934906
[32m[20221124 23:43:22 @pendulum_agent.py:291][0m 28200000 total steps have happened
[32m[20221124 23:43:22 @pendulum_agent.py:281][0m #------------------------ Iteration 564 --------------------------#
[32m[20221124 23:43:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:43:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:43:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:43:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:43:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:43:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:43:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:43:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:43:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:43:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:43:26 @pendulum_agent.py:307][0m Sample time: 3.319617986679077
[32m[20221124 23:43:35 @pendulum_agent.py:312][0m Update time: 8.876290082931519
[32m[20221124 23:43:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:43:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:43:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:43:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:43:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:43:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:43:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:43:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:43:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:43:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:43:36 @pendulum_agent.py:317][0m Evaluation time: 1.1571059226989746
[32m[20221124 23:43:36 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:43:36 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:43:36 @pendulum_agent.py:289][0m Total time: 8485.721664905548
[32m[20221124 23:43:36 @pendulum_agent.py:291][0m 28250000 total steps have happened
[32m[20221124 23:43:36 @pendulum_agent.py:281][0m #------------------------ Iteration 565 --------------------------#
[32m[20221124 23:43:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 23.2
[32m[20221124 23:43:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 50.4
[32m[20221124 23:43:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 21.4
[32m[20221124 23:43:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 27.4
[32m[20221124 23:43:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 19.6
[32m[20221124 23:43:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 52.2
[32m[20221124 23:43:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 23.0
[32m[20221124 23:43:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 36.4
[32m[20221124 23:43:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 25.0
[32m[20221124 23:43:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 26.6
[32m[20221124 23:43:39 @pendulum_agent.py:307][0m Sample time: 3.310515880584717
[32m[20221124 23:43:49 @pendulum_agent.py:312][0m Update time: 9.389204978942871
[32m[20221124 23:43:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:43:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:43:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:43:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:43:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:43:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:43:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:43:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:43:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:43:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:43:51 @pendulum_agent.py:317][0m Evaluation time: 1.853013038635254
[32m[20221124 23:43:51 @pendulum_agent.py:285][0m Average TRAINING episode reward: 30.52
[32m[20221124 23:43:51 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:43:51 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:43:51 @pendulum_agent.py:289][0m Total time: 8500.551218032837
[32m[20221124 23:43:51 @pendulum_agent.py:291][0m 28300000 total steps have happened
[32m[20221124 23:43:51 @pendulum_agent.py:281][0m #------------------------ Iteration 566 --------------------------#
[32m[20221124 23:43:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 13.8
[32m[20221124 23:43:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 21.0
[32m[20221124 23:43:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.2
[32m[20221124 23:43:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 11.2
[32m[20221124 23:43:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 10.8
[32m[20221124 23:43:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 9.2
[32m[20221124 23:43:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 10.2
[32m[20221124 23:43:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.4
[32m[20221124 23:43:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.4
[32m[20221124 23:43:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.0
[32m[20221124 23:43:55 @pendulum_agent.py:307][0m Sample time: 3.576754093170166
[32m[20221124 23:44:03 @pendulum_agent.py:312][0m Update time: 8.833905935287476
[32m[20221124 23:44:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:44:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:44:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:44:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:44:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:44:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:44:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:44:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:44:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:44:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:44:04 @pendulum_agent.py:317][0m Evaluation time: 0.7189669609069824
[32m[20221124 23:44:04 @pendulum_agent.py:285][0m Average TRAINING episode reward: 10.22
[32m[20221124 23:44:04 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:44:04 @pendulum_agent.py:289][0m Total time: 8513.9501080513
[32m[20221124 23:44:04 @pendulum_agent.py:291][0m 28350000 total steps have happened
[32m[20221124 23:44:04 @pendulum_agent.py:281][0m #------------------------ Iteration 567 --------------------------#
[32m[20221124 23:44:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:44:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:44:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:44:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:44:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:44:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:44:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:44:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:44:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:44:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:44:08 @pendulum_agent.py:307][0m Sample time: 3.8038368225097656
[32m[20221124 23:44:17 @pendulum_agent.py:312][0m Update time: 8.796095371246338
[32m[20221124 23:44:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:44:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:44:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:44:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:44:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:44:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:44:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:44:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:44:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:44:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:44:18 @pendulum_agent.py:317][0m Evaluation time: 0.9401628971099854
[32m[20221124 23:44:18 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:44:18 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:44:18 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:44:18 @pendulum_agent.py:289][0m Total time: 8527.76177406311
[32m[20221124 23:44:18 @pendulum_agent.py:291][0m 28400000 total steps have happened
[32m[20221124 23:44:18 @pendulum_agent.py:281][0m #------------------------ Iteration 568 --------------------------#
[32m[20221124 23:44:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:44:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:44:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:44:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:44:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:44:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:44:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:44:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:44:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:44:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:44:22 @pendulum_agent.py:307][0m Sample time: 3.8012940883636475
[32m[20221124 23:44:31 @pendulum_agent.py:312][0m Update time: 8.690286874771118
[32m[20221124 23:44:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:44:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:44:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:44:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:44:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:44:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:44:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:44:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:44:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:44:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:44:32 @pendulum_agent.py:317][0m Evaluation time: 0.990577220916748
[32m[20221124 23:44:32 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:44:32 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:44:32 @pendulum_agent.py:289][0m Total time: 8541.49231505394
[32m[20221124 23:44:32 @pendulum_agent.py:291][0m 28450000 total steps have happened
[32m[20221124 23:44:32 @pendulum_agent.py:281][0m #------------------------ Iteration 569 --------------------------#
[32m[20221124 23:44:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:44:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:44:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:44:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:44:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:44:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:44:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:44:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:44:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:44:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:44:36 @pendulum_agent.py:307][0m Sample time: 3.892616033554077
[32m[20221124 23:44:46 @pendulum_agent.py:312][0m Update time: 10.020435094833374
[32m[20221124 23:44:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:44:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:44:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:44:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:44:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:44:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:44:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:44:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:44:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:44:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:44:46 @pendulum_agent.py:317][0m Evaluation time: 0.6921920776367188
[32m[20221124 23:44:47 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:44:47 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:44:47 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:44:47 @pendulum_agent.py:289][0m Total time: 8556.373522043228
[32m[20221124 23:44:47 @pendulum_agent.py:291][0m 28500000 total steps have happened
[32m[20221124 23:44:47 @pendulum_agent.py:281][0m #------------------------ Iteration 570 --------------------------#
[32m[20221124 23:44:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:44:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:44:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:44:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:44:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:44:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:44:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:44:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:44:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:44:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:44:50 @pendulum_agent.py:307][0m Sample time: 3.5509049892425537
[32m[20221124 23:44:59 @pendulum_agent.py:312][0m Update time: 8.703504800796509
[32m[20221124 23:44:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:44:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:44:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:44:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:44:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:44:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:44:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:44:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:44:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:44:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:45:00 @pendulum_agent.py:317][0m Evaluation time: 0.5837271213531494
[32m[20221124 23:45:00 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:45:00 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:45:00 @pendulum_agent.py:289][0m Total time: 8569.502056837082
[32m[20221124 23:45:00 @pendulum_agent.py:291][0m 28550000 total steps have happened
[32m[20221124 23:45:00 @pendulum_agent.py:281][0m #------------------------ Iteration 571 --------------------------#
[32m[20221124 23:45:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:45:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:45:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:45:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:45:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:45:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:45:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:45:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:45:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:45:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:45:04 @pendulum_agent.py:307][0m Sample time: 3.7502400875091553
[32m[20221124 23:45:13 @pendulum_agent.py:312][0m Update time: 9.750048875808716
[32m[20221124 23:45:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1000.0
[32m[20221124 23:45:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1000.0
[32m[20221124 23:45:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1000.0
[32m[20221124 23:45:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1000.0
[32m[20221124 23:45:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1000.0
[32m[20221124 23:45:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1000.0
[32m[20221124 23:45:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1000.0
[32m[20221124 23:45:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1000.0
[32m[20221124 23:45:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1000.0
[32m[20221124 23:45:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1000.0
[32m[20221124 23:45:14 @pendulum_agent.py:317][0m Evaluation time: 0.5843930244445801
[32m[20221124 23:45:14 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:45:14 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:45:14 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:45:14 @pendulum_agent.py:289][0m Total time: 8583.87589597702
[32m[20221124 23:45:14 @pendulum_agent.py:291][0m 28600000 total steps have happened
[32m[20221124 23:45:14 @pendulum_agent.py:281][0m #------------------------ Iteration 572 --------------------------#
[32m[20221124 23:45:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:45:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:45:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:45:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:45:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:45:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:45:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:45:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:45:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 33.4
[32m[20221124 23:45:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:45:18 @pendulum_agent.py:307][0m Sample time: 3.7479989528656006
[32m[20221124 23:45:27 @pendulum_agent.py:312][0m Update time: 8.921194076538086
[32m[20221124 23:45:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:45:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:45:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:45:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:45:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:45:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:45:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:45:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:45:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:45:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:45:28 @pendulum_agent.py:317][0m Evaluation time: 0.5783050060272217
[32m[20221124 23:45:28 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.34
[32m[20221124 23:45:28 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:45:28 @pendulum_agent.py:289][0m Total time: 8597.413526058197
[32m[20221124 23:45:28 @pendulum_agent.py:291][0m 28650000 total steps have happened
[32m[20221124 23:45:28 @pendulum_agent.py:281][0m #------------------------ Iteration 573 --------------------------#
[32m[20221124 23:45:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:45:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:45:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:45:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:45:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:45:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:45:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:45:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:45:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:45:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:45:32 @pendulum_agent.py:307][0m Sample time: 3.8116188049316406
[32m[20221124 23:45:41 @pendulum_agent.py:312][0m Update time: 8.918930292129517
[32m[20221124 23:45:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:45:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:45:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:45:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:45:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:45:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:45:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:45:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:45:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:45:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:45:41 @pendulum_agent.py:317][0m Evaluation time: 0.7109177112579346
[32m[20221124 23:45:42 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:45:42 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:45:42 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:45:42 @pendulum_agent.py:289][0m Total time: 8611.153818130493
[32m[20221124 23:45:42 @pendulum_agent.py:291][0m 28700000 total steps have happened
[32m[20221124 23:45:42 @pendulum_agent.py:281][0m #------------------------ Iteration 574 --------------------------#
[32m[20221124 23:45:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:45:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:45:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:45:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:45:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:45:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:45:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:45:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:45:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:45:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:45:45 @pendulum_agent.py:307][0m Sample time: 3.4920380115509033
[32m[20221124 23:45:54 @pendulum_agent.py:312][0m Update time: 9.167829990386963
[32m[20221124 23:45:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:45:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:45:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:45:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:45:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:45:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:45:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:45:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:45:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:45:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:45:55 @pendulum_agent.py:317][0m Evaluation time: 0.8381800651550293
[32m[20221124 23:45:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:45:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:45:55 @pendulum_agent.py:289][0m Total time: 8624.922966957092
[32m[20221124 23:45:55 @pendulum_agent.py:291][0m 28750000 total steps have happened
[32m[20221124 23:45:55 @pendulum_agent.py:281][0m #------------------------ Iteration 575 --------------------------#
[32m[20221124 23:45:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 15.2
[32m[20221124 23:45:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.6
[32m[20221124 23:45:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.0
[32m[20221124 23:45:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 20.0
[32m[20221124 23:45:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 7.4
[32m[20221124 23:45:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 7.6
[32m[20221124 23:45:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 15.2
[32m[20221124 23:45:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 38.2
[32m[20221124 23:45:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.0
[32m[20221124 23:45:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 7.2
[32m[20221124 23:45:59 @pendulum_agent.py:307][0m Sample time: 3.2630929946899414
[32m[20221124 23:46:08 @pendulum_agent.py:312][0m Update time: 9.807951211929321
[32m[20221124 23:46:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:46:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:46:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:46:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:46:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:46:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:46:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:46:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:46:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:46:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:46:09 @pendulum_agent.py:317][0m Evaluation time: 1.021083116531372
[32m[20221124 23:46:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 13.14
[32m[20221124 23:46:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:46:10 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:46:10 @pendulum_agent.py:289][0m Total time: 8639.30605506897
[32m[20221124 23:46:10 @pendulum_agent.py:291][0m 28800000 total steps have happened
[32m[20221124 23:46:10 @pendulum_agent.py:281][0m #------------------------ Iteration 576 --------------------------#
[32m[20221124 23:46:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:46:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:46:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:46:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:46:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:46:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:46:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:46:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:46:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:46:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:46:13 @pendulum_agent.py:307][0m Sample time: 3.511431932449341
[32m[20221124 23:46:22 @pendulum_agent.py:312][0m Update time: 9.140727043151855
[32m[20221124 23:46:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:46:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:46:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:46:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:46:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:46:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:46:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:46:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:46:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:46:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:46:24 @pendulum_agent.py:317][0m Evaluation time: 1.1571829319000244
[32m[20221124 23:46:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:46:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:46:24 @pendulum_agent.py:289][0m Total time: 8653.426130771637
[32m[20221124 23:46:24 @pendulum_agent.py:291][0m 28850000 total steps have happened
[32m[20221124 23:46:24 @pendulum_agent.py:281][0m #------------------------ Iteration 577 --------------------------#
[32m[20221124 23:46:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:46:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:46:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:46:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:46:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:46:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:46:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:46:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:46:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:46:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:46:27 @pendulum_agent.py:307][0m Sample time: 3.3123669624328613
[32m[20221124 23:46:37 @pendulum_agent.py:312][0m Update time: 9.407786130905151
[32m[20221124 23:46:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:46:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:46:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:46:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:46:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:46:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:46:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:46:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:46:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:46:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:46:38 @pendulum_agent.py:317][0m Evaluation time: 1.1569948196411133
[32m[20221124 23:46:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:46:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:46:38 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:46:38 @pendulum_agent.py:289][0m Total time: 8667.591487884521
[32m[20221124 23:46:38 @pendulum_agent.py:291][0m 28900000 total steps have happened
[32m[20221124 23:46:38 @pendulum_agent.py:281][0m #------------------------ Iteration 578 --------------------------#
[32m[20221124 23:46:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:46:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:46:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:46:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:46:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:46:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:46:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:46:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:46:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:46:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:46:42 @pendulum_agent.py:307][0m Sample time: 3.580824851989746
[32m[20221124 23:46:51 @pendulum_agent.py:312][0m Update time: 9.157947063446045
[32m[20221124 23:46:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:46:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:46:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:46:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:46:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:46:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:46:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:46:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:46:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:46:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:46:51 @pendulum_agent.py:317][0m Evaluation time: 0.6989960670471191
[32m[20221124 23:46:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:46:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:46:52 @pendulum_agent.py:289][0m Total time: 8681.300812005997
[32m[20221124 23:46:52 @pendulum_agent.py:291][0m 28950000 total steps have happened
[32m[20221124 23:46:52 @pendulum_agent.py:281][0m #------------------------ Iteration 579 --------------------------#
[32m[20221124 23:46:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.6
[32m[20221124 23:46:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 20.8
[32m[20221124 23:46:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.6
[32m[20221124 23:46:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 23.6
[32m[20221124 23:46:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 19.6
[32m[20221124 23:46:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.2
[32m[20221124 23:46:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 25.4
[32m[20221124 23:46:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 14.0
[32m[20221124 23:46:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.4
[32m[20221124 23:46:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.8
[32m[20221124 23:46:55 @pendulum_agent.py:307][0m Sample time: 3.6175880432128906
[32m[20221124 23:47:04 @pendulum_agent.py:312][0m Update time: 8.927288055419922
[32m[20221124 23:47:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:47:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:47:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:47:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:47:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:47:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:47:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:47:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:47:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:47:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:47:05 @pendulum_agent.py:317][0m Evaluation time: 0.7174201011657715
[32m[20221124 23:47:05 @pendulum_agent.py:285][0m Average TRAINING episode reward: 13.3
[32m[20221124 23:47:05 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:47:05 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:47:05 @pendulum_agent.py:289][0m Total time: 8694.853991031647
[32m[20221124 23:47:05 @pendulum_agent.py:291][0m 29000000 total steps have happened
[32m[20221124 23:47:05 @pendulum_agent.py:281][0m #------------------------ Iteration 580 --------------------------#
[32m[20221124 23:47:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:47:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:47:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:47:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:47:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:47:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:47:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:47:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:47:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:47:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:47:09 @pendulum_agent.py:307][0m Sample time: 3.531200885772705
[32m[20221124 23:47:18 @pendulum_agent.py:312][0m Update time: 8.98630404472351
[32m[20221124 23:47:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:47:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:47:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:47:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:47:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:47:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:47:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:47:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:47:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:47:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:47:18 @pendulum_agent.py:317][0m Evaluation time: 0.7149460315704346
[32m[20221124 23:47:19 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:47:19 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:47:19 @pendulum_agent.py:289][0m Total time: 8708.363938093185
[32m[20221124 23:47:19 @pendulum_agent.py:291][0m 29050000 total steps have happened
[32m[20221124 23:47:19 @pendulum_agent.py:281][0m #------------------------ Iteration 581 --------------------------#
[32m[20221124 23:47:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:47:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:47:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:47:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:47:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:47:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:47:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:47:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:47:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:47:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:47:23 @pendulum_agent.py:307][0m Sample time: 3.8089098930358887
[32m[20221124 23:47:33 @pendulum_agent.py:312][0m Update time: 10.35319209098816
[32m[20221124 23:47:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:47:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:47:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:47:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:47:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:47:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:47:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:47:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:47:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:47:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:47:33 @pendulum_agent.py:317][0m Evaluation time: 0.5725998878479004
[32m[20221124 23:47:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:47:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:47:34 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:47:34 @pendulum_agent.py:289][0m Total time: 8723.411139965057
[32m[20221124 23:47:34 @pendulum_agent.py:291][0m 29100000 total steps have happened
[32m[20221124 23:47:34 @pendulum_agent.py:281][0m #------------------------ Iteration 582 --------------------------#
[32m[20221124 23:47:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:47:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:47:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:47:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:47:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:47:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:47:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:47:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:47:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:47:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:47:38 @pendulum_agent.py:307][0m Sample time: 3.742027997970581
[32m[20221124 23:47:46 @pendulum_agent.py:312][0m Update time: 8.706248998641968
[32m[20221124 23:47:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:47:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:47:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:47:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:47:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:47:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:47:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:47:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:47:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:47:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:47:47 @pendulum_agent.py:317][0m Evaluation time: 0.7082581520080566
[32m[20221124 23:47:47 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:47:47 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:47:47 @pendulum_agent.py:289][0m Total time: 8736.85350394249
[32m[20221124 23:47:47 @pendulum_agent.py:291][0m 29150000 total steps have happened
[32m[20221124 23:47:47 @pendulum_agent.py:281][0m #------------------------ Iteration 583 --------------------------#
[32m[20221124 23:47:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:47:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:47:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:47:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:47:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:47:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:47:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:47:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:47:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:47:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:47:51 @pendulum_agent.py:307][0m Sample time: 3.5745677947998047
[32m[20221124 23:48:00 @pendulum_agent.py:312][0m Update time: 8.733237028121948
[32m[20221124 23:48:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:48:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:48:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:48:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:48:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:48:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:48:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:48:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:48:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:48:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:48:00 @pendulum_agent.py:317][0m Evaluation time: 0.6929070949554443
[32m[20221124 23:48:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:48:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:48:01 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:48:01 @pendulum_agent.py:289][0m Total time: 8750.147057056427
[32m[20221124 23:48:01 @pendulum_agent.py:291][0m 29200000 total steps have happened
[32m[20221124 23:48:01 @pendulum_agent.py:281][0m #------------------------ Iteration 584 --------------------------#
[32m[20221124 23:48:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.4
[32m[20221124 23:48:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 19.4
[32m[20221124 23:48:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 10.2
[32m[20221124 23:48:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 24.6
[32m[20221124 23:48:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 19.8
[32m[20221124 23:48:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 12.2
[32m[20221124 23:48:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.8
[32m[20221124 23:48:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 10.6
[32m[20221124 23:48:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.6
[32m[20221124 23:48:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 66.6
[32m[20221124 23:48:04 @pendulum_agent.py:307][0m Sample time: 3.5219151973724365
[32m[20221124 23:48:13 @pendulum_agent.py:312][0m Update time: 9.018976926803589
[32m[20221124 23:48:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:48:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:48:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:48:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:48:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:48:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:48:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:48:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:48:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:48:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:48:14 @pendulum_agent.py:317][0m Evaluation time: 0.854680061340332
[32m[20221124 23:48:14 @pendulum_agent.py:285][0m Average TRAINING episode reward: 17.52
[32m[20221124 23:48:14 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:48:14 @pendulum_agent.py:289][0m Total time: 8763.837299823761
[32m[20221124 23:48:14 @pendulum_agent.py:291][0m 29250000 total steps have happened
[32m[20221124 23:48:14 @pendulum_agent.py:281][0m #------------------------ Iteration 585 --------------------------#
[32m[20221124 23:48:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:48:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:48:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:48:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:48:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:48:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:48:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:48:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:48:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:48:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:48:18 @pendulum_agent.py:307][0m Sample time: 3.322988986968994
[32m[20221124 23:48:27 @pendulum_agent.py:312][0m Update time: 8.986855030059814
[32m[20221124 23:48:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:48:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:48:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:48:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:48:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:48:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:48:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:48:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:48:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:48:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:48:28 @pendulum_agent.py:317][0m Evaluation time: 1.0429739952087402
[32m[20221124 23:48:28 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:48:28 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:48:28 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:48:28 @pendulum_agent.py:289][0m Total time: 8777.453320026398
[32m[20221124 23:48:28 @pendulum_agent.py:291][0m 29300000 total steps have happened
[32m[20221124 23:48:28 @pendulum_agent.py:281][0m #------------------------ Iteration 586 --------------------------#
[32m[20221124 23:48:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:48:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:48:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:48:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:48:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:48:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:48:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:48:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:48:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:48:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:48:31 @pendulum_agent.py:307][0m Sample time: 3.250833034515381
[32m[20221124 23:48:41 @pendulum_agent.py:312][0m Update time: 9.418823957443237
[32m[20221124 23:48:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:48:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:48:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:48:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:48:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:48:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:48:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:48:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:48:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:48:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:48:42 @pendulum_agent.py:317][0m Evaluation time: 1.0424580574035645
[32m[20221124 23:48:42 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:48:42 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:48:42 @pendulum_agent.py:289][0m Total time: 8791.43670296669
[32m[20221124 23:48:42 @pendulum_agent.py:291][0m 29350000 total steps have happened
[32m[20221124 23:48:42 @pendulum_agent.py:281][0m #------------------------ Iteration 587 --------------------------#
[32m[20221124 23:48:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:48:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:48:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:48:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:48:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:48:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:48:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:48:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:48:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:48:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:48:45 @pendulum_agent.py:307][0m Sample time: 3.6260340213775635
[32m[20221124 23:48:54 @pendulum_agent.py:312][0m Update time: 8.738547801971436
[32m[20221124 23:48:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:48:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:48:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:48:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:48:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:48:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:48:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:48:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:48:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:48:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:48:55 @pendulum_agent.py:317][0m Evaluation time: 0.7070481777191162
[32m[20221124 23:48:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:48:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:48:55 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:48:55 @pendulum_agent.py:289][0m Total time: 8804.792515993118
[32m[20221124 23:48:55 @pendulum_agent.py:291][0m 29400000 total steps have happened
[32m[20221124 23:48:55 @pendulum_agent.py:281][0m #------------------------ Iteration 588 --------------------------#
[32m[20221124 23:48:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:48:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:48:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:48:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:48:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:48:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:48:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:48:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:48:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:48:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:48:59 @pendulum_agent.py:307][0m Sample time: 3.6616408824920654
[32m[20221124 23:49:10 @pendulum_agent.py:312][0m Update time: 11.043394088745117
[32m[20221124 23:49:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:49:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:49:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:49:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:49:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:49:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:49:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:49:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:49:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:49:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:49:11 @pendulum_agent.py:317][0m Evaluation time: 0.7079617977142334
[32m[20221124 23:49:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:49:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:49:11 @pendulum_agent.py:289][0m Total time: 8820.474665880203
[32m[20221124 23:49:11 @pendulum_agent.py:291][0m 29450000 total steps have happened
[32m[20221124 23:49:11 @pendulum_agent.py:281][0m #------------------------ Iteration 589 --------------------------#
[32m[20221124 23:49:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.0
[32m[20221124 23:49:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.6
[32m[20221124 23:49:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.6
[32m[20221124 23:49:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.2
[32m[20221124 23:49:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 10.8
[32m[20221124 23:49:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.0
[32m[20221124 23:49:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.0
[32m[20221124 23:49:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.4
[32m[20221124 23:49:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 7.0
[32m[20221124 23:49:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.0
[32m[20221124 23:49:15 @pendulum_agent.py:307][0m Sample time: 3.848716974258423
[32m[20221124 23:49:24 @pendulum_agent.py:312][0m Update time: 8.797489881515503
[32m[20221124 23:49:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 948.0
[32m[20221124 23:49:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 948.0
[32m[20221124 23:49:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 948.0
[32m[20221124 23:49:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 948.0
[32m[20221124 23:49:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 948.0
[32m[20221124 23:49:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 948.0
[32m[20221124 23:49:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 948.0
[32m[20221124 23:49:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 948.0
[32m[20221124 23:49:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 948.0
[32m[20221124 23:49:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 948.0
[32m[20221124 23:49:24 @pendulum_agent.py:317][0m Evaluation time: 0.5794072151184082
[32m[20221124 23:49:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.96
[32m[20221124 23:49:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:49:24 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:49:24 @pendulum_agent.py:289][0m Total time: 8833.998866081238
[32m[20221124 23:49:24 @pendulum_agent.py:291][0m 29500000 total steps have happened
[32m[20221124 23:49:24 @pendulum_agent.py:281][0m #------------------------ Iteration 590 --------------------------#
[32m[20221124 23:49:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:49:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:49:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:49:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:49:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:49:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:49:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:49:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:49:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:49:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:49:28 @pendulum_agent.py:307][0m Sample time: 3.611567974090576
[32m[20221124 23:49:37 @pendulum_agent.py:312][0m Update time: 9.292757987976074
[32m[20221124 23:49:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:49:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:49:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:49:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:49:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:49:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:49:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:49:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:49:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:49:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:49:38 @pendulum_agent.py:317][0m Evaluation time: 0.827089786529541
[32m[20221124 23:49:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:49:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:49:38 @pendulum_agent.py:289][0m Total time: 8848.025589942932
[32m[20221124 23:49:38 @pendulum_agent.py:291][0m 29550000 total steps have happened
[32m[20221124 23:49:38 @pendulum_agent.py:281][0m #------------------------ Iteration 591 --------------------------#
[32m[20221124 23:49:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.4
[32m[20221124 23:49:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.4
[32m[20221124 23:49:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.4
[32m[20221124 23:49:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.4
[32m[20221124 23:49:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.4
[32m[20221124 23:49:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 8.0
[32m[20221124 23:49:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.0
[32m[20221124 23:49:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.8
[32m[20221124 23:49:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.6
[32m[20221124 23:49:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.2
[32m[20221124 23:49:42 @pendulum_agent.py:307][0m Sample time: 3.596630096435547
[32m[20221124 23:49:51 @pendulum_agent.py:312][0m Update time: 9.276798963546753
[32m[20221124 23:49:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:49:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:49:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:49:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:49:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:49:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:49:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:49:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:49:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:49:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:49:52 @pendulum_agent.py:317][0m Evaluation time: 1.0419731140136719
[32m[20221124 23:49:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.06
[32m[20221124 23:49:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:49:53 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:49:53 @pendulum_agent.py:289][0m Total time: 8862.232477903366
[32m[20221124 23:49:53 @pendulum_agent.py:291][0m 29600000 total steps have happened
[32m[20221124 23:49:53 @pendulum_agent.py:281][0m #------------------------ Iteration 592 --------------------------#
[32m[20221124 23:49:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:49:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:49:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:49:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:49:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:49:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:49:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:49:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:49:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:49:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:49:56 @pendulum_agent.py:307][0m Sample time: 3.5936079025268555
[32m[20221124 23:50:05 @pendulum_agent.py:312][0m Update time: 9.161714315414429
[32m[20221124 23:50:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:50:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:50:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:50:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:50:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:50:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:50:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:50:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:50:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:50:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:50:06 @pendulum_agent.py:317][0m Evaluation time: 0.7268078327178955
[32m[20221124 23:50:06 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:50:06 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:50:06 @pendulum_agent.py:289][0m Total time: 8875.98896408081
[32m[20221124 23:50:06 @pendulum_agent.py:291][0m 29650000 total steps have happened
[32m[20221124 23:50:06 @pendulum_agent.py:281][0m #------------------------ Iteration 593 --------------------------#
[32m[20221124 23:50:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:50:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:50:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:50:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:50:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:50:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:50:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:50:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:50:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:50:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:50:10 @pendulum_agent.py:307][0m Sample time: 3.5933852195739746
[32m[20221124 23:50:20 @pendulum_agent.py:312][0m Update time: 9.618444919586182
[32m[20221124 23:50:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:50:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:50:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:50:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:50:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:50:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:50:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:50:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:50:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:50:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:50:20 @pendulum_agent.py:317][0m Evaluation time: 0.5943121910095215
[32m[20221124 23:50:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:50:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:50:20 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:50:20 @pendulum_agent.py:289][0m Total time: 8890.075778007507
[32m[20221124 23:50:20 @pendulum_agent.py:291][0m 29700000 total steps have happened
[32m[20221124 23:50:20 @pendulum_agent.py:281][0m #------------------------ Iteration 594 --------------------------#
[32m[20221124 23:50:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.6
[32m[20221124 23:50:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.8
[32m[20221124 23:50:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.0
[32m[20221124 23:50:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.6
[32m[20221124 23:50:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.4
[32m[20221124 23:50:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.8
[32m[20221124 23:50:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.4
[32m[20221124 23:50:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.0
[32m[20221124 23:50:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.0
[32m[20221124 23:50:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.4
[32m[20221124 23:50:24 @pendulum_agent.py:307][0m Sample time: 3.7834413051605225
[32m[20221124 23:50:34 @pendulum_agent.py:312][0m Update time: 9.677352905273438
[32m[20221124 23:50:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:50:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:50:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:50:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:50:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:50:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:50:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:50:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:50:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:50:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:50:35 @pendulum_agent.py:317][0m Evaluation time: 0.6956729888916016
[32m[20221124 23:50:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.9
[32m[20221124 23:50:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:50:35 @pendulum_agent.py:289][0m Total time: 8904.533831119537
[32m[20221124 23:50:35 @pendulum_agent.py:291][0m 29750000 total steps have happened
[32m[20221124 23:50:35 @pendulum_agent.py:281][0m #------------------------ Iteration 595 --------------------------#
[32m[20221124 23:50:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:50:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:50:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:50:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:50:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:50:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:50:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:50:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:50:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:50:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:50:39 @pendulum_agent.py:307][0m Sample time: 3.734189033508301
[32m[20221124 23:50:48 @pendulum_agent.py:312][0m Update time: 9.839104175567627
[32m[20221124 23:50:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:50:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:50:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:50:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:50:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:50:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:50:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:50:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:50:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:50:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:50:49 @pendulum_agent.py:317][0m Evaluation time: 0.7033426761627197
[32m[20221124 23:50:49 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:50:49 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:50:50 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:50:50 @pendulum_agent.py:289][0m Total time: 8919.10798406601
[32m[20221124 23:50:50 @pendulum_agent.py:291][0m 29800000 total steps have happened
[32m[20221124 23:50:50 @pendulum_agent.py:281][0m #------------------------ Iteration 596 --------------------------#
[32m[20221124 23:50:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:50:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:50:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:50:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:50:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:50:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:50:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:50:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:50:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:50:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:50:53 @pendulum_agent.py:307][0m Sample time: 3.5693840980529785
[32m[20221124 23:51:04 @pendulum_agent.py:312][0m Update time: 10.485342025756836
[32m[20221124 23:51:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:51:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:51:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:51:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:51:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:51:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:51:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:51:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:51:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:51:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:51:04 @pendulum_agent.py:317][0m Evaluation time: 0.9371509552001953
[32m[20221124 23:51:05 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:51:05 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:51:05 @pendulum_agent.py:289][0m Total time: 8934.408386945724
[32m[20221124 23:51:05 @pendulum_agent.py:291][0m 29850000 total steps have happened
[32m[20221124 23:51:05 @pendulum_agent.py:281][0m #------------------------ Iteration 597 --------------------------#
[32m[20221124 23:51:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:51:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:51:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:51:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:51:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:51:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:51:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:51:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:51:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:51:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:51:08 @pendulum_agent.py:307][0m Sample time: 3.665677785873413
[32m[20221124 23:51:17 @pendulum_agent.py:312][0m Update time: 8.70911717414856
[32m[20221124 23:51:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:51:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:51:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:51:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:51:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:51:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:51:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:51:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:51:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:51:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:51:18 @pendulum_agent.py:317][0m Evaluation time: 0.6932828426361084
[32m[20221124 23:51:18 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:51:18 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:51:18 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:51:18 @pendulum_agent.py:289][0m Total time: 8947.769686937332
[32m[20221124 23:51:18 @pendulum_agent.py:291][0m 29900000 total steps have happened
[32m[20221124 23:51:18 @pendulum_agent.py:281][0m #------------------------ Iteration 598 --------------------------#
[32m[20221124 23:51:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:51:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:51:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:51:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:51:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:51:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:51:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:51:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:51:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:51:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:51:22 @pendulum_agent.py:307][0m Sample time: 3.6215391159057617
[32m[20221124 23:51:31 @pendulum_agent.py:312][0m Update time: 8.95591688156128
[32m[20221124 23:51:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:51:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:51:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:51:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:51:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:51:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:51:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:51:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:51:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:51:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:51:31 @pendulum_agent.py:317][0m Evaluation time: 0.6940670013427734
[32m[20221124 23:51:32 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:51:32 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:51:32 @pendulum_agent.py:289][0m Total time: 8961.352823019028
[32m[20221124 23:51:32 @pendulum_agent.py:291][0m 29950000 total steps have happened
[32m[20221124 23:51:32 @pendulum_agent.py:281][0m #------------------------ Iteration 599 --------------------------#
[32m[20221124 23:51:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:51:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:51:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:51:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:51:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:51:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:51:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:51:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:51:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:51:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:51:35 @pendulum_agent.py:307][0m Sample time: 3.3988919258117676
[32m[20221124 23:51:44 @pendulum_agent.py:312][0m Update time: 9.128064155578613
[32m[20221124 23:51:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:51:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:51:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:51:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:51:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:51:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:51:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:51:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:51:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:51:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:51:45 @pendulum_agent.py:317][0m Evaluation time: 0.9420280456542969
[32m[20221124 23:51:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:51:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:51:45 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:51:45 @pendulum_agent.py:289][0m Total time: 8975.095094919205
[32m[20221124 23:51:45 @pendulum_agent.py:291][0m 30000000 total steps have happened
[32m[20221124 23:51:45 @pendulum_agent.py:281][0m #------------------------ Iteration 600 --------------------------#
[32m[20221124 23:51:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.8
[32m[20221124 23:51:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.6
[32m[20221124 23:51:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.0
[32m[20221124 23:51:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.2
[32m[20221124 23:51:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.8
[32m[20221124 23:51:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.4
[32m[20221124 23:51:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.6
[32m[20221124 23:51:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.2
[32m[20221124 23:51:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.4
[32m[20221124 23:51:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.8
[32m[20221124 23:51:49 @pendulum_agent.py:307][0m Sample time: 3.35699725151062
[32m[20221124 23:51:58 @pendulum_agent.py:312][0m Update time: 9.57008695602417
[32m[20221124 23:51:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:51:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:51:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:51:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:51:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:51:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:51:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:51:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:51:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:51:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:52:00 @pendulum_agent.py:317][0m Evaluation time: 1.651939868927002
[32m[20221124 23:52:00 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.38
[32m[20221124 23:52:00 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:52:00 @pendulum_agent.py:289][0m Total time: 8989.965369939804
[32m[20221124 23:52:00 @pendulum_agent.py:291][0m 30050000 total steps have happened
[32m[20221124 23:52:00 @pendulum_agent.py:281][0m #------------------------ Iteration 601 --------------------------#
[32m[20221124 23:52:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:52:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:52:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:52:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:52:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:52:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:52:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:52:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:52:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:52:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:52:04 @pendulum_agent.py:307][0m Sample time: 3.7727210521698
[32m[20221124 23:52:13 @pendulum_agent.py:312][0m Update time: 8.663882970809937
[32m[20221124 23:52:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:52:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:52:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:52:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:52:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:52:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:52:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:52:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:52:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:52:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:52:14 @pendulum_agent.py:317][0m Evaluation time: 0.7276339530944824
[32m[20221124 23:52:14 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:52:14 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:52:14 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:52:14 @pendulum_agent.py:289][0m Total time: 9003.4250228405
[32m[20221124 23:52:14 @pendulum_agent.py:291][0m 30100000 total steps have happened
[32m[20221124 23:52:14 @pendulum_agent.py:281][0m #------------------------ Iteration 602 --------------------------#
[32m[20221124 23:52:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 8.6
[32m[20221124 23:52:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 9.2
[32m[20221124 23:52:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 9.2
[32m[20221124 23:52:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.6
[32m[20221124 23:52:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 8.2
[32m[20221124 23:52:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 10.4
[32m[20221124 23:52:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 7.6
[32m[20221124 23:52:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.6
[32m[20221124 23:52:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 8.4
[32m[20221124 23:52:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 13.2
[32m[20221124 23:52:17 @pendulum_agent.py:307][0m Sample time: 3.653467893600464
[32m[20221124 23:52:26 @pendulum_agent.py:312][0m Update time: 8.806839227676392
[32m[20221124 23:52:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:52:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:52:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:52:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:52:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:52:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:52:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:52:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:52:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:52:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:52:27 @pendulum_agent.py:317][0m Evaluation time: 0.6987318992614746
[32m[20221124 23:52:27 @pendulum_agent.py:285][0m Average TRAINING episode reward: 9.0
[32m[20221124 23:52:27 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:52:27 @pendulum_agent.py:289][0m Total time: 9016.856569051743
[32m[20221124 23:52:27 @pendulum_agent.py:291][0m 30150000 total steps have happened
[32m[20221124 23:52:27 @pendulum_agent.py:281][0m #------------------------ Iteration 603 --------------------------#
[32m[20221124 23:52:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:52:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:52:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:52:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:52:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:52:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:52:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:52:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:52:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:52:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:52:31 @pendulum_agent.py:307][0m Sample time: 3.7554399967193604
[32m[20221124 23:52:41 @pendulum_agent.py:312][0m Update time: 10.196694135665894
[32m[20221124 23:52:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:52:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:52:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:52:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:52:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:52:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:52:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:52:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:52:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:52:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:52:42 @pendulum_agent.py:317][0m Evaluation time: 0.6912078857421875
[32m[20221124 23:52:42 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:52:42 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:52:42 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:52:42 @pendulum_agent.py:289][0m Total time: 9031.798194885254
[32m[20221124 23:52:42 @pendulum_agent.py:291][0m 30200000 total steps have happened
[32m[20221124 23:52:42 @pendulum_agent.py:281][0m #------------------------ Iteration 604 --------------------------#
[32m[20221124 23:52:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:52:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:52:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:52:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:52:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:52:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:52:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:52:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:52:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:52:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:52:46 @pendulum_agent.py:307][0m Sample time: 3.589306116104126
[32m[20221124 23:52:55 @pendulum_agent.py:312][0m Update time: 9.31336784362793
[32m[20221124 23:52:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:52:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:52:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:52:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:52:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:52:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:52:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:52:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:52:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:52:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:52:56 @pendulum_agent.py:317][0m Evaluation time: 0.8079721927642822
[32m[20221124 23:52:56 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:52:56 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:52:56 @pendulum_agent.py:289][0m Total time: 9045.801549911499
[32m[20221124 23:52:56 @pendulum_agent.py:291][0m 30250000 total steps have happened
[32m[20221124 23:52:56 @pendulum_agent.py:281][0m #------------------------ Iteration 605 --------------------------#
[32m[20221124 23:52:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:52:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:52:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:52:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:52:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:52:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:52:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:52:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:52:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:52:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:53:00 @pendulum_agent.py:307][0m Sample time: 3.6283118724823
[32m[20221124 23:53:09 @pendulum_agent.py:312][0m Update time: 8.804206132888794
[32m[20221124 23:53:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:53:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:53:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:53:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:53:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:53:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:53:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:53:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:53:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:53:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:53:09 @pendulum_agent.py:317][0m Evaluation time: 0.8094727993011475
[32m[20221124 23:53:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:53:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:53:10 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:53:10 @pendulum_agent.py:289][0m Total time: 9059.378509044647
[32m[20221124 23:53:10 @pendulum_agent.py:291][0m 30300000 total steps have happened
[32m[20221124 23:53:10 @pendulum_agent.py:281][0m #------------------------ Iteration 606 --------------------------#
[32m[20221124 23:53:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:53:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:53:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:53:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:53:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:53:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:53:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:53:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:53:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:53:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:53:14 @pendulum_agent.py:307][0m Sample time: 3.926609992980957
[32m[20221124 23:53:23 @pendulum_agent.py:312][0m Update time: 9.185950994491577
[32m[20221124 23:53:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:53:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:53:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:53:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:53:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:53:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:53:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:53:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:53:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:53:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:53:24 @pendulum_agent.py:317][0m Evaluation time: 0.7005031108856201
[32m[20221124 23:53:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:53:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:53:24 @pendulum_agent.py:289][0m Total time: 9073.450294017792
[32m[20221124 23:53:24 @pendulum_agent.py:291][0m 30350000 total steps have happened
[32m[20221124 23:53:24 @pendulum_agent.py:281][0m #------------------------ Iteration 607 --------------------------#
[32m[20221124 23:53:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:53:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:53:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:53:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:53:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:53:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:53:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:53:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:53:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:53:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:53:27 @pendulum_agent.py:307][0m Sample time: 3.600311756134033
[32m[20221124 23:53:36 @pendulum_agent.py:312][0m Update time: 9.02461314201355
[32m[20221124 23:53:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:53:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:53:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:53:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:53:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:53:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:53:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:53:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:53:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:53:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:53:37 @pendulum_agent.py:317][0m Evaluation time: 0.6707441806793213
[32m[20221124 23:53:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:53:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:53:37 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:53:37 @pendulum_agent.py:289][0m Total time: 9087.022225141525
[32m[20221124 23:53:37 @pendulum_agent.py:291][0m 30400000 total steps have happened
[32m[20221124 23:53:37 @pendulum_agent.py:281][0m #------------------------ Iteration 608 --------------------------#
[32m[20221124 23:53:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:53:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:53:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:53:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:53:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:53:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:53:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:53:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:53:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:53:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:53:41 @pendulum_agent.py:307][0m Sample time: 3.4791719913482666
[32m[20221124 23:53:52 @pendulum_agent.py:312][0m Update time: 10.739205837249756
[32m[20221124 23:53:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:53:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:53:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:53:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:53:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:53:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:53:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:53:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:53:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:53:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:53:52 @pendulum_agent.py:317][0m Evaluation time: 0.8485541343688965
[32m[20221124 23:53:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:53:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:53:53 @pendulum_agent.py:289][0m Total time: 9102.359568119049
[32m[20221124 23:53:53 @pendulum_agent.py:291][0m 30450000 total steps have happened
[32m[20221124 23:53:53 @pendulum_agent.py:281][0m #------------------------ Iteration 609 --------------------------#
[32m[20221124 23:53:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:53:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:53:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:53:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:53:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:53:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:53:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:53:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:53:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:53:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:53:56 @pendulum_agent.py:307][0m Sample time: 3.468942165374756
[32m[20221124 23:54:06 @pendulum_agent.py:312][0m Update time: 9.947641134262085
[32m[20221124 23:54:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:54:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:54:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:54:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:54:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:54:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:54:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:54:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:54:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:54:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:54:07 @pendulum_agent.py:317][0m Evaluation time: 1.0329468250274658
[32m[20221124 23:54:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:54:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:54:07 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:54:07 @pendulum_agent.py:289][0m Total time: 9117.086822032928
[32m[20221124 23:54:07 @pendulum_agent.py:291][0m 30500000 total steps have happened
[32m[20221124 23:54:07 @pendulum_agent.py:281][0m #------------------------ Iteration 610 --------------------------#
[32m[20221124 23:54:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:54:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:54:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:54:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:54:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:54:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:54:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:54:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:54:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:54:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:54:11 @pendulum_agent.py:307][0m Sample time: 3.3848822116851807
[32m[20221124 23:54:24 @pendulum_agent.py:312][0m Update time: 13.613629817962646
[32m[20221124 23:54:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:54:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:54:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:54:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:54:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:54:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:54:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:54:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:54:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:54:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:54:26 @pendulum_agent.py:317][0m Evaluation time: 1.1544971466064453
[32m[20221124 23:54:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:54:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:54:26 @pendulum_agent.py:289][0m Total time: 9135.516821861267
[32m[20221124 23:54:26 @pendulum_agent.py:291][0m 30550000 total steps have happened
[32m[20221124 23:54:26 @pendulum_agent.py:281][0m #------------------------ Iteration 611 --------------------------#
[32m[20221124 23:54:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:54:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:54:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:54:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:54:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:54:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:54:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:54:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:54:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:54:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:54:29 @pendulum_agent.py:307][0m Sample time: 3.4193050861358643
[32m[20221124 23:54:38 @pendulum_agent.py:312][0m Update time: 8.717231035232544
[32m[20221124 23:54:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:54:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:54:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:54:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:54:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:54:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:54:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:54:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:54:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:54:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:54:40 @pendulum_agent.py:317][0m Evaluation time: 1.7996718883514404
[32m[20221124 23:54:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:54:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:54:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:54:40 @pendulum_agent.py:289][0m Total time: 9149.736824989319
[32m[20221124 23:54:40 @pendulum_agent.py:291][0m 30600000 total steps have happened
[32m[20221124 23:54:40 @pendulum_agent.py:281][0m #------------------------ Iteration 612 --------------------------#
[32m[20221124 23:54:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 14.8
[32m[20221124 23:54:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 9.6
[32m[20221124 23:54:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 11.0
[32m[20221124 23:54:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 13.0
[32m[20221124 23:54:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.4
[32m[20221124 23:54:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 20.6
[32m[20221124 23:54:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 15.2
[32m[20221124 23:54:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 13.2
[32m[20221124 23:54:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 9.8
[32m[20221124 23:54:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 11.4
[32m[20221124 23:54:44 @pendulum_agent.py:307][0m Sample time: 3.59879994392395
[32m[20221124 23:54:53 @pendulum_agent.py:312][0m Update time: 8.79221510887146
[32m[20221124 23:54:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:54:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:54:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:54:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:54:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:54:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:54:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:54:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:54:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:54:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:54:53 @pendulum_agent.py:317][0m Evaluation time: 0.6921191215515137
[32m[20221124 23:54:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 12.6
[32m[20221124 23:54:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:54:53 @pendulum_agent.py:289][0m Total time: 9163.093039035797
[32m[20221124 23:54:53 @pendulum_agent.py:291][0m 30650000 total steps have happened
[32m[20221124 23:54:53 @pendulum_agent.py:281][0m #------------------------ Iteration 613 --------------------------#
[32m[20221124 23:54:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:54:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:54:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:54:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:54:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:54:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:54:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:54:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:54:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:54:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:54:57 @pendulum_agent.py:307][0m Sample time: 3.674057960510254
[32m[20221124 23:55:06 @pendulum_agent.py:312][0m Update time: 8.607079267501831
[32m[20221124 23:55:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:55:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:55:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:55:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:55:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:55:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:55:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:55:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:55:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:55:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:55:07 @pendulum_agent.py:317][0m Evaluation time: 0.9249489307403564
[32m[20221124 23:55:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:55:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:55:07 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:55:07 @pendulum_agent.py:289][0m Total time: 9176.573105096817
[32m[20221124 23:55:07 @pendulum_agent.py:291][0m 30700000 total steps have happened
[32m[20221124 23:55:07 @pendulum_agent.py:281][0m #------------------------ Iteration 614 --------------------------#
[32m[20221124 23:55:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:55:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:55:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:55:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:55:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:55:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:55:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:55:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:55:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:55:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:55:11 @pendulum_agent.py:307][0m Sample time: 3.852259874343872
[32m[20221124 23:55:22 @pendulum_agent.py:312][0m Update time: 10.719067096710205
[32m[20221124 23:55:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:55:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:55:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:55:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:55:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:55:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:55:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:55:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:55:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:55:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:55:22 @pendulum_agent.py:317][0m Evaluation time: 0.9032440185546875
[32m[20221124 23:55:23 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:55:23 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:55:23 @pendulum_agent.py:289][0m Total time: 9192.32397198677
[32m[20221124 23:55:23 @pendulum_agent.py:291][0m 30750000 total steps have happened
[32m[20221124 23:55:23 @pendulum_agent.py:281][0m #------------------------ Iteration 615 --------------------------#
[32m[20221124 23:55:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:55:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:55:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:55:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:55:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:55:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:55:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:55:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:55:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:55:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:55:27 @pendulum_agent.py:307][0m Sample time: 3.9016411304473877
[32m[20221124 23:55:35 @pendulum_agent.py:312][0m Update time: 8.70107388496399
[32m[20221124 23:55:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:55:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:55:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:55:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:55:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:55:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:55:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:55:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:55:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:55:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:55:36 @pendulum_agent.py:317][0m Evaluation time: 0.6946322917938232
[32m[20221124 23:55:36 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:55:36 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:55:36 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:55:36 @pendulum_agent.py:289][0m Total time: 9205.895240068436
[32m[20221124 23:55:36 @pendulum_agent.py:291][0m 30800000 total steps have happened
[32m[20221124 23:55:36 @pendulum_agent.py:281][0m #------------------------ Iteration 616 --------------------------#
[32m[20221124 23:55:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:55:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:55:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:55:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:55:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:55:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:55:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:55:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:55:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:55:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:55:40 @pendulum_agent.py:307][0m Sample time: 3.5683047771453857
[32m[20221124 23:55:49 @pendulum_agent.py:312][0m Update time: 8.746445178985596
[32m[20221124 23:55:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:55:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:55:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:55:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:55:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:55:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:55:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:55:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:55:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:55:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:55:49 @pendulum_agent.py:317][0m Evaluation time: 0.5589931011199951
[32m[20221124 23:55:49 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:55:49 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:55:49 @pendulum_agent.py:289][0m Total time: 9219.067805051804
[32m[20221124 23:55:49 @pendulum_agent.py:291][0m 30850000 total steps have happened
[32m[20221124 23:55:49 @pendulum_agent.py:281][0m #------------------------ Iteration 617 --------------------------#
[32m[20221124 23:55:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 8.2
[32m[20221124 23:55:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 9.0
[32m[20221124 23:55:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.6
[32m[20221124 23:55:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.4
[32m[20221124 23:55:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 7.6
[32m[20221124 23:55:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.2
[32m[20221124 23:55:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 9.4
[32m[20221124 23:55:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.6
[32m[20221124 23:55:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.0
[32m[20221124 23:55:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 9.6
[32m[20221124 23:55:53 @pendulum_agent.py:307][0m Sample time: 3.7722299098968506
[32m[20221124 23:56:02 @pendulum_agent.py:312][0m Update time: 8.651340961456299
[32m[20221124 23:56:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:56:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:56:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:56:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:56:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:56:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:56:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:56:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:56:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:56:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:56:02 @pendulum_agent.py:317][0m Evaluation time: 0.5807859897613525
[32m[20221124 23:56:03 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.86
[32m[20221124 23:56:03 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:56:03 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:56:03 @pendulum_agent.py:289][0m Total time: 9232.373819112778
[32m[20221124 23:56:03 @pendulum_agent.py:291][0m 30900000 total steps have happened
[32m[20221124 23:56:03 @pendulum_agent.py:281][0m #------------------------ Iteration 618 --------------------------#
[32m[20221124 23:56:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.2
[32m[20221124 23:56:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.8
[32m[20221124 23:56:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.4
[32m[20221124 23:56:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.0
[32m[20221124 23:56:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.2
[32m[20221124 23:56:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.2
[32m[20221124 23:56:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.2
[32m[20221124 23:56:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.8
[32m[20221124 23:56:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.2
[32m[20221124 23:56:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.4
[32m[20221124 23:56:06 @pendulum_agent.py:307][0m Sample time: 3.7263753414154053
[32m[20221124 23:56:20 @pendulum_agent.py:312][0m Update time: 13.20354676246643
[32m[20221124 23:56:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:56:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:56:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:56:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:56:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:56:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:56:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:56:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:56:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:56:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:56:20 @pendulum_agent.py:317][0m Evaluation time: 0.574923038482666
[32m[20221124 23:56:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.74
[32m[20221124 23:56:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:56:21 @pendulum_agent.py:289][0m Total time: 9250.186428070068
[32m[20221124 23:56:21 @pendulum_agent.py:291][0m 30950000 total steps have happened
[32m[20221124 23:56:21 @pendulum_agent.py:281][0m #------------------------ Iteration 619 --------------------------#
[32m[20221124 23:56:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 10.8
[32m[20221124 23:56:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 9.0
[32m[20221124 23:56:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:56:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 9.6
[32m[20221124 23:56:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 10.8
[32m[20221124 23:56:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.8
[32m[20221124 23:56:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 17.0
[32m[20221124 23:56:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 14.6
[32m[20221124 23:56:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 13.2
[32m[20221124 23:56:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 10.0
[32m[20221124 23:56:24 @pendulum_agent.py:307][0m Sample time: 3.8025147914886475
[32m[20221124 23:56:34 @pendulum_agent.py:312][0m Update time: 10.071935415267944
[32m[20221124 23:56:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:56:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:56:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:56:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:56:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:56:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:56:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:56:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:56:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:56:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:56:35 @pendulum_agent.py:317][0m Evaluation time: 0.6826367378234863
[32m[20221124 23:56:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 10.28
[32m[20221124 23:56:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:56:35 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:56:35 @pendulum_agent.py:289][0m Total time: 9265.024002075195
[32m[20221124 23:56:35 @pendulum_agent.py:291][0m 31000000 total steps have happened
[32m[20221124 23:56:35 @pendulum_agent.py:281][0m #------------------------ Iteration 620 --------------------------#
[32m[20221124 23:56:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 15.2
[32m[20221124 23:56:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 7.2
[32m[20221124 23:56:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 11.6
[32m[20221124 23:56:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 11.2
[32m[20221124 23:56:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 12.0
[32m[20221124 23:56:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 7.4
[32m[20221124 23:56:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 12.0
[32m[20221124 23:56:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 14.0
[32m[20221124 23:56:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 8.0
[32m[20221124 23:56:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 11.0
[32m[20221124 23:56:39 @pendulum_agent.py:307][0m Sample time: 3.5575270652770996
[32m[20221124 23:56:55 @pendulum_agent.py:312][0m Update time: 15.958416938781738
[32m[20221124 23:56:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:56:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:56:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:56:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:56:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:56:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:56:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:56:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:56:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:56:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:56:56 @pendulum_agent.py:317][0m Evaluation time: 0.8093328475952148
[32m[20221124 23:56:56 @pendulum_agent.py:285][0m Average TRAINING episode reward: 10.96
[32m[20221124 23:56:56 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:56:56 @pendulum_agent.py:289][0m Total time: 9285.644455909729
[32m[20221124 23:56:56 @pendulum_agent.py:291][0m 31050000 total steps have happened
[32m[20221124 23:56:56 @pendulum_agent.py:281][0m #------------------------ Iteration 621 --------------------------#
[32m[20221124 23:56:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:56:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:56:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:56:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:56:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:56:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:56:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:56:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:56:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:56:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:56:59 @pendulum_agent.py:307][0m Sample time: 3.343390941619873
[32m[20221124 23:57:18 @pendulum_agent.py:312][0m Update time: 18.19773268699646
[32m[20221124 23:57:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:57:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:57:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:57:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:57:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:57:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:57:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:57:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:57:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:57:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:57:19 @pendulum_agent.py:317][0m Evaluation time: 1.0215601921081543
[32m[20221124 23:57:19 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:57:19 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:57:19 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:57:19 @pendulum_agent.py:289][0m Total time: 9308.480473995209
[32m[20221124 23:57:19 @pendulum_agent.py:291][0m 31100000 total steps have happened
[32m[20221124 23:57:19 @pendulum_agent.py:281][0m #------------------------ Iteration 622 --------------------------#
[32m[20221124 23:57:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:57:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:57:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:57:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:57:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:57:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:57:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:57:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:57:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:57:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:57:23 @pendulum_agent.py:307][0m Sample time: 3.6975040435791016
[32m[20221124 23:57:35 @pendulum_agent.py:312][0m Update time: 12.197309970855713
[32m[20221124 23:57:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:57:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:57:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:57:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:57:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:57:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:57:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:57:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:57:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:57:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:57:36 @pendulum_agent.py:317][0m Evaluation time: 1.1482610702514648
[32m[20221124 23:57:36 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:57:36 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:57:36 @pendulum_agent.py:289][0m Total time: 9325.802547931671
[32m[20221124 23:57:36 @pendulum_agent.py:291][0m 31150000 total steps have happened
[32m[20221124 23:57:36 @pendulum_agent.py:281][0m #------------------------ Iteration 623 --------------------------#
[32m[20221124 23:57:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.4
[32m[20221124 23:57:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.2
[32m[20221124 23:57:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.0
[32m[20221124 23:57:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.8
[32m[20221124 23:57:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.2
[32m[20221124 23:57:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 9.2
[32m[20221124 23:57:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.2
[32m[20221124 23:57:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.4
[32m[20221124 23:57:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 13.2
[32m[20221124 23:57:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 9.8
[32m[20221124 23:57:39 @pendulum_agent.py:307][0m Sample time: 3.2984888553619385
[32m[20221124 23:57:48 @pendulum_agent.py:312][0m Update time: 8.558087348937988
[32m[20221124 23:57:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:57:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:57:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:57:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:57:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:57:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:57:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:57:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:57:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:57:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:57:49 @pendulum_agent.py:317][0m Evaluation time: 1.1515657901763916
[32m[20221124 23:57:49 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.74
[32m[20221124 23:57:49 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:57:49 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:57:49 @pendulum_agent.py:289][0m Total time: 9339.083218812943
[32m[20221124 23:57:49 @pendulum_agent.py:291][0m 31200000 total steps have happened
[32m[20221124 23:57:49 @pendulum_agent.py:281][0m #------------------------ Iteration 624 --------------------------#
[32m[20221124 23:57:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:57:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:57:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:57:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:57:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:57:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:57:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:57:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:57:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:57:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:57:53 @pendulum_agent.py:307][0m Sample time: 3.652590751647949
[32m[20221124 23:58:02 @pendulum_agent.py:312][0m Update time: 8.69356107711792
[32m[20221124 23:58:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:58:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:58:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:58:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:58:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:58:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:58:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:58:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:58:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:58:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:58:03 @pendulum_agent.py:317][0m Evaluation time: 0.722893238067627
[32m[20221124 23:58:03 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:58:03 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:58:03 @pendulum_agent.py:289][0m Total time: 9352.427869796753
[32m[20221124 23:58:03 @pendulum_agent.py:291][0m 31250000 total steps have happened
[32m[20221124 23:58:03 @pendulum_agent.py:281][0m #------------------------ Iteration 625 --------------------------#
[32m[20221124 23:58:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:58:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:58:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:58:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:58:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:58:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:58:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:58:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:58:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:58:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:58:07 @pendulum_agent.py:307][0m Sample time: 3.735342025756836
[32m[20221124 23:58:17 @pendulum_agent.py:312][0m Update time: 10.05063509941101
[32m[20221124 23:58:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 956.0
[32m[20221124 23:58:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 956.0
[32m[20221124 23:58:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 956.0
[32m[20221124 23:58:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 956.0
[32m[20221124 23:58:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 956.0
[32m[20221124 23:58:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 956.0
[32m[20221124 23:58:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 956.0
[32m[20221124 23:58:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 956.0
[32m[20221124 23:58:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 956.0
[32m[20221124 23:58:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 956.0
[32m[20221124 23:58:17 @pendulum_agent.py:317][0m Evaluation time: 0.7203748226165771
[32m[20221124 23:58:18 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:58:18 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:58:18 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:58:18 @pendulum_agent.py:289][0m Total time: 9367.219795942307
[32m[20221124 23:58:18 @pendulum_agent.py:291][0m 31300000 total steps have happened
[32m[20221124 23:58:18 @pendulum_agent.py:281][0m #------------------------ Iteration 626 --------------------------#
[32m[20221124 23:58:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:58:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:58:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:58:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:58:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:58:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:58:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:58:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:58:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:58:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:58:21 @pendulum_agent.py:307][0m Sample time: 3.573683977127075
[32m[20221124 23:58:37 @pendulum_agent.py:312][0m Update time: 15.87633204460144
[32m[20221124 23:58:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:58:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:58:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:58:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:58:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:58:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:58:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:58:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:58:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:58:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:58:38 @pendulum_agent.py:317][0m Evaluation time: 0.7049429416656494
[32m[20221124 23:58:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:58:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:58:38 @pendulum_agent.py:289][0m Total time: 9387.657975912094
[32m[20221124 23:58:38 @pendulum_agent.py:291][0m 31350000 total steps have happened
[32m[20221124 23:58:38 @pendulum_agent.py:281][0m #------------------------ Iteration 627 --------------------------#
[32m[20221124 23:58:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:58:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:58:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:58:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:58:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:58:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:58:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:58:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:58:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:58:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:58:42 @pendulum_agent.py:307][0m Sample time: 3.8474676609039307
[32m[20221124 23:58:57 @pendulum_agent.py:312][0m Update time: 14.754189014434814
[32m[20221124 23:58:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:58:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:58:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:58:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:58:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:58:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:58:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:58:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:58:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:58:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:58:57 @pendulum_agent.py:317][0m Evaluation time: 0.5638630390167236
[32m[20221124 23:58:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:58:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:58:58 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:58:58 @pendulum_agent.py:289][0m Total time: 9407.127578020096
[32m[20221124 23:58:58 @pendulum_agent.py:291][0m 31400000 total steps have happened
[32m[20221124 23:58:58 @pendulum_agent.py:281][0m #------------------------ Iteration 628 --------------------------#
[32m[20221124 23:58:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:58:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:58:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:58:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:58:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:58:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:58:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:58:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:58:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:58:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:59:01 @pendulum_agent.py:307][0m Sample time: 3.761820077896118
[32m[20221124 23:59:10 @pendulum_agent.py:312][0m Update time: 8.724565029144287
[32m[20221124 23:59:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:59:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:59:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:59:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:59:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:59:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:59:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:59:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:59:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:59:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:59:11 @pendulum_agent.py:317][0m Evaluation time: 0.6937859058380127
[32m[20221124 23:59:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:59:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:59:11 @pendulum_agent.py:289][0m Total time: 9420.591800928116
[32m[20221124 23:59:11 @pendulum_agent.py:291][0m 31450000 total steps have happened
[32m[20221124 23:59:11 @pendulum_agent.py:281][0m #------------------------ Iteration 629 --------------------------#
[32m[20221124 23:59:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:59:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:59:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:59:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:59:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:59:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:59:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:59:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:59:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:59:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:59:15 @pendulum_agent.py:307][0m Sample time: 3.72060227394104
[32m[20221124 23:59:24 @pendulum_agent.py:312][0m Update time: 8.824318885803223
[32m[20221124 23:59:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:59:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:59:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:59:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:59:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:59:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:59:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:59:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:59:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:59:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:59:24 @pendulum_agent.py:317][0m Evaluation time: 0.6933860778808594
[32m[20221124 23:59:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:59:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:59:24 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:59:25 @pendulum_agent.py:289][0m Total time: 9434.106647014618
[32m[20221124 23:59:25 @pendulum_agent.py:291][0m 31500000 total steps have happened
[32m[20221124 23:59:25 @pendulum_agent.py:281][0m #------------------------ Iteration 630 --------------------------#
[32m[20221124 23:59:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:59:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:59:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:59:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:59:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:59:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:59:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:59:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:59:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:59:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:59:28 @pendulum_agent.py:307][0m Sample time: 3.6494739055633545
[32m[20221124 23:59:37 @pendulum_agent.py:312][0m Update time: 8.818862199783325
[32m[20221124 23:59:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:59:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:59:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:59:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:59:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:59:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:59:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:59:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:59:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:59:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:59:38 @pendulum_agent.py:317][0m Evaluation time: 0.8445649147033691
[32m[20221124 23:59:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:59:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:59:38 @pendulum_agent.py:289][0m Total time: 9447.70351600647
[32m[20221124 23:59:38 @pendulum_agent.py:291][0m 31550000 total steps have happened
[32m[20221124 23:59:38 @pendulum_agent.py:281][0m #------------------------ Iteration 631 --------------------------#
[32m[20221124 23:59:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:59:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:59:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:59:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:59:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:59:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:59:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:59:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:59:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:59:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:59:41 @pendulum_agent.py:307][0m Sample time: 3.37414813041687
[32m[20221124 23:59:50 @pendulum_agent.py:312][0m Update time: 8.840962171554565
[32m[20221124 23:59:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 30.0
[32m[20221124 23:59:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 30.0
[32m[20221124 23:59:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 30.0
[32m[20221124 23:59:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 30.0
[32m[20221124 23:59:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 30.0
[32m[20221124 23:59:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 30.0
[32m[20221124 23:59:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 30.0
[32m[20221124 23:59:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 30.0
[32m[20221124 23:59:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 30.0
[32m[20221124 23:59:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 30.0
[32m[20221124 23:59:51 @pendulum_agent.py:317][0m Evaluation time: 1.028627872467041
[32m[20221124 23:59:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 23:59:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 23:59:52 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 23:59:52 @pendulum_agent.py:289][0m Total time: 9461.227754831314
[32m[20221124 23:59:52 @pendulum_agent.py:291][0m 31600000 total steps have happened
[32m[20221124 23:59:52 @pendulum_agent.py:281][0m #------------------------ Iteration 632 --------------------------#
[32m[20221124 23:59:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 23:59:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 23:59:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 23:59:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 23:59:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 23:59:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 23:59:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 23:59:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 23:59:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 23:59:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 23:59:55 @pendulum_agent.py:307][0m Sample time: 3.2043352127075195
[32m[20221125 00:00:04 @pendulum_agent.py:312][0m Update time: 8.997395038604736
[32m[20221125 00:00:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:00:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:00:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:00:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:00:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:00:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:00:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:00:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:00:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:00:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:00:05 @pendulum_agent.py:317][0m Evaluation time: 1.0502479076385498
[32m[20221125 00:00:05 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:00:05 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:00:05 @pendulum_agent.py:289][0m Total time: 9474.760574817657
[32m[20221125 00:00:05 @pendulum_agent.py:291][0m 31650000 total steps have happened
[32m[20221125 00:00:05 @pendulum_agent.py:281][0m #------------------------ Iteration 633 --------------------------#
[32m[20221125 00:00:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:00:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:00:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:00:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:00:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:00:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:00:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:00:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:00:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:00:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:00:09 @pendulum_agent.py:307][0m Sample time: 3.6606099605560303
[32m[20221125 00:00:18 @pendulum_agent.py:312][0m Update time: 8.706696033477783
[32m[20221125 00:00:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:00:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:00:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:00:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:00:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:00:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:00:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:00:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:00:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:00:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:00:18 @pendulum_agent.py:317][0m Evaluation time: 0.7152900695800781
[32m[20221125 00:00:19 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:00:19 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:00:19 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:00:19 @pendulum_agent.py:289][0m Total time: 9488.125640153885
[32m[20221125 00:00:19 @pendulum_agent.py:291][0m 31700000 total steps have happened
[32m[20221125 00:00:19 @pendulum_agent.py:281][0m #------------------------ Iteration 634 --------------------------#
[32m[20221125 00:00:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.8
[32m[20221125 00:00:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.4
[32m[20221125 00:00:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.8
[32m[20221125 00:00:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.0
[32m[20221125 00:00:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.6
[32m[20221125 00:00:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.4
[32m[20221125 00:00:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.2
[32m[20221125 00:00:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.8
[32m[20221125 00:00:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.6
[32m[20221125 00:00:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 8.8
[32m[20221125 00:00:22 @pendulum_agent.py:307][0m Sample time: 3.7771799564361572
[32m[20221125 00:00:33 @pendulum_agent.py:312][0m Update time: 10.382008075714111
[32m[20221125 00:00:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:00:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:00:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:00:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:00:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:00:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:00:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:00:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:00:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:00:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:00:33 @pendulum_agent.py:317][0m Evaluation time: 0.7090928554534912
[32m[20221125 00:00:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.84
[32m[20221125 00:00:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:00:34 @pendulum_agent.py:289][0m Total time: 9503.281466007233
[32m[20221125 00:00:34 @pendulum_agent.py:291][0m 31750000 total steps have happened
[32m[20221125 00:00:34 @pendulum_agent.py:281][0m #------------------------ Iteration 635 --------------------------#
[32m[20221125 00:00:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 10.6
[32m[20221125 00:00:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:00:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:00:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:00:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:00:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:00:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:00:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.2
[32m[20221125 00:00:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:00:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 10.8
[32m[20221125 00:00:38 @pendulum_agent.py:307][0m Sample time: 3.8430111408233643
[32m[20221125 00:00:58 @pendulum_agent.py:312][0m Update time: 20.003741025924683
[32m[20221125 00:00:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:00:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:00:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:00:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:00:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:00:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:00:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:00:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:00:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:00:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:00:58 @pendulum_agent.py:317][0m Evaluation time: 0.593289852142334
[32m[20221125 00:00:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.86
[32m[20221125 00:00:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:00:58 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:00:58 @pendulum_agent.py:289][0m Total time: 9528.016335964203
[32m[20221125 00:00:58 @pendulum_agent.py:291][0m 31800000 total steps have happened
[32m[20221125 00:00:58 @pendulum_agent.py:281][0m #------------------------ Iteration 636 --------------------------#
[32m[20221125 00:00:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:00:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:00:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:00:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:00:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:00:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:00:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:00:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:00:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:00:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:01:02 @pendulum_agent.py:307][0m Sample time: 3.661989688873291
[32m[20221125 00:01:15 @pendulum_agent.py:312][0m Update time: 12.941524028778076
[32m[20221125 00:01:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:01:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:01:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:01:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:01:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:01:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:01:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:01:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:01:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:01:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:01:16 @pendulum_agent.py:317][0m Evaluation time: 0.8332672119140625
[32m[20221125 00:01:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:01:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:01:16 @pendulum_agent.py:289][0m Total time: 9545.721300840378
[32m[20221125 00:01:16 @pendulum_agent.py:291][0m 31850000 total steps have happened
[32m[20221125 00:01:16 @pendulum_agent.py:281][0m #------------------------ Iteration 637 --------------------------#
[32m[20221125 00:01:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 10.0
[32m[20221125 00:01:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 13.2
[32m[20221125 00:01:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 11.8
[32m[20221125 00:01:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 9.0
[32m[20221125 00:01:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.4
[32m[20221125 00:01:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.4
[32m[20221125 00:01:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 9.6
[32m[20221125 00:01:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 12.8
[32m[20221125 00:01:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.4
[32m[20221125 00:01:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 8.2
[32m[20221125 00:01:20 @pendulum_agent.py:307][0m Sample time: 3.4897878170013428
[32m[20221125 00:01:28 @pendulum_agent.py:312][0m Update time: 8.70097804069519
[32m[20221125 00:01:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:01:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:01:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:01:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:01:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:01:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:01:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:01:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:01:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:01:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:01:29 @pendulum_agent.py:317][0m Evaluation time: 1.022651195526123
[32m[20221125 00:01:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 8.88
[32m[20221125 00:01:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:01:30 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:01:30 @pendulum_agent.py:289][0m Total time: 9559.212687015533
[32m[20221125 00:01:30 @pendulum_agent.py:291][0m 31900000 total steps have happened
[32m[20221125 00:01:30 @pendulum_agent.py:281][0m #------------------------ Iteration 638 --------------------------#
[32m[20221125 00:01:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:01:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 13.6
[32m[20221125 00:01:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:01:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:01:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:01:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:01:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:01:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:01:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:01:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:01:33 @pendulum_agent.py:307][0m Sample time: 3.589672803878784
[32m[20221125 00:02:00 @pendulum_agent.py:312][0m Update time: 27.033313989639282
[32m[20221125 00:02:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:02:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:02:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:02:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:02:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:02:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:02:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:02:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:02:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:02:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:02:01 @pendulum_agent.py:317][0m Evaluation time: 0.710259199142456
[32m[20221125 00:02:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 1.36
[32m[20221125 00:02:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:02:01 @pendulum_agent.py:289][0m Total time: 9590.825914144516
[32m[20221125 00:02:01 @pendulum_agent.py:291][0m 31950000 total steps have happened
[32m[20221125 00:02:01 @pendulum_agent.py:281][0m #------------------------ Iteration 639 --------------------------#
[32m[20221125 00:02:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.2
[32m[20221125 00:02:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.8
[32m[20221125 00:02:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.0
[32m[20221125 00:02:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.2
[32m[20221125 00:02:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.6
[32m[20221125 00:02:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.0
[32m[20221125 00:02:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.2
[32m[20221125 00:02:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.8
[32m[20221125 00:02:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.6
[32m[20221125 00:02:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.4
[32m[20221125 00:02:05 @pendulum_agent.py:307][0m Sample time: 3.6750669479370117
[32m[20221125 00:02:25 @pendulum_agent.py:312][0m Update time: 19.891200065612793
[32m[20221125 00:02:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:02:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:02:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:02:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:02:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:02:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:02:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:02:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:02:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:02:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:02:25 @pendulum_agent.py:317][0m Evaluation time: 0.5618669986724854
[32m[20221125 00:02:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.68
[32m[20221125 00:02:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:02:26 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:02:26 @pendulum_agent.py:289][0m Total time: 9615.253299951553
[32m[20221125 00:02:26 @pendulum_agent.py:291][0m 32000000 total steps have happened
[32m[20221125 00:02:26 @pendulum_agent.py:281][0m #------------------------ Iteration 640 --------------------------#
[32m[20221125 00:02:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:02:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:02:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:02:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:02:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:02:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:02:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:02:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:02:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:02:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:02:29 @pendulum_agent.py:307][0m Sample time: 3.7204742431640625
[32m[20221125 00:02:53 @pendulum_agent.py:312][0m Update time: 23.640727996826172
[32m[20221125 00:02:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:02:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:02:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:02:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:02:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:02:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:02:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:02:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:02:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:02:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:02:54 @pendulum_agent.py:317][0m Evaluation time: 0.6962587833404541
[32m[20221125 00:02:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:02:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:02:54 @pendulum_agent.py:289][0m Total time: 9643.591261863708
[32m[20221125 00:02:54 @pendulum_agent.py:291][0m 32050000 total steps have happened
[32m[20221125 00:02:54 @pendulum_agent.py:281][0m #------------------------ Iteration 641 --------------------------#
[32m[20221125 00:02:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.8
[32m[20221125 00:02:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.2
[32m[20221125 00:02:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.0
[32m[20221125 00:02:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.4
[32m[20221125 00:02:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.8
[32m[20221125 00:02:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.8
[32m[20221125 00:02:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.8
[32m[20221125 00:02:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 8.0
[32m[20221125 00:02:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.6
[32m[20221125 00:02:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.2
[32m[20221125 00:02:58 @pendulum_agent.py:307][0m Sample time: 3.7775697708129883
[32m[20221125 00:03:20 @pendulum_agent.py:312][0m Update time: 22.44000816345215
[32m[20221125 00:03:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:03:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:03:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:03:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:03:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:03:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:03:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:03:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:03:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:03:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:03:21 @pendulum_agent.py:317][0m Evaluation time: 0.6802351474761963
[32m[20221125 00:03:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.06
[32m[20221125 00:03:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:03:21 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:03:21 @pendulum_agent.py:289][0m Total time: 9670.770680904388
[32m[20221125 00:03:21 @pendulum_agent.py:291][0m 32100000 total steps have happened
[32m[20221125 00:03:21 @pendulum_agent.py:281][0m #------------------------ Iteration 642 --------------------------#
[32m[20221125 00:03:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:03:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:03:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:03:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:03:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:03:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:03:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:03:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:03:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:03:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:03:25 @pendulum_agent.py:307][0m Sample time: 3.5676732063293457
[32m[20221125 00:03:33 @pendulum_agent.py:312][0m Update time: 8.626473903656006
[32m[20221125 00:03:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:03:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:03:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:03:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:03:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:03:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:03:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:03:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:03:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:03:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:03:34 @pendulum_agent.py:317][0m Evaluation time: 0.9223837852478027
[32m[20221125 00:03:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:03:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:03:35 @pendulum_agent.py:289][0m Total time: 9684.172013044357
[32m[20221125 00:03:35 @pendulum_agent.py:291][0m 32150000 total steps have happened
[32m[20221125 00:03:35 @pendulum_agent.py:281][0m #------------------------ Iteration 643 --------------------------#
[32m[20221125 00:03:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:03:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:03:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:03:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:03:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:03:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:03:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:03:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:03:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:03:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:03:38 @pendulum_agent.py:307][0m Sample time: 3.6763436794281006
[32m[20221125 00:03:47 @pendulum_agent.py:312][0m Update time: 8.554341316223145
[32m[20221125 00:03:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:03:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:03:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:03:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:03:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:03:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:03:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:03:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:03:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:03:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:03:47 @pendulum_agent.py:317][0m Evaluation time: 0.685187816619873
[32m[20221125 00:03:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:03:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:03:48 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:03:48 @pendulum_agent.py:289][0m Total time: 9697.346824169159
[32m[20221125 00:03:48 @pendulum_agent.py:291][0m 32200000 total steps have happened
[32m[20221125 00:03:48 @pendulum_agent.py:281][0m #------------------------ Iteration 644 --------------------------#
[32m[20221125 00:03:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:03:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:03:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:03:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:03:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:03:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:03:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:03:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:03:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:03:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:03:51 @pendulum_agent.py:307][0m Sample time: 3.606478691101074
[32m[20221125 00:04:01 @pendulum_agent.py:312][0m Update time: 9.355782270431519
[32m[20221125 00:04:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:04:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:04:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:04:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:04:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:04:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:04:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:04:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:04:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:04:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:04:01 @pendulum_agent.py:317][0m Evaluation time: 0.669266939163208
[32m[20221125 00:04:02 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:04:02 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:04:02 @pendulum_agent.py:289][0m Total time: 9711.275084018707
[32m[20221125 00:04:02 @pendulum_agent.py:291][0m 32250000 total steps have happened
[32m[20221125 00:04:02 @pendulum_agent.py:281][0m #------------------------ Iteration 645 --------------------------#
[32m[20221125 00:04:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:04:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:04:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:04:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:04:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:04:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:04:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:04:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:04:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:04:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:04:05 @pendulum_agent.py:307][0m Sample time: 3.4993510246276855
[32m[20221125 00:04:32 @pendulum_agent.py:312][0m Update time: 26.389866828918457
[32m[20221125 00:04:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:04:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:04:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:04:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:04:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:04:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:04:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:04:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:04:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:04:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:04:32 @pendulum_agent.py:317][0m Evaluation time: 0.9049959182739258
[32m[20221125 00:04:33 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:04:33 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:04:33 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:04:33 @pendulum_agent.py:289][0m Total time: 9742.333456993103
[32m[20221125 00:04:33 @pendulum_agent.py:291][0m 32300000 total steps have happened
[32m[20221125 00:04:33 @pendulum_agent.py:281][0m #------------------------ Iteration 646 --------------------------#
[32m[20221125 00:04:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:04:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.6
[32m[20221125 00:04:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:04:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:04:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:04:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:04:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:04:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:04:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:04:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:04:36 @pendulum_agent.py:307][0m Sample time: 3.3020710945129395
[32m[20221125 00:04:45 @pendulum_agent.py:312][0m Update time: 8.666084051132202
[32m[20221125 00:04:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:04:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:04:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:04:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:04:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:04:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:04:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:04:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:04:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:04:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:04:46 @pendulum_agent.py:317][0m Evaluation time: 1.6274769306182861
[32m[20221125 00:04:47 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.06
[32m[20221125 00:04:47 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:04:47 @pendulum_agent.py:289][0m Total time: 9756.214318990707
[32m[20221125 00:04:47 @pendulum_agent.py:291][0m 32350000 total steps have happened
[32m[20221125 00:04:47 @pendulum_agent.py:281][0m #------------------------ Iteration 647 --------------------------#
[32m[20221125 00:04:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:04:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:04:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:04:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:04:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:04:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:04:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:04:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:04:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:04:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:04:50 @pendulum_agent.py:307][0m Sample time: 3.7710440158843994
[32m[20221125 00:05:06 @pendulum_agent.py:312][0m Update time: 15.329864025115967
[32m[20221125 00:05:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:05:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:05:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:05:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:05:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:05:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:05:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:05:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:05:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:05:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:05:06 @pendulum_agent.py:317][0m Evaluation time: 0.6917638778686523
[32m[20221125 00:05:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:05:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:05:07 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:05:07 @pendulum_agent.py:289][0m Total time: 9776.281593084335
[32m[20221125 00:05:07 @pendulum_agent.py:291][0m 32400000 total steps have happened
[32m[20221125 00:05:07 @pendulum_agent.py:281][0m #------------------------ Iteration 648 --------------------------#
[32m[20221125 00:05:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:05:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:05:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:05:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:05:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:05:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:05:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:05:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:05:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:05:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:05:10 @pendulum_agent.py:307][0m Sample time: 3.582259178161621
[32m[20221125 00:05:29 @pendulum_agent.py:312][0m Update time: 18.92806386947632
[32m[20221125 00:05:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:05:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:05:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:05:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:05:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:05:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:05:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:05:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:05:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:05:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:05:30 @pendulum_agent.py:317][0m Evaluation time: 0.6961770057678223
[32m[20221125 00:05:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:05:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:05:30 @pendulum_agent.py:289][0m Total time: 9799.758434057236
[32m[20221125 00:05:30 @pendulum_agent.py:291][0m 32450000 total steps have happened
[32m[20221125 00:05:30 @pendulum_agent.py:281][0m #------------------------ Iteration 649 --------------------------#
[32m[20221125 00:05:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:05:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:05:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:05:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:05:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:05:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:05:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:05:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:05:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:05:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:05:34 @pendulum_agent.py:307][0m Sample time: 3.730942964553833
[32m[20221125 00:05:43 @pendulum_agent.py:312][0m Update time: 8.724331140518188
[32m[20221125 00:05:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:05:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:05:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:05:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:05:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:05:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:05:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:05:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:05:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:05:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:05:43 @pendulum_agent.py:317][0m Evaluation time: 0.7016189098358154
[32m[20221125 00:05:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:05:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:05:44 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:05:44 @pendulum_agent.py:289][0m Total time: 9813.198616981506
[32m[20221125 00:05:44 @pendulum_agent.py:291][0m 32500000 total steps have happened
[32m[20221125 00:05:44 @pendulum_agent.py:281][0m #------------------------ Iteration 650 --------------------------#
[32m[20221125 00:05:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 12.4
[32m[20221125 00:05:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 10.6
[32m[20221125 00:05:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 16.8
[32m[20221125 00:05:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.0
[32m[20221125 00:05:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 11.2
[32m[20221125 00:05:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.6
[32m[20221125 00:05:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 12.4
[32m[20221125 00:05:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.0
[32m[20221125 00:05:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 10.4
[32m[20221125 00:05:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 17.4
[32m[20221125 00:05:47 @pendulum_agent.py:307][0m Sample time: 3.538084030151367
[32m[20221125 00:05:56 @pendulum_agent.py:312][0m Update time: 8.833516836166382
[32m[20221125 00:05:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:05:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:05:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:05:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:05:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:05:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:05:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:05:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:05:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:05:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:05:57 @pendulum_agent.py:317][0m Evaluation time: 0.8335831165313721
[32m[20221125 00:05:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 10.68
[32m[20221125 00:05:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:05:57 @pendulum_agent.py:289][0m Total time: 9826.672151088715
[32m[20221125 00:05:57 @pendulum_agent.py:291][0m 32550000 total steps have happened
[32m[20221125 00:05:57 @pendulum_agent.py:281][0m #------------------------ Iteration 651 --------------------------#
[32m[20221125 00:05:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 8.2
[32m[20221125 00:05:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:05:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:05:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:05:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.2
[32m[20221125 00:05:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:05:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:05:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:05:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:05:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:06:01 @pendulum_agent.py:307][0m Sample time: 3.709810972213745
[32m[20221125 00:06:10 @pendulum_agent.py:312][0m Update time: 8.754698991775513
[32m[20221125 00:06:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:06:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:06:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:06:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:06:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:06:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:06:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:06:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:06:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:06:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:06:10 @pendulum_agent.py:317][0m Evaluation time: 0.6999509334564209
[32m[20221125 00:06:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 1.54
[32m[20221125 00:06:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:06:11 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:06:11 @pendulum_agent.py:289][0m Total time: 9840.11670589447
[32m[20221125 00:06:11 @pendulum_agent.py:291][0m 32600000 total steps have happened
[32m[20221125 00:06:11 @pendulum_agent.py:281][0m #------------------------ Iteration 652 --------------------------#
[32m[20221125 00:06:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:06:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:06:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:06:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:06:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:06:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:06:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:06:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:06:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:06:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:06:14 @pendulum_agent.py:307][0m Sample time: 3.8085460662841797
[32m[20221125 00:06:23 @pendulum_agent.py:312][0m Update time: 8.795927047729492
[32m[20221125 00:06:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:06:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:06:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:06:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:06:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:06:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:06:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:06:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:06:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:06:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:06:24 @pendulum_agent.py:317][0m Evaluation time: 0.7182278633117676
[32m[20221125 00:06:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:06:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:06:24 @pendulum_agent.py:289][0m Total time: 9853.720462083817
[32m[20221125 00:06:24 @pendulum_agent.py:291][0m 32650000 total steps have happened
[32m[20221125 00:06:24 @pendulum_agent.py:281][0m #------------------------ Iteration 653 --------------------------#
[32m[20221125 00:06:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:06:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:06:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:06:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:06:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:06:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:06:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:06:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:06:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:06:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:06:28 @pendulum_agent.py:307][0m Sample time: 3.6207590103149414
[32m[20221125 00:06:39 @pendulum_agent.py:312][0m Update time: 10.860262155532837
[32m[20221125 00:06:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:06:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:06:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:06:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:06:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:06:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:06:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:06:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:06:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:06:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:06:39 @pendulum_agent.py:317][0m Evaluation time: 0.7003600597381592
[32m[20221125 00:06:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:06:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:06:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:06:40 @pendulum_agent.py:289][0m Total time: 9869.199981927872
[32m[20221125 00:06:40 @pendulum_agent.py:291][0m 32700000 total steps have happened
[32m[20221125 00:06:40 @pendulum_agent.py:281][0m #------------------------ Iteration 654 --------------------------#
[32m[20221125 00:06:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:06:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:06:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:06:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:06:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:06:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:06:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:06:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:06:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:06:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:06:43 @pendulum_agent.py:307][0m Sample time: 3.4950318336486816
[32m[20221125 00:06:52 @pendulum_agent.py:312][0m Update time: 8.846307039260864
[32m[20221125 00:06:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:06:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:06:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:06:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:06:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:06:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:06:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:06:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:06:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:06:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:06:53 @pendulum_agent.py:317][0m Evaluation time: 0.8323068618774414
[32m[20221125 00:06:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:06:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:06:53 @pendulum_agent.py:289][0m Total time: 9882.651716947556
[32m[20221125 00:06:53 @pendulum_agent.py:291][0m 32750000 total steps have happened
[32m[20221125 00:06:53 @pendulum_agent.py:281][0m #------------------------ Iteration 655 --------------------------#
[32m[20221125 00:06:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:06:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:06:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:06:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:06:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:06:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:06:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:06:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:06:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:06:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:06:57 @pendulum_agent.py:307][0m Sample time: 3.4686291217803955
[32m[20221125 00:07:14 @pendulum_agent.py:312][0m Update time: 17.170485019683838
[32m[20221125 00:07:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:07:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:07:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:07:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:07:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:07:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:07:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:07:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:07:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:07:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:07:15 @pendulum_agent.py:317][0m Evaluation time: 1.0343270301818848
[32m[20221125 00:07:15 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:07:15 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:07:15 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:07:15 @pendulum_agent.py:289][0m Total time: 9904.612489938736
[32m[20221125 00:07:15 @pendulum_agent.py:291][0m 32800000 total steps have happened
[32m[20221125 00:07:15 @pendulum_agent.py:281][0m #------------------------ Iteration 656 --------------------------#
[32m[20221125 00:07:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 9.2
[32m[20221125 00:07:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 10.8
[32m[20221125 00:07:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.4
[32m[20221125 00:07:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.6
[32m[20221125 00:07:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.6
[32m[20221125 00:07:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.8
[32m[20221125 00:07:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.2
[32m[20221125 00:07:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.0
[32m[20221125 00:07:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.4
[32m[20221125 00:07:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.6
[32m[20221125 00:07:18 @pendulum_agent.py:307][0m Sample time: 3.356501817703247
[32m[20221125 00:07:43 @pendulum_agent.py:312][0m Update time: 24.360340118408203
[32m[20221125 00:07:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:07:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:07:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:07:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:07:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:07:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:07:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:07:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:07:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:07:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:07:44 @pendulum_agent.py:317][0m Evaluation time: 1.1514780521392822
[32m[20221125 00:07:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.86
[32m[20221125 00:07:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:07:44 @pendulum_agent.py:289][0m Total time: 9933.752658843994
[32m[20221125 00:07:44 @pendulum_agent.py:291][0m 32850000 total steps have happened
[32m[20221125 00:07:44 @pendulum_agent.py:281][0m #------------------------ Iteration 657 --------------------------#
[32m[20221125 00:07:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:07:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:07:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:07:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:07:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:07:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:07:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:07:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:07:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:07:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:07:48 @pendulum_agent.py:307][0m Sample time: 3.398027181625366
[32m[20221125 00:07:56 @pendulum_agent.py:312][0m Update time: 8.657603025436401
[32m[20221125 00:07:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:07:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:07:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:07:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:07:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:07:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:07:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:07:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:07:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:07:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:07:58 @pendulum_agent.py:317][0m Evaluation time: 1.793590784072876
[32m[20221125 00:07:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:07:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:07:58 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:07:58 @pendulum_agent.py:289][0m Total time: 9947.88648891449
[32m[20221125 00:07:58 @pendulum_agent.py:291][0m 32900000 total steps have happened
[32m[20221125 00:07:58 @pendulum_agent.py:281][0m #------------------------ Iteration 658 --------------------------#
[32m[20221125 00:07:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.2
[32m[20221125 00:07:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.4
[32m[20221125 00:07:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.6
[32m[20221125 00:07:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.0
[32m[20221125 00:07:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.2
[32m[20221125 00:07:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.4
[32m[20221125 00:07:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.6
[32m[20221125 00:07:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.2
[32m[20221125 00:07:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.8
[32m[20221125 00:07:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.8
[32m[20221125 00:08:02 @pendulum_agent.py:307][0m Sample time: 3.542788028717041
[32m[20221125 00:08:17 @pendulum_agent.py:312][0m Update time: 15.188183784484863
[32m[20221125 00:08:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:08:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:08:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:08:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:08:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:08:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:08:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:08:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:08:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:08:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:08:18 @pendulum_agent.py:317][0m Evaluation time: 0.7098333835601807
[32m[20221125 00:08:18 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.02
[32m[20221125 00:08:18 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:08:18 @pendulum_agent.py:289][0m Total time: 9967.606339931488
[32m[20221125 00:08:18 @pendulum_agent.py:291][0m 32950000 total steps have happened
[32m[20221125 00:08:18 @pendulum_agent.py:281][0m #------------------------ Iteration 659 --------------------------#
[32m[20221125 00:08:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:08:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:08:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:08:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:08:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:08:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:08:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:08:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:08:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:08:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:08:22 @pendulum_agent.py:307][0m Sample time: 3.752868890762329
[32m[20221125 00:08:30 @pendulum_agent.py:312][0m Update time: 8.573047161102295
[32m[20221125 00:08:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:08:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:08:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:08:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:08:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:08:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:08:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:08:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:08:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:08:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:08:31 @pendulum_agent.py:317][0m Evaluation time: 0.9660830497741699
[32m[20221125 00:08:32 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:08:32 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:08:32 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:08:32 @pendulum_agent.py:289][0m Total time: 9981.183858156204
[32m[20221125 00:08:32 @pendulum_agent.py:291][0m 33000000 total steps have happened
[32m[20221125 00:08:32 @pendulum_agent.py:281][0m #------------------------ Iteration 660 --------------------------#
[32m[20221125 00:08:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:08:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:08:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:08:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:08:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:08:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:08:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:08:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:08:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:08:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:08:35 @pendulum_agent.py:307][0m Sample time: 3.83951997756958
[32m[20221125 00:08:44 @pendulum_agent.py:312][0m Update time: 8.566133975982666
[32m[20221125 00:08:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:08:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:08:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:08:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:08:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:08:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:08:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:08:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:08:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:08:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:08:45 @pendulum_agent.py:317][0m Evaluation time: 0.9151732921600342
[32m[20221125 00:08:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:08:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:08:45 @pendulum_agent.py:289][0m Total time: 9994.75733089447
[32m[20221125 00:08:45 @pendulum_agent.py:291][0m 33050000 total steps have happened
[32m[20221125 00:08:45 @pendulum_agent.py:281][0m #------------------------ Iteration 661 --------------------------#
[32m[20221125 00:08:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:08:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:08:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:08:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:08:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:08:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:08:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:08:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:08:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:08:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:08:49 @pendulum_agent.py:307][0m Sample time: 3.874819040298462
[32m[20221125 00:09:09 @pendulum_agent.py:312][0m Update time: 20.45756483078003
[32m[20221125 00:09:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:09:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:09:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:09:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:09:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:09:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:09:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:09:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:09:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:09:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:09:10 @pendulum_agent.py:317][0m Evaluation time: 0.6832699775695801
[32m[20221125 00:09:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:09:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:09:10 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:09:10 @pendulum_agent.py:289][0m Total time: 10020.063005924225
[32m[20221125 00:09:10 @pendulum_agent.py:291][0m 33100000 total steps have happened
[32m[20221125 00:09:10 @pendulum_agent.py:281][0m #------------------------ Iteration 662 --------------------------#
[32m[20221125 00:09:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:09:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:09:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:09:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:09:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:09:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:09:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:09:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:09:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:09:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:09:14 @pendulum_agent.py:307][0m Sample time: 3.4729461669921875
[32m[20221125 00:09:25 @pendulum_agent.py:312][0m Update time: 11.37103009223938
[32m[20221125 00:09:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:09:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:09:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:09:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:09:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:09:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:09:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:09:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:09:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:09:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:09:26 @pendulum_agent.py:317][0m Evaluation time: 0.5669100284576416
[32m[20221125 00:09:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:09:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:09:26 @pendulum_agent.py:289][0m Total time: 10035.771645784378
[32m[20221125 00:09:26 @pendulum_agent.py:291][0m 33150000 total steps have happened
[32m[20221125 00:09:26 @pendulum_agent.py:281][0m #------------------------ Iteration 663 --------------------------#
[32m[20221125 00:09:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.8
[32m[20221125 00:09:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.4
[32m[20221125 00:09:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.8
[32m[20221125 00:09:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.6
[32m[20221125 00:09:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.6
[32m[20221125 00:09:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.2
[32m[20221125 00:09:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.4
[32m[20221125 00:09:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.6
[32m[20221125 00:09:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.6
[32m[20221125 00:09:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.0
[32m[20221125 00:09:30 @pendulum_agent.py:307][0m Sample time: 3.7286226749420166
[32m[20221125 00:09:40 @pendulum_agent.py:312][0m Update time: 10.149302005767822
[32m[20221125 00:09:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:09:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:09:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:09:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:09:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:09:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:09:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:09:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:09:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:09:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:09:41 @pendulum_agent.py:317][0m Evaluation time: 0.5792281627655029
[32m[20221125 00:09:41 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.1
[32m[20221125 00:09:41 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:09:41 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:09:41 @pendulum_agent.py:289][0m Total time: 10050.528270959854
[32m[20221125 00:09:41 @pendulum_agent.py:291][0m 33200000 total steps have happened
[32m[20221125 00:09:41 @pendulum_agent.py:281][0m #------------------------ Iteration 664 --------------------------#
[32m[20221125 00:09:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:09:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:09:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:09:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:09:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:09:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:09:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:09:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:09:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:09:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:09:45 @pendulum_agent.py:307][0m Sample time: 3.7347891330718994
[32m[20221125 00:09:53 @pendulum_agent.py:312][0m Update time: 8.744359016418457
[32m[20221125 00:09:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:09:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:09:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:09:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:09:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:09:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:09:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:09:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:09:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:09:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:09:54 @pendulum_agent.py:317][0m Evaluation time: 0.5714030265808105
[32m[20221125 00:09:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:09:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:09:54 @pendulum_agent.py:289][0m Total time: 10063.88592004776
[32m[20221125 00:09:54 @pendulum_agent.py:291][0m 33250000 total steps have happened
[32m[20221125 00:09:54 @pendulum_agent.py:281][0m #------------------------ Iteration 665 --------------------------#
[32m[20221125 00:09:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.2
[32m[20221125 00:09:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.6
[32m[20221125 00:09:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1.8
[32m[20221125 00:09:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.2
[32m[20221125 00:09:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1.6
[32m[20221125 00:09:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.4
[32m[20221125 00:09:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.4
[32m[20221125 00:09:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.6
[32m[20221125 00:09:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.6
[32m[20221125 00:09:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.4
[32m[20221125 00:09:58 @pendulum_agent.py:307][0m Sample time: 3.799928903579712
[32m[20221125 00:10:20 @pendulum_agent.py:312][0m Update time: 22.31739115715027
[32m[20221125 00:10:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:10:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:10:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:10:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:10:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:10:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:10:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:10:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:10:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:10:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:10:21 @pendulum_agent.py:317][0m Evaluation time: 0.670665979385376
[32m[20221125 00:10:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 1.68
[32m[20221125 00:10:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:10:21 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:10:21 @pendulum_agent.py:289][0m Total time: 10090.94485092163
[32m[20221125 00:10:21 @pendulum_agent.py:291][0m 33300000 total steps have happened
[32m[20221125 00:10:21 @pendulum_agent.py:281][0m #------------------------ Iteration 666 --------------------------#
[32m[20221125 00:10:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:10:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:10:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:10:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:10:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:10:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:10:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:10:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:10:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:10:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:10:25 @pendulum_agent.py:307][0m Sample time: 3.568037986755371
[32m[20221125 00:10:34 @pendulum_agent.py:312][0m Update time: 8.693547010421753
[32m[20221125 00:10:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:10:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:10:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:10:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:10:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:10:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:10:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:10:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:10:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:10:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:10:34 @pendulum_agent.py:317][0m Evaluation time: 0.8053629398345947
[32m[20221125 00:10:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:10:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:10:35 @pendulum_agent.py:289][0m Total time: 10104.305145978928
[32m[20221125 00:10:35 @pendulum_agent.py:291][0m 33350000 total steps have happened
[32m[20221125 00:10:35 @pendulum_agent.py:281][0m #------------------------ Iteration 667 --------------------------#
[32m[20221125 00:10:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:10:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:10:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:10:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:10:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:10:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:10:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:10:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:10:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:10:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:10:38 @pendulum_agent.py:307][0m Sample time: 3.331709861755371
[32m[20221125 00:10:52 @pendulum_agent.py:312][0m Update time: 13.491182088851929
[32m[20221125 00:10:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:10:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:10:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:10:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:10:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:10:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:10:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:10:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:10:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:10:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:10:53 @pendulum_agent.py:317][0m Evaluation time: 1.015887975692749
[32m[20221125 00:10:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:10:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:10:53 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:10:53 @pendulum_agent.py:289][0m Total time: 10122.414836883545
[32m[20221125 00:10:53 @pendulum_agent.py:291][0m 33400000 total steps have happened
[32m[20221125 00:10:53 @pendulum_agent.py:281][0m #------------------------ Iteration 668 --------------------------#
[32m[20221125 00:10:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:10:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:10:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:10:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:10:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:10:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:10:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:10:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:10:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:10:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:10:56 @pendulum_agent.py:307][0m Sample time: 3.6257739067077637
[32m[20221125 00:11:09 @pendulum_agent.py:312][0m Update time: 12.126589298248291
[32m[20221125 00:11:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:11:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:11:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:11:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:11:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:11:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:11:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:11:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:11:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:11:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:11:10 @pendulum_agent.py:317][0m Evaluation time: 1.1546778678894043
[32m[20221125 00:11:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:11:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:11:10 @pendulum_agent.py:289][0m Total time: 10139.60252213478
[32m[20221125 00:11:10 @pendulum_agent.py:291][0m 33450000 total steps have happened
[32m[20221125 00:11:10 @pendulum_agent.py:281][0m #------------------------ Iteration 669 --------------------------#
[32m[20221125 00:11:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:11:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:11:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:11:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:11:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:11:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:11:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:11:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:11:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:11:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:11:13 @pendulum_agent.py:307][0m Sample time: 3.3632261753082275
[32m[20221125 00:11:22 @pendulum_agent.py:312][0m Update time: 8.616986751556396
[32m[20221125 00:11:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:11:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:11:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:11:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:11:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:11:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:11:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:11:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:11:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:11:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:11:23 @pendulum_agent.py:317][0m Evaluation time: 1.1614820957183838
[32m[20221125 00:11:23 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:11:23 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:11:23 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:11:23 @pendulum_agent.py:289][0m Total time: 10153.010426998138
[32m[20221125 00:11:23 @pendulum_agent.py:291][0m 33500000 total steps have happened
[32m[20221125 00:11:23 @pendulum_agent.py:281][0m #------------------------ Iteration 670 --------------------------#
[32m[20221125 00:11:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:11:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:11:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:11:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:11:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:11:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:11:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:11:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:11:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:11:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:11:27 @pendulum_agent.py:307][0m Sample time: 3.649136781692505
[32m[20221125 00:11:36 @pendulum_agent.py:312][0m Update time: 8.735907077789307
[32m[20221125 00:11:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:11:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:11:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:11:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:11:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:11:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:11:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:11:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:11:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:11:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:11:36 @pendulum_agent.py:317][0m Evaluation time: 0.7043869495391846
[32m[20221125 00:11:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:11:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:11:37 @pendulum_agent.py:289][0m Total time: 10166.375790119171
[32m[20221125 00:11:37 @pendulum_agent.py:291][0m 33550000 total steps have happened
[32m[20221125 00:11:37 @pendulum_agent.py:281][0m #------------------------ Iteration 671 --------------------------#
[32m[20221125 00:11:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:11:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:11:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:11:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:11:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:11:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:11:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:11:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:11:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:11:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:11:40 @pendulum_agent.py:307][0m Sample time: 3.6405868530273438
[32m[20221125 00:11:49 @pendulum_agent.py:312][0m Update time: 8.797526121139526
[32m[20221125 00:11:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:11:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:11:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:11:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:11:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:11:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:11:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:11:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:11:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:11:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:11:50 @pendulum_agent.py:317][0m Evaluation time: 0.7181880474090576
[32m[20221125 00:11:50 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:11:50 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:11:50 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:11:50 @pendulum_agent.py:289][0m Total time: 10179.811779022217
[32m[20221125 00:11:50 @pendulum_agent.py:291][0m 33600000 total steps have happened
[32m[20221125 00:11:50 @pendulum_agent.py:281][0m #------------------------ Iteration 672 --------------------------#
[32m[20221125 00:11:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:11:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:11:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:11:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:11:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:11:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:11:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:11:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:11:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:11:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:11:54 @pendulum_agent.py:307][0m Sample time: 3.494675874710083
[32m[20221125 00:12:09 @pendulum_agent.py:312][0m Update time: 15.077148914337158
[32m[20221125 00:12:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:12:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:12:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:12:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:12:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:12:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:12:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:12:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:12:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:12:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:12:09 @pendulum_agent.py:317][0m Evaluation time: 0.7023799419403076
[32m[20221125 00:12:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:12:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:12:10 @pendulum_agent.py:289][0m Total time: 10199.364369153976
[32m[20221125 00:12:10 @pendulum_agent.py:291][0m 33650000 total steps have happened
[32m[20221125 00:12:10 @pendulum_agent.py:281][0m #------------------------ Iteration 673 --------------------------#
[32m[20221125 00:12:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.4
[32m[20221125 00:12:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.6
[32m[20221125 00:12:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.4
[32m[20221125 00:12:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.6
[32m[20221125 00:12:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.6
[32m[20221125 00:12:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.0
[32m[20221125 00:12:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.6
[32m[20221125 00:12:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.6
[32m[20221125 00:12:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.2
[32m[20221125 00:12:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.0
[32m[20221125 00:12:14 @pendulum_agent.py:307][0m Sample time: 3.772584915161133
[32m[20221125 00:12:40 @pendulum_agent.py:312][0m Update time: 26.120739936828613
[32m[20221125 00:12:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:12:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:12:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:12:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:12:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:12:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:12:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:12:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:12:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:12:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:12:40 @pendulum_agent.py:317][0m Evaluation time: 0.580228328704834
[32m[20221125 00:12:41 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.7
[32m[20221125 00:12:41 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:12:41 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:12:41 @pendulum_agent.py:289][0m Total time: 10230.125019073486
[32m[20221125 00:12:41 @pendulum_agent.py:291][0m 33700000 total steps have happened
[32m[20221125 00:12:41 @pendulum_agent.py:281][0m #------------------------ Iteration 674 --------------------------#
[32m[20221125 00:12:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:12:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:12:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:12:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:12:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:12:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:12:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:12:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:12:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:12:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:12:44 @pendulum_agent.py:307][0m Sample time: 3.731940746307373
[32m[20221125 00:12:53 @pendulum_agent.py:312][0m Update time: 8.690389156341553
[32m[20221125 00:12:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:12:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:12:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:12:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:12:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:12:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:12:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:12:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:12:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:12:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:12:54 @pendulum_agent.py:317][0m Evaluation time: 0.6874639987945557
[32m[20221125 00:12:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:12:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:12:54 @pendulum_agent.py:289][0m Total time: 10243.512085914612
[32m[20221125 00:12:54 @pendulum_agent.py:291][0m 33750000 total steps have happened
[32m[20221125 00:12:54 @pendulum_agent.py:281][0m #------------------------ Iteration 675 --------------------------#
[32m[20221125 00:12:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:12:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:12:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:12:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:12:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:12:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:12:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:12:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:12:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:12:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:12:58 @pendulum_agent.py:307][0m Sample time: 3.6065032482147217
[32m[20221125 00:13:10 @pendulum_agent.py:312][0m Update time: 12.76360273361206
[32m[20221125 00:13:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:13:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:13:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:13:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:13:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:13:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:13:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:13:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:13:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:13:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:13:11 @pendulum_agent.py:317][0m Evaluation time: 0.6971211433410645
[32m[20221125 00:13:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:13:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:13:11 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:13:11 @pendulum_agent.py:289][0m Total time: 10260.852548122406
[32m[20221125 00:13:11 @pendulum_agent.py:291][0m 33800000 total steps have happened
[32m[20221125 00:13:11 @pendulum_agent.py:281][0m #------------------------ Iteration 676 --------------------------#
[32m[20221125 00:13:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.6
[32m[20221125 00:13:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.6
[32m[20221125 00:13:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.8
[32m[20221125 00:13:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.8
[32m[20221125 00:13:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.4
[32m[20221125 00:13:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.6
[32m[20221125 00:13:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.8
[32m[20221125 00:13:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.4
[32m[20221125 00:13:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.8
[32m[20221125 00:13:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.2
[32m[20221125 00:13:15 @pendulum_agent.py:307][0m Sample time: 3.5906481742858887
[32m[20221125 00:13:23 @pendulum_agent.py:312][0m Update time: 8.647170066833496
[32m[20221125 00:13:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:13:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:13:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:13:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:13:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:13:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:13:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:13:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:13:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:13:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:13:24 @pendulum_agent.py:317][0m Evaluation time: 0.8253798484802246
[32m[20221125 00:13:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.2
[32m[20221125 00:13:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:13:25 @pendulum_agent.py:289][0m Total time: 10274.202898979187
[32m[20221125 00:13:25 @pendulum_agent.py:291][0m 33850000 total steps have happened
[32m[20221125 00:13:25 @pendulum_agent.py:281][0m #------------------------ Iteration 677 --------------------------#
[32m[20221125 00:13:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.6
[32m[20221125 00:13:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1.4
[32m[20221125 00:13:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.4
[32m[20221125 00:13:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.6
[32m[20221125 00:13:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.4
[32m[20221125 00:13:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.4
[32m[20221125 00:13:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1.4
[32m[20221125 00:13:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.6
[32m[20221125 00:13:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.4
[32m[20221125 00:13:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1.2
[32m[20221125 00:13:28 @pendulum_agent.py:307][0m Sample time: 3.3674159049987793
[32m[20221125 00:13:41 @pendulum_agent.py:312][0m Update time: 12.879970073699951
[32m[20221125 00:13:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.0
[32m[20221125 00:13:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.0
[32m[20221125 00:13:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.0
[32m[20221125 00:13:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.0
[32m[20221125 00:13:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.0
[32m[20221125 00:13:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.0
[32m[20221125 00:13:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.0
[32m[20221125 00:13:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.0
[32m[20221125 00:13:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.0
[32m[20221125 00:13:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.0
[32m[20221125 00:13:42 @pendulum_agent.py:317][0m Evaluation time: 1.0289089679718018
[32m[20221125 00:13:42 @pendulum_agent.py:285][0m Average TRAINING episode reward: 1.64
[32m[20221125 00:13:42 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:13:42 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:13:42 @pendulum_agent.py:289][0m Total time: 10291.74713587761
[32m[20221125 00:13:42 @pendulum_agent.py:291][0m 33900000 total steps have happened
[32m[20221125 00:13:42 @pendulum_agent.py:281][0m #------------------------ Iteration 678 --------------------------#
[32m[20221125 00:13:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:13:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:13:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:13:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:13:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:13:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:13:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:13:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:13:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:13:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:13:45 @pendulum_agent.py:307][0m Sample time: 3.224884033203125
[32m[20221125 00:13:58 @pendulum_agent.py:312][0m Update time: 13.08719515800476
[32m[20221125 00:13:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 15.0
[32m[20221125 00:13:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 15.0
[32m[20221125 00:13:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 15.0
[32m[20221125 00:13:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 15.0
[32m[20221125 00:13:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 15.0
[32m[20221125 00:13:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 15.0
[32m[20221125 00:13:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 15.0
[32m[20221125 00:13:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 15.0
[32m[20221125 00:13:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 15.0
[32m[20221125 00:13:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 15.0
[32m[20221125 00:13:59 @pendulum_agent.py:317][0m Evaluation time: 1.039867877960205
[32m[20221125 00:14:00 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:14:00 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:14:00 @pendulum_agent.py:289][0m Total time: 10309.376018047333
[32m[20221125 00:14:00 @pendulum_agent.py:291][0m 33950000 total steps have happened
[32m[20221125 00:14:00 @pendulum_agent.py:281][0m #------------------------ Iteration 679 --------------------------#
[32m[20221125 00:14:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:14:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:14:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:14:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:14:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:14:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:14:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:14:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:14:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:14:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:14:04 @pendulum_agent.py:307][0m Sample time: 3.817678689956665
[32m[20221125 00:14:12 @pendulum_agent.py:312][0m Update time: 8.771684169769287
[32m[20221125 00:14:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:14:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:14:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:14:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:14:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:14:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:14:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:14:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:14:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:14:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:14:13 @pendulum_agent.py:317][0m Evaluation time: 0.7028758525848389
[32m[20221125 00:14:13 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:14:13 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:14:13 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:14:13 @pendulum_agent.py:289][0m Total time: 10322.939962148666
[32m[20221125 00:14:13 @pendulum_agent.py:291][0m 34000000 total steps have happened
[32m[20221125 00:14:13 @pendulum_agent.py:281][0m #------------------------ Iteration 680 --------------------------#
[32m[20221125 00:14:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:14:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:14:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:14:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:14:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:14:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:14:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:14:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:14:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:14:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:14:17 @pendulum_agent.py:307][0m Sample time: 3.6613612174987793
[32m[20221125 00:14:26 @pendulum_agent.py:312][0m Update time: 8.662683963775635
[32m[20221125 00:14:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:14:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:14:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:14:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:14:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:14:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:14:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:14:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:14:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:14:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:14:26 @pendulum_agent.py:317][0m Evaluation time: 0.7096691131591797
[32m[20221125 00:14:27 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:14:27 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:14:27 @pendulum_agent.py:289][0m Total time: 10336.25144290924
[32m[20221125 00:14:27 @pendulum_agent.py:291][0m 34050000 total steps have happened
[32m[20221125 00:14:27 @pendulum_agent.py:281][0m #------------------------ Iteration 681 --------------------------#
[32m[20221125 00:14:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:14:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:14:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:14:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:14:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:14:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:14:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:14:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:14:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:14:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:14:30 @pendulum_agent.py:307][0m Sample time: 3.8448657989501953
[32m[20221125 00:14:45 @pendulum_agent.py:312][0m Update time: 14.448941230773926
[32m[20221125 00:14:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:14:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:14:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:14:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:14:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:14:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:14:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:14:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:14:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:14:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:14:46 @pendulum_agent.py:317][0m Evaluation time: 0.580204963684082
[32m[20221125 00:14:46 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:14:46 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:14:46 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:14:46 @pendulum_agent.py:289][0m Total time: 10355.439157962799
[32m[20221125 00:14:46 @pendulum_agent.py:291][0m 34100000 total steps have happened
[32m[20221125 00:14:46 @pendulum_agent.py:281][0m #------------------------ Iteration 682 --------------------------#
[32m[20221125 00:14:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:14:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:14:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:14:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:14:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:14:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:14:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:14:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:14:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:14:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:14:49 @pendulum_agent.py:307][0m Sample time: 3.632788896560669
[32m[20221125 00:14:58 @pendulum_agent.py:312][0m Update time: 8.687823057174683
[32m[20221125 00:14:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:14:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:14:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:14:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:14:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:14:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:14:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:14:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:14:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:14:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:14:59 @pendulum_agent.py:317][0m Evaluation time: 0.8387279510498047
[32m[20221125 00:14:59 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:14:59 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:14:59 @pendulum_agent.py:289][0m Total time: 10368.888441085815
[32m[20221125 00:14:59 @pendulum_agent.py:291][0m 34150000 total steps have happened
[32m[20221125 00:14:59 @pendulum_agent.py:281][0m #------------------------ Iteration 683 --------------------------#
[32m[20221125 00:15:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:15:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:15:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:15:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:15:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:15:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:15:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:15:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:15:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:15:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:15:03 @pendulum_agent.py:307][0m Sample time: 3.490372896194458
[32m[20221125 00:15:13 @pendulum_agent.py:312][0m Update time: 10.453557014465332
[32m[20221125 00:15:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:15:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:15:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:15:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:15:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:15:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:15:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:15:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:15:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:15:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:15:14 @pendulum_agent.py:317][0m Evaluation time: 1.0291681289672852
[32m[20221125 00:15:15 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:15:15 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:15:15 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:15:15 @pendulum_agent.py:289][0m Total time: 10384.144434928894
[32m[20221125 00:15:15 @pendulum_agent.py:291][0m 34200000 total steps have happened
[32m[20221125 00:15:15 @pendulum_agent.py:281][0m #------------------------ Iteration 684 --------------------------#
[32m[20221125 00:15:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:15:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:15:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:15:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:15:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:15:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:15:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:15:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:15:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:15:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:15:18 @pendulum_agent.py:307][0m Sample time: 3.6201188564300537
[32m[20221125 00:15:27 @pendulum_agent.py:312][0m Update time: 8.913275957107544
[32m[20221125 00:15:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:15:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:15:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:15:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:15:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:15:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:15:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:15:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:15:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:15:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:15:28 @pendulum_agent.py:317][0m Evaluation time: 0.6996099948883057
[32m[20221125 00:15:28 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:15:28 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:15:28 @pendulum_agent.py:289][0m Total time: 10397.67044711113
[32m[20221125 00:15:28 @pendulum_agent.py:291][0m 34250000 total steps have happened
[32m[20221125 00:15:28 @pendulum_agent.py:281][0m #------------------------ Iteration 685 --------------------------#
[32m[20221125 00:15:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:15:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:15:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:15:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:15:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:15:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:15:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:15:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:15:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:15:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:15:32 @pendulum_agent.py:307][0m Sample time: 3.7545318603515625
[32m[20221125 00:15:43 @pendulum_agent.py:312][0m Update time: 10.725940227508545
[32m[20221125 00:15:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:15:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:15:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:15:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:15:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:15:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:15:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:15:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:15:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:15:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:15:43 @pendulum_agent.py:317][0m Evaluation time: 0.5880188941955566
[32m[20221125 00:15:43 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:15:43 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:15:43 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:15:43 @pendulum_agent.py:289][0m Total time: 10413.026293039322
[32m[20221125 00:15:43 @pendulum_agent.py:291][0m 34300000 total steps have happened
[32m[20221125 00:15:43 @pendulum_agent.py:281][0m #------------------------ Iteration 686 --------------------------#
[32m[20221125 00:15:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 8.8
[32m[20221125 00:15:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 11.0
[32m[20221125 00:15:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 9.0
[32m[20221125 00:15:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 8.8
[32m[20221125 00:15:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.2
[32m[20221125 00:15:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.0
[32m[20221125 00:15:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 7.4
[32m[20221125 00:15:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 7.8
[32m[20221125 00:15:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 9.4
[32m[20221125 00:15:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 10.0
[32m[20221125 00:15:47 @pendulum_agent.py:307][0m Sample time: 3.745455026626587
[32m[20221125 00:15:56 @pendulum_agent.py:312][0m Update time: 8.713486194610596
[32m[20221125 00:15:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:15:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:15:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:15:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:15:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:15:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:15:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:15:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:15:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:15:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:15:57 @pendulum_agent.py:317][0m Evaluation time: 0.6984739303588867
[32m[20221125 00:15:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 8.64
[32m[20221125 00:15:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:15:57 @pendulum_agent.py:289][0m Total time: 10426.46442103386
[32m[20221125 00:15:57 @pendulum_agent.py:291][0m 34350000 total steps have happened
[32m[20221125 00:15:57 @pendulum_agent.py:281][0m #------------------------ Iteration 687 --------------------------#
[32m[20221125 00:15:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:15:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:15:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:15:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:15:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:15:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:15:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:15:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:15:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:15:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:16:01 @pendulum_agent.py:307][0m Sample time: 3.7586748600006104
[32m[20221125 00:16:14 @pendulum_agent.py:312][0m Update time: 13.118649244308472
[32m[20221125 00:16:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:16:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:16:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:16:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:16:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:16:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:16:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:16:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:16:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:16:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:16:14 @pendulum_agent.py:317][0m Evaluation time: 0.6903679370880127
[32m[20221125 00:16:15 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:16:15 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:16:15 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:16:15 @pendulum_agent.py:289][0m Total time: 10444.30812907219
[32m[20221125 00:16:15 @pendulum_agent.py:291][0m 34400000 total steps have happened
[32m[20221125 00:16:15 @pendulum_agent.py:281][0m #------------------------ Iteration 688 --------------------------#
[32m[20221125 00:16:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:16:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:16:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:16:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:16:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:16:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:16:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:16:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:16:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:16:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:16:18 @pendulum_agent.py:307][0m Sample time: 3.5570449829101562
[32m[20221125 00:16:31 @pendulum_agent.py:312][0m Update time: 12.669543981552124
[32m[20221125 00:16:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:16:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:16:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:16:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:16:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:16:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:16:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:16:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:16:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:16:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:16:32 @pendulum_agent.py:317][0m Evaluation time: 0.8961670398712158
[32m[20221125 00:16:32 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:16:32 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:16:32 @pendulum_agent.py:289][0m Total time: 10461.700195074081
[32m[20221125 00:16:32 @pendulum_agent.py:291][0m 34450000 total steps have happened
[32m[20221125 00:16:32 @pendulum_agent.py:281][0m #------------------------ Iteration 689 --------------------------#
[32m[20221125 00:16:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:16:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:16:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:16:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:16:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:16:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:16:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:16:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:16:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:16:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:16:36 @pendulum_agent.py:307][0m Sample time: 3.837898015975952
[32m[20221125 00:16:47 @pendulum_agent.py:312][0m Update time: 11.043044805526733
[32m[20221125 00:16:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:16:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:16:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:16:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:16:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:16:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:16:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:16:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:16:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:16:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:16:48 @pendulum_agent.py:317][0m Evaluation time: 0.6963150501251221
[32m[20221125 00:16:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:16:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:16:48 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:16:48 @pendulum_agent.py:289][0m Total time: 10477.556808233261
[32m[20221125 00:16:48 @pendulum_agent.py:291][0m 34500000 total steps have happened
[32m[20221125 00:16:48 @pendulum_agent.py:281][0m #------------------------ Iteration 690 --------------------------#
[32m[20221125 00:16:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.0
[32m[20221125 00:16:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.2
[32m[20221125 00:16:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.6
[32m[20221125 00:16:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.8
[32m[20221125 00:16:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.8
[32m[20221125 00:16:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.0
[32m[20221125 00:16:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.4
[32m[20221125 00:16:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.6
[32m[20221125 00:16:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.0
[32m[20221125 00:16:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.4
[32m[20221125 00:16:52 @pendulum_agent.py:307][0m Sample time: 3.6550629138946533
[32m[20221125 00:17:03 @pendulum_agent.py:312][0m Update time: 10.986319065093994
[32m[20221125 00:17:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:17:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:17:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:17:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:17:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:17:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:17:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:17:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:17:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:17:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:17:03 @pendulum_agent.py:317][0m Evaluation time: 0.6732239723205566
[32m[20221125 00:17:04 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.48
[32m[20221125 00:17:04 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:17:04 @pendulum_agent.py:289][0m Total time: 10493.17208480835
[32m[20221125 00:17:04 @pendulum_agent.py:291][0m 34550000 total steps have happened
[32m[20221125 00:17:04 @pendulum_agent.py:281][0m #------------------------ Iteration 691 --------------------------#
[32m[20221125 00:17:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:17:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:17:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:17:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:17:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:17:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:17:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:17:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:17:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:17:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:17:07 @pendulum_agent.py:307][0m Sample time: 3.4252309799194336
[32m[20221125 00:17:16 @pendulum_agent.py:312][0m Update time: 8.864343166351318
[32m[20221125 00:17:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:17:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:17:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:17:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:17:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:17:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:17:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:17:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:17:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:17:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:17:17 @pendulum_agent.py:317][0m Evaluation time: 0.9354140758514404
[32m[20221125 00:17:17 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:17:17 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:17:17 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:17:17 @pendulum_agent.py:289][0m Total time: 10506.672283172607
[32m[20221125 00:17:17 @pendulum_agent.py:291][0m 34600000 total steps have happened
[32m[20221125 00:17:17 @pendulum_agent.py:281][0m #------------------------ Iteration 692 --------------------------#
[32m[20221125 00:17:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.2
[32m[20221125 00:17:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.2
[32m[20221125 00:17:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.2
[32m[20221125 00:17:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.2
[32m[20221125 00:17:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.4
[32m[20221125 00:17:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.4
[32m[20221125 00:17:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:17:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:17:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.2
[32m[20221125 00:17:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.4
[32m[20221125 00:17:20 @pendulum_agent.py:307][0m Sample time: 3.3456220626831055
[32m[20221125 00:17:29 @pendulum_agent.py:312][0m Update time: 8.866952896118164
[32m[20221125 00:17:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:17:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:17:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:17:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:17:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:17:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:17:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:17:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:17:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:17:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:17:31 @pendulum_agent.py:317][0m Evaluation time: 1.6569831371307373
[32m[20221125 00:17:31 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.42
[32m[20221125 00:17:31 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:17:31 @pendulum_agent.py:289][0m Total time: 10520.841526985168
[32m[20221125 00:17:31 @pendulum_agent.py:291][0m 34650000 total steps have happened
[32m[20221125 00:17:31 @pendulum_agent.py:281][0m #------------------------ Iteration 693 --------------------------#
[32m[20221125 00:17:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:17:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:17:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:17:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:17:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:17:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:17:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:17:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:17:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:17:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:17:35 @pendulum_agent.py:307][0m Sample time: 3.814422130584717
[32m[20221125 00:17:45 @pendulum_agent.py:312][0m Update time: 9.76974081993103
[32m[20221125 00:17:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:17:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:17:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:17:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:17:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:17:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:17:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:17:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:17:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:17:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:17:46 @pendulum_agent.py:317][0m Evaluation time: 0.7168171405792236
[32m[20221125 00:17:46 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:17:46 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:17:46 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:17:46 @pendulum_agent.py:289][0m Total time: 10535.421658992767
[32m[20221125 00:17:46 @pendulum_agent.py:291][0m 34700000 total steps have happened
[32m[20221125 00:17:46 @pendulum_agent.py:281][0m #------------------------ Iteration 694 --------------------------#
[32m[20221125 00:17:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:17:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:17:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:17:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:17:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:17:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:17:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:17:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:17:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:17:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:17:50 @pendulum_agent.py:307][0m Sample time: 3.693942070007324
[32m[20221125 00:18:08 @pendulum_agent.py:312][0m Update time: 18.653138875961304
[32m[20221125 00:18:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:18:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:18:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:18:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:18:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:18:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:18:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:18:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:18:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:18:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:18:09 @pendulum_agent.py:317][0m Evaluation time: 0.709010124206543
[32m[20221125 00:18:09 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:18:09 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:18:09 @pendulum_agent.py:289][0m Total time: 10558.755912780762
[32m[20221125 00:18:09 @pendulum_agent.py:291][0m 34750000 total steps have happened
[32m[20221125 00:18:09 @pendulum_agent.py:281][0m #------------------------ Iteration 695 --------------------------#
[32m[20221125 00:18:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.6
[32m[20221125 00:18:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.0
[32m[20221125 00:18:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.0
[32m[20221125 00:18:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.2
[32m[20221125 00:18:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.4
[32m[20221125 00:18:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.6
[32m[20221125 00:18:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.8
[32m[20221125 00:18:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.0
[32m[20221125 00:18:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.2
[32m[20221125 00:18:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.6
[32m[20221125 00:18:13 @pendulum_agent.py:307][0m Sample time: 3.7653417587280273
[32m[20221125 00:18:46 @pendulum_agent.py:312][0m Update time: 32.82510328292847
[32m[20221125 00:18:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:18:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:18:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:18:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:18:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:18:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:18:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:18:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:18:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:18:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:18:46 @pendulum_agent.py:317][0m Evaluation time: 0.7094347476959229
[32m[20221125 00:18:47 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.54
[32m[20221125 00:18:47 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:18:47 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:18:47 @pendulum_agent.py:289][0m Total time: 10596.325758934021
[32m[20221125 00:18:47 @pendulum_agent.py:291][0m 34800000 total steps have happened
[32m[20221125 00:18:47 @pendulum_agent.py:281][0m #------------------------ Iteration 696 --------------------------#
[32m[20221125 00:18:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:18:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:18:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:18:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:18:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:18:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:18:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:18:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:18:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:18:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:18:50 @pendulum_agent.py:307][0m Sample time: 3.608848810195923
[32m[20221125 00:19:08 @pendulum_agent.py:312][0m Update time: 17.371628999710083
[32m[20221125 00:19:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:19:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:19:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:19:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:19:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:19:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:19:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:19:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:19:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:19:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:19:09 @pendulum_agent.py:317][0m Evaluation time: 0.8266310691833496
[32m[20221125 00:19:09 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:19:09 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:19:09 @pendulum_agent.py:289][0m Total time: 10618.404526948929
[32m[20221125 00:19:09 @pendulum_agent.py:291][0m 34850000 total steps have happened
[32m[20221125 00:19:09 @pendulum_agent.py:281][0m #------------------------ Iteration 697 --------------------------#
[32m[20221125 00:19:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.8
[32m[20221125 00:19:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.2
[32m[20221125 00:19:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.6
[32m[20221125 00:19:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.8
[32m[20221125 00:19:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.8
[32m[20221125 00:19:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.0
[32m[20221125 00:19:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.8
[32m[20221125 00:19:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.2
[32m[20221125 00:19:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.8
[32m[20221125 00:19:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.8
[32m[20221125 00:19:12 @pendulum_agent.py:307][0m Sample time: 3.699169158935547
[32m[20221125 00:19:27 @pendulum_agent.py:312][0m Update time: 14.6460862159729
[32m[20221125 00:19:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:19:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:19:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:19:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:19:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:19:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:19:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:19:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:19:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:19:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:19:28 @pendulum_agent.py:317][0m Evaluation time: 0.7310647964477539
[32m[20221125 00:19:28 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.48
[32m[20221125 00:19:28 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:19:28 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:19:28 @pendulum_agent.py:289][0m Total time: 10637.757766008377
[32m[20221125 00:19:28 @pendulum_agent.py:291][0m 34900000 total steps have happened
[32m[20221125 00:19:28 @pendulum_agent.py:281][0m #------------------------ Iteration 698 --------------------------#
[32m[20221125 00:19:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.6
[32m[20221125 00:19:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.0
[32m[20221125 00:19:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.6
[32m[20221125 00:19:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.8
[32m[20221125 00:19:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.4
[32m[20221125 00:19:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.2
[32m[20221125 00:19:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 13.6
[32m[20221125 00:19:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.0
[32m[20221125 00:19:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.4
[32m[20221125 00:19:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.0
[32m[20221125 00:19:32 @pendulum_agent.py:307][0m Sample time: 3.789166212081909
[32m[20221125 00:19:48 @pendulum_agent.py:312][0m Update time: 16.36813473701477
[32m[20221125 00:19:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:19:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:19:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:19:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:19:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:19:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:19:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:19:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:19:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:19:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:19:49 @pendulum_agent.py:317][0m Evaluation time: 0.7024834156036377
[32m[20221125 00:19:49 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.16
[32m[20221125 00:19:49 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:19:49 @pendulum_agent.py:289][0m Total time: 10658.91485786438
[32m[20221125 00:19:49 @pendulum_agent.py:291][0m 34950000 total steps have happened
[32m[20221125 00:19:49 @pendulum_agent.py:281][0m #------------------------ Iteration 699 --------------------------#
[32m[20221125 00:19:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:19:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:19:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:19:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:19:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:19:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:19:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:19:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:19:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:19:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:19:53 @pendulum_agent.py:307][0m Sample time: 3.5783872604370117
[32m[20221125 00:20:17 @pendulum_agent.py:312][0m Update time: 24.03665256500244
[32m[20221125 00:20:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:20:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:20:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:20:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:20:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:20:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:20:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:20:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:20:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:20:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:20:18 @pendulum_agent.py:317][0m Evaluation time: 0.706754207611084
[32m[20221125 00:20:18 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:20:18 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:20:18 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:20:18 @pendulum_agent.py:289][0m Total time: 10687.523717164993
[32m[20221125 00:20:18 @pendulum_agent.py:291][0m 35000000 total steps have happened
[32m[20221125 00:20:18 @pendulum_agent.py:281][0m #------------------------ Iteration 700 --------------------------#
[32m[20221125 00:20:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:20:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:20:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:20:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:20:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:20:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:20:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:20:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:20:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:20:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:20:21 @pendulum_agent.py:307][0m Sample time: 3.468635082244873
[32m[20221125 00:20:30 @pendulum_agent.py:312][0m Update time: 8.827998161315918
[32m[20221125 00:20:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:20:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:20:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:20:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:20:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:20:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:20:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:20:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:20:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:20:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:20:31 @pendulum_agent.py:317][0m Evaluation time: 0.8285267353057861
[32m[20221125 00:20:31 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:20:31 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:20:31 @pendulum_agent.py:289][0m Total time: 10700.92838382721
[32m[20221125 00:20:31 @pendulum_agent.py:291][0m 35050000 total steps have happened
[32m[20221125 00:20:31 @pendulum_agent.py:281][0m #------------------------ Iteration 701 --------------------------#
[32m[20221125 00:20:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:20:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:20:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:20:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:20:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:20:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:20:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:20:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:20:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:20:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:20:35 @pendulum_agent.py:307][0m Sample time: 3.407309055328369
[32m[20221125 00:20:56 @pendulum_agent.py:312][0m Update time: 21.308258056640625
[32m[20221125 00:20:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:20:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:20:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:20:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:20:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:20:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:20:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:20:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:20:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:20:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:20:57 @pendulum_agent.py:317][0m Evaluation time: 1.0453588962554932
[32m[20221125 00:20:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:20:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:20:57 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:20:57 @pendulum_agent.py:289][0m Total time: 10726.96921300888
[32m[20221125 00:20:57 @pendulum_agent.py:291][0m 35100000 total steps have happened
[32m[20221125 00:20:57 @pendulum_agent.py:281][0m #------------------------ Iteration 702 --------------------------#
[32m[20221125 00:20:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.4
[32m[20221125 00:20:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.6
[32m[20221125 00:20:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.0
[32m[20221125 00:20:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.6
[32m[20221125 00:20:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.4
[32m[20221125 00:20:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.6
[32m[20221125 00:20:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.8
[32m[20221125 00:20:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.4
[32m[20221125 00:20:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.6
[32m[20221125 00:20:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 9.4
[32m[20221125 00:21:01 @pendulum_agent.py:307][0m Sample time: 3.359998941421509
[32m[20221125 00:21:11 @pendulum_agent.py:312][0m Update time: 9.859915018081665
[32m[20221125 00:21:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:21:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:21:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:21:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:21:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:21:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:21:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:21:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:21:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:21:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:21:12 @pendulum_agent.py:317][0m Evaluation time: 1.140866994857788
[32m[20221125 00:21:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.78
[32m[20221125 00:21:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:21:12 @pendulum_agent.py:289][0m Total time: 10741.612201929092
[32m[20221125 00:21:12 @pendulum_agent.py:291][0m 35150000 total steps have happened
[32m[20221125 00:21:12 @pendulum_agent.py:281][0m #------------------------ Iteration 703 --------------------------#
[32m[20221125 00:21:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.6
[32m[20221125 00:21:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.6
[32m[20221125 00:21:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.6
[32m[20221125 00:21:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.8
[32m[20221125 00:21:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.0
[32m[20221125 00:21:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.6
[32m[20221125 00:21:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.0
[32m[20221125 00:21:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.6
[32m[20221125 00:21:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.4
[32m[20221125 00:21:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.0
[32m[20221125 00:21:15 @pendulum_agent.py:307][0m Sample time: 3.367933988571167
[32m[20221125 00:21:24 @pendulum_agent.py:312][0m Update time: 8.776660919189453
[32m[20221125 00:21:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:21:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:21:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:21:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:21:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:21:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:21:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:21:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:21:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:21:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:21:26 @pendulum_agent.py:317][0m Evaluation time: 1.7952182292938232
[32m[20221125 00:21:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.22
[32m[20221125 00:21:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:21:26 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:21:26 @pendulum_agent.py:289][0m Total time: 10755.838330984116
[32m[20221125 00:21:26 @pendulum_agent.py:291][0m 35200000 total steps have happened
[32m[20221125 00:21:26 @pendulum_agent.py:281][0m #------------------------ Iteration 704 --------------------------#
[32m[20221125 00:21:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:21:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:21:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:21:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:21:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:21:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:21:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:21:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:21:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:21:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:21:30 @pendulum_agent.py:307][0m Sample time: 3.519490957260132
[32m[20221125 00:21:44 @pendulum_agent.py:312][0m Update time: 13.921649932861328
[32m[20221125 00:21:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:21:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:21:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:21:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:21:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:21:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:21:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:21:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:21:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:21:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:21:44 @pendulum_agent.py:317][0m Evaluation time: 0.6951098442077637
[32m[20221125 00:21:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:21:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:21:45 @pendulum_agent.py:289][0m Total time: 10774.237108945847
[32m[20221125 00:21:45 @pendulum_agent.py:291][0m 35250000 total steps have happened
[32m[20221125 00:21:45 @pendulum_agent.py:281][0m #------------------------ Iteration 705 --------------------------#
[32m[20221125 00:21:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:21:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:21:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:21:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:21:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:21:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:21:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:21:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:21:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:21:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:21:48 @pendulum_agent.py:307][0m Sample time: 3.6731841564178467
[32m[20221125 00:21:57 @pendulum_agent.py:312][0m Update time: 8.708696842193604
[32m[20221125 00:21:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:21:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:21:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:21:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:21:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:21:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:21:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:21:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:21:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:21:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:21:58 @pendulum_agent.py:317][0m Evaluation time: 0.9360098838806152
[32m[20221125 00:21:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:21:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:21:58 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:21:58 @pendulum_agent.py:289][0m Total time: 10787.849840164185
[32m[20221125 00:21:58 @pendulum_agent.py:291][0m 35300000 total steps have happened
[32m[20221125 00:21:58 @pendulum_agent.py:281][0m #------------------------ Iteration 706 --------------------------#
[32m[20221125 00:21:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.8
[32m[20221125 00:21:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.0
[32m[20221125 00:21:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.4
[32m[20221125 00:21:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.0
[32m[20221125 00:21:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.0
[32m[20221125 00:21:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.2
[32m[20221125 00:21:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.6
[32m[20221125 00:21:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.4
[32m[20221125 00:21:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1.6
[32m[20221125 00:21:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.2
[32m[20221125 00:22:02 @pendulum_agent.py:307][0m Sample time: 3.8468070030212402
[32m[20221125 00:22:11 @pendulum_agent.py:312][0m Update time: 8.728848218917847
[32m[20221125 00:22:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:22:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:22:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:22:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:22:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:22:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:22:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:22:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:22:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:22:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:22:12 @pendulum_agent.py:317][0m Evaluation time: 0.9307677745819092
[32m[20221125 00:22:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.12
[32m[20221125 00:22:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:22:12 @pendulum_agent.py:289][0m Total time: 10801.613600969315
[32m[20221125 00:22:12 @pendulum_agent.py:291][0m 35350000 total steps have happened
[32m[20221125 00:22:12 @pendulum_agent.py:281][0m #------------------------ Iteration 707 --------------------------#
[32m[20221125 00:22:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:22:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:22:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:22:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:22:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:22:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:22:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:22:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:22:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:22:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:22:16 @pendulum_agent.py:307][0m Sample time: 3.835919141769409
[32m[20221125 00:22:29 @pendulum_agent.py:312][0m Update time: 13.349255084991455
[32m[20221125 00:22:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:22:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:22:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:22:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:22:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:22:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:22:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:22:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:22:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:22:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:22:30 @pendulum_agent.py:317][0m Evaluation time: 0.6911520957946777
[32m[20221125 00:22:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:22:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:22:30 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:22:30 @pendulum_agent.py:289][0m Total time: 10819.7752161026
[32m[20221125 00:22:30 @pendulum_agent.py:291][0m 35400000 total steps have happened
[32m[20221125 00:22:30 @pendulum_agent.py:281][0m #------------------------ Iteration 708 --------------------------#
[32m[20221125 00:22:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:22:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:22:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:22:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:22:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:22:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:22:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:22:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:22:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:22:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:22:34 @pendulum_agent.py:307][0m Sample time: 3.554673910140991
[32m[20221125 00:22:46 @pendulum_agent.py:312][0m Update time: 12.598457098007202
[32m[20221125 00:22:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:22:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:22:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:22:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:22:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:22:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:22:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:22:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:22:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:22:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:22:47 @pendulum_agent.py:317][0m Evaluation time: 0.5578320026397705
[32m[20221125 00:22:47 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:22:47 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:22:47 @pendulum_agent.py:289][0m Total time: 10836.783242940903
[32m[20221125 00:22:47 @pendulum_agent.py:291][0m 35450000 total steps have happened
[32m[20221125 00:22:47 @pendulum_agent.py:281][0m #------------------------ Iteration 709 --------------------------#
[32m[20221125 00:22:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 10.8
[32m[20221125 00:22:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 10.8
[32m[20221125 00:22:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 11.6
[32m[20221125 00:22:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 14.0
[32m[20221125 00:22:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 17.8
[32m[20221125 00:22:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 17.4
[32m[20221125 00:22:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 15.2
[32m[20221125 00:22:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 14.8
[32m[20221125 00:22:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 15.8
[32m[20221125 00:22:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 13.4
[32m[20221125 00:22:51 @pendulum_agent.py:307][0m Sample time: 3.7930901050567627
[32m[20221125 00:23:02 @pendulum_agent.py:312][0m Update time: 11.077913045883179
[32m[20221125 00:23:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:23:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:23:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:23:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:23:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:23:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:23:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:23:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:23:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:23:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:23:03 @pendulum_agent.py:317][0m Evaluation time: 0.575408935546875
[32m[20221125 00:23:03 @pendulum_agent.py:285][0m Average TRAINING episode reward: 14.16
[32m[20221125 00:23:03 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:23:03 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:23:03 @pendulum_agent.py:289][0m Total time: 10852.533190011978
[32m[20221125 00:23:03 @pendulum_agent.py:291][0m 35500000 total steps have happened
[32m[20221125 00:23:03 @pendulum_agent.py:281][0m #------------------------ Iteration 710 --------------------------#
[32m[20221125 00:23:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:23:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:23:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:23:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:23:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:23:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:23:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:23:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:23:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:23:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:23:07 @pendulum_agent.py:307][0m Sample time: 3.729501962661743
[32m[20221125 00:23:15 @pendulum_agent.py:312][0m Update time: 8.81630825996399
[32m[20221125 00:23:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:23:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:23:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:23:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:23:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:23:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:23:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:23:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:23:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:23:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:23:16 @pendulum_agent.py:317][0m Evaluation time: 0.5651509761810303
[32m[20221125 00:23:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:23:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:23:16 @pendulum_agent.py:289][0m Total time: 10865.949928998947
[32m[20221125 00:23:16 @pendulum_agent.py:291][0m 35550000 total steps have happened
[32m[20221125 00:23:16 @pendulum_agent.py:281][0m #------------------------ Iteration 711 --------------------------#
[32m[20221125 00:23:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 9.8
[32m[20221125 00:23:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 9.0
[32m[20221125 00:23:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 8.6
[32m[20221125 00:23:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 13.6
[32m[20221125 00:23:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 9.2
[32m[20221125 00:23:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 11.8
[32m[20221125 00:23:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 11.2
[32m[20221125 00:23:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.8
[32m[20221125 00:23:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 8.6
[32m[20221125 00:23:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 10.6
[32m[20221125 00:23:20 @pendulum_agent.py:307][0m Sample time: 3.8491249084472656
[32m[20221125 00:23:40 @pendulum_agent.py:312][0m Update time: 20.2089741230011
[32m[20221125 00:23:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:23:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:23:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:23:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:23:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:23:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:23:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:23:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:23:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:23:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:23:41 @pendulum_agent.py:317][0m Evaluation time: 0.6702179908752441
[32m[20221125 00:23:41 @pendulum_agent.py:285][0m Average TRAINING episode reward: 9.82
[32m[20221125 00:23:41 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:23:41 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:23:41 @pendulum_agent.py:289][0m Total time: 10890.952963113785
[32m[20221125 00:23:41 @pendulum_agent.py:291][0m 35600000 total steps have happened
[32m[20221125 00:23:41 @pendulum_agent.py:281][0m #------------------------ Iteration 712 --------------------------#
[32m[20221125 00:23:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:23:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:23:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:23:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:23:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:23:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:23:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:23:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:23:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:23:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:23:45 @pendulum_agent.py:307][0m Sample time: 3.5504300594329834
[32m[20221125 00:24:01 @pendulum_agent.py:312][0m Update time: 16.07801580429077
[32m[20221125 00:24:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:24:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:24:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:24:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:24:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:24:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:24:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:24:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:24:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:24:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:24:02 @pendulum_agent.py:317][0m Evaluation time: 0.8181209564208984
[32m[20221125 00:24:02 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:24:02 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:24:02 @pendulum_agent.py:289][0m Total time: 10911.693253993988
[32m[20221125 00:24:02 @pendulum_agent.py:291][0m 35650000 total steps have happened
[32m[20221125 00:24:02 @pendulum_agent.py:281][0m #------------------------ Iteration 713 --------------------------#
[32m[20221125 00:24:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:24:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:24:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:24:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:24:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:24:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:24:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:24:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:24:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:24:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:24:05 @pendulum_agent.py:307][0m Sample time: 3.312709093093872
[32m[20221125 00:24:14 @pendulum_agent.py:312][0m Update time: 8.86380410194397
[32m[20221125 00:24:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:24:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:24:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:24:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:24:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:24:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:24:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:24:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:24:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:24:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:24:15 @pendulum_agent.py:317][0m Evaluation time: 1.040712833404541
[32m[20221125 00:24:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:24:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:24:16 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:24:16 @pendulum_agent.py:289][0m Total time: 10925.188883781433
[32m[20221125 00:24:16 @pendulum_agent.py:291][0m 35700000 total steps have happened
[32m[20221125 00:24:16 @pendulum_agent.py:281][0m #------------------------ Iteration 714 --------------------------#
[32m[20221125 00:24:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:24:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:24:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:24:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:24:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:24:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:24:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:24:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:24:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:24:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:24:19 @pendulum_agent.py:307][0m Sample time: 3.484294891357422
[32m[20221125 00:24:30 @pendulum_agent.py:312][0m Update time: 10.698529958724976
[32m[20221125 00:24:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:24:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:24:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:24:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:24:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:24:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:24:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:24:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:24:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:24:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:24:31 @pendulum_agent.py:317][0m Evaluation time: 1.1456210613250732
[32m[20221125 00:24:31 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:24:31 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:24:31 @pendulum_agent.py:289][0m Total time: 10940.7998919487
[32m[20221125 00:24:31 @pendulum_agent.py:291][0m 35750000 total steps have happened
[32m[20221125 00:24:31 @pendulum_agent.py:281][0m #------------------------ Iteration 715 --------------------------#
[32m[20221125 00:24:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:24:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:24:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:24:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:24:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:24:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:24:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:24:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:24:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:24:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:24:35 @pendulum_agent.py:307][0m Sample time: 3.3618059158325195
[32m[20221125 00:24:52 @pendulum_agent.py:312][0m Update time: 17.271600008010864
[32m[20221125 00:24:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:24:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:24:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:24:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:24:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:24:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:24:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:24:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:24:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:24:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:24:53 @pendulum_agent.py:317][0m Evaluation time: 1.1378960609436035
[32m[20221125 00:24:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:24:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:24:53 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:24:53 @pendulum_agent.py:289][0m Total time: 10962.841001987457
[32m[20221125 00:24:53 @pendulum_agent.py:291][0m 35800000 total steps have happened
[32m[20221125 00:24:53 @pendulum_agent.py:281][0m #------------------------ Iteration 716 --------------------------#
[32m[20221125 00:24:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:24:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:24:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:24:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:24:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:24:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:24:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:24:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:24:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:24:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:24:57 @pendulum_agent.py:307][0m Sample time: 3.751343250274658
[32m[20221125 00:25:06 @pendulum_agent.py:312][0m Update time: 8.917366981506348
[32m[20221125 00:25:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:25:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:25:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:25:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:25:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:25:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:25:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:25:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:25:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:25:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:25:07 @pendulum_agent.py:317][0m Evaluation time: 0.7029168605804443
[32m[20221125 00:25:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:25:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:25:07 @pendulum_agent.py:289][0m Total time: 10976.488729953766
[32m[20221125 00:25:07 @pendulum_agent.py:291][0m 35850000 total steps have happened
[32m[20221125 00:25:07 @pendulum_agent.py:281][0m #------------------------ Iteration 717 --------------------------#
[32m[20221125 00:25:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:25:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:25:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:25:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:25:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:25:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:25:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:25:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:25:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:25:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:25:11 @pendulum_agent.py:307][0m Sample time: 3.6443259716033936
[32m[20221125 00:25:34 @pendulum_agent.py:312][0m Update time: 23.40140199661255
[32m[20221125 00:25:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:25:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:25:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:25:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:25:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:25:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:25:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:25:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:25:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:25:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:25:35 @pendulum_agent.py:317][0m Evaluation time: 0.7097151279449463
[32m[20221125 00:25:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:25:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:25:35 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:25:35 @pendulum_agent.py:289][0m Total time: 11004.51758313179
[32m[20221125 00:25:35 @pendulum_agent.py:291][0m 35900000 total steps have happened
[32m[20221125 00:25:35 @pendulum_agent.py:281][0m #------------------------ Iteration 718 --------------------------#
[32m[20221125 00:25:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.0
[32m[20221125 00:25:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.6
[32m[20221125 00:25:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.6
[32m[20221125 00:25:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 11.0
[32m[20221125 00:25:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 44.0
[32m[20221125 00:25:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 11.2
[32m[20221125 00:25:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.2
[32m[20221125 00:25:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 7.8
[32m[20221125 00:25:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 11.6
[32m[20221125 00:25:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.6
[32m[20221125 00:25:38 @pendulum_agent.py:307][0m Sample time: 3.537412166595459
[32m[20221125 00:25:47 @pendulum_agent.py:312][0m Update time: 8.912827968597412
[32m[20221125 00:25:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:25:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:25:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:25:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:25:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:25:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:25:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:25:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:25:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:25:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:25:48 @pendulum_agent.py:317][0m Evaluation time: 0.6846849918365479
[32m[20221125 00:25:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 10.46
[32m[20221125 00:25:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:25:48 @pendulum_agent.py:289][0m Total time: 11017.925745010376
[32m[20221125 00:25:48 @pendulum_agent.py:291][0m 35950000 total steps have happened
[32m[20221125 00:25:48 @pendulum_agent.py:281][0m #------------------------ Iteration 719 --------------------------#
[32m[20221125 00:25:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:25:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:25:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:25:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:25:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:25:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:25:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:25:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:25:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:25:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:25:52 @pendulum_agent.py:307][0m Sample time: 3.7883031368255615
[32m[20221125 00:26:07 @pendulum_agent.py:312][0m Update time: 15.17793583869934
[32m[20221125 00:26:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:26:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:26:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:26:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:26:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:26:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:26:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:26:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:26:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:26:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:26:08 @pendulum_agent.py:317][0m Evaluation time: 0.5737059116363525
[32m[20221125 00:26:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:26:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:26:08 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:26:08 @pendulum_agent.py:289][0m Total time: 11037.769603967667
[32m[20221125 00:26:08 @pendulum_agent.py:291][0m 36000000 total steps have happened
[32m[20221125 00:26:08 @pendulum_agent.py:281][0m #------------------------ Iteration 720 --------------------------#
[32m[20221125 00:26:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:26:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:26:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:26:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:26:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:26:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:26:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:26:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:26:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:26:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:26:12 @pendulum_agent.py:307][0m Sample time: 3.8407421112060547
[32m[20221125 00:26:21 @pendulum_agent.py:312][0m Update time: 8.845524072647095
[32m[20221125 00:26:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:26:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:26:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:26:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:26:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:26:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:26:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:26:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:26:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:26:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:26:22 @pendulum_agent.py:317][0m Evaluation time: 0.7008988857269287
[32m[20221125 00:26:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:26:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:26:22 @pendulum_agent.py:289][0m Total time: 11051.431721925735
[32m[20221125 00:26:22 @pendulum_agent.py:291][0m 36050000 total steps have happened
[32m[20221125 00:26:22 @pendulum_agent.py:281][0m #------------------------ Iteration 721 --------------------------#
[32m[20221125 00:26:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:26:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:26:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:26:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:26:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:26:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:26:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:26:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:26:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:26:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:26:25 @pendulum_agent.py:307][0m Sample time: 3.5762922763824463
[32m[20221125 00:26:34 @pendulum_agent.py:312][0m Update time: 8.993368864059448
[32m[20221125 00:26:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:26:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:26:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:26:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:26:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:26:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:26:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:26:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:26:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:26:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:26:35 @pendulum_agent.py:317][0m Evaluation time: 0.6980419158935547
[32m[20221125 00:26:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:26:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:26:35 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:26:35 @pendulum_agent.py:289][0m Total time: 11064.970415115356
[32m[20221125 00:26:35 @pendulum_agent.py:291][0m 36100000 total steps have happened
[32m[20221125 00:26:35 @pendulum_agent.py:281][0m #------------------------ Iteration 722 --------------------------#
[32m[20221125 00:26:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:26:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:26:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:26:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:26:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:26:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:26:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.2
[32m[20221125 00:26:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.0
[32m[20221125 00:26:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:26:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.6
[32m[20221125 00:26:39 @pendulum_agent.py:307][0m Sample time: 3.5345358848571777
[32m[20221125 00:26:48 @pendulum_agent.py:312][0m Update time: 8.905839204788208
[32m[20221125 00:26:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1000.0
[32m[20221125 00:26:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1000.0
[32m[20221125 00:26:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1000.0
[32m[20221125 00:26:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1000.0
[32m[20221125 00:26:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1000.0
[32m[20221125 00:26:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1000.0
[32m[20221125 00:26:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1000.0
[32m[20221125 00:26:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1000.0
[32m[20221125 00:26:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1000.0
[32m[20221125 00:26:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1000.0
[32m[20221125 00:26:49 @pendulum_agent.py:317][0m Evaluation time: 0.8361718654632568
[32m[20221125 00:26:49 @pendulum_agent.py:285][0m Average TRAINING episode reward: 1.18
[32m[20221125 00:26:49 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:26:49 @pendulum_agent.py:289][0m Total time: 11078.524752140045
[32m[20221125 00:26:49 @pendulum_agent.py:291][0m 36150000 total steps have happened
[32m[20221125 00:26:49 @pendulum_agent.py:281][0m #------------------------ Iteration 723 --------------------------#
[32m[20221125 00:26:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:26:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:26:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:26:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:26:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:26:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:26:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:26:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:26:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:26:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:26:52 @pendulum_agent.py:307][0m Sample time: 3.341876983642578
[32m[20221125 00:27:01 @pendulum_agent.py:312][0m Update time: 8.967399835586548
[32m[20221125 00:27:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:27:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:27:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:27:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:27:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:27:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:27:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:27:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:27:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:27:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:27:02 @pendulum_agent.py:317][0m Evaluation time: 1.0612139701843262
[32m[20221125 00:27:03 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:27:03 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:27:03 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:27:03 @pendulum_agent.py:289][0m Total time: 11092.175575971603
[32m[20221125 00:27:03 @pendulum_agent.py:291][0m 36200000 total steps have happened
[32m[20221125 00:27:03 @pendulum_agent.py:281][0m #------------------------ Iteration 724 --------------------------#
[32m[20221125 00:27:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:27:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:27:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:27:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:27:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:27:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:27:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:27:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:27:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:27:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:27:06 @pendulum_agent.py:307][0m Sample time: 3.2268128395080566
[32m[20221125 00:27:15 @pendulum_agent.py:312][0m Update time: 9.099488973617554
[32m[20221125 00:27:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:27:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:27:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:27:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:27:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:27:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:27:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:27:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:27:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:27:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:27:16 @pendulum_agent.py:317][0m Evaluation time: 1.058326005935669
[32m[20221125 00:27:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:27:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:27:16 @pendulum_agent.py:289][0m Total time: 11105.83825802803
[32m[20221125 00:27:16 @pendulum_agent.py:291][0m 36250000 total steps have happened
[32m[20221125 00:27:16 @pendulum_agent.py:281][0m #------------------------ Iteration 725 --------------------------#
[32m[20221125 00:27:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:27:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:27:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.6
[32m[20221125 00:27:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.2
[32m[20221125 00:27:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:27:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:27:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:27:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.2
[32m[20221125 00:27:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:27:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.4
[32m[20221125 00:27:20 @pendulum_agent.py:307][0m Sample time: 3.643620014190674
[32m[20221125 00:27:43 @pendulum_agent.py:312][0m Update time: 23.24736523628235
[32m[20221125 00:27:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:27:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:27:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:27:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:27:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:27:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:27:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:27:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:27:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:27:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:27:44 @pendulum_agent.py:317][0m Evaluation time: 0.7106029987335205
[32m[20221125 00:27:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.74
[32m[20221125 00:27:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:27:44 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:27:44 @pendulum_agent.py:289][0m Total time: 11133.718507051468
[32m[20221125 00:27:44 @pendulum_agent.py:291][0m 36300000 total steps have happened
[32m[20221125 00:27:44 @pendulum_agent.py:281][0m #------------------------ Iteration 726 --------------------------#
[32m[20221125 00:27:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 15.6
[32m[20221125 00:27:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 14.4
[32m[20221125 00:27:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 15.4
[32m[20221125 00:27:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.8
[32m[20221125 00:27:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 11.8
[32m[20221125 00:27:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.8
[32m[20221125 00:27:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 10.2
[32m[20221125 00:27:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 14.6
[32m[20221125 00:27:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 13.0
[32m[20221125 00:27:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.8
[32m[20221125 00:27:48 @pendulum_agent.py:307][0m Sample time: 3.628721237182617
[32m[20221125 00:27:57 @pendulum_agent.py:312][0m Update time: 8.839289903640747
[32m[20221125 00:27:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:27:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:27:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:27:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:27:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:27:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:27:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:27:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:27:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:27:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:27:57 @pendulum_agent.py:317][0m Evaluation time: 0.7199211120605469
[32m[20221125 00:27:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 11.44
[32m[20221125 00:27:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:27:58 @pendulum_agent.py:289][0m Total time: 11147.185605049133
[32m[20221125 00:27:58 @pendulum_agent.py:291][0m 36350000 total steps have happened
[32m[20221125 00:27:58 @pendulum_agent.py:281][0m #------------------------ Iteration 727 --------------------------#
[32m[20221125 00:27:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:27:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:27:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:27:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:27:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:27:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:27:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:27:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:27:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:27:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:28:01 @pendulum_agent.py:307][0m Sample time: 3.8216629028320312
[32m[20221125 00:28:23 @pendulum_agent.py:312][0m Update time: 21.594884872436523
[32m[20221125 00:28:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:28:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:28:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:28:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:28:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:28:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:28:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:28:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:28:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:28:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:28:24 @pendulum_agent.py:317][0m Evaluation time: 0.5736069679260254
[32m[20221125 00:28:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:28:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:28:24 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:28:24 @pendulum_agent.py:289][0m Total time: 11173.47751903534
[32m[20221125 00:28:24 @pendulum_agent.py:291][0m 36400000 total steps have happened
[32m[20221125 00:28:24 @pendulum_agent.py:281][0m #------------------------ Iteration 728 --------------------------#
[32m[20221125 00:28:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:28:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:28:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:28:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:28:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:28:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:28:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:28:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:28:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:28:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:28:28 @pendulum_agent.py:307][0m Sample time: 3.6342761516571045
[32m[20221125 00:28:56 @pendulum_agent.py:312][0m Update time: 28.632801055908203
[32m[20221125 00:28:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:28:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:28:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:28:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:28:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:28:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:28:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:28:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:28:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:28:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:28:57 @pendulum_agent.py:317][0m Evaluation time: 0.836432695388794
[32m[20221125 00:28:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:28:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:28:57 @pendulum_agent.py:289][0m Total time: 11206.856739997864
[32m[20221125 00:28:57 @pendulum_agent.py:291][0m 36450000 total steps have happened
[32m[20221125 00:28:57 @pendulum_agent.py:281][0m #------------------------ Iteration 729 --------------------------#
[32m[20221125 00:28:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 10.6
[32m[20221125 00:28:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 11.2
[32m[20221125 00:28:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 13.8
[32m[20221125 00:28:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 13.4
[32m[20221125 00:28:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.6
[32m[20221125 00:28:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.2
[32m[20221125 00:28:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 13.0
[32m[20221125 00:28:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 18.6
[32m[20221125 00:28:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 43.2
[32m[20221125 00:28:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 15.6
[32m[20221125 00:29:01 @pendulum_agent.py:307][0m Sample time: 3.4863648414611816
[32m[20221125 00:29:18 @pendulum_agent.py:312][0m Update time: 17.51966905593872
[32m[20221125 00:29:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:29:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:29:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:29:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:29:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:29:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:29:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:29:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:29:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:29:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:29:19 @pendulum_agent.py:317][0m Evaluation time: 1.0084009170532227
[32m[20221125 00:29:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 15.22
[32m[20221125 00:29:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:29:20 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:29:20 @pendulum_agent.py:289][0m Total time: 11229.140182971954
[32m[20221125 00:29:20 @pendulum_agent.py:291][0m 36500000 total steps have happened
[32m[20221125 00:29:20 @pendulum_agent.py:281][0m #------------------------ Iteration 730 --------------------------#
[32m[20221125 00:29:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:29:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:29:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:29:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:29:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:29:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:29:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:29:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:29:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:29:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:29:23 @pendulum_agent.py:307][0m Sample time: 3.5811960697174072
[32m[20221125 00:29:36 @pendulum_agent.py:312][0m Update time: 12.954910039901733
[32m[20221125 00:29:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:29:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:29:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:29:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:29:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:29:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:29:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:29:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:29:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:29:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:29:37 @pendulum_agent.py:317][0m Evaluation time: 0.7066898345947266
[32m[20221125 00:29:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:29:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:29:37 @pendulum_agent.py:289][0m Total time: 11246.658659934998
[32m[20221125 00:29:37 @pendulum_agent.py:291][0m 36550000 total steps have happened
[32m[20221125 00:29:37 @pendulum_agent.py:281][0m #------------------------ Iteration 731 --------------------------#
[32m[20221125 00:29:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:29:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:29:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:29:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:29:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:29:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:29:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:29:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:29:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:29:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:29:41 @pendulum_agent.py:307][0m Sample time: 3.567497968673706
[32m[20221125 00:29:49 @pendulum_agent.py:312][0m Update time: 8.839936017990112
[32m[20221125 00:29:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:29:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:29:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:29:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:29:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:29:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:29:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:29:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:29:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:29:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:29:50 @pendulum_agent.py:317][0m Evaluation time: 0.5780699253082275
[32m[20221125 00:29:50 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:29:50 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:29:50 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:29:50 @pendulum_agent.py:289][0m Total time: 11259.931025028229
[32m[20221125 00:29:50 @pendulum_agent.py:291][0m 36600000 total steps have happened
[32m[20221125 00:29:50 @pendulum_agent.py:281][0m #------------------------ Iteration 732 --------------------------#
[32m[20221125 00:29:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:29:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:29:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:29:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:29:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:29:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:29:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:29:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:29:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:29:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:29:54 @pendulum_agent.py:307][0m Sample time: 3.7580220699310303
[32m[20221125 00:30:04 @pendulum_agent.py:312][0m Update time: 10.299123764038086
[32m[20221125 00:30:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:30:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:30:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:30:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:30:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:30:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:30:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:30:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:30:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:30:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:30:05 @pendulum_agent.py:317][0m Evaluation time: 0.6915221214294434
[32m[20221125 00:30:05 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:30:05 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:30:05 @pendulum_agent.py:289][0m Total time: 11274.956070184708
[32m[20221125 00:30:05 @pendulum_agent.py:291][0m 36650000 total steps have happened
[32m[20221125 00:30:05 @pendulum_agent.py:281][0m #------------------------ Iteration 733 --------------------------#
[32m[20221125 00:30:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.0
[32m[20221125 00:30:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.0
[32m[20221125 00:30:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.4
[32m[20221125 00:30:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.6
[32m[20221125 00:30:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 30.2
[32m[20221125 00:30:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.8
[32m[20221125 00:30:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.2
[32m[20221125 00:30:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.2
[32m[20221125 00:30:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.6
[32m[20221125 00:30:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.4
[32m[20221125 00:30:09 @pendulum_agent.py:307][0m Sample time: 3.695174217224121
[32m[20221125 00:30:20 @pendulum_agent.py:312][0m Update time: 10.952647924423218
[32m[20221125 00:30:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:30:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:30:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:30:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:30:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:30:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:30:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:30:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:30:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:30:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:30:21 @pendulum_agent.py:317][0m Evaluation time: 0.6963560581207275
[32m[20221125 00:30:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.94
[32m[20221125 00:30:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:30:21 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:30:21 @pendulum_agent.py:289][0m Total time: 11290.575220823288
[32m[20221125 00:30:21 @pendulum_agent.py:291][0m 36700000 total steps have happened
[32m[20221125 00:30:21 @pendulum_agent.py:281][0m #------------------------ Iteration 734 --------------------------#
[32m[20221125 00:30:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:30:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:30:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:30:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:30:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:30:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:30:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:30:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:30:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:30:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:30:25 @pendulum_agent.py:307][0m Sample time: 3.7839198112487793
[32m[20221125 00:30:33 @pendulum_agent.py:312][0m Update time: 8.69973611831665
[32m[20221125 00:30:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:30:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:30:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:30:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:30:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:30:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:30:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:30:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:30:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:30:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:30:34 @pendulum_agent.py:317][0m Evaluation time: 0.9269919395446777
[32m[20221125 00:30:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:30:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:30:35 @pendulum_agent.py:289][0m Total time: 11304.267727136612
[32m[20221125 00:30:35 @pendulum_agent.py:291][0m 36750000 total steps have happened
[32m[20221125 00:30:35 @pendulum_agent.py:281][0m #------------------------ Iteration 735 --------------------------#
[32m[20221125 00:30:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:30:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:30:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:30:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:30:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:30:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:30:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:30:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:30:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:30:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:30:38 @pendulum_agent.py:307][0m Sample time: 3.7072079181671143
[32m[20221125 00:30:47 @pendulum_agent.py:312][0m Update time: 8.837520837783813
[32m[20221125 00:30:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:30:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:30:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:30:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:30:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:30:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:30:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:30:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:30:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:30:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:30:48 @pendulum_agent.py:317][0m Evaluation time: 0.7129690647125244
[32m[20221125 00:30:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:30:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:30:48 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:30:48 @pendulum_agent.py:289][0m Total time: 11317.791762113571
[32m[20221125 00:30:48 @pendulum_agent.py:291][0m 36800000 total steps have happened
[32m[20221125 00:30:48 @pendulum_agent.py:281][0m #------------------------ Iteration 736 --------------------------#
[32m[20221125 00:30:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:30:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:30:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:30:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:30:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:30:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:30:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:30:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:30:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:30:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:30:52 @pendulum_agent.py:307][0m Sample time: 3.6748690605163574
[32m[20221125 00:31:06 @pendulum_agent.py:312][0m Update time: 13.879178047180176
[32m[20221125 00:31:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1000.0
[32m[20221125 00:31:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1000.0
[32m[20221125 00:31:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1000.0
[32m[20221125 00:31:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1000.0
[32m[20221125 00:31:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1000.0
[32m[20221125 00:31:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1000.0
[32m[20221125 00:31:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1000.0
[32m[20221125 00:31:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1000.0
[32m[20221125 00:31:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1000.0
[32m[20221125 00:31:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1000.0
[32m[20221125 00:31:06 @pendulum_agent.py:317][0m Evaluation time: 0.672576904296875
[32m[20221125 00:31:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:31:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:31:07 @pendulum_agent.py:289][0m Total time: 11336.296663045883
[32m[20221125 00:31:07 @pendulum_agent.py:291][0m 36850000 total steps have happened
[32m[20221125 00:31:07 @pendulum_agent.py:281][0m #------------------------ Iteration 737 --------------------------#
[32m[20221125 00:31:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:31:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:31:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:31:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:31:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:31:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:31:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:31:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:31:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:31:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:31:10 @pendulum_agent.py:307][0m Sample time: 3.3740618228912354
[32m[20221125 00:31:19 @pendulum_agent.py:312][0m Update time: 8.88272500038147
[32m[20221125 00:31:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:31:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:31:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:31:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:31:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:31:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:31:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:31:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:31:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:31:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:31:20 @pendulum_agent.py:317][0m Evaluation time: 0.9307820796966553
[32m[20221125 00:31:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:31:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:31:20 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:31:20 @pendulum_agent.py:289][0m Total time: 11349.749371051788
[32m[20221125 00:31:20 @pendulum_agent.py:291][0m 36900000 total steps have happened
[32m[20221125 00:31:20 @pendulum_agent.py:281][0m #------------------------ Iteration 738 --------------------------#
[32m[20221125 00:31:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:31:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:31:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:31:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:31:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:31:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:31:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:31:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:31:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:31:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:31:23 @pendulum_agent.py:307][0m Sample time: 3.309321880340576
[32m[20221125 00:31:38 @pendulum_agent.py:312][0m Update time: 15.021538734436035
[32m[20221125 00:31:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:31:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:31:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:31:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:31:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:31:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:31:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:31:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:31:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:31:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:31:40 @pendulum_agent.py:317][0m Evaluation time: 1.6352603435516357
[32m[20221125 00:31:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:31:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:31:40 @pendulum_agent.py:289][0m Total time: 11369.999850988388
[32m[20221125 00:31:40 @pendulum_agent.py:291][0m 36950000 total steps have happened
[32m[20221125 00:31:40 @pendulum_agent.py:281][0m #------------------------ Iteration 739 --------------------------#
[32m[20221125 00:31:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:31:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:31:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:31:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:31:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:31:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:31:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:31:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:31:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:31:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:31:44 @pendulum_agent.py:307][0m Sample time: 3.78475284576416
[32m[20221125 00:31:53 @pendulum_agent.py:312][0m Update time: 8.8092360496521
[32m[20221125 00:31:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:31:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:31:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:31:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:31:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:31:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:31:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:31:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:31:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:31:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:31:54 @pendulum_agent.py:317][0m Evaluation time: 0.7111608982086182
[32m[20221125 00:31:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:31:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:31:54 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:31:54 @pendulum_agent.py:289][0m Total time: 11383.576819896698
[32m[20221125 00:31:54 @pendulum_agent.py:291][0m 37000000 total steps have happened
[32m[20221125 00:31:54 @pendulum_agent.py:281][0m #------------------------ Iteration 740 --------------------------#
[32m[20221125 00:31:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:31:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:31:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:31:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:31:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:31:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:31:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:31:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:31:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:31:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:31:58 @pendulum_agent.py:307][0m Sample time: 3.6152281761169434
[32m[20221125 00:32:07 @pendulum_agent.py:312][0m Update time: 9.463652849197388
[32m[20221125 00:32:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:32:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:32:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:32:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:32:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:32:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:32:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:32:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:32:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:32:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:32:08 @pendulum_agent.py:317][0m Evaluation time: 0.6912970542907715
[32m[20221125 00:32:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:32:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:32:08 @pendulum_agent.py:289][0m Total time: 11397.625502824783
[32m[20221125 00:32:08 @pendulum_agent.py:291][0m 37050000 total steps have happened
[32m[20221125 00:32:08 @pendulum_agent.py:281][0m #------------------------ Iteration 741 --------------------------#
[32m[20221125 00:32:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.6
[32m[20221125 00:32:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:32:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 9.4
[32m[20221125 00:32:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:32:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:32:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:32:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:32:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 11.2
[32m[20221125 00:32:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 7.2
[32m[20221125 00:32:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:32:12 @pendulum_agent.py:307][0m Sample time: 3.684670925140381
[32m[20221125 00:32:21 @pendulum_agent.py:312][0m Update time: 8.869693994522095
[32m[20221125 00:32:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:32:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:32:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:32:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:32:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:32:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:32:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:32:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:32:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:32:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:32:21 @pendulum_agent.py:317][0m Evaluation time: 0.6977660655975342
[32m[20221125 00:32:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.44
[32m[20221125 00:32:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:32:22 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:32:22 @pendulum_agent.py:289][0m Total time: 11411.154778957367
[32m[20221125 00:32:22 @pendulum_agent.py:291][0m 37100000 total steps have happened
[32m[20221125 00:32:22 @pendulum_agent.py:281][0m #------------------------ Iteration 742 --------------------------#
[32m[20221125 00:32:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:32:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:32:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:32:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:32:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:32:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:32:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:32:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:32:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 11.4
[32m[20221125 00:32:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:32:25 @pendulum_agent.py:307][0m Sample time: 3.573235034942627
[32m[20221125 00:32:34 @pendulum_agent.py:312][0m Update time: 8.953354120254517
[32m[20221125 00:32:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:32:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:32:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:32:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:32:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:32:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:32:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:32:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:32:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:32:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:32:35 @pendulum_agent.py:317][0m Evaluation time: 0.8051416873931885
[32m[20221125 00:32:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 1.14
[32m[20221125 00:32:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:32:35 @pendulum_agent.py:289][0m Total time: 11424.757014989853
[32m[20221125 00:32:35 @pendulum_agent.py:291][0m 37150000 total steps have happened
[32m[20221125 00:32:35 @pendulum_agent.py:281][0m #------------------------ Iteration 743 --------------------------#
[32m[20221125 00:32:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:32:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:32:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:32:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:32:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:32:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:32:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:32:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:32:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:32:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:32:39 @pendulum_agent.py:307][0m Sample time: 3.673794984817505
[32m[20221125 00:32:48 @pendulum_agent.py:312][0m Update time: 8.762925148010254
[32m[20221125 00:32:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:32:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:32:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:32:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:32:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:32:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:32:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:32:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:32:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:32:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:32:48 @pendulum_agent.py:317][0m Evaluation time: 0.6956291198730469
[32m[20221125 00:32:49 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:32:49 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:32:49 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:32:49 @pendulum_agent.py:289][0m Total time: 11438.158200979233
[32m[20221125 00:32:49 @pendulum_agent.py:291][0m 37200000 total steps have happened
[32m[20221125 00:32:49 @pendulum_agent.py:281][0m #------------------------ Iteration 744 --------------------------#
[32m[20221125 00:32:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:32:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:32:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:32:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:32:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:32:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:32:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:32:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:32:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:32:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:32:52 @pendulum_agent.py:307][0m Sample time: 3.8589282035827637
[32m[20221125 00:33:07 @pendulum_agent.py:312][0m Update time: 14.464724779129028
[32m[20221125 00:33:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:33:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:33:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:33:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:33:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:33:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:33:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:33:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:33:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:33:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:33:08 @pendulum_agent.py:317][0m Evaluation time: 0.705751895904541
[32m[20221125 00:33:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:33:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:33:08 @pendulum_agent.py:289][0m Total time: 11457.496056079865
[32m[20221125 00:33:08 @pendulum_agent.py:291][0m 37250000 total steps have happened
[32m[20221125 00:33:08 @pendulum_agent.py:281][0m #------------------------ Iteration 745 --------------------------#
[32m[20221125 00:33:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:33:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:33:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:33:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:33:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:33:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:33:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:33:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:33:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:33:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:33:12 @pendulum_agent.py:307][0m Sample time: 3.6206421852111816
[32m[20221125 00:33:21 @pendulum_agent.py:312][0m Update time: 9.985781908035278
[32m[20221125 00:33:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:33:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:33:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:33:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:33:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:33:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:33:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:33:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:33:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:33:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:33:22 @pendulum_agent.py:317][0m Evaluation time: 0.7244689464569092
[32m[20221125 00:33:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:33:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:33:22 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:33:22 @pendulum_agent.py:289][0m Total time: 11472.10185098648
[32m[20221125 00:33:22 @pendulum_agent.py:291][0m 37300000 total steps have happened
[32m[20221125 00:33:22 @pendulum_agent.py:281][0m #------------------------ Iteration 746 --------------------------#
[32m[20221125 00:33:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.8
[32m[20221125 00:33:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.4
[32m[20221125 00:33:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.0
[32m[20221125 00:33:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.4
[32m[20221125 00:33:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.2
[32m[20221125 00:33:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.0
[32m[20221125 00:33:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.2
[32m[20221125 00:33:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.2
[32m[20221125 00:33:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.8
[32m[20221125 00:33:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.2
[32m[20221125 00:33:26 @pendulum_agent.py:307][0m Sample time: 3.5362629890441895
[32m[20221125 00:33:51 @pendulum_agent.py:312][0m Update time: 25.171129941940308
[32m[20221125 00:33:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 33.0
[32m[20221125 00:33:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 33.0
[32m[20221125 00:33:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 33.0
[32m[20221125 00:33:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 33.0
[32m[20221125 00:33:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 33.0
[32m[20221125 00:33:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 33.0
[32m[20221125 00:33:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 33.0
[32m[20221125 00:33:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 33.0
[32m[20221125 00:33:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 33.0
[32m[20221125 00:33:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 33.0
[32m[20221125 00:33:52 @pendulum_agent.py:317][0m Evaluation time: 0.8313751220703125
[32m[20221125 00:33:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.62
[32m[20221125 00:33:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:33:52 @pendulum_agent.py:289][0m Total time: 11501.917350053787
[32m[20221125 00:33:52 @pendulum_agent.py:291][0m 37350000 total steps have happened
[32m[20221125 00:33:52 @pendulum_agent.py:281][0m #------------------------ Iteration 747 --------------------------#
[32m[20221125 00:33:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:33:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:33:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:33:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:33:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:33:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:33:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:33:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:33:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:33:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:33:56 @pendulum_agent.py:307][0m Sample time: 3.3924977779388428
[32m[20221125 00:34:05 @pendulum_agent.py:312][0m Update time: 9.546241998672485
[32m[20221125 00:34:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:34:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:34:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:34:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:34:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:34:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:34:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:34:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:34:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:34:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:34:06 @pendulum_agent.py:317][0m Evaluation time: 1.0332450866699219
[32m[20221125 00:34:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:34:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:34:07 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:34:07 @pendulum_agent.py:289][0m Total time: 11516.162853956223
[32m[20221125 00:34:07 @pendulum_agent.py:291][0m 37400000 total steps have happened
[32m[20221125 00:34:07 @pendulum_agent.py:281][0m #------------------------ Iteration 748 --------------------------#
[32m[20221125 00:34:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 9.4
[32m[20221125 00:34:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 19.0
[32m[20221125 00:34:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 8.8
[32m[20221125 00:34:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 11.6
[32m[20221125 00:34:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 17.6
[32m[20221125 00:34:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 12.2
[32m[20221125 00:34:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 14.8
[32m[20221125 00:34:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 10.4
[32m[20221125 00:34:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.8
[32m[20221125 00:34:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 13.4
[32m[20221125 00:34:10 @pendulum_agent.py:307][0m Sample time: 3.421053886413574
[32m[20221125 00:34:19 @pendulum_agent.py:312][0m Update time: 8.732878923416138
[32m[20221125 00:34:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:34:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:34:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:34:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:34:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:34:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:34:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:34:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:34:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:34:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:34:20 @pendulum_agent.py:317][0m Evaluation time: 1.1595470905303955
[32m[20221125 00:34:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 12.0
[32m[20221125 00:34:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:34:20 @pendulum_agent.py:289][0m Total time: 11529.742612838745
[32m[20221125 00:34:20 @pendulum_agent.py:291][0m 37450000 total steps have happened
[32m[20221125 00:34:20 @pendulum_agent.py:281][0m #------------------------ Iteration 749 --------------------------#
[32m[20221125 00:34:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.0
[32m[20221125 00:34:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.4
[32m[20221125 00:34:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.2
[32m[20221125 00:34:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.4
[32m[20221125 00:34:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.0
[32m[20221125 00:34:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.8
[32m[20221125 00:34:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.2
[32m[20221125 00:34:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.2
[32m[20221125 00:34:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.2
[32m[20221125 00:34:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 9.4
[32m[20221125 00:34:23 @pendulum_agent.py:307][0m Sample time: 3.3441550731658936
[32m[20221125 00:34:32 @pendulum_agent.py:312][0m Update time: 8.715095043182373
[32m[20221125 00:34:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:34:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:34:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:34:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:34:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:34:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:34:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:34:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:34:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:34:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:34:34 @pendulum_agent.py:317][0m Evaluation time: 1.7999279499053955
[32m[20221125 00:34:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.38
[32m[20221125 00:34:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:34:34 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:34:34 @pendulum_agent.py:289][0m Total time: 11543.88029885292
[32m[20221125 00:34:34 @pendulum_agent.py:291][0m 37500000 total steps have happened
[32m[20221125 00:34:34 @pendulum_agent.py:281][0m #------------------------ Iteration 750 --------------------------#
[32m[20221125 00:34:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:34:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:34:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:34:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:34:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:34:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:34:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:34:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:34:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:34:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:34:38 @pendulum_agent.py:307][0m Sample time: 3.5720951557159424
[32m[20221125 00:35:02 @pendulum_agent.py:312][0m Update time: 23.75546383857727
[32m[20221125 00:35:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:35:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:35:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:35:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:35:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:35:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:35:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:35:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:35:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:35:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:35:02 @pendulum_agent.py:317][0m Evaluation time: 0.7148301601409912
[32m[20221125 00:35:03 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:35:03 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:35:03 @pendulum_agent.py:289][0m Total time: 11572.200349092484
[32m[20221125 00:35:03 @pendulum_agent.py:291][0m 37550000 total steps have happened
[32m[20221125 00:35:03 @pendulum_agent.py:281][0m #------------------------ Iteration 751 --------------------------#
[32m[20221125 00:35:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:35:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:35:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:35:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:35:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:35:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:35:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:35:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:35:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:35:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:35:06 @pendulum_agent.py:307][0m Sample time: 3.6582388877868652
[32m[20221125 00:35:15 @pendulum_agent.py:312][0m Update time: 8.73735499382019
[32m[20221125 00:35:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:35:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:35:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:35:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:35:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:35:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:35:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:35:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:35:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:35:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:35:16 @pendulum_agent.py:317][0m Evaluation time: 0.9413299560546875
[32m[20221125 00:35:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:35:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:35:16 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:35:16 @pendulum_agent.py:289][0m Total time: 11585.809339046478
[32m[20221125 00:35:16 @pendulum_agent.py:291][0m 37600000 total steps have happened
[32m[20221125 00:35:16 @pendulum_agent.py:281][0m #------------------------ Iteration 752 --------------------------#
[32m[20221125 00:35:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:35:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:35:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:35:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:35:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:35:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:35:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:35:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:35:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:35:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:35:20 @pendulum_agent.py:307][0m Sample time: 3.8526883125305176
[32m[20221125 00:35:40 @pendulum_agent.py:312][0m Update time: 19.895211935043335
[32m[20221125 00:35:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:35:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:35:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:35:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:35:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:35:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:35:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:35:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:35:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:35:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:35:41 @pendulum_agent.py:317][0m Evaluation time: 0.8939199447631836
[32m[20221125 00:35:41 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:35:41 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:35:41 @pendulum_agent.py:289][0m Total time: 11610.69816493988
[32m[20221125 00:35:41 @pendulum_agent.py:291][0m 37650000 total steps have happened
[32m[20221125 00:35:41 @pendulum_agent.py:281][0m #------------------------ Iteration 753 --------------------------#
[32m[20221125 00:35:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:35:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:35:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:35:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:35:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:35:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:35:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:35:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:35:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:35:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:35:45 @pendulum_agent.py:307][0m Sample time: 3.844193935394287
[32m[20221125 00:35:55 @pendulum_agent.py:312][0m Update time: 9.683283805847168
[32m[20221125 00:35:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:35:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:35:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:35:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:35:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:35:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:35:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:35:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:35:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:35:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:35:55 @pendulum_agent.py:317][0m Evaluation time: 0.685021162033081
[32m[20221125 00:35:56 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:35:56 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:35:56 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:35:56 @pendulum_agent.py:289][0m Total time: 11625.188184976578
[32m[20221125 00:35:56 @pendulum_agent.py:291][0m 37700000 total steps have happened
[32m[20221125 00:35:56 @pendulum_agent.py:281][0m #------------------------ Iteration 754 --------------------------#
[32m[20221125 00:35:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:35:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:35:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:35:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:35:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:35:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:35:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:35:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:35:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:35:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:35:59 @pendulum_agent.py:307][0m Sample time: 3.562248945236206
[32m[20221125 00:36:11 @pendulum_agent.py:312][0m Update time: 12.122744083404541
[32m[20221125 00:36:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:36:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:36:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:36:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:36:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:36:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:36:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:36:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:36:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:36:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:36:12 @pendulum_agent.py:317][0m Evaluation time: 0.5857570171356201
[32m[20221125 00:36:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:36:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:36:12 @pendulum_agent.py:289][0m Total time: 11641.754981040955
[32m[20221125 00:36:12 @pendulum_agent.py:291][0m 37750000 total steps have happened
[32m[20221125 00:36:12 @pendulum_agent.py:281][0m #------------------------ Iteration 755 --------------------------#
[32m[20221125 00:36:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.2
[32m[20221125 00:36:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.2
[32m[20221125 00:36:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.2
[32m[20221125 00:36:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.2
[32m[20221125 00:36:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.2
[32m[20221125 00:36:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.2
[32m[20221125 00:36:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.2
[32m[20221125 00:36:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.2
[32m[20221125 00:36:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.2
[32m[20221125 00:36:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1.0
[32m[20221125 00:36:16 @pendulum_agent.py:307][0m Sample time: 3.7597620487213135
[32m[20221125 00:36:26 @pendulum_agent.py:312][0m Update time: 10.409116983413696
[32m[20221125 00:36:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:36:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:36:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:36:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:36:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:36:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:36:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:36:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:36:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:36:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:36:27 @pendulum_agent.py:317][0m Evaluation time: 0.563845157623291
[32m[20221125 00:36:27 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.28
[32m[20221125 00:36:27 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:36:27 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:36:27 @pendulum_agent.py:289][0m Total time: 11656.78849196434
[32m[20221125 00:36:27 @pendulum_agent.py:291][0m 37800000 total steps have happened
[32m[20221125 00:36:27 @pendulum_agent.py:281][0m #------------------------ Iteration 756 --------------------------#
[32m[20221125 00:36:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.8
[32m[20221125 00:36:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.4
[32m[20221125 00:36:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.0
[32m[20221125 00:36:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.8
[32m[20221125 00:36:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.2
[32m[20221125 00:36:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.8
[32m[20221125 00:36:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.0
[32m[20221125 00:36:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 7.6
[32m[20221125 00:36:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.0
[32m[20221125 00:36:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.4
[32m[20221125 00:36:31 @pendulum_agent.py:307][0m Sample time: 3.7178380489349365
[32m[20221125 00:36:41 @pendulum_agent.py:312][0m Update time: 10.03054690361023
[32m[20221125 00:36:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:36:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:36:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:36:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:36:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:36:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:36:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:36:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:36:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:36:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:36:42 @pendulum_agent.py:317][0m Evaluation time: 0.5733060836791992
[32m[20221125 00:36:42 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.9
[32m[20221125 00:36:42 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:36:42 @pendulum_agent.py:289][0m Total time: 11671.404744148254
[32m[20221125 00:36:42 @pendulum_agent.py:291][0m 37850000 total steps have happened
[32m[20221125 00:36:42 @pendulum_agent.py:281][0m #------------------------ Iteration 757 --------------------------#
[32m[20221125 00:36:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 9.8
[32m[20221125 00:36:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.6
[32m[20221125 00:36:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.0
[32m[20221125 00:36:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 8.6
[32m[20221125 00:36:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.0
[32m[20221125 00:36:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.4
[32m[20221125 00:36:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.0
[32m[20221125 00:36:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.6
[32m[20221125 00:36:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 11.0
[32m[20221125 00:36:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.4
[32m[20221125 00:36:46 @pendulum_agent.py:307][0m Sample time: 3.8100638389587402
[32m[20221125 00:36:56 @pendulum_agent.py:312][0m Update time: 10.71578311920166
[32m[20221125 00:36:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:36:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:36:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:36:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:36:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:36:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:36:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:36:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:36:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:36:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:36:57 @pendulum_agent.py:317][0m Evaluation time: 0.6813890933990479
[32m[20221125 00:36:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.84
[32m[20221125 00:36:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:36:57 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:36:57 @pendulum_agent.py:289][0m Total time: 11686.885224819183
[32m[20221125 00:36:57 @pendulum_agent.py:291][0m 37900000 total steps have happened
[32m[20221125 00:36:57 @pendulum_agent.py:281][0m #------------------------ Iteration 758 --------------------------#
[32m[20221125 00:36:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:36:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:36:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:36:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:36:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:36:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:36:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:36:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:36:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:36:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:37:01 @pendulum_agent.py:307][0m Sample time: 3.5605499744415283
[32m[20221125 00:37:10 @pendulum_agent.py:312][0m Update time: 8.901890993118286
[32m[20221125 00:37:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:37:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:37:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:37:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:37:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:37:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:37:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:37:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:37:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:37:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:37:11 @pendulum_agent.py:317][0m Evaluation time: 0.8088161945343018
[32m[20221125 00:37:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:37:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:37:11 @pendulum_agent.py:289][0m Total time: 11700.444196939468
[32m[20221125 00:37:11 @pendulum_agent.py:291][0m 37950000 total steps have happened
[32m[20221125 00:37:11 @pendulum_agent.py:281][0m #------------------------ Iteration 759 --------------------------#
[32m[20221125 00:37:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:37:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:37:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:37:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:37:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:37:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:37:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:37:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:37:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:37:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:37:14 @pendulum_agent.py:307][0m Sample time: 3.3256280422210693
[32m[20221125 00:37:23 @pendulum_agent.py:312][0m Update time: 8.762985944747925
[32m[20221125 00:37:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.0
[32m[20221125 00:37:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.0
[32m[20221125 00:37:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.0
[32m[20221125 00:37:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.0
[32m[20221125 00:37:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.0
[32m[20221125 00:37:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.0
[32m[20221125 00:37:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.0
[32m[20221125 00:37:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.0
[32m[20221125 00:37:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.0
[32m[20221125 00:37:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.0
[32m[20221125 00:37:24 @pendulum_agent.py:317][0m Evaluation time: 1.0317020416259766
[32m[20221125 00:37:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:37:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:37:24 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:37:24 @pendulum_agent.py:289][0m Total time: 11713.8365380764
[32m[20221125 00:37:24 @pendulum_agent.py:291][0m 38000000 total steps have happened
[32m[20221125 00:37:24 @pendulum_agent.py:281][0m #------------------------ Iteration 760 --------------------------#
[32m[20221125 00:37:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.6
[32m[20221125 00:37:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.6
[32m[20221125 00:37:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.6
[32m[20221125 00:37:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.8
[32m[20221125 00:37:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.0
[32m[20221125 00:37:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.6
[32m[20221125 00:37:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.6
[32m[20221125 00:37:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.6
[32m[20221125 00:37:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.4
[32m[20221125 00:37:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.0
[32m[20221125 00:37:28 @pendulum_agent.py:307][0m Sample time: 3.5948286056518555
[32m[20221125 00:37:42 @pendulum_agent.py:312][0m Update time: 14.354811191558838
[32m[20221125 00:37:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:37:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:37:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:37:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:37:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:37:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:37:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:37:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:37:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:37:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:37:43 @pendulum_agent.py:317][0m Evaluation time: 1.1489160060882568
[32m[20221125 00:37:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 1.28
[32m[20221125 00:37:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:37:44 @pendulum_agent.py:289][0m Total time: 11733.215235948563
[32m[20221125 00:37:44 @pendulum_agent.py:291][0m 38050000 total steps have happened
[32m[20221125 00:37:44 @pendulum_agent.py:281][0m #------------------------ Iteration 761 --------------------------#
[32m[20221125 00:37:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 11.0
[32m[20221125 00:37:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:37:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 8.4
[32m[20221125 00:37:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 11.8
[32m[20221125 00:37:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.8
[32m[20221125 00:37:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.2
[32m[20221125 00:37:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.4
[32m[20221125 00:37:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.6
[32m[20221125 00:37:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 10.4
[32m[20221125 00:37:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 10.4
[32m[20221125 00:37:47 @pendulum_agent.py:307][0m Sample time: 3.389101982116699
[32m[20221125 00:37:56 @pendulum_agent.py:312][0m Update time: 8.852090120315552
[32m[20221125 00:37:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:37:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:37:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:37:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:37:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:37:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:37:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:37:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:37:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:37:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:37:57 @pendulum_agent.py:317][0m Evaluation time: 1.168508768081665
[32m[20221125 00:37:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 8.0
[32m[20221125 00:37:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:37:57 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:37:57 @pendulum_agent.py:289][0m Total time: 11746.89823794365
[32m[20221125 00:37:57 @pendulum_agent.py:291][0m 38100000 total steps have happened
[32m[20221125 00:37:57 @pendulum_agent.py:281][0m #------------------------ Iteration 762 --------------------------#
[32m[20221125 00:37:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 8.2
[32m[20221125 00:37:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.4
[32m[20221125 00:37:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 7.4
[32m[20221125 00:37:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.4
[32m[20221125 00:37:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.8
[32m[20221125 00:37:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.2
[32m[20221125 00:37:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.0
[32m[20221125 00:37:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.2
[32m[20221125 00:37:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 7.6
[32m[20221125 00:37:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.6
[32m[20221125 00:38:01 @pendulum_agent.py:307][0m Sample time: 3.6302340030670166
[32m[20221125 00:38:23 @pendulum_agent.py:312][0m Update time: 21.681336879730225
[32m[20221125 00:38:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:38:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:38:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:38:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:38:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:38:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:38:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:38:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:38:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:38:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:38:23 @pendulum_agent.py:317][0m Evaluation time: 0.7033312320709229
[32m[20221125 00:38:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.58
[32m[20221125 00:38:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:38:24 @pendulum_agent.py:289][0m Total time: 11773.192458868027
[32m[20221125 00:38:24 @pendulum_agent.py:291][0m 38150000 total steps have happened
[32m[20221125 00:38:24 @pendulum_agent.py:281][0m #------------------------ Iteration 763 --------------------------#
[32m[20221125 00:38:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:38:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:38:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:38:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:38:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:38:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:38:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:38:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:38:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:38:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:38:27 @pendulum_agent.py:307][0m Sample time: 3.593564748764038
[32m[20221125 00:38:37 @pendulum_agent.py:312][0m Update time: 9.570221185684204
[32m[20221125 00:38:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:38:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:38:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:38:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:38:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:38:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:38:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:38:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:38:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:38:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:38:37 @pendulum_agent.py:317][0m Evaluation time: 0.7079150676727295
[32m[20221125 00:38:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:38:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:38:38 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:38:38 @pendulum_agent.py:289][0m Total time: 11787.349951982498
[32m[20221125 00:38:38 @pendulum_agent.py:291][0m 38200000 total steps have happened
[32m[20221125 00:38:38 @pendulum_agent.py:281][0m #------------------------ Iteration 764 --------------------------#
[32m[20221125 00:38:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.2
[32m[20221125 00:38:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1.4
[32m[20221125 00:38:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.4
[32m[20221125 00:38:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.2
[32m[20221125 00:38:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.6
[32m[20221125 00:38:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1.6
[32m[20221125 00:38:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.6
[32m[20221125 00:38:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.2
[32m[20221125 00:38:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.6
[32m[20221125 00:38:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1.4
[32m[20221125 00:38:41 @pendulum_agent.py:307][0m Sample time: 3.6683080196380615
[32m[20221125 00:38:54 @pendulum_agent.py:312][0m Update time: 12.28467607498169
[32m[20221125 00:38:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:38:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:38:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:38:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:38:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:38:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:38:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:38:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:38:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:38:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:38:54 @pendulum_agent.py:317][0m Evaluation time: 0.6981260776519775
[32m[20221125 00:38:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 1.42
[32m[20221125 00:38:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:38:55 @pendulum_agent.py:289][0m Total time: 11804.273943901062
[32m[20221125 00:38:55 @pendulum_agent.py:291][0m 38250000 total steps have happened
[32m[20221125 00:38:55 @pendulum_agent.py:281][0m #------------------------ Iteration 765 --------------------------#
[32m[20221125 00:38:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.2
[32m[20221125 00:38:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.2
[32m[20221125 00:38:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 7.0
[32m[20221125 00:38:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.0
[32m[20221125 00:38:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 8.8
[32m[20221125 00:38:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 7.2
[32m[20221125 00:38:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.8
[32m[20221125 00:38:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.0
[32m[20221125 00:38:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.2
[32m[20221125 00:38:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.0
[32m[20221125 00:38:59 @pendulum_agent.py:307][0m Sample time: 3.835824966430664
[32m[20221125 00:39:15 @pendulum_agent.py:312][0m Update time: 16.13762402534485
[32m[20221125 00:39:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:39:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:39:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:39:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:39:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:39:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:39:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:39:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:39:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:39:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:39:15 @pendulum_agent.py:317][0m Evaluation time: 0.5719540119171143
[32m[20221125 00:39:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.14
[32m[20221125 00:39:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:39:16 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:39:16 @pendulum_agent.py:289][0m Total time: 11825.121527910233
[32m[20221125 00:39:16 @pendulum_agent.py:291][0m 38300000 total steps have happened
[32m[20221125 00:39:16 @pendulum_agent.py:281][0m #------------------------ Iteration 766 --------------------------#
[32m[20221125 00:39:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:39:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:39:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:39:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:39:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:39:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:39:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:39:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:39:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:39:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:39:19 @pendulum_agent.py:307][0m Sample time: 3.7498581409454346
[32m[20221125 00:39:28 @pendulum_agent.py:312][0m Update time: 8.986325025558472
[32m[20221125 00:39:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:39:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:39:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:39:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:39:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:39:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:39:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:39:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:39:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:39:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:39:29 @pendulum_agent.py:317][0m Evaluation time: 0.6765260696411133
[32m[20221125 00:39:29 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:39:29 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:39:29 @pendulum_agent.py:289][0m Total time: 11838.812530994415
[32m[20221125 00:39:29 @pendulum_agent.py:291][0m 38350000 total steps have happened
[32m[20221125 00:39:29 @pendulum_agent.py:281][0m #------------------------ Iteration 767 --------------------------#
[32m[20221125 00:39:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:39:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:39:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:39:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:39:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:39:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:39:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:39:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:39:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:39:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:39:33 @pendulum_agent.py:307][0m Sample time: 3.603383779525757
[32m[20221125 00:39:42 @pendulum_agent.py:312][0m Update time: 9.022311210632324
[32m[20221125 00:39:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:39:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:39:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:39:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:39:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:39:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:39:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:39:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:39:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:39:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:39:43 @pendulum_agent.py:317][0m Evaluation time: 0.6882140636444092
[32m[20221125 00:39:43 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:39:43 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:39:43 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:39:43 @pendulum_agent.py:289][0m Total time: 11852.414569854736
[32m[20221125 00:39:43 @pendulum_agent.py:291][0m 38400000 total steps have happened
[32m[20221125 00:39:43 @pendulum_agent.py:281][0m #------------------------ Iteration 768 --------------------------#
[32m[20221125 00:39:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 11.4
[32m[20221125 00:39:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 11.2
[32m[20221125 00:39:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 10.8
[32m[20221125 00:39:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 8.8
[32m[20221125 00:39:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 9.6
[32m[20221125 00:39:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 9.8
[32m[20221125 00:39:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 9.4
[32m[20221125 00:39:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 9.0
[32m[20221125 00:39:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 9.0
[32m[20221125 00:39:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 9.4
[32m[20221125 00:39:46 @pendulum_agent.py:307][0m Sample time: 3.598200798034668
[32m[20221125 00:39:55 @pendulum_agent.py:312][0m Update time: 9.055906057357788
[32m[20221125 00:39:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 27.0
[32m[20221125 00:39:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 27.0
[32m[20221125 00:39:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 27.0
[32m[20221125 00:39:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 27.0
[32m[20221125 00:39:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 27.0
[32m[20221125 00:39:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 27.0
[32m[20221125 00:39:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 27.0
[32m[20221125 00:39:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 27.0
[32m[20221125 00:39:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 27.0
[32m[20221125 00:39:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 27.0
[32m[20221125 00:39:56 @pendulum_agent.py:317][0m Evaluation time: 0.8453052043914795
[32m[20221125 00:39:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 9.84
[32m[20221125 00:39:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:39:57 @pendulum_agent.py:289][0m Total time: 11866.197960853577
[32m[20221125 00:39:57 @pendulum_agent.py:291][0m 38450000 total steps have happened
[32m[20221125 00:39:57 @pendulum_agent.py:281][0m #------------------------ Iteration 769 --------------------------#
[32m[20221125 00:39:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.4
[32m[20221125 00:39:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.2
[32m[20221125 00:39:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.6
[32m[20221125 00:39:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.8
[32m[20221125 00:39:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.0
[32m[20221125 00:39:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.6
[32m[20221125 00:39:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.4
[32m[20221125 00:39:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.6
[32m[20221125 00:39:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.4
[32m[20221125 00:39:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.0
[32m[20221125 00:40:00 @pendulum_agent.py:307][0m Sample time: 3.526312828063965
[32m[20221125 00:40:09 @pendulum_agent.py:312][0m Update time: 9.015221118927002
[32m[20221125 00:40:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:40:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:40:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:40:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:40:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:40:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:40:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:40:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:40:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:40:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:40:10 @pendulum_agent.py:317][0m Evaluation time: 1.068161964416504
[32m[20221125 00:40:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.2
[32m[20221125 00:40:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:40:10 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:40:10 @pendulum_agent.py:289][0m Total time: 11880.076560020447
[32m[20221125 00:40:10 @pendulum_agent.py:291][0m 38500000 total steps have happened
[32m[20221125 00:40:10 @pendulum_agent.py:281][0m #------------------------ Iteration 770 --------------------------#
[32m[20221125 00:40:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:40:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:40:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:40:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:40:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:40:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:40:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:40:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:40:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:40:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:40:14 @pendulum_agent.py:307][0m Sample time: 3.219074010848999
[32m[20221125 00:40:23 @pendulum_agent.py:312][0m Update time: 9.070971965789795
[32m[20221125 00:40:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:40:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:40:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:40:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:40:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:40:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:40:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:40:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:40:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:40:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:40:24 @pendulum_agent.py:317][0m Evaluation time: 1.0446269512176514
[32m[20221125 00:40:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:40:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:40:24 @pendulum_agent.py:289][0m Total time: 11893.686376810074
[32m[20221125 00:40:24 @pendulum_agent.py:291][0m 38550000 total steps have happened
[32m[20221125 00:40:24 @pendulum_agent.py:281][0m #------------------------ Iteration 771 --------------------------#
[32m[20221125 00:40:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 8.8
[32m[20221125 00:40:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.6
[32m[20221125 00:40:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.0
[32m[20221125 00:40:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 9.2
[32m[20221125 00:40:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.4
[32m[20221125 00:40:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 9.0
[32m[20221125 00:40:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 8.6
[32m[20221125 00:40:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 7.4
[32m[20221125 00:40:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 12.2
[32m[20221125 00:40:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 11.4
[32m[20221125 00:40:28 @pendulum_agent.py:307][0m Sample time: 3.6724307537078857
[32m[20221125 00:40:37 @pendulum_agent.py:312][0m Update time: 8.976338148117065
[32m[20221125 00:40:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:40:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:40:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:40:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:40:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:40:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:40:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:40:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:40:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:40:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:40:37 @pendulum_agent.py:317][0m Evaluation time: 0.7145512104034424
[32m[20221125 00:40:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 8.56
[32m[20221125 00:40:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:40:38 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:40:38 @pendulum_agent.py:289][0m Total time: 11907.324625015259
[32m[20221125 00:40:38 @pendulum_agent.py:291][0m 38600000 total steps have happened
[32m[20221125 00:40:38 @pendulum_agent.py:281][0m #------------------------ Iteration 772 --------------------------#
[32m[20221125 00:40:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:40:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:40:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:40:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:40:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:40:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:40:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:40:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:40:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:40:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:40:41 @pendulum_agent.py:307][0m Sample time: 3.653167724609375
[32m[20221125 00:40:50 @pendulum_agent.py:312][0m Update time: 8.91124415397644
[32m[20221125 00:40:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:40:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:40:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:40:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:40:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:40:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:40:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:40:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:40:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:40:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:40:51 @pendulum_agent.py:317][0m Evaluation time: 0.7080099582672119
[32m[20221125 00:40:51 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:40:51 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:40:51 @pendulum_agent.py:289][0m Total time: 11920.879832983017
[32m[20221125 00:40:51 @pendulum_agent.py:291][0m 38650000 total steps have happened
[32m[20221125 00:40:51 @pendulum_agent.py:281][0m #------------------------ Iteration 773 --------------------------#
[32m[20221125 00:40:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:40:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:40:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:40:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:40:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:40:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:40:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:40:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:40:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:40:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:40:55 @pendulum_agent.py:307][0m Sample time: 3.8978829383850098
[32m[20221125 00:41:07 @pendulum_agent.py:312][0m Update time: 11.95737910270691
[32m[20221125 00:41:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:41:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:41:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:41:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:41:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:41:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:41:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:41:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:41:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:41:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:41:08 @pendulum_agent.py:317][0m Evaluation time: 0.5739889144897461
[32m[20221125 00:41:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:41:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:41:08 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:41:08 @pendulum_agent.py:289][0m Total time: 11937.623976945877
[32m[20221125 00:41:08 @pendulum_agent.py:291][0m 38700000 total steps have happened
[32m[20221125 00:41:08 @pendulum_agent.py:281][0m #------------------------ Iteration 774 --------------------------#
[32m[20221125 00:41:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:41:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:41:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:41:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:41:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:41:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:41:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:41:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:41:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:41:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:41:12 @pendulum_agent.py:307][0m Sample time: 3.657715082168579
[32m[20221125 00:41:21 @pendulum_agent.py:312][0m Update time: 8.906403064727783
[32m[20221125 00:41:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:41:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:41:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:41:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:41:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:41:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:41:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:41:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:41:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:41:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:41:21 @pendulum_agent.py:317][0m Evaluation time: 0.8241117000579834
[32m[20221125 00:41:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:41:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:41:22 @pendulum_agent.py:289][0m Total time: 11951.294649124146
[32m[20221125 00:41:22 @pendulum_agent.py:291][0m 38750000 total steps have happened
[32m[20221125 00:41:22 @pendulum_agent.py:281][0m #------------------------ Iteration 775 --------------------------#
[32m[20221125 00:41:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:41:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:41:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:41:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:41:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:41:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:41:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:41:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:41:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:41:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:41:25 @pendulum_agent.py:307][0m Sample time: 3.5491273403167725
[32m[20221125 00:41:34 @pendulum_agent.py:312][0m Update time: 9.021996021270752
[32m[20221125 00:41:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:41:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:41:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:41:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:41:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:41:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:41:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:41:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:41:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:41:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:41:35 @pendulum_agent.py:317][0m Evaluation time: 1.0263538360595703
[32m[20221125 00:41:36 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:41:36 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:41:36 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:41:36 @pendulum_agent.py:289][0m Total time: 11965.18501496315
[32m[20221125 00:41:36 @pendulum_agent.py:291][0m 38800000 total steps have happened
[32m[20221125 00:41:36 @pendulum_agent.py:281][0m #------------------------ Iteration 776 --------------------------#
[32m[20221125 00:41:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.4
[32m[20221125 00:41:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 10.2
[32m[20221125 00:41:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 7.6
[32m[20221125 00:41:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 13.4
[32m[20221125 00:41:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 8.4
[32m[20221125 00:41:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 12.4
[32m[20221125 00:41:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 11.4
[32m[20221125 00:41:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 10.6
[32m[20221125 00:41:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 9.6
[32m[20221125 00:41:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.2
[32m[20221125 00:41:39 @pendulum_agent.py:307][0m Sample time: 3.609147310256958
[32m[20221125 00:41:52 @pendulum_agent.py:312][0m Update time: 12.512326717376709
[32m[20221125 00:41:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:41:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:41:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:41:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:41:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:41:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:41:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:41:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:41:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:41:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:41:52 @pendulum_agent.py:317][0m Evaluation time: 0.6950850486755371
[32m[20221125 00:41:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 9.72
[32m[20221125 00:41:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:41:53 @pendulum_agent.py:289][0m Total time: 11982.283340930939
[32m[20221125 00:41:53 @pendulum_agent.py:291][0m 38850000 total steps have happened
[32m[20221125 00:41:53 @pendulum_agent.py:281][0m #------------------------ Iteration 777 --------------------------#
[32m[20221125 00:41:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:41:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:41:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:41:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:41:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:41:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:41:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:41:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:41:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:41:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:41:56 @pendulum_agent.py:307][0m Sample time: 3.6314990520477295
[32m[20221125 00:42:07 @pendulum_agent.py:312][0m Update time: 10.584144830703735
[32m[20221125 00:42:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:42:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:42:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:42:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:42:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:42:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:42:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:42:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:42:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:42:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:42:07 @pendulum_agent.py:317][0m Evaluation time: 0.5858979225158691
[32m[20221125 00:42:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:42:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:42:08 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:42:08 @pendulum_agent.py:289][0m Total time: 11997.396044015884
[32m[20221125 00:42:08 @pendulum_agent.py:291][0m 38900000 total steps have happened
[32m[20221125 00:42:08 @pendulum_agent.py:281][0m #------------------------ Iteration 778 --------------------------#
[32m[20221125 00:42:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:42:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:42:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:42:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:42:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:42:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:42:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:42:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:42:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:42:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:42:12 @pendulum_agent.py:307][0m Sample time: 3.769908905029297
[32m[20221125 00:42:29 @pendulum_agent.py:312][0m Update time: 17.479851961135864
[32m[20221125 00:42:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:42:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:42:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:42:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:42:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:42:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:42:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:42:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:42:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:42:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:42:30 @pendulum_agent.py:317][0m Evaluation time: 0.6686320304870605
[32m[20221125 00:42:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:42:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:42:30 @pendulum_agent.py:289][0m Total time: 12019.596174955368
[32m[20221125 00:42:30 @pendulum_agent.py:291][0m 38950000 total steps have happened
[32m[20221125 00:42:30 @pendulum_agent.py:281][0m #------------------------ Iteration 779 --------------------------#
[32m[20221125 00:42:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.2
[32m[20221125 00:42:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.0
[32m[20221125 00:42:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.0
[32m[20221125 00:42:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 8.6
[32m[20221125 00:42:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.8
[32m[20221125 00:42:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 7.4
[32m[20221125 00:42:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 14.0
[32m[20221125 00:42:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.2
[32m[20221125 00:42:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.4
[32m[20221125 00:42:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.0
[32m[20221125 00:42:34 @pendulum_agent.py:307][0m Sample time: 3.72312593460083
[32m[20221125 00:42:48 @pendulum_agent.py:312][0m Update time: 13.988039016723633
[32m[20221125 00:42:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:42:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:42:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:42:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:42:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:42:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:42:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:42:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:42:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:42:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:42:48 @pendulum_agent.py:317][0m Evaluation time: 0.6825809478759766
[32m[20221125 00:42:49 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.16
[32m[20221125 00:42:49 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:42:49 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:42:49 @pendulum_agent.py:289][0m Total time: 12038.270197868347
[32m[20221125 00:42:49 @pendulum_agent.py:291][0m 39000000 total steps have happened
[32m[20221125 00:42:49 @pendulum_agent.py:281][0m #------------------------ Iteration 780 --------------------------#
[32m[20221125 00:42:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:42:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:42:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:42:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:42:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:42:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:42:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:42:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:42:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:42:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:42:52 @pendulum_agent.py:307][0m Sample time: 3.5685620307922363
[32m[20221125 00:43:10 @pendulum_agent.py:312][0m Update time: 17.439507961273193
[32m[20221125 00:43:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:43:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:43:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:43:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:43:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:43:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:43:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:43:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:43:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:43:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:43:11 @pendulum_agent.py:317][0m Evaluation time: 0.9420351982116699
[32m[20221125 00:43:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:43:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:43:11 @pendulum_agent.py:289][0m Total time: 12060.512481927872
[32m[20221125 00:43:11 @pendulum_agent.py:291][0m 39050000 total steps have happened
[32m[20221125 00:43:11 @pendulum_agent.py:281][0m #------------------------ Iteration 781 --------------------------#
[32m[20221125 00:43:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:43:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:43:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:43:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:43:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:43:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:43:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:43:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:43:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:43:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:43:15 @pendulum_agent.py:307][0m Sample time: 3.681212902069092
[32m[20221125 00:43:24 @pendulum_agent.py:312][0m Update time: 8.95542287826538
[32m[20221125 00:43:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:43:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:43:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:43:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:43:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:43:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:43:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:43:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:43:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:43:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:43:24 @pendulum_agent.py:317][0m Evaluation time: 0.6895380020141602
[32m[20221125 00:43:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:43:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:43:25 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:43:25 @pendulum_agent.py:289][0m Total time: 12074.114254951477
[32m[20221125 00:43:25 @pendulum_agent.py:291][0m 39100000 total steps have happened
[32m[20221125 00:43:25 @pendulum_agent.py:281][0m #------------------------ Iteration 782 --------------------------#
[32m[20221125 00:43:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:43:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:43:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:43:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:43:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:43:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:43:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:43:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:43:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:43:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:43:28 @pendulum_agent.py:307][0m Sample time: 3.690808057785034
[32m[20221125 00:43:37 @pendulum_agent.py:312][0m Update time: 8.89522385597229
[32m[20221125 00:43:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:43:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:43:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:43:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:43:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:43:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:43:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:43:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:43:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:43:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:43:38 @pendulum_agent.py:317][0m Evaluation time: 0.676753044128418
[32m[20221125 00:43:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:43:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:43:38 @pendulum_agent.py:289][0m Total time: 12087.669235944748
[32m[20221125 00:43:38 @pendulum_agent.py:291][0m 39150000 total steps have happened
[32m[20221125 00:43:38 @pendulum_agent.py:281][0m #------------------------ Iteration 783 --------------------------#
[32m[20221125 00:43:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:43:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:43:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:43:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:43:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:43:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:43:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:43:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:43:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:43:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:43:41 @pendulum_agent.py:307][0m Sample time: 3.356112003326416
[32m[20221125 00:43:50 @pendulum_agent.py:312][0m Update time: 8.878415822982788
[32m[20221125 00:43:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:43:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:43:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:43:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:43:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:43:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:43:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:43:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:43:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:43:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:43:51 @pendulum_agent.py:317][0m Evaluation time: 0.9176361560821533
[32m[20221125 00:43:51 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:43:51 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:43:51 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:43:51 @pendulum_agent.py:289][0m Total time: 12101.090258836746
[32m[20221125 00:43:51 @pendulum_agent.py:291][0m 39200000 total steps have happened
[32m[20221125 00:43:51 @pendulum_agent.py:281][0m #------------------------ Iteration 784 --------------------------#
[32m[20221125 00:43:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:43:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:43:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:43:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:43:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:43:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:43:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:43:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:43:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:43:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:43:55 @pendulum_agent.py:307][0m Sample time: 3.2722768783569336
[32m[20221125 00:44:04 @pendulum_agent.py:312][0m Update time: 8.83033013343811
[32m[20221125 00:44:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:44:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:44:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:44:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:44:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:44:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:44:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:44:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:44:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:44:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:44:05 @pendulum_agent.py:317][0m Evaluation time: 1.6227290630340576
[32m[20221125 00:44:05 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:44:05 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:44:05 @pendulum_agent.py:289][0m Total time: 12115.10412311554
[32m[20221125 00:44:05 @pendulum_agent.py:291][0m 39250000 total steps have happened
[32m[20221125 00:44:05 @pendulum_agent.py:281][0m #------------------------ Iteration 785 --------------------------#
[32m[20221125 00:44:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:44:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:44:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:44:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:44:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:44:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:44:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:44:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:44:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:44:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:44:09 @pendulum_agent.py:307][0m Sample time: 3.7789111137390137
[32m[20221125 00:44:18 @pendulum_agent.py:312][0m Update time: 8.842720985412598
[32m[20221125 00:44:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:44:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:44:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:44:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:44:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:44:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:44:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:44:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:44:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:44:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:44:19 @pendulum_agent.py:317][0m Evaluation time: 0.7005729675292969
[32m[20221125 00:44:19 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:44:19 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:44:19 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:44:19 @pendulum_agent.py:289][0m Total time: 12128.69390797615
[32m[20221125 00:44:19 @pendulum_agent.py:291][0m 39300000 total steps have happened
[32m[20221125 00:44:19 @pendulum_agent.py:281][0m #------------------------ Iteration 786 --------------------------#
[32m[20221125 00:44:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:44:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:44:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:44:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:44:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:44:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:44:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:44:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:44:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:44:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:44:23 @pendulum_agent.py:307][0m Sample time: 3.7458608150482178
[32m[20221125 00:44:32 @pendulum_agent.py:312][0m Update time: 8.93262505531311
[32m[20221125 00:44:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:44:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:44:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:44:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:44:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:44:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:44:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:44:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:44:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:44:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:44:32 @pendulum_agent.py:317][0m Evaluation time: 0.7091951370239258
[32m[20221125 00:44:33 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:44:33 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:44:33 @pendulum_agent.py:289][0m Total time: 12142.363281011581
[32m[20221125 00:44:33 @pendulum_agent.py:291][0m 39350000 total steps have happened
[32m[20221125 00:44:33 @pendulum_agent.py:281][0m #------------------------ Iteration 787 --------------------------#
[32m[20221125 00:44:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:44:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:44:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:44:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:44:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:44:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:44:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:44:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:44:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:44:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:44:37 @pendulum_agent.py:307][0m Sample time: 3.7776567935943604
[32m[20221125 00:44:45 @pendulum_agent.py:312][0m Update time: 8.867645978927612
[32m[20221125 00:44:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:44:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:44:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:44:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:44:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:44:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:44:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:44:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:44:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:44:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:44:46 @pendulum_agent.py:317][0m Evaluation time: 0.6826920509338379
[32m[20221125 00:44:46 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:44:46 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:44:46 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:44:46 @pendulum_agent.py:289][0m Total time: 12155.979786872864
[32m[20221125 00:44:46 @pendulum_agent.py:291][0m 39400000 total steps have happened
[32m[20221125 00:44:46 @pendulum_agent.py:281][0m #------------------------ Iteration 788 --------------------------#
[32m[20221125 00:44:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:44:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:44:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:44:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:44:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:44:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:44:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:44:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:44:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:44:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:44:50 @pendulum_agent.py:307][0m Sample time: 3.4794270992279053
[32m[20221125 00:45:09 @pendulum_agent.py:312][0m Update time: 18.924903869628906
[32m[20221125 00:45:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:45:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:45:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:45:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:45:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:45:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:45:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:45:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:45:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:45:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:45:10 @pendulum_agent.py:317][0m Evaluation time: 0.8319370746612549
[32m[20221125 00:45:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:45:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:45:10 @pendulum_agent.py:289][0m Total time: 12179.48589515686
[32m[20221125 00:45:10 @pendulum_agent.py:291][0m 39450000 total steps have happened
[32m[20221125 00:45:10 @pendulum_agent.py:281][0m #------------------------ Iteration 789 --------------------------#
[32m[20221125 00:45:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.4
[32m[20221125 00:45:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.2
[32m[20221125 00:45:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.4
[32m[20221125 00:45:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.0
[32m[20221125 00:45:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.0
[32m[20221125 00:45:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.0
[32m[20221125 00:45:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.2
[32m[20221125 00:45:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.8
[32m[20221125 00:45:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.0
[32m[20221125 00:45:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.4
[32m[20221125 00:45:14 @pendulum_agent.py:307][0m Sample time: 3.648128032684326
[32m[20221125 00:45:22 @pendulum_agent.py:312][0m Update time: 8.908329248428345
[32m[20221125 00:45:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 22.0
[32m[20221125 00:45:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 22.0
[32m[20221125 00:45:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 22.0
[32m[20221125 00:45:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 22.0
[32m[20221125 00:45:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 22.0
[32m[20221125 00:45:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 22.0
[32m[20221125 00:45:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 22.0
[32m[20221125 00:45:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 22.0
[32m[20221125 00:45:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 22.0
[32m[20221125 00:45:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 22.0
[32m[20221125 00:45:23 @pendulum_agent.py:317][0m Evaluation time: 0.6924717426300049
[32m[20221125 00:45:23 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.94
[32m[20221125 00:45:23 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:45:23 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:45:23 @pendulum_agent.py:289][0m Total time: 12193.005023002625
[32m[20221125 00:45:23 @pendulum_agent.py:291][0m 39500000 total steps have happened
[32m[20221125 00:45:23 @pendulum_agent.py:281][0m #------------------------ Iteration 790 --------------------------#
[32m[20221125 00:45:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:45:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:45:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:45:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:45:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:45:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:45:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:45:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:45:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:45:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:45:27 @pendulum_agent.py:307][0m Sample time: 3.7251641750335693
[32m[20221125 00:45:41 @pendulum_agent.py:312][0m Update time: 13.767523050308228
[32m[20221125 00:45:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:45:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:45:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:45:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:45:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:45:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:45:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:45:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:45:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:45:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:45:42 @pendulum_agent.py:317][0m Evaluation time: 0.7188160419464111
[32m[20221125 00:45:42 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:45:42 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:45:42 @pendulum_agent.py:289][0m Total time: 12211.495949983597
[32m[20221125 00:45:42 @pendulum_agent.py:291][0m 39550000 total steps have happened
[32m[20221125 00:45:42 @pendulum_agent.py:281][0m #------------------------ Iteration 791 --------------------------#
[32m[20221125 00:45:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:45:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:45:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:45:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:45:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:45:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:45:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:45:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:45:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:45:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:45:45 @pendulum_agent.py:307][0m Sample time: 3.5659101009368896
[32m[20221125 00:45:59 @pendulum_agent.py:312][0m Update time: 13.798492908477783
[32m[20221125 00:45:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:45:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:45:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:45:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:45:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:45:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:46:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:46:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:46:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:46:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:46:00 @pendulum_agent.py:317][0m Evaluation time: 0.6866960525512695
[32m[20221125 00:46:00 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:46:00 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:46:00 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:46:00 @pendulum_agent.py:289][0m Total time: 12229.834470033646
[32m[20221125 00:46:00 @pendulum_agent.py:291][0m 39600000 total steps have happened
[32m[20221125 00:46:00 @pendulum_agent.py:281][0m #------------------------ Iteration 792 --------------------------#
[32m[20221125 00:46:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:46:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:46:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:46:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:46:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:46:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:46:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:46:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:46:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:46:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:46:04 @pendulum_agent.py:307][0m Sample time: 3.5931079387664795
[32m[20221125 00:46:19 @pendulum_agent.py:312][0m Update time: 15.464908838272095
[32m[20221125 00:46:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:46:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:46:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:46:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:46:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:46:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:46:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:46:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:46:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:46:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:46:20 @pendulum_agent.py:317][0m Evaluation time: 0.8176040649414062
[32m[20221125 00:46:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:46:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:46:20 @pendulum_agent.py:289][0m Total time: 12250.002737045288
[32m[20221125 00:46:20 @pendulum_agent.py:291][0m 39650000 total steps have happened
[32m[20221125 00:46:20 @pendulum_agent.py:281][0m #------------------------ Iteration 793 --------------------------#
[32m[20221125 00:46:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:46:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:46:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:46:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:46:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:46:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:46:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:46:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:46:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:46:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:46:24 @pendulum_agent.py:307][0m Sample time: 3.453758955001831
[32m[20221125 00:46:33 @pendulum_agent.py:312][0m Update time: 9.519577741622925
[32m[20221125 00:46:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:46:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:46:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:46:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:46:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:46:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:46:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:46:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:46:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:46:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:46:34 @pendulum_agent.py:317][0m Evaluation time: 1.0186281204223633
[32m[20221125 00:46:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:46:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:46:35 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:46:35 @pendulum_agent.py:289][0m Total time: 12264.276453018188
[32m[20221125 00:46:35 @pendulum_agent.py:291][0m 39700000 total steps have happened
[32m[20221125 00:46:35 @pendulum_agent.py:281][0m #------------------------ Iteration 794 --------------------------#
[32m[20221125 00:46:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.4
[32m[20221125 00:46:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.6
[32m[20221125 00:46:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:46:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.8
[32m[20221125 00:46:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.6
[32m[20221125 00:46:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.2
[32m[20221125 00:46:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.0
[32m[20221125 00:46:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.6
[32m[20221125 00:46:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 8.4
[32m[20221125 00:46:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.2
[32m[20221125 00:46:38 @pendulum_agent.py:307][0m Sample time: 3.316326856613159
[32m[20221125 00:46:47 @pendulum_agent.py:312][0m Update time: 8.80447006225586
[32m[20221125 00:46:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:46:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:46:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:46:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:46:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:46:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:46:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:46:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:46:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:46:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:46:48 @pendulum_agent.py:317][0m Evaluation time: 1.1579618453979492
[32m[20221125 00:46:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.18
[32m[20221125 00:46:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:46:48 @pendulum_agent.py:289][0m Total time: 12277.829672813416
[32m[20221125 00:46:48 @pendulum_agent.py:291][0m 39750000 total steps have happened
[32m[20221125 00:46:48 @pendulum_agent.py:281][0m #------------------------ Iteration 795 --------------------------#
[32m[20221125 00:46:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:46:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:46:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:46:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:46:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:46:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:46:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:46:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:46:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:46:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:46:52 @pendulum_agent.py:307][0m Sample time: 3.3353850841522217
[32m[20221125 00:47:00 @pendulum_agent.py:312][0m Update time: 8.815424919128418
[32m[20221125 00:47:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:47:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:47:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:47:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:47:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:47:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:47:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:47:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:47:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:47:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:47:02 @pendulum_agent.py:317][0m Evaluation time: 1.7914550304412842
[32m[20221125 00:47:02 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:47:02 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:47:02 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:47:02 @pendulum_agent.py:289][0m Total time: 12292.071515083313
[32m[20221125 00:47:02 @pendulum_agent.py:291][0m 39800000 total steps have happened
[32m[20221125 00:47:02 @pendulum_agent.py:281][0m #------------------------ Iteration 796 --------------------------#
[32m[20221125 00:47:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:47:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:47:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:47:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:47:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:47:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:47:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:47:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:47:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:47:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:47:06 @pendulum_agent.py:307][0m Sample time: 3.5765879154205322
[32m[20221125 00:47:15 @pendulum_agent.py:312][0m Update time: 8.960746049880981
[32m[20221125 00:47:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:47:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:47:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:47:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:47:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:47:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:47:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:47:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:47:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:47:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:47:16 @pendulum_agent.py:317][0m Evaluation time: 0.7163670063018799
[32m[20221125 00:47:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:47:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:47:16 @pendulum_agent.py:289][0m Total time: 12305.59900689125
[32m[20221125 00:47:16 @pendulum_agent.py:291][0m 39850000 total steps have happened
[32m[20221125 00:47:16 @pendulum_agent.py:281][0m #------------------------ Iteration 797 --------------------------#
[32m[20221125 00:47:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 10.2
[32m[20221125 00:47:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 8.6
[32m[20221125 00:47:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 7.0
[32m[20221125 00:47:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 12.4
[32m[20221125 00:47:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 8.0
[32m[20221125 00:47:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.8
[32m[20221125 00:47:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 10.0
[32m[20221125 00:47:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 10.6
[32m[20221125 00:47:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 13.0
[32m[20221125 00:47:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 9.4
[32m[20221125 00:47:20 @pendulum_agent.py:307][0m Sample time: 3.7436962127685547
[32m[20221125 00:47:29 @pendulum_agent.py:312][0m Update time: 8.8300039768219
[32m[20221125 00:47:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 30.0
[32m[20221125 00:47:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 30.0
[32m[20221125 00:47:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 30.0
[32m[20221125 00:47:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 30.0
[32m[20221125 00:47:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 30.0
[32m[20221125 00:47:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 30.0
[32m[20221125 00:47:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 30.0
[32m[20221125 00:47:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 30.0
[32m[20221125 00:47:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 30.0
[32m[20221125 00:47:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 30.0
[32m[20221125 00:47:30 @pendulum_agent.py:317][0m Evaluation time: 0.9464468955993652
[32m[20221125 00:47:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 9.8
[32m[20221125 00:47:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:47:30 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:47:30 @pendulum_agent.py:289][0m Total time: 12319.40365409851
[32m[20221125 00:47:30 @pendulum_agent.py:291][0m 39900000 total steps have happened
[32m[20221125 00:47:30 @pendulum_agent.py:281][0m #------------------------ Iteration 798 --------------------------#
[32m[20221125 00:47:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 11.4
[32m[20221125 00:47:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 12.2
[32m[20221125 00:47:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 10.2
[32m[20221125 00:47:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 12.4
[32m[20221125 00:47:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 12.0
[32m[20221125 00:47:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 16.4
[32m[20221125 00:47:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 12.2
[32m[20221125 00:47:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 11.8
[32m[20221125 00:47:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 12.6
[32m[20221125 00:47:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 12.2
[32m[20221125 00:47:34 @pendulum_agent.py:307][0m Sample time: 3.8872230052948
[32m[20221125 00:48:05 @pendulum_agent.py:312][0m Update time: 31.19105100631714
[32m[20221125 00:48:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:48:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:48:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:48:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:48:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:48:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:48:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:48:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:48:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:48:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:48:06 @pendulum_agent.py:317][0m Evaluation time: 0.9226510524749756
[32m[20221125 00:48:06 @pendulum_agent.py:285][0m Average TRAINING episode reward: 12.34
[32m[20221125 00:48:06 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:48:06 @pendulum_agent.py:289][0m Total time: 12355.706810951233
[32m[20221125 00:48:06 @pendulum_agent.py:291][0m 39950000 total steps have happened
[32m[20221125 00:48:06 @pendulum_agent.py:281][0m #------------------------ Iteration 799 --------------------------#
[32m[20221125 00:48:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:48:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:48:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:48:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:48:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:48:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:48:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:48:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:48:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:48:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:48:10 @pendulum_agent.py:307][0m Sample time: 3.936500072479248
[32m[20221125 00:48:19 @pendulum_agent.py:312][0m Update time: 8.872820854187012
[32m[20221125 00:48:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:48:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:48:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:48:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:48:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:48:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:48:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:48:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:48:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:48:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:48:20 @pendulum_agent.py:317][0m Evaluation time: 0.6891791820526123
[32m[20221125 00:48:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:48:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:48:20 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:48:20 @pendulum_agent.py:289][0m Total time: 12369.497087955475
[32m[20221125 00:48:20 @pendulum_agent.py:291][0m 40000000 total steps have happened
[32m[20221125 00:48:20 @pendulum_agent.py:281][0m #------------------------ Iteration 800 --------------------------#
[32m[20221125 00:48:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 16.2
[32m[20221125 00:48:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 14.2
[32m[20221125 00:48:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 15.6
[32m[20221125 00:48:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.0
[32m[20221125 00:48:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 20.4
[32m[20221125 00:48:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 15.2
[32m[20221125 00:48:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 16.6
[32m[20221125 00:48:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.6
[32m[20221125 00:48:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.4
[32m[20221125 00:48:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 13.6
[32m[20221125 00:48:23 @pendulum_agent.py:307][0m Sample time: 3.554358959197998
[32m[20221125 00:48:46 @pendulum_agent.py:312][0m Update time: 22.98937702178955
[32m[20221125 00:48:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:48:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:48:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:48:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:48:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:48:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:48:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:48:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:48:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:48:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:48:47 @pendulum_agent.py:317][0m Evaluation time: 0.5749351978302002
[32m[20221125 00:48:47 @pendulum_agent.py:285][0m Average TRAINING episode reward: 13.48
[32m[20221125 00:48:47 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:48:47 @pendulum_agent.py:289][0m Total time: 12396.903455018997
[32m[20221125 00:48:47 @pendulum_agent.py:291][0m 40050000 total steps have happened
[32m[20221125 00:48:47 @pendulum_agent.py:281][0m #------------------------ Iteration 801 --------------------------#
[32m[20221125 00:48:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:48:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:48:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:48:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:48:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:48:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:48:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:48:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:48:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:48:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:48:51 @pendulum_agent.py:307][0m Sample time: 3.775291919708252
[32m[20221125 00:49:02 @pendulum_agent.py:312][0m Update time: 10.899161100387573
[32m[20221125 00:49:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:49:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:49:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:49:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:49:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:49:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:49:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:49:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:49:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:49:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:49:03 @pendulum_agent.py:317][0m Evaluation time: 0.5570628643035889
[32m[20221125 00:49:03 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:49:03 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:49:03 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:49:03 @pendulum_agent.py:289][0m Total time: 12412.435604810715
[32m[20221125 00:49:03 @pendulum_agent.py:291][0m 40100000 total steps have happened
[32m[20221125 00:49:03 @pendulum_agent.py:281][0m #------------------------ Iteration 802 --------------------------#
[32m[20221125 00:49:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:49:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:49:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:49:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:49:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:49:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:49:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:49:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:49:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:49:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:49:07 @pendulum_agent.py:307][0m Sample time: 3.759424924850464
[32m[20221125 00:49:16 @pendulum_agent.py:312][0m Update time: 9.076053142547607
[32m[20221125 00:49:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:49:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:49:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:49:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:49:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:49:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:49:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:49:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:49:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:49:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:49:16 @pendulum_agent.py:317][0m Evaluation time: 0.56955885887146
[32m[20221125 00:49:17 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:49:17 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:49:17 @pendulum_agent.py:289][0m Total time: 12426.13781094551
[32m[20221125 00:49:17 @pendulum_agent.py:291][0m 40150000 total steps have happened
[32m[20221125 00:49:17 @pendulum_agent.py:281][0m #------------------------ Iteration 803 --------------------------#
[32m[20221125 00:49:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:49:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:49:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:49:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:49:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:49:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:49:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:49:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:49:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:49:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:49:20 @pendulum_agent.py:307][0m Sample time: 3.8227410316467285
[32m[20221125 00:49:30 @pendulum_agent.py:312][0m Update time: 10.032912015914917
[32m[20221125 00:49:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:49:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:49:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:49:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:49:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:49:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:49:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:49:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:49:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:49:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:49:31 @pendulum_agent.py:317][0m Evaluation time: 0.6726880073547363
[32m[20221125 00:49:31 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:49:31 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:49:31 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:49:31 @pendulum_agent.py:289][0m Total time: 12440.949385881424
[32m[20221125 00:49:31 @pendulum_agent.py:291][0m 40200000 total steps have happened
[32m[20221125 00:49:31 @pendulum_agent.py:281][0m #------------------------ Iteration 804 --------------------------#
[32m[20221125 00:49:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.4
[32m[20221125 00:49:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.2
[32m[20221125 00:49:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.0
[32m[20221125 00:49:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.8
[32m[20221125 00:49:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.4
[32m[20221125 00:49:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.8
[32m[20221125 00:49:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.6
[32m[20221125 00:49:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.6
[32m[20221125 00:49:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.4
[32m[20221125 00:49:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.2
[32m[20221125 00:49:35 @pendulum_agent.py:307][0m Sample time: 3.498581886291504
[32m[20221125 00:49:44 @pendulum_agent.py:312][0m Update time: 9.016634941101074
[32m[20221125 00:49:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:49:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:49:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:49:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:49:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:49:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:49:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:49:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:49:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:49:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:49:45 @pendulum_agent.py:317][0m Evaluation time: 0.8166210651397705
[32m[20221125 00:49:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.64
[32m[20221125 00:49:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:49:45 @pendulum_agent.py:289][0m Total time: 12454.577315092087
[32m[20221125 00:49:45 @pendulum_agent.py:291][0m 40250000 total steps have happened
[32m[20221125 00:49:45 @pendulum_agent.py:281][0m #------------------------ Iteration 805 --------------------------#
[32m[20221125 00:49:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.2
[32m[20221125 00:49:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.6
[32m[20221125 00:49:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.0
[32m[20221125 00:49:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.0
[32m[20221125 00:49:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.6
[32m[20221125 00:49:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.4
[32m[20221125 00:49:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 3.8
[32m[20221125 00:49:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.0
[32m[20221125 00:49:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.0
[32m[20221125 00:49:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.0
[32m[20221125 00:49:48 @pendulum_agent.py:307][0m Sample time: 3.246213674545288
[32m[20221125 00:50:10 @pendulum_agent.py:312][0m Update time: 21.529567003250122
[32m[20221125 00:50:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:50:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:50:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:50:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:50:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:50:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:50:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:50:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:50:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:50:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:50:11 @pendulum_agent.py:317][0m Evaluation time: 1.0328550338745117
[32m[20221125 00:50:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.36
[32m[20221125 00:50:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:50:11 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:50:11 @pendulum_agent.py:289][0m Total time: 12480.663310050964
[32m[20221125 00:50:11 @pendulum_agent.py:291][0m 40300000 total steps have happened
[32m[20221125 00:50:11 @pendulum_agent.py:281][0m #------------------------ Iteration 806 --------------------------#
[32m[20221125 00:50:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:50:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:50:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:50:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:50:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:50:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:50:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:50:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:50:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:50:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:50:15 @pendulum_agent.py:307][0m Sample time: 3.5289831161499023
[32m[20221125 00:50:44 @pendulum_agent.py:312][0m Update time: 29.518590927124023
[32m[20221125 00:50:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:50:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:50:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:50:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:50:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:50:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:50:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:50:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:50:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:50:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:50:45 @pendulum_agent.py:317][0m Evaluation time: 1.13372802734375
[32m[20221125 00:50:46 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:50:46 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:50:46 @pendulum_agent.py:289][0m Total time: 12515.126065015793
[32m[20221125 00:50:46 @pendulum_agent.py:291][0m 40350000 total steps have happened
[32m[20221125 00:50:46 @pendulum_agent.py:281][0m #------------------------ Iteration 807 --------------------------#
[32m[20221125 00:50:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:50:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:50:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:50:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:50:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:50:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:50:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:50:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:50:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:50:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:50:49 @pendulum_agent.py:307][0m Sample time: 3.3821287155151367
[32m[20221125 00:50:59 @pendulum_agent.py:312][0m Update time: 9.848807334899902
[32m[20221125 00:50:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:50:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:50:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:50:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:50:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:50:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:50:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:50:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:50:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:50:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:51:00 @pendulum_agent.py:317][0m Evaluation time: 1.150237798690796
[32m[20221125 00:51:00 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:51:00 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:51:00 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:51:00 @pendulum_agent.py:289][0m Total time: 12529.78328704834
[32m[20221125 00:51:00 @pendulum_agent.py:291][0m 40400000 total steps have happened
[32m[20221125 00:51:00 @pendulum_agent.py:281][0m #------------------------ Iteration 808 --------------------------#
[32m[20221125 00:51:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:51:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:51:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:51:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:51:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:51:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:51:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:51:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:51:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:51:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:51:04 @pendulum_agent.py:307][0m Sample time: 3.6365621089935303
[32m[20221125 00:51:13 @pendulum_agent.py:312][0m Update time: 9.076794862747192
[32m[20221125 00:51:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:51:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:51:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:51:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:51:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:51:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:51:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:51:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:51:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:51:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:51:14 @pendulum_agent.py:317][0m Evaluation time: 0.7023649215698242
[32m[20221125 00:51:14 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:51:14 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:51:14 @pendulum_agent.py:289][0m Total time: 12543.473731994629
[32m[20221125 00:51:14 @pendulum_agent.py:291][0m 40450000 total steps have happened
[32m[20221125 00:51:14 @pendulum_agent.py:281][0m #------------------------ Iteration 809 --------------------------#
[32m[20221125 00:51:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.2
[32m[20221125 00:51:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.0
[32m[20221125 00:51:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.2
[32m[20221125 00:51:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.8
[32m[20221125 00:51:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.8
[32m[20221125 00:51:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.4
[32m[20221125 00:51:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.8
[32m[20221125 00:51:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.4
[32m[20221125 00:51:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.8
[32m[20221125 00:51:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.8
[32m[20221125 00:51:18 @pendulum_agent.py:307][0m Sample time: 3.6476101875305176
[32m[20221125 00:51:37 @pendulum_agent.py:312][0m Update time: 19.052757024765015
[32m[20221125 00:51:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:51:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:51:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:51:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:51:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:51:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:51:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:51:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:51:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:51:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:51:37 @pendulum_agent.py:317][0m Evaluation time: 0.7183029651641846
[32m[20221125 00:51:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.12
[32m[20221125 00:51:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:51:38 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:51:38 @pendulum_agent.py:289][0m Total time: 12567.17837691307
[32m[20221125 00:51:38 @pendulum_agent.py:291][0m 40500000 total steps have happened
[32m[20221125 00:51:38 @pendulum_agent.py:281][0m #------------------------ Iteration 810 --------------------------#
[32m[20221125 00:51:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:51:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:51:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:51:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:51:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:51:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:51:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:51:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:51:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:51:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:51:41 @pendulum_agent.py:307][0m Sample time: 3.558695077896118
[32m[20221125 00:51:50 @pendulum_agent.py:312][0m Update time: 9.07697582244873
[32m[20221125 00:51:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:51:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:51:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:51:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:51:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:51:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:51:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:51:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:51:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:51:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:51:51 @pendulum_agent.py:317][0m Evaluation time: 0.6874041557312012
[32m[20221125 00:51:51 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:51:51 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:51:51 @pendulum_agent.py:289][0m Total time: 12580.78116607666
[32m[20221125 00:51:51 @pendulum_agent.py:291][0m 40550000 total steps have happened
[32m[20221125 00:51:51 @pendulum_agent.py:281][0m #------------------------ Iteration 811 --------------------------#
[32m[20221125 00:51:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.2
[32m[20221125 00:51:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.2
[32m[20221125 00:51:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.6
[32m[20221125 00:51:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.8
[32m[20221125 00:51:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.4
[32m[20221125 00:51:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 7.8
[32m[20221125 00:51:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.8
[32m[20221125 00:51:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.6
[32m[20221125 00:51:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.6
[32m[20221125 00:51:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.2
[32m[20221125 00:51:55 @pendulum_agent.py:307][0m Sample time: 3.8407249450683594
[32m[20221125 00:52:04 @pendulum_agent.py:312][0m Update time: 8.936781167984009
[32m[20221125 00:52:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:52:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:52:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:52:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:52:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:52:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:52:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:52:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:52:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:52:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:52:05 @pendulum_agent.py:317][0m Evaluation time: 0.5877807140350342
[32m[20221125 00:52:05 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.62
[32m[20221125 00:52:05 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:52:05 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:52:05 @pendulum_agent.py:289][0m Total time: 12594.4597260952
[32m[20221125 00:52:05 @pendulum_agent.py:291][0m 40600000 total steps have happened
[32m[20221125 00:52:05 @pendulum_agent.py:281][0m #------------------------ Iteration 812 --------------------------#
[32m[20221125 00:52:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.2
[32m[20221125 00:52:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.4
[32m[20221125 00:52:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.6
[32m[20221125 00:52:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.6
[32m[20221125 00:52:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.0
[32m[20221125 00:52:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.4
[32m[20221125 00:52:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.4
[32m[20221125 00:52:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.4
[32m[20221125 00:52:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.4
[32m[20221125 00:52:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.0
[32m[20221125 00:52:09 @pendulum_agent.py:307][0m Sample time: 3.7225229740142822
[32m[20221125 00:52:21 @pendulum_agent.py:312][0m Update time: 11.951081275939941
[32m[20221125 00:52:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:52:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:52:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:52:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:52:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:52:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:52:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:52:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:52:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:52:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:52:21 @pendulum_agent.py:317][0m Evaluation time: 0.6929259300231934
[32m[20221125 00:52:22 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.44
[32m[20221125 00:52:22 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:52:22 @pendulum_agent.py:289][0m Total time: 12611.122714042664
[32m[20221125 00:52:22 @pendulum_agent.py:291][0m 40650000 total steps have happened
[32m[20221125 00:52:22 @pendulum_agent.py:281][0m #------------------------ Iteration 813 --------------------------#
[32m[20221125 00:52:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:52:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:52:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:52:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:52:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:52:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:52:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:52:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:52:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:52:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:52:25 @pendulum_agent.py:307][0m Sample time: 3.677907943725586
[32m[20221125 00:52:34 @pendulum_agent.py:312][0m Update time: 8.85942792892456
[32m[20221125 00:52:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:52:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:52:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:52:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:52:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:52:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:52:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:52:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:52:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:52:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:52:35 @pendulum_agent.py:317][0m Evaluation time: 0.692756175994873
[32m[20221125 00:52:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:52:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:52:35 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:52:35 @pendulum_agent.py:289][0m Total time: 12624.620912075043
[32m[20221125 00:52:35 @pendulum_agent.py:291][0m 40700000 total steps have happened
[32m[20221125 00:52:35 @pendulum_agent.py:281][0m #------------------------ Iteration 814 --------------------------#
[32m[20221125 00:52:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.0
[32m[20221125 00:52:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1.0
[32m[20221125 00:52:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.6
[32m[20221125 00:52:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1.0
[32m[20221125 00:52:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.8
[32m[20221125 00:52:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1.0
[32m[20221125 00:52:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.0
[32m[20221125 00:52:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.0
[32m[20221125 00:52:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.8
[32m[20221125 00:52:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.0
[32m[20221125 00:52:39 @pendulum_agent.py:307][0m Sample time: 3.592054843902588
[32m[20221125 00:52:56 @pendulum_agent.py:312][0m Update time: 17.705862045288086
[32m[20221125 00:52:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:52:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:52:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:52:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:52:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:52:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:52:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:52:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:52:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:52:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:52:57 @pendulum_agent.py:317][0m Evaluation time: 0.8329839706420898
[32m[20221125 00:52:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.92
[32m[20221125 00:52:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:52:57 @pendulum_agent.py:289][0m Total time: 12647.038167953491
[32m[20221125 00:52:57 @pendulum_agent.py:291][0m 40750000 total steps have happened
[32m[20221125 00:52:57 @pendulum_agent.py:281][0m #------------------------ Iteration 815 --------------------------#
[32m[20221125 00:52:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:52:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:52:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:52:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:52:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:52:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:52:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:52:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:52:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:52:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:53:01 @pendulum_agent.py:307][0m Sample time: 3.328317880630493
[32m[20221125 00:53:10 @pendulum_agent.py:312][0m Update time: 8.933694124221802
[32m[20221125 00:53:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:53:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:53:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:53:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:53:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:53:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:53:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:53:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:53:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:53:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:53:11 @pendulum_agent.py:317][0m Evaluation time: 1.0370781421661377
[32m[20221125 00:53:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:53:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:53:11 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:53:11 @pendulum_agent.py:289][0m Total time: 12660.6281042099
[32m[20221125 00:53:11 @pendulum_agent.py:291][0m 40800000 total steps have happened
[32m[20221125 00:53:11 @pendulum_agent.py:281][0m #------------------------ Iteration 816 --------------------------#
[32m[20221125 00:53:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.0
[32m[20221125 00:53:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.4
[32m[20221125 00:53:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.4
[32m[20221125 00:53:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.0
[32m[20221125 00:53:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.6
[32m[20221125 00:53:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.4
[32m[20221125 00:53:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.2
[32m[20221125 00:53:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.0
[32m[20221125 00:53:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.2
[32m[20221125 00:53:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.8
[32m[20221125 00:53:14 @pendulum_agent.py:307][0m Sample time: 3.2684969902038574
[32m[20221125 00:53:25 @pendulum_agent.py:312][0m Update time: 10.296822786331177
[32m[20221125 00:53:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:53:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:53:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:53:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:53:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:53:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:53:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:53:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:53:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:53:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:53:26 @pendulum_agent.py:317][0m Evaluation time: 1.0481600761413574
[32m[20221125 00:53:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.2
[32m[20221125 00:53:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:53:26 @pendulum_agent.py:289][0m Total time: 12675.517101049423
[32m[20221125 00:53:26 @pendulum_agent.py:291][0m 40850000 total steps have happened
[32m[20221125 00:53:26 @pendulum_agent.py:281][0m #------------------------ Iteration 817 --------------------------#
[32m[20221125 00:53:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:53:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:53:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:53:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:53:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:53:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:53:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:53:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:53:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:53:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:53:30 @pendulum_agent.py:307][0m Sample time: 3.6030619144439697
[32m[20221125 00:53:38 @pendulum_agent.py:312][0m Update time: 8.920249938964844
[32m[20221125 00:53:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:53:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:53:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:53:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:53:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:53:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:53:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:53:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:53:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:53:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:53:39 @pendulum_agent.py:317][0m Evaluation time: 0.6980209350585938
[32m[20221125 00:53:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:53:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:53:39 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:53:39 @pendulum_agent.py:289][0m Total time: 12689.027176856995
[32m[20221125 00:53:39 @pendulum_agent.py:291][0m 40900000 total steps have happened
[32m[20221125 00:53:39 @pendulum_agent.py:281][0m #------------------------ Iteration 818 --------------------------#
[32m[20221125 00:53:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:53:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:53:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:53:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:53:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:53:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:53:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:53:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:53:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:53:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:53:43 @pendulum_agent.py:307][0m Sample time: 3.7115590572357178
[32m[20221125 00:53:52 @pendulum_agent.py:312][0m Update time: 8.872655868530273
[32m[20221125 00:53:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:53:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:53:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:53:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:53:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:53:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:53:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:53:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:53:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:53:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:53:53 @pendulum_agent.py:317][0m Evaluation time: 0.7053680419921875
[32m[20221125 00:53:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:53:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:53:53 @pendulum_agent.py:289][0m Total time: 12702.592674016953
[32m[20221125 00:53:53 @pendulum_agent.py:291][0m 40950000 total steps have happened
[32m[20221125 00:53:53 @pendulum_agent.py:281][0m #------------------------ Iteration 819 --------------------------#
[32m[20221125 00:53:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:53:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:53:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:53:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:53:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:53:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:53:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:53:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:53:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:53:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:53:57 @pendulum_agent.py:307][0m Sample time: 3.8091189861297607
[32m[20221125 00:54:15 @pendulum_agent.py:312][0m Update time: 18.230144023895264
[32m[20221125 00:54:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:54:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:54:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:54:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:54:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:54:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:54:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:54:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:54:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:54:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:54:16 @pendulum_agent.py:317][0m Evaluation time: 0.5707030296325684
[32m[20221125 00:54:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:54:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:54:16 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:54:16 @pendulum_agent.py:289][0m Total time: 12725.504648208618
[32m[20221125 00:54:16 @pendulum_agent.py:291][0m 41000000 total steps have happened
[32m[20221125 00:54:16 @pendulum_agent.py:281][0m #------------------------ Iteration 820 --------------------------#
[32m[20221125 00:54:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.2
[32m[20221125 00:54:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.4
[32m[20221125 00:54:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.8
[32m[20221125 00:54:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.2
[32m[20221125 00:54:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.0
[32m[20221125 00:54:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.6
[32m[20221125 00:54:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.6
[32m[20221125 00:54:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.8
[32m[20221125 00:54:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.4
[32m[20221125 00:54:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.4
[32m[20221125 00:54:20 @pendulum_agent.py:307][0m Sample time: 3.6271779537200928
[32m[20221125 00:54:28 @pendulum_agent.py:312][0m Update time: 8.826491832733154
[32m[20221125 00:54:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:54:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:54:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:54:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:54:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:54:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:54:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:54:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:54:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:54:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:54:29 @pendulum_agent.py:317][0m Evaluation time: 0.8169851303100586
[32m[20221125 00:54:29 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.14
[32m[20221125 00:54:29 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:54:29 @pendulum_agent.py:289][0m Total time: 12739.056777954102
[32m[20221125 00:54:29 @pendulum_agent.py:291][0m 41050000 total steps have happened
[32m[20221125 00:54:29 @pendulum_agent.py:281][0m #------------------------ Iteration 821 --------------------------#
[32m[20221125 00:54:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.4
[32m[20221125 00:54:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 8.6
[32m[20221125 00:54:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 9.2
[32m[20221125 00:54:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 7.8
[32m[20221125 00:54:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 9.8
[32m[20221125 00:54:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 9.6
[32m[20221125 00:54:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.8
[32m[20221125 00:54:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 8.0
[32m[20221125 00:54:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 8.6
[32m[20221125 00:54:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 9.0
[32m[20221125 00:54:33 @pendulum_agent.py:307][0m Sample time: 3.484304189682007
[32m[20221125 00:54:51 @pendulum_agent.py:312][0m Update time: 17.722163915634155
[32m[20221125 00:54:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:54:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:54:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:54:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:54:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:54:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:54:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:54:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:54:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:54:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:54:52 @pendulum_agent.py:317][0m Evaluation time: 1.0224871635437012
[32m[20221125 00:54:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 8.58
[32m[20221125 00:54:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:54:52 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:54:52 @pendulum_agent.py:289][0m Total time: 12761.55607175827
[32m[20221125 00:54:52 @pendulum_agent.py:291][0m 41100000 total steps have happened
[32m[20221125 00:54:52 @pendulum_agent.py:281][0m #------------------------ Iteration 822 --------------------------#
[32m[20221125 00:54:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:54:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:54:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:54:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:54:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:54:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:54:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:54:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:54:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:54:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:54:56 @pendulum_agent.py:307][0m Sample time: 3.6443283557891846
[32m[20221125 00:55:10 @pendulum_agent.py:312][0m Update time: 14.445175647735596
[32m[20221125 00:55:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:55:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:55:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:55:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:55:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:55:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:55:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:55:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:55:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:55:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:55:11 @pendulum_agent.py:317][0m Evaluation time: 0.7163431644439697
[32m[20221125 00:55:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:55:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:55:11 @pendulum_agent.py:289][0m Total time: 12780.63301897049
[32m[20221125 00:55:11 @pendulum_agent.py:291][0m 41150000 total steps have happened
[32m[20221125 00:55:11 @pendulum_agent.py:281][0m #------------------------ Iteration 823 --------------------------#
[32m[20221125 00:55:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:55:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:55:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:55:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:55:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:55:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:55:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:55:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:55:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:55:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:55:15 @pendulum_agent.py:307][0m Sample time: 3.5785419940948486
[32m[20221125 00:55:24 @pendulum_agent.py:312][0m Update time: 8.948405027389526
[32m[20221125 00:55:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:55:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:55:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:55:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:55:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:55:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:55:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:55:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:55:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:55:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:55:24 @pendulum_agent.py:317][0m Evaluation time: 0.5663199424743652
[32m[20221125 00:55:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:55:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:55:24 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:55:24 @pendulum_agent.py:289][0m Total time: 12794.020164966583
[32m[20221125 00:55:24 @pendulum_agent.py:291][0m 41200000 total steps have happened
[32m[20221125 00:55:24 @pendulum_agent.py:281][0m #------------------------ Iteration 824 --------------------------#
[32m[20221125 00:55:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:55:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:55:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:55:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:55:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:55:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:55:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:55:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:55:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:55:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:55:28 @pendulum_agent.py:307][0m Sample time: 3.7962379455566406
[32m[20221125 00:55:37 @pendulum_agent.py:312][0m Update time: 8.831849098205566
[32m[20221125 00:55:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:55:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:55:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:55:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:55:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:55:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:55:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:55:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:55:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:55:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:55:38 @pendulum_agent.py:317][0m Evaluation time: 0.6738109588623047
[32m[20221125 00:55:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:55:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:55:38 @pendulum_agent.py:289][0m Total time: 12807.603400945663
[32m[20221125 00:55:38 @pendulum_agent.py:291][0m 41250000 total steps have happened
[32m[20221125 00:55:38 @pendulum_agent.py:281][0m #------------------------ Iteration 825 --------------------------#
[32m[20221125 00:55:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:55:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:55:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:55:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:55:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:55:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:55:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:55:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:55:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:55:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:55:42 @pendulum_agent.py:307][0m Sample time: 3.7554450035095215
[32m[20221125 00:55:58 @pendulum_agent.py:312][0m Update time: 16.33836317062378
[32m[20221125 00:55:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:55:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:55:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:55:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:55:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:55:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:55:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:55:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:55:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:55:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:55:59 @pendulum_agent.py:317][0m Evaluation time: 0.6865959167480469
[32m[20221125 00:55:59 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:55:59 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:55:59 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:55:59 @pendulum_agent.py:289][0m Total time: 12828.660120010376
[32m[20221125 00:55:59 @pendulum_agent.py:291][0m 41300000 total steps have happened
[32m[20221125 00:55:59 @pendulum_agent.py:281][0m #------------------------ Iteration 826 --------------------------#
[32m[20221125 00:56:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:56:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:56:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:56:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:56:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:56:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:56:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:56:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:56:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:56:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:56:03 @pendulum_agent.py:307][0m Sample time: 3.674983024597168
[32m[20221125 00:56:30 @pendulum_agent.py:312][0m Update time: 27.679716110229492
[32m[20221125 00:56:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:56:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:56:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:56:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:56:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:56:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:56:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:56:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:56:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:56:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:56:31 @pendulum_agent.py:317][0m Evaluation time: 0.9121918678283691
[32m[20221125 00:56:32 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:56:32 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:56:32 @pendulum_agent.py:289][0m Total time: 12861.201126098633
[32m[20221125 00:56:32 @pendulum_agent.py:291][0m 41350000 total steps have happened
[32m[20221125 00:56:32 @pendulum_agent.py:281][0m #------------------------ Iteration 827 --------------------------#
[32m[20221125 00:56:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:56:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:56:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:56:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:56:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:56:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:56:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:56:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:56:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:56:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:56:35 @pendulum_agent.py:307][0m Sample time: 3.732050895690918
[32m[20221125 00:56:44 @pendulum_agent.py:312][0m Update time: 8.861446142196655
[32m[20221125 00:56:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:56:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:56:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:56:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:56:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:56:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:56:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:56:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:56:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:56:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:56:45 @pendulum_agent.py:317][0m Evaluation time: 0.6889889240264893
[32m[20221125 00:56:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:56:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:56:45 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:56:45 @pendulum_agent.py:289][0m Total time: 12874.762163877487
[32m[20221125 00:56:45 @pendulum_agent.py:291][0m 41400000 total steps have happened
[32m[20221125 00:56:45 @pendulum_agent.py:281][0m #------------------------ Iteration 828 --------------------------#
[32m[20221125 00:56:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:56:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:56:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:56:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:56:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:56:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:56:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:56:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:56:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:56:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:56:49 @pendulum_agent.py:307][0m Sample time: 3.6866443157196045
[32m[20221125 00:57:06 @pendulum_agent.py:312][0m Update time: 16.780611753463745
[32m[20221125 00:57:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:57:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:57:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:57:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:57:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:57:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:57:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:57:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:57:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:57:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:57:06 @pendulum_agent.py:317][0m Evaluation time: 0.6729710102081299
[32m[20221125 00:57:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:57:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:57:07 @pendulum_agent.py:289][0m Total time: 12896.192836999893
[32m[20221125 00:57:07 @pendulum_agent.py:291][0m 41450000 total steps have happened
[32m[20221125 00:57:07 @pendulum_agent.py:281][0m #------------------------ Iteration 829 --------------------------#
[32m[20221125 00:57:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.4
[32m[20221125 00:57:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.6
[32m[20221125 00:57:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.0
[32m[20221125 00:57:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 7.0
[32m[20221125 00:57:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.2
[32m[20221125 00:57:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 7.2
[32m[20221125 00:57:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.8
[32m[20221125 00:57:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.8
[32m[20221125 00:57:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 10.8
[32m[20221125 00:57:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.6
[32m[20221125 00:57:10 @pendulum_agent.py:307][0m Sample time: 3.4599099159240723
[32m[20221125 00:57:19 @pendulum_agent.py:312][0m Update time: 9.116657257080078
[32m[20221125 00:57:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:57:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:57:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:57:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:57:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:57:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:57:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:57:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:57:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:57:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:57:20 @pendulum_agent.py:317][0m Evaluation time: 0.9127368927001953
[32m[20221125 00:57:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.74
[32m[20221125 00:57:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:57:20 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:57:20 @pendulum_agent.py:289][0m Total time: 12909.953558921814
[32m[20221125 00:57:20 @pendulum_agent.py:291][0m 41500000 total steps have happened
[32m[20221125 00:57:20 @pendulum_agent.py:281][0m #------------------------ Iteration 830 --------------------------#
[32m[20221125 00:57:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:57:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:57:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:57:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:57:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:57:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:57:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:57:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:57:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:57:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:57:24 @pendulum_agent.py:307][0m Sample time: 3.4479198455810547
[32m[20221125 00:57:33 @pendulum_agent.py:312][0m Update time: 8.860506057739258
[32m[20221125 00:57:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:57:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:57:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:57:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:57:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:57:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:57:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:57:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:57:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:57:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:57:34 @pendulum_agent.py:317][0m Evaluation time: 1.6265830993652344
[32m[20221125 00:57:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:57:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:57:35 @pendulum_agent.py:289][0m Total time: 12924.183084011078
[32m[20221125 00:57:35 @pendulum_agent.py:291][0m 41550000 total steps have happened
[32m[20221125 00:57:35 @pendulum_agent.py:281][0m #------------------------ Iteration 831 --------------------------#
[32m[20221125 00:57:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:57:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:57:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:57:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:57:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:57:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:57:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:57:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:57:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:57:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:57:38 @pendulum_agent.py:307][0m Sample time: 3.8484880924224854
[32m[20221125 00:57:54 @pendulum_agent.py:312][0m Update time: 15.852039098739624
[32m[20221125 00:57:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:57:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:57:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:57:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:57:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:57:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:57:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:57:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:57:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:57:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:57:55 @pendulum_agent.py:317][0m Evaluation time: 0.7116348743438721
[32m[20221125 00:57:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:57:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:57:55 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:57:55 @pendulum_agent.py:289][0m Total time: 12944.87547492981
[32m[20221125 00:57:55 @pendulum_agent.py:291][0m 41600000 total steps have happened
[32m[20221125 00:57:55 @pendulum_agent.py:281][0m #------------------------ Iteration 832 --------------------------#
[32m[20221125 00:57:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:57:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:57:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:57:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:57:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:57:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:57:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:57:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:57:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:57:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:57:59 @pendulum_agent.py:307][0m Sample time: 3.6065969467163086
[32m[20221125 00:58:08 @pendulum_agent.py:312][0m Update time: 9.087790966033936
[32m[20221125 00:58:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:58:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:58:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:58:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:58:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:58:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:58:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:58:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:58:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:58:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:58:09 @pendulum_agent.py:317][0m Evaluation time: 0.7037758827209473
[32m[20221125 00:58:09 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:58:09 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:58:09 @pendulum_agent.py:289][0m Total time: 12958.552446842194
[32m[20221125 00:58:09 @pendulum_agent.py:291][0m 41650000 total steps have happened
[32m[20221125 00:58:09 @pendulum_agent.py:281][0m #------------------------ Iteration 833 --------------------------#
[32m[20221125 00:58:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:58:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:58:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:58:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:58:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:58:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:58:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:58:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:58:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:58:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:58:13 @pendulum_agent.py:307][0m Sample time: 3.758439064025879
[32m[20221125 00:58:25 @pendulum_agent.py:312][0m Update time: 12.676812171936035
[32m[20221125 00:58:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:58:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:58:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:58:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:58:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:58:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:58:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:58:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:58:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:58:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:58:26 @pendulum_agent.py:317][0m Evaluation time: 0.6849396228790283
[32m[20221125 00:58:26 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:58:26 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:58:26 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:58:26 @pendulum_agent.py:289][0m Total time: 12975.961990118027
[32m[20221125 00:58:26 @pendulum_agent.py:291][0m 41700000 total steps have happened
[32m[20221125 00:58:26 @pendulum_agent.py:281][0m #------------------------ Iteration 834 --------------------------#
[32m[20221125 00:58:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:58:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:58:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:58:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:58:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:58:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:58:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:58:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:58:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:58:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:58:30 @pendulum_agent.py:307][0m Sample time: 3.6030101776123047
[32m[20221125 00:58:59 @pendulum_agent.py:312][0m Update time: 29.48139190673828
[32m[20221125 00:59:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:59:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:59:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:59:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:59:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:59:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:59:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:59:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:59:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:59:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:59:00 @pendulum_agent.py:317][0m Evaluation time: 0.810762882232666
[32m[20221125 00:59:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:59:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:59:01 @pendulum_agent.py:289][0m Total time: 13010.131687879562
[32m[20221125 00:59:01 @pendulum_agent.py:291][0m 41750000 total steps have happened
[32m[20221125 00:59:01 @pendulum_agent.py:281][0m #------------------------ Iteration 835 --------------------------#
[32m[20221125 00:59:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.8
[32m[20221125 00:59:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.6
[32m[20221125 00:59:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.0
[32m[20221125 00:59:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.2
[32m[20221125 00:59:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.8
[32m[20221125 00:59:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.4
[32m[20221125 00:59:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.8
[32m[20221125 00:59:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.0
[32m[20221125 00:59:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.2
[32m[20221125 00:59:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.4
[32m[20221125 00:59:04 @pendulum_agent.py:307][0m Sample time: 3.6309781074523926
[32m[20221125 00:59:13 @pendulum_agent.py:312][0m Update time: 8.727534770965576
[32m[20221125 00:59:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:59:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:59:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:59:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:59:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:59:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:59:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:59:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:59:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:59:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:59:14 @pendulum_agent.py:317][0m Evaluation time: 0.6866092681884766
[32m[20221125 00:59:14 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.42
[32m[20221125 00:59:14 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:59:14 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:59:14 @pendulum_agent.py:289][0m Total time: 13023.449455022812
[32m[20221125 00:59:14 @pendulum_agent.py:291][0m 41800000 total steps have happened
[32m[20221125 00:59:14 @pendulum_agent.py:281][0m #------------------------ Iteration 836 --------------------------#
[32m[20221125 00:59:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:59:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:59:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:59:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:59:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:59:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:59:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:59:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:59:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:59:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:59:18 @pendulum_agent.py:307][0m Sample time: 3.7677807807922363
[32m[20221125 00:59:33 @pendulum_agent.py:312][0m Update time: 15.40143895149231
[32m[20221125 00:59:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:59:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:59:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:59:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:59:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:59:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:59:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:59:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:59:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:59:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:59:34 @pendulum_agent.py:317][0m Evaluation time: 0.7034950256347656
[32m[20221125 00:59:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 00:59:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:59:34 @pendulum_agent.py:289][0m Total time: 13043.60150384903
[32m[20221125 00:59:34 @pendulum_agent.py:291][0m 41850000 total steps have happened
[32m[20221125 00:59:34 @pendulum_agent.py:281][0m #------------------------ Iteration 837 --------------------------#
[32m[20221125 00:59:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.0
[32m[20221125 00:59:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.8
[32m[20221125 00:59:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.2
[32m[20221125 00:59:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.4
[32m[20221125 00:59:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.8
[32m[20221125 00:59:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.6
[32m[20221125 00:59:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.6
[32m[20221125 00:59:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.0
[32m[20221125 00:59:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.2
[32m[20221125 00:59:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.0
[32m[20221125 00:59:38 @pendulum_agent.py:307][0m Sample time: 3.7197251319885254
[32m[20221125 00:59:55 @pendulum_agent.py:312][0m Update time: 17.072420835494995
[32m[20221125 00:59:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 00:59:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 00:59:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 00:59:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 00:59:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 00:59:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 00:59:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 00:59:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 00:59:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 00:59:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 00:59:55 @pendulum_agent.py:317][0m Evaluation time: 0.7037742137908936
[32m[20221125 00:59:56 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.56
[32m[20221125 00:59:56 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 00:59:56 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 00:59:56 @pendulum_agent.py:289][0m Total time: 13065.386610984802
[32m[20221125 00:59:56 @pendulum_agent.py:291][0m 41900000 total steps have happened
[32m[20221125 00:59:56 @pendulum_agent.py:281][0m #------------------------ Iteration 838 --------------------------#
[32m[20221125 00:59:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.4
[32m[20221125 00:59:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.6
[32m[20221125 00:59:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.0
[32m[20221125 00:59:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.6
[32m[20221125 00:59:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1.0
[32m[20221125 00:59:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1.2
[32m[20221125 00:59:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1.0
[32m[20221125 00:59:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.6
[32m[20221125 00:59:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.8
[32m[20221125 00:59:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.2
[32m[20221125 00:59:59 @pendulum_agent.py:307][0m Sample time: 3.6147749423980713
[32m[20221125 01:00:16 @pendulum_agent.py:312][0m Update time: 16.560237884521484
[32m[20221125 01:00:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:00:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:00:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:00:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:00:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:00:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:00:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:00:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:00:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:00:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:00:17 @pendulum_agent.py:317][0m Evaluation time: 0.8507461547851562
[32m[20221125 01:00:17 @pendulum_agent.py:285][0m Average TRAINING episode reward: 1.84
[32m[20221125 01:00:17 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:00:17 @pendulum_agent.py:289][0m Total time: 13086.70072221756
[32m[20221125 01:00:17 @pendulum_agent.py:291][0m 41950000 total steps have happened
[32m[20221125 01:00:17 @pendulum_agent.py:281][0m #------------------------ Iteration 839 --------------------------#
[32m[20221125 01:00:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:00:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:00:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:00:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:00:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:00:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:00:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:00:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:00:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:00:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:00:21 @pendulum_agent.py:307][0m Sample time: 3.447373151779175
[32m[20221125 01:00:31 @pendulum_agent.py:312][0m Update time: 10.337460994720459
[32m[20221125 01:00:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:00:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:00:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:00:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:00:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:00:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:00:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:00:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:00:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:00:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:00:32 @pendulum_agent.py:317][0m Evaluation time: 1.0166850090026855
[32m[20221125 01:00:32 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:00:32 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:00:32 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:00:32 @pendulum_agent.py:289][0m Total time: 13101.79331612587
[32m[20221125 01:00:32 @pendulum_agent.py:291][0m 42000000 total steps have happened
[32m[20221125 01:00:32 @pendulum_agent.py:281][0m #------------------------ Iteration 840 --------------------------#
[32m[20221125 01:00:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:00:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:00:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:00:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:00:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:00:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:00:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:00:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:00:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:00:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:00:35 @pendulum_agent.py:307][0m Sample time: 3.2679247856140137
[32m[20221125 01:00:44 @pendulum_agent.py:312][0m Update time: 8.657607316970825
[32m[20221125 01:00:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:00:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:00:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:00:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:00:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:00:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:00:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:00:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:00:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:00:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:00:45 @pendulum_agent.py:317][0m Evaluation time: 1.1581850051879883
[32m[20221125 01:00:46 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:00:46 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:00:46 @pendulum_agent.py:289][0m Total time: 13115.15125489235
[32m[20221125 01:00:46 @pendulum_agent.py:291][0m 42050000 total steps have happened
[32m[20221125 01:00:46 @pendulum_agent.py:281][0m #------------------------ Iteration 841 --------------------------#
[32m[20221125 01:00:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:00:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:00:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:00:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:00:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:00:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:00:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:00:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:00:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:00:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:00:49 @pendulum_agent.py:307][0m Sample time: 3.41625714302063
[32m[20221125 01:01:03 @pendulum_agent.py:312][0m Update time: 14.234715223312378
[32m[20221125 01:01:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:01:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:01:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:01:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:01:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:01:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:01:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:01:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:01:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:01:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:01:05 @pendulum_agent.py:317][0m Evaluation time: 1.8885889053344727
[32m[20221125 01:01:05 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:01:05 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:01:05 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:01:05 @pendulum_agent.py:289][0m Total time: 13134.977974891663
[32m[20221125 01:01:05 @pendulum_agent.py:291][0m 42100000 total steps have happened
[32m[20221125 01:01:05 @pendulum_agent.py:281][0m #------------------------ Iteration 842 --------------------------#
[32m[20221125 01:01:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:01:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:01:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:01:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:01:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:01:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:01:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:01:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:01:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:01:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:01:09 @pendulum_agent.py:307][0m Sample time: 3.5632150173187256
[32m[20221125 01:01:22 @pendulum_agent.py:312][0m Update time: 13.383844137191772
[32m[20221125 01:01:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:01:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:01:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:01:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:01:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:01:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:01:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:01:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:01:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:01:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:01:23 @pendulum_agent.py:317][0m Evaluation time: 0.7016689777374268
[32m[20221125 01:01:23 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:01:23 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:01:23 @pendulum_agent.py:289][0m Total time: 13152.902418136597
[32m[20221125 01:01:23 @pendulum_agent.py:291][0m 42150000 total steps have happened
[32m[20221125 01:01:23 @pendulum_agent.py:281][0m #------------------------ Iteration 843 --------------------------#
[32m[20221125 01:01:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:01:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:01:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:01:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:01:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:01:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:01:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:01:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:01:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:01:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:01:27 @pendulum_agent.py:307][0m Sample time: 3.674021005630493
[32m[20221125 01:01:36 @pendulum_agent.py:312][0m Update time: 8.712938070297241
[32m[20221125 01:01:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:01:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:01:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:01:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:01:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:01:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:01:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:01:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:01:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:01:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:01:37 @pendulum_agent.py:317][0m Evaluation time: 0.984785795211792
[32m[20221125 01:01:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:01:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:01:37 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:01:37 @pendulum_agent.py:289][0m Total time: 13166.576270103455
[32m[20221125 01:01:37 @pendulum_agent.py:291][0m 42200000 total steps have happened
[32m[20221125 01:01:37 @pendulum_agent.py:281][0m #------------------------ Iteration 844 --------------------------#
[32m[20221125 01:01:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:01:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:01:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:01:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:01:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:01:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:01:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:01:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:01:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:01:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:01:41 @pendulum_agent.py:307][0m Sample time: 3.890800952911377
[32m[20221125 01:01:50 @pendulum_agent.py:312][0m Update time: 8.777269840240479
[32m[20221125 01:01:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:01:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:01:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:01:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:01:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:01:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:01:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:01:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:01:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:01:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:01:51 @pendulum_agent.py:317][0m Evaluation time: 0.9253151416778564
[32m[20221125 01:01:51 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:01:51 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:01:51 @pendulum_agent.py:289][0m Total time: 13180.440914154053
[32m[20221125 01:01:51 @pendulum_agent.py:291][0m 42250000 total steps have happened
[32m[20221125 01:01:51 @pendulum_agent.py:281][0m #------------------------ Iteration 845 --------------------------#
[32m[20221125 01:01:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:01:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:01:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:01:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:01:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:01:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:01:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:01:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:01:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:01:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:01:55 @pendulum_agent.py:307][0m Sample time: 3.9195852279663086
[32m[20221125 01:02:10 @pendulum_agent.py:312][0m Update time: 14.918165683746338
[32m[20221125 01:02:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:02:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:02:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:02:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:02:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:02:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:02:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:02:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:02:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:02:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:02:10 @pendulum_agent.py:317][0m Evaluation time: 0.685941219329834
[32m[20221125 01:02:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:02:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:02:11 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:02:11 @pendulum_agent.py:289][0m Total time: 13200.23064994812
[32m[20221125 01:02:11 @pendulum_agent.py:291][0m 42300000 total steps have happened
[32m[20221125 01:02:11 @pendulum_agent.py:281][0m #------------------------ Iteration 846 --------------------------#
[32m[20221125 01:02:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:02:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:02:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:02:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:02:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:02:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:02:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:02:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:02:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:02:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:02:14 @pendulum_agent.py:307][0m Sample time: 3.5607731342315674
[32m[20221125 01:02:23 @pendulum_agent.py:312][0m Update time: 8.935505867004395
[32m[20221125 01:02:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:02:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:02:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:02:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:02:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:02:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:02:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:02:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:02:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:02:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:02:24 @pendulum_agent.py:317][0m Evaluation time: 0.5616791248321533
[32m[20221125 01:02:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:02:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:02:24 @pendulum_agent.py:289][0m Total time: 13213.579400062561
[32m[20221125 01:02:24 @pendulum_agent.py:291][0m 42350000 total steps have happened
[32m[20221125 01:02:24 @pendulum_agent.py:281][0m #------------------------ Iteration 847 --------------------------#
[32m[20221125 01:02:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.8
[32m[20221125 01:02:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.6
[32m[20221125 01:02:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 7.8
[32m[20221125 01:02:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 7.8
[32m[20221125 01:02:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.4
[32m[20221125 01:02:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 8.6
[32m[20221125 01:02:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.8
[32m[20221125 01:02:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 7.2
[32m[20221125 01:02:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.4
[32m[20221125 01:02:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.2
[32m[20221125 01:02:28 @pendulum_agent.py:307][0m Sample time: 3.788350820541382
[32m[20221125 01:02:45 @pendulum_agent.py:312][0m Update time: 17.197301149368286
[32m[20221125 01:02:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:02:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:02:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:02:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:02:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:02:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:02:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:02:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:02:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:02:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:02:46 @pendulum_agent.py:317][0m Evaluation time: 0.5714371204376221
[32m[20221125 01:02:46 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.16
[32m[20221125 01:02:46 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:02:46 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:02:46 @pendulum_agent.py:289][0m Total time: 13235.441766023636
[32m[20221125 01:02:46 @pendulum_agent.py:291][0m 42400000 total steps have happened
[32m[20221125 01:02:46 @pendulum_agent.py:281][0m #------------------------ Iteration 848 --------------------------#
[32m[20221125 01:02:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:02:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:02:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:02:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:02:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:02:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:02:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:02:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:02:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:02:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:02:50 @pendulum_agent.py:307][0m Sample time: 3.7861790657043457
[32m[20221125 01:02:58 @pendulum_agent.py:312][0m Update time: 8.799530029296875
[32m[20221125 01:02:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:02:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:02:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:02:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:02:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:02:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:02:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:02:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:02:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:02:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:02:59 @pendulum_agent.py:317][0m Evaluation time: 0.5761470794677734
[32m[20221125 01:02:59 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:02:59 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:02:59 @pendulum_agent.py:289][0m Total time: 13248.895670890808
[32m[20221125 01:02:59 @pendulum_agent.py:291][0m 42450000 total steps have happened
[32m[20221125 01:02:59 @pendulum_agent.py:281][0m #------------------------ Iteration 849 --------------------------#
[32m[20221125 01:03:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.2
[32m[20221125 01:03:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.8
[32m[20221125 01:03:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 7.4
[32m[20221125 01:03:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 10.2
[32m[20221125 01:03:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 7.0
[32m[20221125 01:03:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.0
[32m[20221125 01:03:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 8.2
[32m[20221125 01:03:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 8.2
[32m[20221125 01:03:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 7.0
[32m[20221125 01:03:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.6
[32m[20221125 01:03:03 @pendulum_agent.py:307][0m Sample time: 3.8076651096343994
[32m[20221125 01:03:12 @pendulum_agent.py:312][0m Update time: 8.716925859451294
[32m[20221125 01:03:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:03:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:03:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:03:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:03:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:03:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:03:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:03:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:03:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:03:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:03:12 @pendulum_agent.py:317][0m Evaluation time: 0.676044225692749
[32m[20221125 01:03:13 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.36
[32m[20221125 01:03:13 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:03:13 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:03:13 @pendulum_agent.py:289][0m Total time: 13262.37285399437
[32m[20221125 01:03:13 @pendulum_agent.py:291][0m 42500000 total steps have happened
[32m[20221125 01:03:13 @pendulum_agent.py:281][0m #------------------------ Iteration 850 --------------------------#
[32m[20221125 01:03:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:03:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:03:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:03:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:03:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:03:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:03:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:03:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:03:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:03:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:03:16 @pendulum_agent.py:307][0m Sample time: 3.49800968170166
[32m[20221125 01:03:37 @pendulum_agent.py:312][0m Update time: 20.479892015457153
[32m[20221125 01:03:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:03:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:03:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:03:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:03:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:03:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:03:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:03:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:03:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:03:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:03:38 @pendulum_agent.py:317][0m Evaluation time: 0.8176360130310059
[32m[20221125 01:03:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:03:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:03:38 @pendulum_agent.py:289][0m Total time: 13287.459601163864
[32m[20221125 01:03:38 @pendulum_agent.py:291][0m 42550000 total steps have happened
[32m[20221125 01:03:38 @pendulum_agent.py:281][0m #------------------------ Iteration 851 --------------------------#
[32m[20221125 01:03:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 11.8
[32m[20221125 01:03:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 11.8
[32m[20221125 01:03:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.0
[32m[20221125 01:03:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 11.6
[32m[20221125 01:03:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 13.4
[32m[20221125 01:03:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.6
[32m[20221125 01:03:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.6
[32m[20221125 01:03:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 12.6
[32m[20221125 01:03:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 11.8
[32m[20221125 01:03:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.0
[32m[20221125 01:03:41 @pendulum_agent.py:307][0m Sample time: 3.307600259780884
[32m[20221125 01:04:00 @pendulum_agent.py:312][0m Update time: 18.570851802825928
[32m[20221125 01:04:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 24.0
[32m[20221125 01:04:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 24.0
[32m[20221125 01:04:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 24.0
[32m[20221125 01:04:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 24.0
[32m[20221125 01:04:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 24.0
[32m[20221125 01:04:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 24.0
[32m[20221125 01:04:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 24.0
[32m[20221125 01:04:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 24.0
[32m[20221125 01:04:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 24.0
[32m[20221125 01:04:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 24.0
[32m[20221125 01:04:01 @pendulum_agent.py:317][0m Evaluation time: 1.0304391384124756
[32m[20221125 01:04:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 9.42
[32m[20221125 01:04:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:04:01 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:04:01 @pendulum_agent.py:289][0m Total time: 13310.654284000397
[32m[20221125 01:04:01 @pendulum_agent.py:291][0m 42600000 total steps have happened
[32m[20221125 01:04:01 @pendulum_agent.py:281][0m #------------------------ Iteration 852 --------------------------#
[32m[20221125 01:04:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.2
[32m[20221125 01:04:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:04:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.8
[32m[20221125 01:04:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:04:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:04:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:04:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.4
[32m[20221125 01:04:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:04:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.2
[32m[20221125 01:04:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.4
[32m[20221125 01:04:05 @pendulum_agent.py:307][0m Sample time: 3.576932907104492
[32m[20221125 01:04:22 @pendulum_agent.py:312][0m Update time: 17.315545082092285
[32m[20221125 01:04:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:04:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:04:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:04:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:04:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:04:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:04:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:04:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:04:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:04:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:04:23 @pendulum_agent.py:317][0m Evaluation time: 1.1463978290557861
[32m[20221125 01:04:23 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.2
[32m[20221125 01:04:23 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:04:23 @pendulum_agent.py:289][0m Total time: 13332.968464136124
[32m[20221125 01:04:23 @pendulum_agent.py:291][0m 42650000 total steps have happened
[32m[20221125 01:04:23 @pendulum_agent.py:281][0m #------------------------ Iteration 853 --------------------------#
[32m[20221125 01:04:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.0
[32m[20221125 01:04:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.4
[32m[20221125 01:04:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.6
[32m[20221125 01:04:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.8
[32m[20221125 01:04:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.6
[32m[20221125 01:04:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.0
[32m[20221125 01:04:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 10.2
[32m[20221125 01:04:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.0
[32m[20221125 01:04:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.0
[32m[20221125 01:04:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.8
[32m[20221125 01:04:27 @pendulum_agent.py:307][0m Sample time: 3.313803195953369
[32m[20221125 01:04:35 @pendulum_agent.py:312][0m Update time: 8.781667709350586
[32m[20221125 01:04:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:04:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:04:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:04:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:04:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:04:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:04:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:04:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:04:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:04:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:04:37 @pendulum_agent.py:317][0m Evaluation time: 1.148266077041626
[32m[20221125 01:04:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.94
[32m[20221125 01:04:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:04:37 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:04:37 @pendulum_agent.py:289][0m Total time: 13346.482104063034
[32m[20221125 01:04:37 @pendulum_agent.py:291][0m 42700000 total steps have happened
[32m[20221125 01:04:37 @pendulum_agent.py:281][0m #------------------------ Iteration 854 --------------------------#
[32m[20221125 01:04:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:04:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:04:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:04:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:04:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:04:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:04:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:04:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:04:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:04:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:04:40 @pendulum_agent.py:307][0m Sample time: 3.6221039295196533
[32m[20221125 01:04:49 @pendulum_agent.py:312][0m Update time: 8.95505976676941
[32m[20221125 01:04:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:04:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:04:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:04:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:04:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:04:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:04:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:04:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:04:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:04:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:04:50 @pendulum_agent.py:317][0m Evaluation time: 0.7159061431884766
[32m[20221125 01:04:50 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:04:50 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:04:50 @pendulum_agent.py:289][0m Total time: 13360.04890012741
[32m[20221125 01:04:50 @pendulum_agent.py:291][0m 42750000 total steps have happened
[32m[20221125 01:04:50 @pendulum_agent.py:281][0m #------------------------ Iteration 855 --------------------------#
[32m[20221125 01:04:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:04:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:04:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:04:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:04:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:04:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:04:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:04:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:04:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:04:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:04:54 @pendulum_agent.py:307][0m Sample time: 3.6143412590026855
[32m[20221125 01:05:03 @pendulum_agent.py:312][0m Update time: 8.891159772872925
[32m[20221125 01:05:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:05:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:05:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:05:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:05:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:05:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:05:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:05:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:05:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:05:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:05:04 @pendulum_agent.py:317][0m Evaluation time: 0.701854944229126
[32m[20221125 01:05:04 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:05:04 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:05:04 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:05:04 @pendulum_agent.py:289][0m Total time: 13373.533514022827
[32m[20221125 01:05:04 @pendulum_agent.py:291][0m 42800000 total steps have happened
[32m[20221125 01:05:04 @pendulum_agent.py:281][0m #------------------------ Iteration 856 --------------------------#
[32m[20221125 01:05:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:05:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:05:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:05:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:05:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:05:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:05:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:05:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:05:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:05:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:05:07 @pendulum_agent.py:307][0m Sample time: 3.4715287685394287
[32m[20221125 01:05:16 @pendulum_agent.py:312][0m Update time: 9.026753187179565
[32m[20221125 01:05:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:05:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:05:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:05:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:05:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:05:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:05:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:05:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:05:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:05:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:05:17 @pendulum_agent.py:317][0m Evaluation time: 0.6993069648742676
[32m[20221125 01:05:17 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:05:17 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:05:17 @pendulum_agent.py:289][0m Total time: 13387.00366783142
[32m[20221125 01:05:17 @pendulum_agent.py:291][0m 42850000 total steps have happened
[32m[20221125 01:05:17 @pendulum_agent.py:281][0m #------------------------ Iteration 857 --------------------------#
[32m[20221125 01:05:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.4
[32m[20221125 01:05:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.4
[32m[20221125 01:05:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 7.0
[32m[20221125 01:05:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.6
[32m[20221125 01:05:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.4
[32m[20221125 01:05:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.8
[32m[20221125 01:05:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.4
[32m[20221125 01:05:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.6
[32m[20221125 01:05:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 8.6
[32m[20221125 01:05:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.2
[32m[20221125 01:05:21 @pendulum_agent.py:307][0m Sample time: 3.7871711254119873
[32m[20221125 01:05:46 @pendulum_agent.py:312][0m Update time: 24.980222940444946
[32m[20221125 01:05:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:05:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:05:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:05:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:05:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:05:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:05:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:05:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:05:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:05:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:05:47 @pendulum_agent.py:317][0m Evaluation time: 0.554887056350708
[32m[20221125 01:05:47 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.74
[32m[20221125 01:05:47 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:05:47 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:05:47 @pendulum_agent.py:289][0m Total time: 13416.61949801445
[32m[20221125 01:05:47 @pendulum_agent.py:291][0m 42900000 total steps have happened
[32m[20221125 01:05:47 @pendulum_agent.py:281][0m #------------------------ Iteration 858 --------------------------#
[32m[20221125 01:05:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:05:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:05:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:05:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:05:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:05:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:05:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:05:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:05:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:05:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:05:51 @pendulum_agent.py:307][0m Sample time: 3.7568087577819824
[32m[20221125 01:06:00 @pendulum_agent.py:312][0m Update time: 8.896440982818604
[32m[20221125 01:06:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:06:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:06:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:06:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:06:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:06:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:06:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:06:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:06:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:06:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:06:00 @pendulum_agent.py:317][0m Evaluation time: 0.690788984298706
[32m[20221125 01:06:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:06:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:06:01 @pendulum_agent.py:289][0m Total time: 13430.252437829971
[32m[20221125 01:06:01 @pendulum_agent.py:291][0m 42950000 total steps have happened
[32m[20221125 01:06:01 @pendulum_agent.py:281][0m #------------------------ Iteration 859 --------------------------#
[32m[20221125 01:06:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:06:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:06:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:06:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:06:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:06:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:06:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:06:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:06:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:06:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:06:04 @pendulum_agent.py:307][0m Sample time: 3.5814740657806396
[32m[20221125 01:06:15 @pendulum_agent.py:312][0m Update time: 11.025099992752075
[32m[20221125 01:06:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:06:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:06:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:06:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:06:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:06:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:06:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:06:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:06:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:06:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:06:16 @pendulum_agent.py:317][0m Evaluation time: 0.710517168045044
[32m[20221125 01:06:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:06:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:06:16 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:06:16 @pendulum_agent.py:289][0m Total time: 13445.841276168823
[32m[20221125 01:06:16 @pendulum_agent.py:291][0m 43000000 total steps have happened
[32m[20221125 01:06:16 @pendulum_agent.py:281][0m #------------------------ Iteration 860 --------------------------#
[32m[20221125 01:06:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:06:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:06:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:06:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:06:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:06:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:06:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:06:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:06:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:06:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:06:20 @pendulum_agent.py:307][0m Sample time: 3.532302141189575
[32m[20221125 01:06:29 @pendulum_agent.py:312][0m Update time: 9.022900819778442
[32m[20221125 01:06:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:06:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:06:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:06:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:06:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:06:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:06:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:06:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:06:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:06:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:06:30 @pendulum_agent.py:317][0m Evaluation time: 0.839968204498291
[32m[20221125 01:06:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:06:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:06:30 @pendulum_agent.py:289][0m Total time: 13459.516882181168
[32m[20221125 01:06:30 @pendulum_agent.py:291][0m 43050000 total steps have happened
[32m[20221125 01:06:30 @pendulum_agent.py:281][0m #------------------------ Iteration 861 --------------------------#
[32m[20221125 01:06:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:06:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:06:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:06:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:06:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:06:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:06:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:06:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:06:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:06:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:06:33 @pendulum_agent.py:307][0m Sample time: 3.3308987617492676
[32m[20221125 01:06:45 @pendulum_agent.py:312][0m Update time: 11.743758201599121
[32m[20221125 01:06:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:06:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:06:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:06:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:06:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:06:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:06:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:06:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:06:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:06:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:06:46 @pendulum_agent.py:317][0m Evaluation time: 1.029292106628418
[32m[20221125 01:06:46 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:06:46 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:06:46 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:06:46 @pendulum_agent.py:289][0m Total time: 13475.901202201843
[32m[20221125 01:06:46 @pendulum_agent.py:291][0m 43100000 total steps have happened
[32m[20221125 01:06:46 @pendulum_agent.py:281][0m #------------------------ Iteration 862 --------------------------#
[32m[20221125 01:06:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:06:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:06:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:06:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:06:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:06:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:06:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:06:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:06:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:06:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:06:50 @pendulum_agent.py:307][0m Sample time: 3.3197410106658936
[32m[20221125 01:06:59 @pendulum_agent.py:312][0m Update time: 8.917647123336792
[32m[20221125 01:06:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:06:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:06:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:06:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:06:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:06:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:06:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:06:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:06:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:06:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:07:00 @pendulum_agent.py:317][0m Evaluation time: 1.0325899124145508
[32m[20221125 01:07:00 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:07:00 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:07:00 @pendulum_agent.py:289][0m Total time: 13489.450888872147
[32m[20221125 01:07:00 @pendulum_agent.py:291][0m 43150000 total steps have happened
[32m[20221125 01:07:00 @pendulum_agent.py:281][0m #------------------------ Iteration 863 --------------------------#
[32m[20221125 01:07:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:07:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:07:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:07:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:07:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:07:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:07:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:07:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:07:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:07:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:07:03 @pendulum_agent.py:307][0m Sample time: 3.628369092941284
[32m[20221125 01:07:12 @pendulum_agent.py:312][0m Update time: 8.983808994293213
[32m[20221125 01:07:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:07:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:07:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:07:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:07:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:07:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:07:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:07:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:07:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:07:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:07:13 @pendulum_agent.py:317][0m Evaluation time: 0.7144057750701904
[32m[20221125 01:07:13 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:07:13 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:07:13 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:07:13 @pendulum_agent.py:289][0m Total time: 13503.055170059204
[32m[20221125 01:07:13 @pendulum_agent.py:291][0m 43200000 total steps have happened
[32m[20221125 01:07:13 @pendulum_agent.py:281][0m #------------------------ Iteration 864 --------------------------#
[32m[20221125 01:07:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.8
[32m[20221125 01:07:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.6
[32m[20221125 01:07:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.2
[32m[20221125 01:07:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.8
[32m[20221125 01:07:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.8
[32m[20221125 01:07:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.2
[32m[20221125 01:07:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.8
[32m[20221125 01:07:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.6
[32m[20221125 01:07:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 10.6
[32m[20221125 01:07:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.4
[32m[20221125 01:07:17 @pendulum_agent.py:307][0m Sample time: 3.705923080444336
[32m[20221125 01:07:28 @pendulum_agent.py:312][0m Update time: 10.775222778320312
[32m[20221125 01:07:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:07:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:07:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:07:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:07:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:07:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:07:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:07:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:07:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:07:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:07:29 @pendulum_agent.py:317][0m Evaluation time: 0.7093780040740967
[32m[20221125 01:07:29 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.58
[32m[20221125 01:07:29 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:07:29 @pendulum_agent.py:289][0m Total time: 13518.519987821579
[32m[20221125 01:07:29 @pendulum_agent.py:291][0m 43250000 total steps have happened
[32m[20221125 01:07:29 @pendulum_agent.py:281][0m #------------------------ Iteration 865 --------------------------#
[32m[20221125 01:07:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:07:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:07:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:07:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:07:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:07:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:07:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:07:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:07:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:07:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:07:33 @pendulum_agent.py:307][0m Sample time: 3.875257968902588
[32m[20221125 01:07:51 @pendulum_agent.py:312][0m Update time: 18.69749617576599
[32m[20221125 01:07:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:07:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:07:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:07:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:07:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:07:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:07:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:07:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:07:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:07:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:07:52 @pendulum_agent.py:317][0m Evaluation time: 0.5786037445068359
[32m[20221125 01:07:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:07:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:07:52 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:07:52 @pendulum_agent.py:289][0m Total time: 13541.980528116226
[32m[20221125 01:07:52 @pendulum_agent.py:291][0m 43300000 total steps have happened
[32m[20221125 01:07:52 @pendulum_agent.py:281][0m #------------------------ Iteration 866 --------------------------#
[32m[20221125 01:07:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:07:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:07:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:07:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:07:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:07:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:07:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:07:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:07:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:07:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:07:56 @pendulum_agent.py:307][0m Sample time: 3.646575927734375
[32m[20221125 01:08:10 @pendulum_agent.py:312][0m Update time: 14.136657238006592
[32m[20221125 01:08:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:08:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:08:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:08:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:08:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:08:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:08:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:08:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:08:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:08:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:08:11 @pendulum_agent.py:317][0m Evaluation time: 0.8108348846435547
[32m[20221125 01:08:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:08:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:08:11 @pendulum_agent.py:289][0m Total time: 13560.855020046234
[32m[20221125 01:08:11 @pendulum_agent.py:291][0m 43350000 total steps have happened
[32m[20221125 01:08:11 @pendulum_agent.py:281][0m #------------------------ Iteration 867 --------------------------#
[32m[20221125 01:08:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:08:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:08:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:08:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:08:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:08:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:08:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:08:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:08:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:08:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:08:15 @pendulum_agent.py:307][0m Sample time: 3.4529471397399902
[32m[20221125 01:08:24 @pendulum_agent.py:312][0m Update time: 8.912837028503418
[32m[20221125 01:08:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:08:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:08:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:08:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:08:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:08:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:08:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:08:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:08:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:08:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:08:25 @pendulum_agent.py:317][0m Evaluation time: 1.0344269275665283
[32m[20221125 01:08:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:08:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:08:25 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:08:25 @pendulum_agent.py:289][0m Total time: 13574.533651828766
[32m[20221125 01:08:25 @pendulum_agent.py:291][0m 43400000 total steps have happened
[32m[20221125 01:08:25 @pendulum_agent.py:281][0m #------------------------ Iteration 868 --------------------------#
[32m[20221125 01:08:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 9.4
[32m[20221125 01:08:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.4
[32m[20221125 01:08:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.2
[32m[20221125 01:08:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 15.0
[32m[20221125 01:08:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 8.4
[32m[20221125 01:08:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 7.0
[32m[20221125 01:08:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 9.8
[32m[20221125 01:08:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.8
[32m[20221125 01:08:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.6
[32m[20221125 01:08:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.2
[32m[20221125 01:08:29 @pendulum_agent.py:307][0m Sample time: 3.602969169616699
[32m[20221125 01:08:37 @pendulum_agent.py:312][0m Update time: 8.910193920135498
[32m[20221125 01:08:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:08:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:08:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:08:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:08:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:08:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:08:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:08:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:08:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:08:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:08:38 @pendulum_agent.py:317][0m Evaluation time: 0.6994738578796387
[32m[20221125 01:08:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.78
[32m[20221125 01:08:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:08:38 @pendulum_agent.py:289][0m Total time: 13588.023368120193
[32m[20221125 01:08:38 @pendulum_agent.py:291][0m 43450000 total steps have happened
[32m[20221125 01:08:38 @pendulum_agent.py:281][0m #------------------------ Iteration 869 --------------------------#
[32m[20221125 01:08:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:08:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:08:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:08:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:08:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:08:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:08:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:08:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:08:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:08:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:08:42 @pendulum_agent.py:307][0m Sample time: 3.695829153060913
[32m[20221125 01:08:51 @pendulum_agent.py:312][0m Update time: 8.886648893356323
[32m[20221125 01:08:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:08:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:08:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:08:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:08:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:08:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:08:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:08:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:08:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:08:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:08:52 @pendulum_agent.py:317][0m Evaluation time: 0.5825860500335693
[32m[20221125 01:08:52 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:08:52 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:08:52 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:08:52 @pendulum_agent.py:289][0m Total time: 13601.490884065628
[32m[20221125 01:08:52 @pendulum_agent.py:291][0m 43500000 total steps have happened
[32m[20221125 01:08:52 @pendulum_agent.py:281][0m #------------------------ Iteration 870 --------------------------#
[32m[20221125 01:08:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:08:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:08:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:08:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:08:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:08:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:08:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:08:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:08:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:08:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:08:56 @pendulum_agent.py:307][0m Sample time: 3.7866950035095215
[32m[20221125 01:09:08 @pendulum_agent.py:312][0m Update time: 12.444376945495605
[32m[20221125 01:09:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:09:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:09:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:09:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:09:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:09:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:09:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:09:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:09:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:09:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:09:09 @pendulum_agent.py:317][0m Evaluation time: 0.6929900646209717
[32m[20221125 01:09:09 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:09:09 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:09:09 @pendulum_agent.py:289][0m Total time: 13618.69719696045
[32m[20221125 01:09:09 @pendulum_agent.py:291][0m 43550000 total steps have happened
[32m[20221125 01:09:09 @pendulum_agent.py:281][0m #------------------------ Iteration 871 --------------------------#
[32m[20221125 01:09:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:09:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:09:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:09:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:09:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:09:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:09:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:09:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:09:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:09:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:09:13 @pendulum_agent.py:307][0m Sample time: 3.8383822441101074
[32m[20221125 01:09:27 @pendulum_agent.py:312][0m Update time: 13.659478902816772
[32m[20221125 01:09:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:09:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:09:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:09:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:09:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:09:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:09:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:09:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:09:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:09:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:09:27 @pendulum_agent.py:317][0m Evaluation time: 0.699941873550415
[32m[20221125 01:09:28 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:09:28 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:09:28 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:09:28 @pendulum_agent.py:289][0m Total time: 13637.173086881638
[32m[20221125 01:09:28 @pendulum_agent.py:291][0m 43600000 total steps have happened
[32m[20221125 01:09:28 @pendulum_agent.py:281][0m #------------------------ Iteration 872 --------------------------#
[32m[20221125 01:09:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:09:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:09:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:09:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:09:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:09:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:09:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:09:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:09:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:09:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:09:31 @pendulum_agent.py:307][0m Sample time: 3.6720707416534424
[32m[20221125 01:09:56 @pendulum_agent.py:312][0m Update time: 24.31473207473755
[32m[20221125 01:09:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:09:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:09:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:09:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:09:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:09:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:09:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:09:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:09:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:09:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:09:56 @pendulum_agent.py:317][0m Evaluation time: 0.9399991035461426
[32m[20221125 01:09:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:09:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:09:57 @pendulum_agent.py:289][0m Total time: 13666.39723110199
[32m[20221125 01:09:57 @pendulum_agent.py:291][0m 43650000 total steps have happened
[32m[20221125 01:09:57 @pendulum_agent.py:281][0m #------------------------ Iteration 873 --------------------------#
[32m[20221125 01:09:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:09:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:09:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:09:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:09:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:09:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:09:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:09:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:09:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:09:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:10:00 @pendulum_agent.py:307][0m Sample time: 3.69619083404541
[32m[20221125 01:10:09 @pendulum_agent.py:312][0m Update time: 8.858694076538086
[32m[20221125 01:10:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:10:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:10:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:10:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:10:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:10:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:10:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:10:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:10:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:10:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:10:10 @pendulum_agent.py:317][0m Evaluation time: 0.695037841796875
[32m[20221125 01:10:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:10:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:10:10 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:10:10 @pendulum_agent.py:289][0m Total time: 13679.908996105194
[32m[20221125 01:10:10 @pendulum_agent.py:291][0m 43700000 total steps have happened
[32m[20221125 01:10:10 @pendulum_agent.py:281][0m #------------------------ Iteration 874 --------------------------#
[32m[20221125 01:10:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:10:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:10:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:10:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:10:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:10:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:10:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:10:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:10:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:10:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:10:14 @pendulum_agent.py:307][0m Sample time: 3.7429888248443604
[32m[20221125 01:10:26 @pendulum_agent.py:312][0m Update time: 11.502730131149292
[32m[20221125 01:10:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:10:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:10:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:10:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:10:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:10:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:10:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:10:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:10:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:10:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:10:26 @pendulum_agent.py:317][0m Evaluation time: 0.6658260822296143
[32m[20221125 01:10:27 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:10:27 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:10:27 @pendulum_agent.py:289][0m Total time: 13696.113445997238
[32m[20221125 01:10:27 @pendulum_agent.py:291][0m 43750000 total steps have happened
[32m[20221125 01:10:27 @pendulum_agent.py:281][0m #------------------------ Iteration 875 --------------------------#
[32m[20221125 01:10:27 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.2
[32m[20221125 01:10:27 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.4
[32m[20221125 01:10:27 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.6
[32m[20221125 01:10:27 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.8
[32m[20221125 01:10:27 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.6
[32m[20221125 01:10:27 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.0
[32m[20221125 01:10:27 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.4
[32m[20221125 01:10:27 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.0
[32m[20221125 01:10:27 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.6
[32m[20221125 01:10:27 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.8
[32m[20221125 01:10:30 @pendulum_agent.py:307][0m Sample time: 3.3643829822540283
[32m[20221125 01:10:39 @pendulum_agent.py:312][0m Update time: 9.417213201522827
[32m[20221125 01:10:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:10:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:10:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:10:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:10:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:10:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:10:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:10:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:10:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:10:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:10:40 @pendulum_agent.py:317][0m Evaluation time: 0.919306755065918
[32m[20221125 01:10:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.74
[32m[20221125 01:10:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:10:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:10:40 @pendulum_agent.py:289][0m Total time: 13710.080849170685
[32m[20221125 01:10:40 @pendulum_agent.py:291][0m 43800000 total steps have happened
[32m[20221125 01:10:40 @pendulum_agent.py:281][0m #------------------------ Iteration 876 --------------------------#
[32m[20221125 01:10:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:10:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:10:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:10:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:10:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:10:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:10:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:10:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:10:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:10:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:10:44 @pendulum_agent.py:307][0m Sample time: 3.2800869941711426
[32m[20221125 01:10:52 @pendulum_agent.py:312][0m Update time: 8.74032998085022
[32m[20221125 01:10:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:10:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:10:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:10:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:10:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:10:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:10:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:10:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:10:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:10:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:10:54 @pendulum_agent.py:317][0m Evaluation time: 1.6441650390625
[32m[20221125 01:10:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:10:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:10:54 @pendulum_agent.py:289][0m Total time: 13724.042011022568
[32m[20221125 01:10:54 @pendulum_agent.py:291][0m 43850000 total steps have happened
[32m[20221125 01:10:54 @pendulum_agent.py:281][0m #------------------------ Iteration 877 --------------------------#
[32m[20221125 01:10:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:10:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:10:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:10:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:10:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:10:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:10:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:10:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:10:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:10:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:10:58 @pendulum_agent.py:307][0m Sample time: 3.7846479415893555
[32m[20221125 01:11:11 @pendulum_agent.py:312][0m Update time: 12.325230121612549
[32m[20221125 01:11:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:11:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:11:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:11:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:11:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:11:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:11:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:11:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:11:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:11:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:11:11 @pendulum_agent.py:317][0m Evaluation time: 0.7039859294891357
[32m[20221125 01:11:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:11:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:11:12 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:11:12 @pendulum_agent.py:289][0m Total time: 13741.138720035553
[32m[20221125 01:11:12 @pendulum_agent.py:291][0m 43900000 total steps have happened
[32m[20221125 01:11:12 @pendulum_agent.py:281][0m #------------------------ Iteration 878 --------------------------#
[32m[20221125 01:11:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:11:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:11:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:11:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:11:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:11:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:11:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:11:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:11:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:11:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:11:15 @pendulum_agent.py:307][0m Sample time: 3.741633892059326
[32m[20221125 01:11:24 @pendulum_agent.py:312][0m Update time: 8.946494102478027
[32m[20221125 01:11:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:11:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:11:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:11:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:11:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:11:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:11:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:11:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:11:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:11:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:11:25 @pendulum_agent.py:317][0m Evaluation time: 0.7020318508148193
[32m[20221125 01:11:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:11:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:11:25 @pendulum_agent.py:289][0m Total time: 13754.805192947388
[32m[20221125 01:11:25 @pendulum_agent.py:291][0m 43950000 total steps have happened
[32m[20221125 01:11:25 @pendulum_agent.py:281][0m #------------------------ Iteration 879 --------------------------#
[32m[20221125 01:11:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:11:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:11:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:11:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:11:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:11:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:11:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:11:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:11:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:11:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:11:29 @pendulum_agent.py:307][0m Sample time: 3.7837541103363037
[32m[20221125 01:11:39 @pendulum_agent.py:312][0m Update time: 10.29951000213623
[32m[20221125 01:11:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:11:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:11:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:11:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:11:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:11:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:11:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:11:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:11:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:11:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:11:40 @pendulum_agent.py:317][0m Evaluation time: 0.6935160160064697
[32m[20221125 01:11:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:11:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:11:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:11:40 @pendulum_agent.py:289][0m Total time: 13769.861478090286
[32m[20221125 01:11:40 @pendulum_agent.py:291][0m 44000000 total steps have happened
[32m[20221125 01:11:40 @pendulum_agent.py:281][0m #------------------------ Iteration 880 --------------------------#
[32m[20221125 01:11:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.4
[32m[20221125 01:11:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.8
[32m[20221125 01:11:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.0
[32m[20221125 01:11:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.6
[32m[20221125 01:11:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.4
[32m[20221125 01:11:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.2
[32m[20221125 01:11:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.0
[32m[20221125 01:11:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.2
[32m[20221125 01:11:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.6
[32m[20221125 01:11:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.0
[32m[20221125 01:11:44 @pendulum_agent.py:307][0m Sample time: 3.5397861003875732
[32m[20221125 01:11:53 @pendulum_agent.py:312][0m Update time: 9.544018745422363
[32m[20221125 01:11:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:11:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:11:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:11:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:11:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:11:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:11:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:11:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:11:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:11:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:11:54 @pendulum_agent.py:317][0m Evaluation time: 0.8430070877075195
[32m[20221125 01:11:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.62
[32m[20221125 01:11:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:11:54 @pendulum_agent.py:289][0m Total time: 13784.058012008667
[32m[20221125 01:11:54 @pendulum_agent.py:291][0m 44050000 total steps have happened
[32m[20221125 01:11:54 @pendulum_agent.py:281][0m #------------------------ Iteration 881 --------------------------#
[32m[20221125 01:11:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:11:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:11:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:11:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:11:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:11:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:11:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:11:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:11:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:11:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:11:58 @pendulum_agent.py:307][0m Sample time: 3.7373950481414795
[32m[20221125 01:12:07 @pendulum_agent.py:312][0m Update time: 8.848550796508789
[32m[20221125 01:12:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:12:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:12:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:12:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:12:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:12:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:12:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:12:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:12:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:12:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:12:08 @pendulum_agent.py:317][0m Evaluation time: 0.7182421684265137
[32m[20221125 01:12:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:12:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:12:08 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:12:08 @pendulum_agent.py:289][0m Total time: 13797.647037029266
[32m[20221125 01:12:08 @pendulum_agent.py:291][0m 44100000 total steps have happened
[32m[20221125 01:12:08 @pendulum_agent.py:281][0m #------------------------ Iteration 882 --------------------------#
[32m[20221125 01:12:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:12:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:12:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:12:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:12:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:12:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:12:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:12:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:12:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:12:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:12:12 @pendulum_agent.py:307][0m Sample time: 3.748368978500366
[32m[20221125 01:12:43 @pendulum_agent.py:312][0m Update time: 31.293564081192017
[32m[20221125 01:12:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:12:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:12:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:12:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:12:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:12:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:12:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:12:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:12:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:12:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:12:44 @pendulum_agent.py:317][0m Evaluation time: 0.6958920955657959
[32m[20221125 01:12:44 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:12:44 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:12:44 @pendulum_agent.py:289][0m Total time: 13833.667081832886
[32m[20221125 01:12:44 @pendulum_agent.py:291][0m 44150000 total steps have happened
[32m[20221125 01:12:44 @pendulum_agent.py:281][0m #------------------------ Iteration 883 --------------------------#
[32m[20221125 01:12:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.2
[32m[20221125 01:12:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:12:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:12:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:12:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:12:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.2
[32m[20221125 01:12:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 9.6
[32m[20221125 01:12:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:12:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:12:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 12.8
[32m[20221125 01:12:48 @pendulum_agent.py:307][0m Sample time: 3.5813028812408447
[32m[20221125 01:12:57 @pendulum_agent.py:312][0m Update time: 8.963727235794067
[32m[20221125 01:12:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:12:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:12:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:12:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:12:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:12:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:12:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:12:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:12:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:12:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:12:57 @pendulum_agent.py:317][0m Evaluation time: 0.6952219009399414
[32m[20221125 01:12:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.48
[32m[20221125 01:12:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:12:58 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:12:58 @pendulum_agent.py:289][0m Total time: 13847.20505309105
[32m[20221125 01:12:58 @pendulum_agent.py:291][0m 44200000 total steps have happened
[32m[20221125 01:12:58 @pendulum_agent.py:281][0m #------------------------ Iteration 884 --------------------------#
[32m[20221125 01:12:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:12:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:12:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:12:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:12:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:12:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:12:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:12:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:12:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:12:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:13:01 @pendulum_agent.py:307][0m Sample time: 3.5566539764404297
[32m[20221125 01:13:10 @pendulum_agent.py:312][0m Update time: 8.955199956893921
[32m[20221125 01:13:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:13:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:13:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:13:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:13:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:13:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:13:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:13:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:13:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:13:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:13:11 @pendulum_agent.py:317][0m Evaluation time: 0.8369760513305664
[32m[20221125 01:13:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:13:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:13:11 @pendulum_agent.py:289][0m Total time: 13860.836667060852
[32m[20221125 01:13:11 @pendulum_agent.py:291][0m 44250000 total steps have happened
[32m[20221125 01:13:11 @pendulum_agent.py:281][0m #------------------------ Iteration 885 --------------------------#
[32m[20221125 01:13:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:13:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:13:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:13:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:13:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:13:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:13:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:13:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:13:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:13:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:13:15 @pendulum_agent.py:307][0m Sample time: 3.526822805404663
[32m[20221125 01:13:24 @pendulum_agent.py:312][0m Update time: 8.928842067718506
[32m[20221125 01:13:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:13:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:13:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:13:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:13:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:13:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:13:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:13:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:13:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:13:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:13:25 @pendulum_agent.py:317][0m Evaluation time: 1.0265007019042969
[32m[20221125 01:13:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:13:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:13:25 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:13:25 @pendulum_agent.py:289][0m Total time: 13874.604048013687
[32m[20221125 01:13:25 @pendulum_agent.py:291][0m 44300000 total steps have happened
[32m[20221125 01:13:25 @pendulum_agent.py:281][0m #------------------------ Iteration 886 --------------------------#
[32m[20221125 01:13:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:13:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:13:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:13:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:13:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:13:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:13:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:13:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:13:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:13:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:13:28 @pendulum_agent.py:307][0m Sample time: 3.362761974334717
[32m[20221125 01:13:40 @pendulum_agent.py:312][0m Update time: 11.34785795211792
[32m[20221125 01:13:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:13:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:13:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:13:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:13:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:13:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:13:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:13:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:13:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:13:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:13:41 @pendulum_agent.py:317][0m Evaluation time: 1.14316987991333
[32m[20221125 01:13:41 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:13:41 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:13:41 @pendulum_agent.py:289][0m Total time: 13890.726066827774
[32m[20221125 01:13:41 @pendulum_agent.py:291][0m 44350000 total steps have happened
[32m[20221125 01:13:41 @pendulum_agent.py:281][0m #------------------------ Iteration 887 --------------------------#
[32m[20221125 01:13:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:13:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:13:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:13:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:13:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:13:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:13:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:13:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:13:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:13:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:13:45 @pendulum_agent.py:307][0m Sample time: 3.4115829467773438
[32m[20221125 01:13:59 @pendulum_agent.py:312][0m Update time: 14.04848313331604
[32m[20221125 01:13:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:13:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:13:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:13:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:13:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:13:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:13:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:13:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:13:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:13:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:14:00 @pendulum_agent.py:317][0m Evaluation time: 1.8066089153289795
[32m[20221125 01:14:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:14:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:14:01 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:14:01 @pendulum_agent.py:289][0m Total time: 13910.291438102722
[32m[20221125 01:14:01 @pendulum_agent.py:291][0m 44400000 total steps have happened
[32m[20221125 01:14:01 @pendulum_agent.py:281][0m #------------------------ Iteration 888 --------------------------#
[32m[20221125 01:14:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.2
[32m[20221125 01:14:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.0
[32m[20221125 01:14:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.4
[32m[20221125 01:14:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.0
[32m[20221125 01:14:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.8
[32m[20221125 01:14:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.2
[32m[20221125 01:14:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.6
[32m[20221125 01:14:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.8
[32m[20221125 01:14:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.2
[32m[20221125 01:14:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.8
[32m[20221125 01:14:04 @pendulum_agent.py:307][0m Sample time: 3.539241075515747
[32m[20221125 01:14:18 @pendulum_agent.py:312][0m Update time: 13.62992787361145
[32m[20221125 01:14:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:14:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:14:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:14:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:14:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:14:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:14:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:14:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:14:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:14:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:14:19 @pendulum_agent.py:317][0m Evaluation time: 0.6917681694030762
[32m[20221125 01:14:19 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.0
[32m[20221125 01:14:19 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:14:19 @pendulum_agent.py:289][0m Total time: 13928.421103954315
[32m[20221125 01:14:19 @pendulum_agent.py:291][0m 44450000 total steps have happened
[32m[20221125 01:14:19 @pendulum_agent.py:281][0m #------------------------ Iteration 889 --------------------------#
[32m[20221125 01:14:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.2
[32m[20221125 01:14:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.8
[32m[20221125 01:14:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.8
[32m[20221125 01:14:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 8.6
[32m[20221125 01:14:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.4
[32m[20221125 01:14:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.0
[32m[20221125 01:14:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.0
[32m[20221125 01:14:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 8.8
[32m[20221125 01:14:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.0
[32m[20221125 01:14:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.6
[32m[20221125 01:14:22 @pendulum_agent.py:307][0m Sample time: 3.6221842765808105
[32m[20221125 01:14:33 @pendulum_agent.py:312][0m Update time: 10.94164776802063
[32m[20221125 01:14:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:14:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:14:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:14:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:14:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:14:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:14:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:14:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:14:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:14:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:14:34 @pendulum_agent.py:317][0m Evaluation time: 0.957482099533081
[32m[20221125 01:14:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.72
[32m[20221125 01:14:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:14:35 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:14:35 @pendulum_agent.py:289][0m Total time: 13944.22969198227
[32m[20221125 01:14:35 @pendulum_agent.py:291][0m 44500000 total steps have happened
[32m[20221125 01:14:35 @pendulum_agent.py:281][0m #------------------------ Iteration 890 --------------------------#
[32m[20221125 01:14:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:14:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:14:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:14:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:14:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:14:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:14:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:14:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:14:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:14:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:14:39 @pendulum_agent.py:307][0m Sample time: 3.9025912284851074
[32m[20221125 01:14:49 @pendulum_agent.py:312][0m Update time: 10.082889795303345
[32m[20221125 01:14:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:14:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:14:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:14:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:14:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:14:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:14:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:14:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:14:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:14:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:14:50 @pendulum_agent.py:317][0m Evaluation time: 0.9449141025543213
[32m[20221125 01:14:50 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:14:50 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:14:50 @pendulum_agent.py:289][0m Total time: 13959.446743011475
[32m[20221125 01:14:50 @pendulum_agent.py:291][0m 44550000 total steps have happened
[32m[20221125 01:14:50 @pendulum_agent.py:281][0m #------------------------ Iteration 891 --------------------------#
[32m[20221125 01:14:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:14:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:14:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:14:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:14:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:14:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:14:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:14:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:14:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:14:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:14:54 @pendulum_agent.py:307][0m Sample time: 3.880213975906372
[32m[20221125 01:15:05 @pendulum_agent.py:312][0m Update time: 11.320401906967163
[32m[20221125 01:15:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:15:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:15:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:15:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:15:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:15:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:15:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:15:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:15:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:15:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:15:06 @pendulum_agent.py:317][0m Evaluation time: 0.7127430438995361
[32m[20221125 01:15:06 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:15:06 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:15:06 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:15:06 @pendulum_agent.py:289][0m Total time: 13975.648399114609
[32m[20221125 01:15:06 @pendulum_agent.py:291][0m 44600000 total steps have happened
[32m[20221125 01:15:06 @pendulum_agent.py:281][0m #------------------------ Iteration 892 --------------------------#
[32m[20221125 01:15:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.0
[32m[20221125 01:15:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 7.2
[32m[20221125 01:15:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.8
[32m[20221125 01:15:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.0
[32m[20221125 01:15:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 7.0
[32m[20221125 01:15:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.6
[32m[20221125 01:15:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.4
[32m[20221125 01:15:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 9.6
[32m[20221125 01:15:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.6
[32m[20221125 01:15:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.8
[32m[20221125 01:15:10 @pendulum_agent.py:307][0m Sample time: 3.503833770751953
[32m[20221125 01:15:18 @pendulum_agent.py:312][0m Update time: 8.9382483959198
[32m[20221125 01:15:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:15:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:15:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:15:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:15:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:15:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:15:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:15:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:15:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:15:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:15:19 @pendulum_agent.py:317][0m Evaluation time: 0.5756998062133789
[32m[20221125 01:15:19 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.2
[32m[20221125 01:15:19 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:15:19 @pendulum_agent.py:289][0m Total time: 13988.946555137634
[32m[20221125 01:15:19 @pendulum_agent.py:291][0m 44650000 total steps have happened
[32m[20221125 01:15:19 @pendulum_agent.py:281][0m #------------------------ Iteration 893 --------------------------#
[32m[20221125 01:15:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:15:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:15:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:15:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:15:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:15:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:15:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:15:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:15:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:15:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:15:23 @pendulum_agent.py:307][0m Sample time: 3.766731023788452
[32m[20221125 01:15:39 @pendulum_agent.py:312][0m Update time: 15.862208127975464
[32m[20221125 01:15:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:15:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:15:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:15:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:15:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:15:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:15:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:15:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:15:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:15:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:15:40 @pendulum_agent.py:317][0m Evaluation time: 0.5704648494720459
[32m[20221125 01:15:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:15:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:15:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:15:40 @pendulum_agent.py:289][0m Total time: 14009.438998937607
[32m[20221125 01:15:40 @pendulum_agent.py:291][0m 44700000 total steps have happened
[32m[20221125 01:15:40 @pendulum_agent.py:281][0m #------------------------ Iteration 894 --------------------------#
[32m[20221125 01:15:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:15:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:15:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:15:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:15:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:15:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:15:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:15:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:15:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:15:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:15:44 @pendulum_agent.py:307][0m Sample time: 3.7935543060302734
[32m[20221125 01:15:54 @pendulum_agent.py:312][0m Update time: 10.436591863632202
[32m[20221125 01:15:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:15:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:15:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:15:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:15:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:15:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:15:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:15:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:15:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:15:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:15:55 @pendulum_agent.py:317][0m Evaluation time: 0.5667209625244141
[32m[20221125 01:15:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:15:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:15:55 @pendulum_agent.py:289][0m Total time: 14024.552150964737
[32m[20221125 01:15:55 @pendulum_agent.py:291][0m 44750000 total steps have happened
[32m[20221125 01:15:55 @pendulum_agent.py:281][0m #------------------------ Iteration 895 --------------------------#
[32m[20221125 01:15:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:15:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:15:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:15:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:15:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:15:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:15:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:15:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:15:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:15:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:15:59 @pendulum_agent.py:307][0m Sample time: 3.9011728763580322
[32m[20221125 01:16:14 @pendulum_agent.py:312][0m Update time: 15.463907241821289
[32m[20221125 01:16:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:16:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:16:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:16:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:16:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:16:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:16:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:16:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:16:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:16:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:16:15 @pendulum_agent.py:317][0m Evaluation time: 0.6784429550170898
[32m[20221125 01:16:15 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:16:15 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:16:15 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:16:15 @pendulum_agent.py:289][0m Total time: 14044.880968809128
[32m[20221125 01:16:15 @pendulum_agent.py:291][0m 44800000 total steps have happened
[32m[20221125 01:16:15 @pendulum_agent.py:281][0m #------------------------ Iteration 896 --------------------------#
[32m[20221125 01:16:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.0
[32m[20221125 01:16:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.6
[32m[20221125 01:16:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1.4
[32m[20221125 01:16:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.2
[32m[20221125 01:16:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1.8
[32m[20221125 01:16:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.2
[32m[20221125 01:16:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.0
[32m[20221125 01:16:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.2
[32m[20221125 01:16:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.4
[32m[20221125 01:16:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.6
[32m[20221125 01:16:19 @pendulum_agent.py:307][0m Sample time: 3.619859218597412
[32m[20221125 01:16:33 @pendulum_agent.py:312][0m Update time: 14.128172874450684
[32m[20221125 01:16:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:16:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:16:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:16:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:16:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:16:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:16:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:16:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:16:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:16:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:16:34 @pendulum_agent.py:317][0m Evaluation time: 0.8215570449829102
[32m[20221125 01:16:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.44
[32m[20221125 01:16:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:16:34 @pendulum_agent.py:289][0m Total time: 14063.73313999176
[32m[20221125 01:16:34 @pendulum_agent.py:291][0m 44850000 total steps have happened
[32m[20221125 01:16:34 @pendulum_agent.py:281][0m #------------------------ Iteration 897 --------------------------#
[32m[20221125 01:16:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:16:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:16:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:16:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:16:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:16:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:16:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:16:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:16:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:16:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:16:37 @pendulum_agent.py:307][0m Sample time: 3.2505269050598145
[32m[20221125 01:17:04 @pendulum_agent.py:312][0m Update time: 26.88313913345337
[32m[20221125 01:17:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:17:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:17:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:17:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:17:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:17:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:17:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:17:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:17:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:17:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:17:05 @pendulum_agent.py:317][0m Evaluation time: 1.0089740753173828
[32m[20221125 01:17:06 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:17:06 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:17:06 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:17:06 @pendulum_agent.py:289][0m Total time: 14095.14908194542
[32m[20221125 01:17:06 @pendulum_agent.py:291][0m 44900000 total steps have happened
[32m[20221125 01:17:06 @pendulum_agent.py:281][0m #------------------------ Iteration 898 --------------------------#
[32m[20221125 01:17:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 9.6
[32m[20221125 01:17:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.0
[32m[20221125 01:17:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.4
[32m[20221125 01:17:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.8
[32m[20221125 01:17:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 8.2
[32m[20221125 01:17:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.6
[32m[20221125 01:17:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.8
[32m[20221125 01:17:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 8.4
[32m[20221125 01:17:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 14.2
[32m[20221125 01:17:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.4
[32m[20221125 01:17:09 @pendulum_agent.py:307][0m Sample time: 3.497093915939331
[32m[20221125 01:17:19 @pendulum_agent.py:312][0m Update time: 10.299731016159058
[32m[20221125 01:17:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:17:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:17:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:17:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:17:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:17:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:17:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:17:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:17:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:17:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:17:20 @pendulum_agent.py:317][0m Evaluation time: 1.1518871784210205
[32m[20221125 01:17:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.94
[32m[20221125 01:17:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:17:21 @pendulum_agent.py:289][0m Total time: 14110.371340036392
[32m[20221125 01:17:21 @pendulum_agent.py:291][0m 44950000 total steps have happened
[32m[20221125 01:17:21 @pendulum_agent.py:281][0m #------------------------ Iteration 899 --------------------------#
[32m[20221125 01:17:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:17:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:17:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:17:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:17:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:17:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:17:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:17:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:17:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:17:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:17:24 @pendulum_agent.py:307][0m Sample time: 3.4281349182128906
[32m[20221125 01:17:33 @pendulum_agent.py:312][0m Update time: 8.813957691192627
[32m[20221125 01:17:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:17:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:17:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:17:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:17:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:17:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:17:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:17:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:17:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:17:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:17:34 @pendulum_agent.py:317][0m Evaluation time: 1.136491060256958
[32m[20221125 01:17:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:17:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:17:34 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:17:34 @pendulum_agent.py:289][0m Total time: 14124.037024974823
[32m[20221125 01:17:34 @pendulum_agent.py:291][0m 45000000 total steps have happened
[32m[20221125 01:17:34 @pendulum_agent.py:281][0m #------------------------ Iteration 900 --------------------------#
[32m[20221125 01:17:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:17:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:17:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:17:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:17:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:17:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:17:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:17:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:17:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:17:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:17:38 @pendulum_agent.py:307][0m Sample time: 3.596898078918457
[32m[20221125 01:18:10 @pendulum_agent.py:312][0m Update time: 32.35165572166443
[32m[20221125 01:18:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:18:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:18:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:18:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:18:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:18:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:18:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:18:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:18:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:18:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:18:11 @pendulum_agent.py:317][0m Evaluation time: 0.7108762264251709
[32m[20221125 01:18:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:18:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:18:11 @pendulum_agent.py:289][0m Total time: 14160.976752996445
[32m[20221125 01:18:11 @pendulum_agent.py:291][0m 45050000 total steps have happened
[32m[20221125 01:18:11 @pendulum_agent.py:281][0m #------------------------ Iteration 901 --------------------------#
[32m[20221125 01:18:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.0
[32m[20221125 01:18:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:18:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.4
[32m[20221125 01:18:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.2
[32m[20221125 01:18:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:18:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 12.4
[32m[20221125 01:18:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 7.6
[32m[20221125 01:18:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.0
[32m[20221125 01:18:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:18:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.4
[32m[20221125 01:18:15 @pendulum_agent.py:307][0m Sample time: 3.624910831451416
[32m[20221125 01:18:24 @pendulum_agent.py:312][0m Update time: 9.006670951843262
[32m[20221125 01:18:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:18:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:18:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:18:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:18:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:18:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:18:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:18:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:18:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:18:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:18:25 @pendulum_agent.py:317][0m Evaluation time: 0.7185120582580566
[32m[20221125 01:18:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.9
[32m[20221125 01:18:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:18:25 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:18:25 @pendulum_agent.py:289][0m Total time: 14174.605314970016
[32m[20221125 01:18:25 @pendulum_agent.py:291][0m 45100000 total steps have happened
[32m[20221125 01:18:25 @pendulum_agent.py:281][0m #------------------------ Iteration 902 --------------------------#
[32m[20221125 01:18:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.6
[32m[20221125 01:18:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.4
[32m[20221125 01:18:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.2
[32m[20221125 01:18:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.6
[32m[20221125 01:18:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.8
[32m[20221125 01:18:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.0
[32m[20221125 01:18:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.8
[32m[20221125 01:18:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.4
[32m[20221125 01:18:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.4
[32m[20221125 01:18:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.4
[32m[20221125 01:18:29 @pendulum_agent.py:307][0m Sample time: 3.5398426055908203
[32m[20221125 01:18:48 @pendulum_agent.py:312][0m Update time: 19.246523141860962
[32m[20221125 01:18:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:18:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:18:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:18:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:18:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:18:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:18:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:18:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:18:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:18:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:18:48 @pendulum_agent.py:317][0m Evaluation time: 0.6804680824279785
[32m[20221125 01:18:49 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.76
[32m[20221125 01:18:49 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:18:49 @pendulum_agent.py:289][0m Total time: 14198.346379995346
[32m[20221125 01:18:49 @pendulum_agent.py:291][0m 45150000 total steps have happened
[32m[20221125 01:18:49 @pendulum_agent.py:281][0m #------------------------ Iteration 903 --------------------------#
[32m[20221125 01:18:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:18:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:18:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:18:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:18:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:18:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:18:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:18:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:18:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:18:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:18:53 @pendulum_agent.py:307][0m Sample time: 3.8346922397613525
[32m[20221125 01:19:06 @pendulum_agent.py:312][0m Update time: 13.301785945892334
[32m[20221125 01:19:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:19:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:19:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:19:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:19:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:19:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:19:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:19:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:19:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:19:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:19:06 @pendulum_agent.py:317][0m Evaluation time: 0.594498872756958
[32m[20221125 01:19:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:19:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:19:07 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:19:07 @pendulum_agent.py:289][0m Total time: 14216.36408495903
[32m[20221125 01:19:07 @pendulum_agent.py:291][0m 45200000 total steps have happened
[32m[20221125 01:19:07 @pendulum_agent.py:281][0m #------------------------ Iteration 904 --------------------------#
[32m[20221125 01:19:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:19:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:19:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:19:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:19:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:19:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:19:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:19:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:19:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:19:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:19:11 @pendulum_agent.py:307][0m Sample time: 3.7889599800109863
[32m[20221125 01:19:24 @pendulum_agent.py:312][0m Update time: 13.731571912765503
[32m[20221125 01:19:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:19:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:19:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:19:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:19:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:19:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:19:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:19:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:19:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:19:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:19:25 @pendulum_agent.py:317][0m Evaluation time: 0.699951171875
[32m[20221125 01:19:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:19:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:19:25 @pendulum_agent.py:289][0m Total time: 14234.863171100616
[32m[20221125 01:19:25 @pendulum_agent.py:291][0m 45250000 total steps have happened
[32m[20221125 01:19:25 @pendulum_agent.py:281][0m #------------------------ Iteration 905 --------------------------#
[32m[20221125 01:19:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:19:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:19:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:19:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:19:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:19:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:19:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:19:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:19:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:19:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:19:29 @pendulum_agent.py:307][0m Sample time: 3.553581953048706
[32m[20221125 01:19:38 @pendulum_agent.py:312][0m Update time: 8.93803095817566
[32m[20221125 01:19:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:19:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:19:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:19:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:19:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:19:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:19:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:19:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:19:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:19:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:19:38 @pendulum_agent.py:317][0m Evaluation time: 0.6877651214599609
[32m[20221125 01:19:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:19:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:19:39 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:19:39 @pendulum_agent.py:289][0m Total time: 14248.315732002258
[32m[20221125 01:19:39 @pendulum_agent.py:291][0m 45300000 total steps have happened
[32m[20221125 01:19:39 @pendulum_agent.py:281][0m #------------------------ Iteration 906 --------------------------#
[32m[20221125 01:19:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:19:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:19:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:19:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:19:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:19:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:19:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:19:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:19:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:19:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:19:42 @pendulum_agent.py:307][0m Sample time: 3.6290178298950195
[32m[20221125 01:19:53 @pendulum_agent.py:312][0m Update time: 10.807456016540527
[32m[20221125 01:19:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:19:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:19:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:19:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:19:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:19:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:19:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:19:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:19:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:19:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:19:54 @pendulum_agent.py:317][0m Evaluation time: 0.8470098972320557
[32m[20221125 01:19:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:19:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:19:54 @pendulum_agent.py:289][0m Total time: 14263.881672143936
[32m[20221125 01:19:54 @pendulum_agent.py:291][0m 45350000 total steps have happened
[32m[20221125 01:19:54 @pendulum_agent.py:281][0m #------------------------ Iteration 907 --------------------------#
[32m[20221125 01:19:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:19:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:19:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:19:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:19:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:19:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:19:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:19:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:19:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:19:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:19:58 @pendulum_agent.py:307][0m Sample time: 3.4525880813598633
[32m[20221125 01:20:12 @pendulum_agent.py:312][0m Update time: 14.732749700546265
[32m[20221125 01:20:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 22.0
[32m[20221125 01:20:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 22.0
[32m[20221125 01:20:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 22.0
[32m[20221125 01:20:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 22.0
[32m[20221125 01:20:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 22.0
[32m[20221125 01:20:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 22.0
[32m[20221125 01:20:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 22.0
[32m[20221125 01:20:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 22.0
[32m[20221125 01:20:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 22.0
[32m[20221125 01:20:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 22.0
[32m[20221125 01:20:14 @pendulum_agent.py:317][0m Evaluation time: 1.0453910827636719
[32m[20221125 01:20:14 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:20:14 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:20:14 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:20:14 @pendulum_agent.py:289][0m Total time: 14283.40026307106
[32m[20221125 01:20:14 @pendulum_agent.py:291][0m 45400000 total steps have happened
[32m[20221125 01:20:14 @pendulum_agent.py:281][0m #------------------------ Iteration 908 --------------------------#
[32m[20221125 01:20:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:20:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:20:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:20:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:20:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:20:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:20:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:20:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:20:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:20:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:20:17 @pendulum_agent.py:307][0m Sample time: 3.2148869037628174
[32m[20221125 01:20:52 @pendulum_agent.py:312][0m Update time: 34.67955422401428
[32m[20221125 01:20:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:20:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:20:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:20:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:20:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:20:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:20:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:20:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:20:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:20:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:20:53 @pendulum_agent.py:317][0m Evaluation time: 1.0379350185394287
[32m[20221125 01:20:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:20:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:20:53 @pendulum_agent.py:289][0m Total time: 14322.609965085983
[32m[20221125 01:20:53 @pendulum_agent.py:291][0m 45450000 total steps have happened
[32m[20221125 01:20:53 @pendulum_agent.py:281][0m #------------------------ Iteration 909 --------------------------#
[32m[20221125 01:20:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:20:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:20:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:20:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:20:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:20:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:20:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:20:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:20:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:20:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:20:57 @pendulum_agent.py:307][0m Sample time: 3.660264015197754
[32m[20221125 01:21:11 @pendulum_agent.py:312][0m Update time: 13.942076921463013
[32m[20221125 01:21:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:21:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:21:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:21:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:21:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:21:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:21:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:21:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:21:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:21:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:21:11 @pendulum_agent.py:317][0m Evaluation time: 0.7029011249542236
[32m[20221125 01:21:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:21:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:21:12 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:21:12 @pendulum_agent.py:289][0m Total time: 14341.187890768051
[32m[20221125 01:21:12 @pendulum_agent.py:291][0m 45500000 total steps have happened
[32m[20221125 01:21:12 @pendulum_agent.py:281][0m #------------------------ Iteration 910 --------------------------#
[32m[20221125 01:21:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:21:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:21:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:21:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:21:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:21:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:21:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:21:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:21:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:21:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:21:15 @pendulum_agent.py:307][0m Sample time: 3.6561408042907715
[32m[20221125 01:21:30 @pendulum_agent.py:312][0m Update time: 15.128807067871094
[32m[20221125 01:21:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:21:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:21:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:21:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:21:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:21:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:21:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:21:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:21:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:21:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:21:31 @pendulum_agent.py:317][0m Evaluation time: 0.7004680633544922
[32m[20221125 01:21:31 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:21:31 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:21:31 @pendulum_agent.py:289][0m Total time: 14360.944103956223
[32m[20221125 01:21:31 @pendulum_agent.py:291][0m 45550000 total steps have happened
[32m[20221125 01:21:31 @pendulum_agent.py:281][0m #------------------------ Iteration 911 --------------------------#
[32m[20221125 01:21:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:21:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:21:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:21:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:21:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:21:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:21:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:21:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:21:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:21:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:21:35 @pendulum_agent.py:307][0m Sample time: 3.836818218231201
[32m[20221125 01:21:44 @pendulum_agent.py:312][0m Update time: 8.96911907196045
[32m[20221125 01:21:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:21:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:21:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:21:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:21:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:21:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:21:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:21:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:21:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:21:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:21:45 @pendulum_agent.py:317][0m Evaluation time: 0.5769598484039307
[32m[20221125 01:21:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:21:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:21:45 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:21:45 @pendulum_agent.py:289][0m Total time: 14374.63547205925
[32m[20221125 01:21:45 @pendulum_agent.py:291][0m 45600000 total steps have happened
[32m[20221125 01:21:45 @pendulum_agent.py:281][0m #------------------------ Iteration 912 --------------------------#
[32m[20221125 01:21:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.0
[32m[20221125 01:21:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.6
[32m[20221125 01:21:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.4
[32m[20221125 01:21:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.2
[32m[20221125 01:21:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 7.2
[32m[20221125 01:21:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.6
[32m[20221125 01:21:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 7.2
[32m[20221125 01:21:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.8
[32m[20221125 01:21:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.0
[32m[20221125 01:21:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.8
[32m[20221125 01:21:49 @pendulum_agent.py:307][0m Sample time: 3.6142680644989014
[32m[20221125 01:22:18 @pendulum_agent.py:312][0m Update time: 28.917349815368652
[32m[20221125 01:22:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:22:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:22:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:22:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:22:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:22:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:22:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:22:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:22:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:22:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:22:18 @pendulum_agent.py:317][0m Evaluation time: 0.8173251152038574
[32m[20221125 01:22:19 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.48
[32m[20221125 01:22:19 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:22:19 @pendulum_agent.py:289][0m Total time: 14408.26718211174
[32m[20221125 01:22:19 @pendulum_agent.py:291][0m 45650000 total steps have happened
[32m[20221125 01:22:19 @pendulum_agent.py:281][0m #------------------------ Iteration 913 --------------------------#
[32m[20221125 01:22:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:22:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:22:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:22:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:22:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:22:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:22:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:22:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:22:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:22:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:22:22 @pendulum_agent.py:307][0m Sample time: 3.575417995452881
[32m[20221125 01:22:47 @pendulum_agent.py:312][0m Update time: 24.50089693069458
[32m[20221125 01:22:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:22:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:22:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:22:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:22:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:22:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:22:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:22:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:22:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:22:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:22:48 @pendulum_agent.py:317][0m Evaluation time: 1.0137150287628174
[32m[20221125 01:22:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:22:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:22:48 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:22:48 @pendulum_agent.py:289][0m Total time: 14437.64477801323
[32m[20221125 01:22:48 @pendulum_agent.py:291][0m 45700000 total steps have happened
[32m[20221125 01:22:48 @pendulum_agent.py:281][0m #------------------------ Iteration 914 --------------------------#
[32m[20221125 01:22:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:22:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:22:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:22:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:22:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:22:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:22:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:22:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:22:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:22:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:22:52 @pendulum_agent.py:307][0m Sample time: 3.6093218326568604
[32m[20221125 01:23:00 @pendulum_agent.py:312][0m Update time: 8.819806098937988
[32m[20221125 01:23:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:23:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:23:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:23:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:23:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:23:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:23:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:23:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:23:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:23:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:23:01 @pendulum_agent.py:317][0m Evaluation time: 0.6950440406799316
[32m[20221125 01:23:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:23:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:23:01 @pendulum_agent.py:289][0m Total time: 14451.042440891266
[32m[20221125 01:23:01 @pendulum_agent.py:291][0m 45750000 total steps have happened
[32m[20221125 01:23:01 @pendulum_agent.py:281][0m #------------------------ Iteration 915 --------------------------#
[32m[20221125 01:23:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:23:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:23:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:23:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:23:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:23:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:23:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:23:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:23:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:23:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:23:05 @pendulum_agent.py:307][0m Sample time: 3.638108253479004
[32m[20221125 01:23:17 @pendulum_agent.py:312][0m Update time: 11.983216762542725
[32m[20221125 01:23:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:23:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:23:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:23:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:23:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:23:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:23:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:23:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:23:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:23:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:23:18 @pendulum_agent.py:317][0m Evaluation time: 0.5790102481842041
[32m[20221125 01:23:18 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:23:18 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:23:18 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:23:18 @pendulum_agent.py:289][0m Total time: 14467.53976392746
[32m[20221125 01:23:18 @pendulum_agent.py:291][0m 45800000 total steps have happened
[32m[20221125 01:23:18 @pendulum_agent.py:281][0m #------------------------ Iteration 916 --------------------------#
[32m[20221125 01:23:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:23:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:23:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:23:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:23:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:23:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:23:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:23:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:23:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:23:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:23:22 @pendulum_agent.py:307][0m Sample time: 3.82374906539917
[32m[20221125 01:23:31 @pendulum_agent.py:312][0m Update time: 8.891259908676147
[32m[20221125 01:23:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:23:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:23:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:23:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:23:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:23:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:23:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:23:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:23:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:23:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:23:31 @pendulum_agent.py:317][0m Evaluation time: 0.7088649272918701
[32m[20221125 01:23:32 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:23:32 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:23:32 @pendulum_agent.py:289][0m Total time: 14481.25201702118
[32m[20221125 01:23:32 @pendulum_agent.py:291][0m 45850000 total steps have happened
[32m[20221125 01:23:32 @pendulum_agent.py:281][0m #------------------------ Iteration 917 --------------------------#
[32m[20221125 01:23:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.8
[32m[20221125 01:23:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.4
[32m[20221125 01:23:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.2
[32m[20221125 01:23:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.8
[32m[20221125 01:23:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.6
[32m[20221125 01:23:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 7.2
[32m[20221125 01:23:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.2
[32m[20221125 01:23:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.8
[32m[20221125 01:23:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.8
[32m[20221125 01:23:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.6
[32m[20221125 01:23:35 @pendulum_agent.py:307][0m Sample time: 3.670914888381958
[32m[20221125 01:23:46 @pendulum_agent.py:312][0m Update time: 10.86566710472107
[32m[20221125 01:23:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:23:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:23:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:23:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:23:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:23:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:23:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:23:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:23:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:23:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:23:47 @pendulum_agent.py:317][0m Evaluation time: 0.6870379447937012
[32m[20221125 01:23:47 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.64
[32m[20221125 01:23:47 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:23:47 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:23:47 @pendulum_agent.py:289][0m Total time: 14496.755210876465
[32m[20221125 01:23:47 @pendulum_agent.py:291][0m 45900000 total steps have happened
[32m[20221125 01:23:47 @pendulum_agent.py:281][0m #------------------------ Iteration 918 --------------------------#
[32m[20221125 01:23:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.4
[32m[20221125 01:23:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.8
[32m[20221125 01:23:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.8
[32m[20221125 01:23:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.4
[32m[20221125 01:23:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.0
[32m[20221125 01:23:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.4
[32m[20221125 01:23:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.8
[32m[20221125 01:23:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.0
[32m[20221125 01:23:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.6
[32m[20221125 01:23:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.2
[32m[20221125 01:23:51 @pendulum_agent.py:307][0m Sample time: 3.576894998550415
[32m[20221125 01:23:59 @pendulum_agent.py:312][0m Update time: 8.735690116882324
[32m[20221125 01:24:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:24:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:24:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:24:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:24:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:24:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:24:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:24:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:24:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:24:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:24:00 @pendulum_agent.py:317][0m Evaluation time: 0.9296519756317139
[32m[20221125 01:24:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.54
[32m[20221125 01:24:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:24:01 @pendulum_agent.py:289][0m Total time: 14510.278116941452
[32m[20221125 01:24:01 @pendulum_agent.py:291][0m 45950000 total steps have happened
[32m[20221125 01:24:01 @pendulum_agent.py:281][0m #------------------------ Iteration 919 --------------------------#
[32m[20221125 01:24:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:24:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:24:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:24:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:24:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:24:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:24:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:24:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:24:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:24:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:24:04 @pendulum_agent.py:307][0m Sample time: 3.703291893005371
[32m[20221125 01:24:20 @pendulum_agent.py:312][0m Update time: 15.255990028381348
[32m[20221125 01:24:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:24:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:24:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:24:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:24:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:24:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:24:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:24:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:24:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:24:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:24:20 @pendulum_agent.py:317][0m Evaluation time: 0.6915802955627441
[32m[20221125 01:24:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:24:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:24:21 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:24:21 @pendulum_agent.py:289][0m Total time: 14530.191681861877
[32m[20221125 01:24:21 @pendulum_agent.py:291][0m 46000000 total steps have happened
[32m[20221125 01:24:21 @pendulum_agent.py:281][0m #------------------------ Iteration 920 --------------------------#
[32m[20221125 01:24:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:24:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:24:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:24:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:24:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:24:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:24:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:24:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:24:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:24:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:24:24 @pendulum_agent.py:307][0m Sample time: 3.668017864227295
[32m[20221125 01:25:06 @pendulum_agent.py:312][0m Update time: 41.40608310699463
[32m[20221125 01:25:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1000.0
[32m[20221125 01:25:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1000.0
[32m[20221125 01:25:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 1000.0
[32m[20221125 01:25:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1000.0
[32m[20221125 01:25:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1000.0
[32m[20221125 01:25:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1000.0
[32m[20221125 01:25:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1000.0
[32m[20221125 01:25:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1000.0
[32m[20221125 01:25:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1000.0
[32m[20221125 01:25:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 1000.0
[32m[20221125 01:25:06 @pendulum_agent.py:317][0m Evaluation time: 0.6615989208221436
[32m[20221125 01:25:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:25:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:25:07 @pendulum_agent.py:289][0m Total time: 14576.22008395195
[32m[20221125 01:25:07 @pendulum_agent.py:291][0m 46050000 total steps have happened
[32m[20221125 01:25:07 @pendulum_agent.py:281][0m #------------------------ Iteration 921 --------------------------#
[32m[20221125 01:25:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.6
[32m[20221125 01:25:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.8
[32m[20221125 01:25:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 15.2
[32m[20221125 01:25:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.0
[32m[20221125 01:25:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 9.0
[32m[20221125 01:25:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.2
[32m[20221125 01:25:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.2
[32m[20221125 01:25:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 13.2
[32m[20221125 01:25:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 9.6
[32m[20221125 01:25:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 11.2
[32m[20221125 01:25:10 @pendulum_agent.py:307][0m Sample time: 3.3566181659698486
[32m[20221125 01:25:20 @pendulum_agent.py:312][0m Update time: 9.88405704498291
[32m[20221125 01:25:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:25:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:25:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:25:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:25:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:25:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:25:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:25:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:25:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:25:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:25:21 @pendulum_agent.py:317][0m Evaluation time: 0.9230997562408447
[32m[20221125 01:25:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 9.1
[32m[20221125 01:25:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:25:21 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:25:21 @pendulum_agent.py:289][0m Total time: 14590.647618055344
[32m[20221125 01:25:21 @pendulum_agent.py:291][0m 46100000 total steps have happened
[32m[20221125 01:25:21 @pendulum_agent.py:281][0m #------------------------ Iteration 922 --------------------------#
[32m[20221125 01:25:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:25:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:25:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:25:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:25:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:25:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:25:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:25:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:25:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:25:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:25:24 @pendulum_agent.py:307][0m Sample time: 3.318485975265503
[32m[20221125 01:25:33 @pendulum_agent.py:312][0m Update time: 8.61889100074768
[32m[20221125 01:25:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:25:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:25:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:25:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:25:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:25:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:25:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:25:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:25:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:25:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:25:35 @pendulum_agent.py:317][0m Evaluation time: 1.644444227218628
[32m[20221125 01:25:35 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:25:35 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:25:35 @pendulum_agent.py:289][0m Total time: 14604.510242938995
[32m[20221125 01:25:35 @pendulum_agent.py:291][0m 46150000 total steps have happened
[32m[20221125 01:25:35 @pendulum_agent.py:281][0m #------------------------ Iteration 923 --------------------------#
[32m[20221125 01:25:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:25:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:25:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:25:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:25:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:25:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:25:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:25:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:25:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:25:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:25:39 @pendulum_agent.py:307][0m Sample time: 3.801239013671875
[32m[20221125 01:26:10 @pendulum_agent.py:312][0m Update time: 31.20266103744507
[32m[20221125 01:26:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:26:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:26:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:26:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:26:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:26:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:26:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:26:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:26:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:26:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:26:11 @pendulum_agent.py:317][0m Evaluation time: 0.7038910388946533
[32m[20221125 01:26:11 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:26:11 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:26:11 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:26:11 @pendulum_agent.py:289][0m Total time: 14640.490082025528
[32m[20221125 01:26:11 @pendulum_agent.py:291][0m 46200000 total steps have happened
[32m[20221125 01:26:11 @pendulum_agent.py:281][0m #------------------------ Iteration 924 --------------------------#
[32m[20221125 01:26:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:26:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:26:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:26:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:26:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:26:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:26:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:26:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:26:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:26:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:26:15 @pendulum_agent.py:307][0m Sample time: 3.6237921714782715
[32m[20221125 01:26:29 @pendulum_agent.py:312][0m Update time: 14.9525728225708
[32m[20221125 01:26:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:26:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:26:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:26:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:26:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:26:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:26:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:26:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:26:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:26:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:26:30 @pendulum_agent.py:317][0m Evaluation time: 0.6986382007598877
[32m[20221125 01:26:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:26:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:26:30 @pendulum_agent.py:289][0m Total time: 14660.034566164017
[32m[20221125 01:26:30 @pendulum_agent.py:291][0m 46250000 total steps have happened
[32m[20221125 01:26:30 @pendulum_agent.py:281][0m #------------------------ Iteration 925 --------------------------#
[32m[20221125 01:26:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:26:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:26:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:26:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:26:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:26:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:26:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:26:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:26:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:26:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:26:34 @pendulum_agent.py:307][0m Sample time: 3.735718250274658
[32m[20221125 01:26:49 @pendulum_agent.py:312][0m Update time: 14.926122903823853
[32m[20221125 01:26:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:26:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:26:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:26:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:26:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:26:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:26:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:26:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:26:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:26:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:26:50 @pendulum_agent.py:317][0m Evaluation time: 0.6974730491638184
[32m[20221125 01:26:50 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:26:50 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:26:50 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:26:50 @pendulum_agent.py:289][0m Total time: 14679.66957616806
[32m[20221125 01:26:50 @pendulum_agent.py:291][0m 46300000 total steps have happened
[32m[20221125 01:26:50 @pendulum_agent.py:281][0m #------------------------ Iteration 926 --------------------------#
[32m[20221125 01:26:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:26:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:26:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:26:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:26:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:26:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:26:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:26:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:26:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:26:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:26:54 @pendulum_agent.py:307][0m Sample time: 3.5241341590881348
[32m[20221125 01:27:04 @pendulum_agent.py:312][0m Update time: 10.316365957260132
[32m[20221125 01:27:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:27:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:27:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:27:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:27:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:27:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:27:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:27:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:27:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:27:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:27:05 @pendulum_agent.py:317][0m Evaluation time: 0.8033580780029297
[32m[20221125 01:27:05 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:27:05 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:27:05 @pendulum_agent.py:289][0m Total time: 14694.583633184433
[32m[20221125 01:27:05 @pendulum_agent.py:291][0m 46350000 total steps have happened
[32m[20221125 01:27:05 @pendulum_agent.py:281][0m #------------------------ Iteration 927 --------------------------#
[32m[20221125 01:27:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:27:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:27:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:27:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:27:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:27:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:27:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:27:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:27:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:27:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:27:09 @pendulum_agent.py:307][0m Sample time: 3.6925740242004395
[32m[20221125 01:27:17 @pendulum_agent.py:312][0m Update time: 8.688305139541626
[32m[20221125 01:27:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:27:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:27:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:27:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:27:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:27:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:27:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:27:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:27:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:27:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:27:18 @pendulum_agent.py:317][0m Evaluation time: 0.7085309028625488
[32m[20221125 01:27:18 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:27:18 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:27:18 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:27:18 @pendulum_agent.py:289][0m Total time: 14707.94488286972
[32m[20221125 01:27:18 @pendulum_agent.py:291][0m 46400000 total steps have happened
[32m[20221125 01:27:18 @pendulum_agent.py:281][0m #------------------------ Iteration 928 --------------------------#
[32m[20221125 01:27:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.4
[32m[20221125 01:27:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.2
[32m[20221125 01:27:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.2
[32m[20221125 01:27:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.2
[32m[20221125 01:27:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.8
[32m[20221125 01:27:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 7.2
[32m[20221125 01:27:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 9.0
[32m[20221125 01:27:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.4
[32m[20221125 01:27:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.4
[32m[20221125 01:27:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.6
[32m[20221125 01:27:22 @pendulum_agent.py:307][0m Sample time: 3.739368200302124
[32m[20221125 01:27:32 @pendulum_agent.py:312][0m Update time: 9.868246793746948
[32m[20221125 01:27:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:27:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:27:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:27:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:27:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:27:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:27:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:27:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:27:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:27:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:27:33 @pendulum_agent.py:317][0m Evaluation time: 0.7175619602203369
[32m[20221125 01:27:33 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.94
[32m[20221125 01:27:33 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:27:33 @pendulum_agent.py:289][0m Total time: 14722.559694051743
[32m[20221125 01:27:33 @pendulum_agent.py:291][0m 46450000 total steps have happened
[32m[20221125 01:27:33 @pendulum_agent.py:281][0m #------------------------ Iteration 929 --------------------------#
[32m[20221125 01:27:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:27:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:27:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:27:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:27:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:27:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:27:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:27:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:27:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:27:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:27:37 @pendulum_agent.py:307][0m Sample time: 3.595064163208008
[32m[20221125 01:27:54 @pendulum_agent.py:312][0m Update time: 17.095978021621704
[32m[20221125 01:27:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:27:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:27:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:27:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:27:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:27:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:27:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:27:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:27:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:27:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:27:54 @pendulum_agent.py:317][0m Evaluation time: 0.6942510604858398
[32m[20221125 01:27:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:27:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:27:55 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:27:55 @pendulum_agent.py:289][0m Total time: 14744.241447210312
[32m[20221125 01:27:55 @pendulum_agent.py:291][0m 46500000 total steps have happened
[32m[20221125 01:27:55 @pendulum_agent.py:281][0m #------------------------ Iteration 930 --------------------------#
[32m[20221125 01:27:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 10.0
[32m[20221125 01:27:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 8.4
[32m[20221125 01:27:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.6
[32m[20221125 01:27:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.8
[32m[20221125 01:27:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.8
[32m[20221125 01:27:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 8.8
[32m[20221125 01:27:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.4
[32m[20221125 01:27:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.6
[32m[20221125 01:27:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.4
[32m[20221125 01:27:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 8.2
[32m[20221125 01:27:58 @pendulum_agent.py:307][0m Sample time: 3.4669620990753174
[32m[20221125 01:28:09 @pendulum_agent.py:312][0m Update time: 10.936409950256348
[32m[20221125 01:28:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:28:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:28:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:28:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:28:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:28:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:28:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:28:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:28:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:28:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:28:10 @pendulum_agent.py:317][0m Evaluation time: 0.8403580188751221
[32m[20221125 01:28:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.5
[32m[20221125 01:28:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:28:10 @pendulum_agent.py:289][0m Total time: 14759.77017378807
[32m[20221125 01:28:10 @pendulum_agent.py:291][0m 46550000 total steps have happened
[32m[20221125 01:28:10 @pendulum_agent.py:281][0m #------------------------ Iteration 931 --------------------------#
[32m[20221125 01:28:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.8
[32m[20221125 01:28:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.8
[32m[20221125 01:28:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.8
[32m[20221125 01:28:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.4
[32m[20221125 01:28:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.8
[32m[20221125 01:28:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.4
[32m[20221125 01:28:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.6
[32m[20221125 01:28:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.8
[32m[20221125 01:28:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.2
[32m[20221125 01:28:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.2
[32m[20221125 01:28:14 @pendulum_agent.py:307][0m Sample time: 3.6398887634277344
[32m[20221125 01:28:31 @pendulum_agent.py:312][0m Update time: 17.354703187942505
[32m[20221125 01:28:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:28:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:28:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:28:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:28:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:28:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:28:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:28:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:28:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:28:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:28:32 @pendulum_agent.py:317][0m Evaluation time: 1.0341289043426514
[32m[20221125 01:28:32 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.18
[32m[20221125 01:28:32 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:28:32 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:28:32 @pendulum_agent.py:289][0m Total time: 14782.082463979721
[32m[20221125 01:28:32 @pendulum_agent.py:291][0m 46600000 total steps have happened
[32m[20221125 01:28:32 @pendulum_agent.py:281][0m #------------------------ Iteration 932 --------------------------#
[32m[20221125 01:28:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.6
[32m[20221125 01:28:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 7.2
[32m[20221125 01:28:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.6
[32m[20221125 01:28:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.4
[32m[20221125 01:28:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.6
[32m[20221125 01:28:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.6
[32m[20221125 01:28:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.6
[32m[20221125 01:28:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.6
[32m[20221125 01:28:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.2
[32m[20221125 01:28:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.8
[32m[20221125 01:28:36 @pendulum_agent.py:307][0m Sample time: 3.338797092437744
[32m[20221125 01:28:45 @pendulum_agent.py:312][0m Update time: 9.07051396369934
[32m[20221125 01:28:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:28:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:28:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:28:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:28:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:28:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:28:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:28:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:28:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:28:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:28:46 @pendulum_agent.py:317][0m Evaluation time: 1.1764988899230957
[32m[20221125 01:28:46 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.52
[32m[20221125 01:28:46 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:28:46 @pendulum_agent.py:289][0m Total time: 14795.949715852737
[32m[20221125 01:28:46 @pendulum_agent.py:291][0m 46650000 total steps have happened
[32m[20221125 01:28:46 @pendulum_agent.py:281][0m #------------------------ Iteration 933 --------------------------#
[32m[20221125 01:28:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:28:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:28:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:28:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:28:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:28:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:28:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:28:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:28:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:28:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:28:50 @pendulum_agent.py:307][0m Sample time: 3.367342948913574
[32m[20221125 01:28:59 @pendulum_agent.py:312][0m Update time: 9.065317869186401
[32m[20221125 01:28:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:28:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:28:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:28:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:28:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:28:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:28:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:28:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:28:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:28:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:29:01 @pendulum_agent.py:317][0m Evaluation time: 1.8047661781311035
[32m[20221125 01:29:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:29:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:29:01 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:29:01 @pendulum_agent.py:289][0m Total time: 14810.475491046906
[32m[20221125 01:29:01 @pendulum_agent.py:291][0m 46700000 total steps have happened
[32m[20221125 01:29:01 @pendulum_agent.py:281][0m #------------------------ Iteration 934 --------------------------#
[32m[20221125 01:29:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:29:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:29:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:29:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:29:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:29:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:29:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:29:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:29:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:29:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:29:04 @pendulum_agent.py:307][0m Sample time: 3.598423957824707
[32m[20221125 01:29:15 @pendulum_agent.py:312][0m Update time: 10.316787004470825
[32m[20221125 01:29:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:29:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:29:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:29:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:29:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:29:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:29:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:29:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:29:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:29:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:29:16 @pendulum_agent.py:317][0m Evaluation time: 0.7160000801086426
[32m[20221125 01:29:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:29:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:29:16 @pendulum_agent.py:289][0m Total time: 14825.376406908035
[32m[20221125 01:29:16 @pendulum_agent.py:291][0m 46750000 total steps have happened
[32m[20221125 01:29:16 @pendulum_agent.py:281][0m #------------------------ Iteration 935 --------------------------#
[32m[20221125 01:29:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:29:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:29:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:29:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:29:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:29:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:29:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:29:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:29:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:29:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:29:19 @pendulum_agent.py:307][0m Sample time: 3.692133903503418
[32m[20221125 01:29:30 @pendulum_agent.py:312][0m Update time: 10.23673129081726
[32m[20221125 01:29:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:29:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:29:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:29:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:29:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:29:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:29:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:29:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:29:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:29:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:29:31 @pendulum_agent.py:317][0m Evaluation time: 0.9385538101196289
[32m[20221125 01:29:31 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:29:31 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:29:31 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:29:31 @pendulum_agent.py:289][0m Total time: 14840.517335891724
[32m[20221125 01:29:31 @pendulum_agent.py:291][0m 46800000 total steps have happened
[32m[20221125 01:29:31 @pendulum_agent.py:281][0m #------------------------ Iteration 936 --------------------------#
[32m[20221125 01:29:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:29:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:29:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:29:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:29:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:29:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:29:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:29:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:29:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:29:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:29:35 @pendulum_agent.py:307][0m Sample time: 3.9044320583343506
[32m[20221125 01:29:55 @pendulum_agent.py:312][0m Update time: 20.433531999588013
[32m[20221125 01:29:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:29:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:29:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:29:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:29:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:29:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:29:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:29:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:29:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:29:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:29:56 @pendulum_agent.py:317][0m Evaluation time: 0.9176039695739746
[32m[20221125 01:29:56 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:29:56 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:29:56 @pendulum_agent.py:289][0m Total time: 14866.034934043884
[32m[20221125 01:29:56 @pendulum_agent.py:291][0m 46850000 total steps have happened
[32m[20221125 01:29:56 @pendulum_agent.py:281][0m #------------------------ Iteration 937 --------------------------#
[32m[20221125 01:29:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:29:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:29:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:29:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:29:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:29:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:29:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:29:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:29:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:29:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:30:00 @pendulum_agent.py:307][0m Sample time: 3.8337600231170654
[32m[20221125 01:30:17 @pendulum_agent.py:312][0m Update time: 16.429017066955566
[32m[20221125 01:30:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:30:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:30:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:30:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:30:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:30:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:30:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:30:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:30:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:30:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:30:17 @pendulum_agent.py:317][0m Evaluation time: 0.6799139976501465
[32m[20221125 01:30:18 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:30:18 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:30:18 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:30:18 @pendulum_agent.py:289][0m Total time: 14887.2666721344
[32m[20221125 01:30:18 @pendulum_agent.py:291][0m 46900000 total steps have happened
[32m[20221125 01:30:18 @pendulum_agent.py:281][0m #------------------------ Iteration 938 --------------------------#
[32m[20221125 01:30:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:30:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:30:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:30:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:30:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:30:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:30:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:30:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:30:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:30:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:30:21 @pendulum_agent.py:307][0m Sample time: 3.518096923828125
[32m[20221125 01:30:30 @pendulum_agent.py:312][0m Update time: 9.0852210521698
[32m[20221125 01:30:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:30:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:30:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:30:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:30:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:30:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:30:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:30:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:30:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:30:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:30:31 @pendulum_agent.py:317][0m Evaluation time: 0.5852408409118652
[32m[20221125 01:30:31 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:30:31 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:30:31 @pendulum_agent.py:289][0m Total time: 14900.762813091278
[32m[20221125 01:30:31 @pendulum_agent.py:291][0m 46950000 total steps have happened
[32m[20221125 01:30:31 @pendulum_agent.py:281][0m #------------------------ Iteration 939 --------------------------#
[32m[20221125 01:30:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 4.8
[32m[20221125 01:30:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.8
[32m[20221125 01:30:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.2
[32m[20221125 01:30:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.8
[32m[20221125 01:30:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.6
[32m[20221125 01:30:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.6
[32m[20221125 01:30:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.2
[32m[20221125 01:30:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.2
[32m[20221125 01:30:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.0
[32m[20221125 01:30:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.2
[32m[20221125 01:30:35 @pendulum_agent.py:307][0m Sample time: 3.772942066192627
[32m[20221125 01:30:44 @pendulum_agent.py:312][0m Update time: 9.068558931350708
[32m[20221125 01:30:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:30:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:30:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:30:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:30:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:30:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:30:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:30:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:30:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:30:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:30:45 @pendulum_agent.py:317][0m Evaluation time: 0.5682778358459473
[32m[20221125 01:30:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.54
[32m[20221125 01:30:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:30:45 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:30:45 @pendulum_agent.py:289][0m Total time: 14914.473341941833
[32m[20221125 01:30:45 @pendulum_agent.py:291][0m 47000000 total steps have happened
[32m[20221125 01:30:45 @pendulum_agent.py:281][0m #------------------------ Iteration 940 --------------------------#
[32m[20221125 01:30:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:30:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:30:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:30:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:30:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:30:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:30:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:30:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:30:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:30:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:30:49 @pendulum_agent.py:307][0m Sample time: 3.7996108531951904
[32m[20221125 01:31:04 @pendulum_agent.py:312][0m Update time: 15.45490312576294
[32m[20221125 01:31:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:31:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:31:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:31:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:31:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:31:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:31:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:31:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:31:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:31:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:31:05 @pendulum_agent.py:317][0m Evaluation time: 0.5801718235015869
[32m[20221125 01:31:05 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:31:05 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:31:05 @pendulum_agent.py:289][0m Total time: 14934.608690977097
[32m[20221125 01:31:05 @pendulum_agent.py:291][0m 47050000 total steps have happened
[32m[20221125 01:31:05 @pendulum_agent.py:281][0m #------------------------ Iteration 941 --------------------------#
[32m[20221125 01:31:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:31:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:31:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:31:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:31:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:31:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:31:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:31:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:31:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:31:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:31:09 @pendulum_agent.py:307][0m Sample time: 3.876555919647217
[32m[20221125 01:31:23 @pendulum_agent.py:312][0m Update time: 14.50397801399231
[32m[20221125 01:31:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:31:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:31:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:31:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:31:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:31:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:31:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:31:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:31:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:31:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:31:24 @pendulum_agent.py:317][0m Evaluation time: 0.6881847381591797
[32m[20221125 01:31:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:31:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:31:24 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:31:24 @pendulum_agent.py:289][0m Total time: 14953.968788862228
[32m[20221125 01:31:24 @pendulum_agent.py:291][0m 47100000 total steps have happened
[32m[20221125 01:31:24 @pendulum_agent.py:281][0m #------------------------ Iteration 942 --------------------------#
[32m[20221125 01:31:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:31:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:31:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:31:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:31:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:31:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:31:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:31:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:31:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:31:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:31:28 @pendulum_agent.py:307][0m Sample time: 3.623795986175537
[32m[20221125 01:31:45 @pendulum_agent.py:312][0m Update time: 16.652781009674072
[32m[20221125 01:31:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:31:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:31:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:31:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:31:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:31:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:31:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:31:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:31:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:31:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:31:45 @pendulum_agent.py:317][0m Evaluation time: 0.8440341949462891
[32m[20221125 01:31:46 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:31:46 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:31:46 @pendulum_agent.py:289][0m Total time: 14975.360507011414
[32m[20221125 01:31:46 @pendulum_agent.py:291][0m 47150000 total steps have happened
[32m[20221125 01:31:46 @pendulum_agent.py:281][0m #------------------------ Iteration 943 --------------------------#
[32m[20221125 01:31:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:31:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:31:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:31:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:31:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:31:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:31:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:31:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:31:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:31:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:31:49 @pendulum_agent.py:307][0m Sample time: 3.288088083267212
[32m[20221125 01:32:00 @pendulum_agent.py:312][0m Update time: 10.942785024642944
[32m[20221125 01:32:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:32:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:32:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:32:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:32:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:32:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:32:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:32:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:32:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:32:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:32:01 @pendulum_agent.py:317][0m Evaluation time: 1.030066728591919
[32m[20221125 01:32:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:32:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:32:01 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:32:01 @pendulum_agent.py:289][0m Total time: 14990.905061006546
[32m[20221125 01:32:01 @pendulum_agent.py:291][0m 47200000 total steps have happened
[32m[20221125 01:32:01 @pendulum_agent.py:281][0m #------------------------ Iteration 944 --------------------------#
[32m[20221125 01:32:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:32:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:32:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:32:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:32:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:32:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:32:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:32:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:32:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:32:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:32:05 @pendulum_agent.py:307][0m Sample time: 3.5055129528045654
[32m[20221125 01:32:14 @pendulum_agent.py:312][0m Update time: 8.986719131469727
[32m[20221125 01:32:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:32:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:32:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:32:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:32:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:32:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:32:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:32:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:32:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:32:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:32:15 @pendulum_agent.py:317][0m Evaluation time: 1.1850690841674805
[32m[20221125 01:32:15 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:32:15 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:32:15 @pendulum_agent.py:289][0m Total time: 15004.860621929169
[32m[20221125 01:32:15 @pendulum_agent.py:291][0m 47250000 total steps have happened
[32m[20221125 01:32:15 @pendulum_agent.py:281][0m #------------------------ Iteration 945 --------------------------#
[32m[20221125 01:32:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 14.4
[32m[20221125 01:32:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 14.4
[32m[20221125 01:32:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 12.2
[32m[20221125 01:32:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 14.4
[32m[20221125 01:32:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.8
[32m[20221125 01:32:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 13.2
[32m[20221125 01:32:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 13.4
[32m[20221125 01:32:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 11.6
[32m[20221125 01:32:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 11.6
[32m[20221125 01:32:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 10.2
[32m[20221125 01:32:19 @pendulum_agent.py:307][0m Sample time: 3.4997551441192627
[32m[20221125 01:32:28 @pendulum_agent.py:312][0m Update time: 9.051324844360352
[32m[20221125 01:32:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:32:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:32:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:32:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:32:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:32:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:32:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:32:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:32:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:32:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:32:29 @pendulum_agent.py:317][0m Evaluation time: 1.1657569408416748
[32m[20221125 01:32:29 @pendulum_agent.py:285][0m Average TRAINING episode reward: 11.92
[32m[20221125 01:32:29 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:32:29 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:32:29 @pendulum_agent.py:289][0m Total time: 15018.847193956375
[32m[20221125 01:32:29 @pendulum_agent.py:291][0m 47300000 total steps have happened
[32m[20221125 01:32:29 @pendulum_agent.py:281][0m #------------------------ Iteration 946 --------------------------#
[32m[20221125 01:32:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.6
[32m[20221125 01:32:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.8
[32m[20221125 01:32:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.2
[32m[20221125 01:32:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.6
[32m[20221125 01:32:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.6
[32m[20221125 01:32:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.4
[32m[20221125 01:32:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.8
[32m[20221125 01:32:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.4
[32m[20221125 01:32:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.6
[32m[20221125 01:32:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 7.8
[32m[20221125 01:32:33 @pendulum_agent.py:307][0m Sample time: 3.5699808597564697
[32m[20221125 01:32:57 @pendulum_agent.py:312][0m Update time: 24.21462392807007
[32m[20221125 01:32:57 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:32:57 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:32:57 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:32:57 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:32:57 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:32:57 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:32:57 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:32:57 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:32:57 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:32:57 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:32:58 @pendulum_agent.py:317][0m Evaluation time: 0.6967010498046875
[32m[20221125 01:32:58 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.08
[32m[20221125 01:32:58 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:32:58 @pendulum_agent.py:289][0m Total time: 15047.609265089035
[32m[20221125 01:32:58 @pendulum_agent.py:291][0m 47350000 total steps have happened
[32m[20221125 01:32:58 @pendulum_agent.py:281][0m #------------------------ Iteration 947 --------------------------#
[32m[20221125 01:32:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 1.8
[32m[20221125 01:32:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.6
[32m[20221125 01:32:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.2
[32m[20221125 01:32:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.8
[32m[20221125 01:32:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.6
[32m[20221125 01:32:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.0
[32m[20221125 01:32:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.2
[32m[20221125 01:32:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.8
[32m[20221125 01:32:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.4
[32m[20221125 01:32:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.2
[32m[20221125 01:33:02 @pendulum_agent.py:307][0m Sample time: 3.6611521244049072
[32m[20221125 01:33:19 @pendulum_agent.py:312][0m Update time: 17.730504989624023
[32m[20221125 01:33:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:33:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:33:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:33:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:33:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:33:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:33:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:33:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:33:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:33:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:33:20 @pendulum_agent.py:317][0m Evaluation time: 0.726017951965332
[32m[20221125 01:33:20 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.66
[32m[20221125 01:33:20 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:33:20 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:33:20 @pendulum_agent.py:289][0m Total time: 15070.002130031586
[32m[20221125 01:33:20 @pendulum_agent.py:291][0m 47400000 total steps have happened
[32m[20221125 01:33:20 @pendulum_agent.py:281][0m #------------------------ Iteration 948 --------------------------#
[32m[20221125 01:33:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:33:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:33:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:33:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:33:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:33:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:33:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:33:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:33:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:33:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:33:24 @pendulum_agent.py:307][0m Sample time: 3.5527477264404297
[32m[20221125 01:33:33 @pendulum_agent.py:312][0m Update time: 9.127264022827148
[32m[20221125 01:33:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:33:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:33:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:33:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:33:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:33:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:33:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:33:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:33:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:33:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:33:34 @pendulum_agent.py:317][0m Evaluation time: 0.6922500133514404
[32m[20221125 01:33:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:33:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:33:34 @pendulum_agent.py:289][0m Total time: 15083.65001320839
[32m[20221125 01:33:34 @pendulum_agent.py:291][0m 47450000 total steps have happened
[32m[20221125 01:33:34 @pendulum_agent.py:281][0m #------------------------ Iteration 949 --------------------------#
[32m[20221125 01:33:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:33:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:33:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:33:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:33:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:33:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:33:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:33:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:33:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:33:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:33:38 @pendulum_agent.py:307][0m Sample time: 3.850843906402588
[32m[20221125 01:33:48 @pendulum_agent.py:312][0m Update time: 9.639471292495728
[32m[20221125 01:33:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:33:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:33:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:33:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:33:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:33:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:33:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:33:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:33:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:33:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:33:48 @pendulum_agent.py:317][0m Evaluation time: 0.5612268447875977
[32m[20221125 01:33:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:33:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:33:48 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:33:48 @pendulum_agent.py:289][0m Total time: 15098.007217168808
[32m[20221125 01:33:48 @pendulum_agent.py:291][0m 47500000 total steps have happened
[32m[20221125 01:33:48 @pendulum_agent.py:281][0m #------------------------ Iteration 950 --------------------------#
[32m[20221125 01:33:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.2
[32m[20221125 01:33:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.6
[32m[20221125 01:33:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.8
[32m[20221125 01:33:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1.8
[32m[20221125 01:33:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.6
[32m[20221125 01:33:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.2
[32m[20221125 01:33:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.8
[32m[20221125 01:33:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.0
[32m[20221125 01:33:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.0
[32m[20221125 01:33:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.4
[32m[20221125 01:33:52 @pendulum_agent.py:307][0m Sample time: 3.8139381408691406
[32m[20221125 01:34:04 @pendulum_agent.py:312][0m Update time: 11.421834945678711
[32m[20221125 01:34:04 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:34:04 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:34:04 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:34:04 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:34:04 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:34:04 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:34:04 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:34:04 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:34:04 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:34:04 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:34:04 @pendulum_agent.py:317][0m Evaluation time: 0.696295976638794
[32m[20221125 01:34:05 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.24
[32m[20221125 01:34:05 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:34:05 @pendulum_agent.py:289][0m Total time: 15114.225183963776
[32m[20221125 01:34:05 @pendulum_agent.py:291][0m 47550000 total steps have happened
[32m[20221125 01:34:05 @pendulum_agent.py:281][0m #------------------------ Iteration 951 --------------------------#
[32m[20221125 01:34:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:34:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:34:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:34:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:34:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:34:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:34:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:34:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:34:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:34:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:34:08 @pendulum_agent.py:307][0m Sample time: 3.7147979736328125
[32m[20221125 01:34:17 @pendulum_agent.py:312][0m Update time: 8.9395911693573
[32m[20221125 01:34:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:34:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:34:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:34:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:34:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:34:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:34:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:34:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:34:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:34:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:34:18 @pendulum_agent.py:317][0m Evaluation time: 0.7091729640960693
[32m[20221125 01:34:18 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:34:18 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:34:18 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:34:18 @pendulum_agent.py:289][0m Total time: 15127.861554861069
[32m[20221125 01:34:18 @pendulum_agent.py:291][0m 47600000 total steps have happened
[32m[20221125 01:34:18 @pendulum_agent.py:281][0m #------------------------ Iteration 952 --------------------------#
[32m[20221125 01:34:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:34:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:34:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:34:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:34:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:34:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:34:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:34:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:34:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:34:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:34:22 @pendulum_agent.py:307][0m Sample time: 3.5718188285827637
[32m[20221125 01:34:32 @pendulum_agent.py:312][0m Update time: 10.339230060577393
[32m[20221125 01:34:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:34:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:34:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:34:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:34:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:34:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:34:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:34:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:34:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:34:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:34:33 @pendulum_agent.py:317][0m Evaluation time: 0.8558142185211182
[32m[20221125 01:34:33 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:34:33 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:34:33 @pendulum_agent.py:289][0m Total time: 15142.912178993225
[32m[20221125 01:34:33 @pendulum_agent.py:291][0m 47650000 total steps have happened
[32m[20221125 01:34:33 @pendulum_agent.py:281][0m #------------------------ Iteration 953 --------------------------#
[32m[20221125 01:34:34 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.0
[32m[20221125 01:34:34 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.2
[32m[20221125 01:34:34 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.0
[32m[20221125 01:34:34 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 6.8
[32m[20221125 01:34:34 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 6.6
[32m[20221125 01:34:34 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.2
[32m[20221125 01:34:34 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.6
[32m[20221125 01:34:34 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.6
[32m[20221125 01:34:34 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.0
[32m[20221125 01:34:34 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.6
[32m[20221125 01:34:37 @pendulum_agent.py:307][0m Sample time: 3.325800895690918
[32m[20221125 01:34:49 @pendulum_agent.py:312][0m Update time: 12.829727172851562
[32m[20221125 01:34:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:34:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:34:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:34:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:34:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:34:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:34:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:34:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:34:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:34:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:34:51 @pendulum_agent.py:317][0m Evaluation time: 1.047677755355835
[32m[20221125 01:34:51 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.46
[32m[20221125 01:34:51 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:34:51 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:34:51 @pendulum_agent.py:289][0m Total time: 15160.392551898956
[32m[20221125 01:34:51 @pendulum_agent.py:291][0m 47700000 total steps have happened
[32m[20221125 01:34:51 @pendulum_agent.py:281][0m #------------------------ Iteration 954 --------------------------#
[32m[20221125 01:34:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:34:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:34:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:34:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:34:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:34:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:34:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:34:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:34:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:34:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:34:54 @pendulum_agent.py:307][0m Sample time: 3.2332417964935303
[32m[20221125 01:35:03 @pendulum_agent.py:312][0m Update time: 9.120925903320312
[32m[20221125 01:35:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 29.0
[32m[20221125 01:35:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 29.0
[32m[20221125 01:35:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 29.0
[32m[20221125 01:35:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 29.0
[32m[20221125 01:35:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 29.0
[32m[20221125 01:35:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 29.0
[32m[20221125 01:35:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 29.0
[32m[20221125 01:35:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 29.0
[32m[20221125 01:35:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 29.0
[32m[20221125 01:35:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 29.0
[32m[20221125 01:35:04 @pendulum_agent.py:317][0m Evaluation time: 1.0372610092163086
[32m[20221125 01:35:04 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:35:04 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:35:04 @pendulum_agent.py:289][0m Total time: 15174.058524131775
[32m[20221125 01:35:04 @pendulum_agent.py:291][0m 47750000 total steps have happened
[32m[20221125 01:35:04 @pendulum_agent.py:281][0m #------------------------ Iteration 955 --------------------------#
[32m[20221125 01:35:05 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:35:05 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:35:05 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:35:05 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:35:05 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:35:05 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:35:05 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:35:05 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:35:05 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:35:05 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:35:08 @pendulum_agent.py:307][0m Sample time: 3.690653085708618
[32m[20221125 01:35:17 @pendulum_agent.py:312][0m Update time: 8.999894857406616
[32m[20221125 01:35:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:35:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:35:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:35:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:35:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:35:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:35:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:35:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:35:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:35:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:35:18 @pendulum_agent.py:317][0m Evaluation time: 0.7206149101257324
[32m[20221125 01:35:18 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:35:18 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:35:18 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:35:18 @pendulum_agent.py:289][0m Total time: 15187.747364997864
[32m[20221125 01:35:18 @pendulum_agent.py:291][0m 47800000 total steps have happened
[32m[20221125 01:35:18 @pendulum_agent.py:281][0m #------------------------ Iteration 956 --------------------------#
[32m[20221125 01:35:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:35:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:35:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:35:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:35:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:35:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:35:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:35:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:35:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:35:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:35:22 @pendulum_agent.py:307][0m Sample time: 3.6497042179107666
[32m[20221125 01:35:31 @pendulum_agent.py:312][0m Update time: 8.826390981674194
[32m[20221125 01:35:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:35:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:35:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:35:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:35:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:35:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:35:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:35:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:35:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:35:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:35:31 @pendulum_agent.py:317][0m Evaluation time: 0.7086138725280762
[32m[20221125 01:35:32 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:35:32 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:35:32 @pendulum_agent.py:289][0m Total time: 15201.221171855927
[32m[20221125 01:35:32 @pendulum_agent.py:291][0m 47850000 total steps have happened
[32m[20221125 01:35:32 @pendulum_agent.py:281][0m #------------------------ Iteration 957 --------------------------#
[32m[20221125 01:35:32 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:35:32 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:35:32 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:35:32 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:35:32 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:35:32 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:35:32 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:35:32 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:35:32 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:35:32 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:35:35 @pendulum_agent.py:307][0m Sample time: 3.8644940853118896
[32m[20221125 01:35:44 @pendulum_agent.py:312][0m Update time: 9.019115924835205
[32m[20221125 01:35:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:35:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:35:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:35:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:35:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:35:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:35:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:35:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:35:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:35:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:35:45 @pendulum_agent.py:317][0m Evaluation time: 0.5862770080566406
[32m[20221125 01:35:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:35:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:35:45 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:35:45 @pendulum_agent.py:289][0m Total time: 15215.000470876694
[32m[20221125 01:35:45 @pendulum_agent.py:291][0m 47900000 total steps have happened
[32m[20221125 01:35:45 @pendulum_agent.py:281][0m #------------------------ Iteration 958 --------------------------#
[32m[20221125 01:35:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:35:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:35:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:35:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:35:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:35:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:35:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:35:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:35:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:35:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:35:49 @pendulum_agent.py:307][0m Sample time: 3.6339190006256104
[32m[20221125 01:36:01 @pendulum_agent.py:312][0m Update time: 11.892621040344238
[32m[20221125 01:36:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:36:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:36:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:36:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:36:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:36:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:36:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:36:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:36:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:36:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:36:02 @pendulum_agent.py:317][0m Evaluation time: 0.8300578594207764
[32m[20221125 01:36:02 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:36:02 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:36:02 @pendulum_agent.py:289][0m Total time: 15231.650666952133
[32m[20221125 01:36:02 @pendulum_agent.py:291][0m 47950000 total steps have happened
[32m[20221125 01:36:02 @pendulum_agent.py:281][0m #------------------------ Iteration 959 --------------------------#
[32m[20221125 01:36:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.0
[32m[20221125 01:36:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.0
[32m[20221125 01:36:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 2.4
[32m[20221125 01:36:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.8
[32m[20221125 01:36:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.2
[32m[20221125 01:36:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.6
[32m[20221125 01:36:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.2
[32m[20221125 01:36:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.8
[32m[20221125 01:36:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.8
[32m[20221125 01:36:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.2
[32m[20221125 01:36:06 @pendulum_agent.py:307][0m Sample time: 3.5507566928863525
[32m[20221125 01:36:15 @pendulum_agent.py:312][0m Update time: 9.032121181488037
[32m[20221125 01:36:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:36:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:36:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:36:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:36:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:36:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:36:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:36:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:36:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:36:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:36:16 @pendulum_agent.py:317][0m Evaluation time: 1.0252509117126465
[32m[20221125 01:36:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.8
[32m[20221125 01:36:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:36:16 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:36:16 @pendulum_agent.py:289][0m Total time: 15245.54103899002
[32m[20221125 01:36:16 @pendulum_agent.py:291][0m 48000000 total steps have happened
[32m[20221125 01:36:16 @pendulum_agent.py:281][0m #------------------------ Iteration 960 --------------------------#
[32m[20221125 01:36:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:36:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:36:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:36:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:36:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:36:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:36:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:36:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:36:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:36:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:36:20 @pendulum_agent.py:307][0m Sample time: 3.6361238956451416
[32m[20221125 01:36:29 @pendulum_agent.py:312][0m Update time: 9.007340908050537
[32m[20221125 01:36:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:36:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:36:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:36:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:36:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:36:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:36:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:36:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:36:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:36:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:36:29 @pendulum_agent.py:317][0m Evaluation time: 0.6919050216674805
[32m[20221125 01:36:30 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:36:30 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:36:30 @pendulum_agent.py:289][0m Total time: 15259.159482002258
[32m[20221125 01:36:30 @pendulum_agent.py:291][0m 48050000 total steps have happened
[32m[20221125 01:36:30 @pendulum_agent.py:281][0m #------------------------ Iteration 961 --------------------------#
[32m[20221125 01:36:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:36:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:36:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:36:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:36:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:36:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:36:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:36:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:36:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:36:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:36:33 @pendulum_agent.py:307][0m Sample time: 3.6262500286102295
[32m[20221125 01:36:44 @pendulum_agent.py:312][0m Update time: 10.9597909450531
[32m[20221125 01:36:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 14.0
[32m[20221125 01:36:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 14.0
[32m[20221125 01:36:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 14.0
[32m[20221125 01:36:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 14.0
[32m[20221125 01:36:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 14.0
[32m[20221125 01:36:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 14.0
[32m[20221125 01:36:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 14.0
[32m[20221125 01:36:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 14.0
[32m[20221125 01:36:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 14.0
[32m[20221125 01:36:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 14.0
[32m[20221125 01:36:45 @pendulum_agent.py:317][0m Evaluation time: 0.5938341617584229
[32m[20221125 01:36:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:36:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:36:45 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:36:45 @pendulum_agent.py:289][0m Total time: 15274.641664028168
[32m[20221125 01:36:45 @pendulum_agent.py:291][0m 48100000 total steps have happened
[32m[20221125 01:36:45 @pendulum_agent.py:281][0m #------------------------ Iteration 962 --------------------------#
[32m[20221125 01:36:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:36:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:36:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:36:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:36:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:36:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:36:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:36:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:36:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:36:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:36:49 @pendulum_agent.py:307][0m Sample time: 3.751487970352173
[32m[20221125 01:37:01 @pendulum_agent.py:312][0m Update time: 12.145872354507446
[32m[20221125 01:37:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:37:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:37:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:37:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:37:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:37:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:37:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:37:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:37:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:37:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:37:02 @pendulum_agent.py:317][0m Evaluation time: 0.7059128284454346
[32m[20221125 01:37:02 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:37:02 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:37:02 @pendulum_agent.py:289][0m Total time: 15291.53691315651
[32m[20221125 01:37:02 @pendulum_agent.py:291][0m 48150000 total steps have happened
[32m[20221125 01:37:02 @pendulum_agent.py:281][0m #------------------------ Iteration 963 --------------------------#
[32m[20221125 01:37:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.0
[32m[20221125 01:37:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.8
[32m[20221125 01:37:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.0
[32m[20221125 01:37:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.2
[32m[20221125 01:37:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 6.2
[32m[20221125 01:37:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.0
[32m[20221125 01:37:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.0
[32m[20221125 01:37:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.6
[32m[20221125 01:37:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 9.6
[32m[20221125 01:37:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 9.8
[32m[20221125 01:37:06 @pendulum_agent.py:307][0m Sample time: 3.753653049468994
[32m[20221125 01:37:24 @pendulum_agent.py:312][0m Update time: 18.103920698165894
[32m[20221125 01:37:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 15.0
[32m[20221125 01:37:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 15.0
[32m[20221125 01:37:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 15.0
[32m[20221125 01:37:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 15.0
[32m[20221125 01:37:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 15.0
[32m[20221125 01:37:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 15.0
[32m[20221125 01:37:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 15.0
[32m[20221125 01:37:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 15.0
[32m[20221125 01:37:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 15.0
[32m[20221125 01:37:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 15.0
[32m[20221125 01:37:24 @pendulum_agent.py:317][0m Evaluation time: 0.695504903793335
[32m[20221125 01:37:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.42
[32m[20221125 01:37:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:37:25 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:37:25 @pendulum_agent.py:289][0m Total time: 15314.372562885284
[32m[20221125 01:37:25 @pendulum_agent.py:291][0m 48200000 total steps have happened
[32m[20221125 01:37:25 @pendulum_agent.py:281][0m #------------------------ Iteration 964 --------------------------#
[32m[20221125 01:37:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:37:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:37:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:37:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:37:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:37:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:37:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:37:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:37:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:37:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:37:28 @pendulum_agent.py:307][0m Sample time: 3.5723068714141846
[32m[20221125 01:37:37 @pendulum_agent.py:312][0m Update time: 8.862182140350342
[32m[20221125 01:37:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:37:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:37:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:37:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:37:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:37:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:37:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:37:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:37:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:37:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:37:38 @pendulum_agent.py:317][0m Evaluation time: 0.8997039794921875
[32m[20221125 01:37:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:37:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:37:38 @pendulum_agent.py:289][0m Total time: 15327.985729932785
[32m[20221125 01:37:38 @pendulum_agent.py:291][0m 48250000 total steps have happened
[32m[20221125 01:37:38 @pendulum_agent.py:281][0m #------------------------ Iteration 965 --------------------------#
[32m[20221125 01:37:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.0
[32m[20221125 01:37:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.6
[32m[20221125 01:37:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.4
[32m[20221125 01:37:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.8
[32m[20221125 01:37:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.0
[32m[20221125 01:37:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 1.8
[32m[20221125 01:37:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 1.8
[32m[20221125 01:37:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.0
[32m[20221125 01:37:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 1.8
[32m[20221125 01:37:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.4
[32m[20221125 01:37:42 @pendulum_agent.py:307][0m Sample time: 3.7488021850585938
[32m[20221125 01:37:53 @pendulum_agent.py:312][0m Update time: 11.11925458908081
[32m[20221125 01:37:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:37:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:37:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:37:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:37:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:37:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:37:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:37:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:37:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:37:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:37:54 @pendulum_agent.py:317][0m Evaluation time: 0.6899101734161377
[32m[20221125 01:37:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 2.26
[32m[20221125 01:37:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:37:54 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:37:54 @pendulum_agent.py:289][0m Total time: 15343.849521160126
[32m[20221125 01:37:54 @pendulum_agent.py:291][0m 48300000 total steps have happened
[32m[20221125 01:37:54 @pendulum_agent.py:281][0m #------------------------ Iteration 966 --------------------------#
[32m[20221125 01:37:55 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:37:55 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:37:55 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:37:55 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:37:55 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:37:55 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:37:55 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:37:55 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:37:55 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:37:55 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:37:58 @pendulum_agent.py:307][0m Sample time: 3.6797921657562256
[32m[20221125 01:38:15 @pendulum_agent.py:312][0m Update time: 17.096610069274902
[32m[20221125 01:38:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:38:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:38:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:38:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:38:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:38:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:38:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:38:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:38:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:38:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:38:16 @pendulum_agent.py:317][0m Evaluation time: 0.6590180397033691
[32m[20221125 01:38:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:38:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:38:16 @pendulum_agent.py:289][0m Total time: 15365.594444036484
[32m[20221125 01:38:16 @pendulum_agent.py:291][0m 48350000 total steps have happened
[32m[20221125 01:38:16 @pendulum_agent.py:281][0m #------------------------ Iteration 967 --------------------------#
[32m[20221125 01:38:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:38:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:38:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:38:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:38:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:38:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:38:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:38:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:38:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:38:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:38:19 @pendulum_agent.py:307][0m Sample time: 3.3815701007843018
[32m[20221125 01:38:33 @pendulum_agent.py:312][0m Update time: 13.363493204116821
[32m[20221125 01:38:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:38:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:38:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:38:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:38:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:38:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:38:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:38:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:38:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:38:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:38:34 @pendulum_agent.py:317][0m Evaluation time: 0.9157257080078125
[32m[20221125 01:38:34 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:38:34 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:38:34 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:38:34 @pendulum_agent.py:289][0m Total time: 15383.525167942047
[32m[20221125 01:38:34 @pendulum_agent.py:291][0m 48400000 total steps have happened
[32m[20221125 01:38:34 @pendulum_agent.py:281][0m #------------------------ Iteration 968 --------------------------#
[32m[20221125 01:38:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:38:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:38:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:38:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:38:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:38:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:38:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:38:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:38:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:38:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:38:37 @pendulum_agent.py:307][0m Sample time: 3.3814988136291504
[32m[20221125 01:38:46 @pendulum_agent.py:312][0m Update time: 8.85484004020691
[32m[20221125 01:38:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:38:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:38:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:38:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:38:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:38:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:38:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:38:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:38:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:38:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:38:48 @pendulum_agent.py:317][0m Evaluation time: 1.6153910160064697
[32m[20221125 01:38:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:38:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:38:48 @pendulum_agent.py:289][0m Total time: 15397.67039513588
[32m[20221125 01:38:48 @pendulum_agent.py:291][0m 48450000 total steps have happened
[32m[20221125 01:38:48 @pendulum_agent.py:281][0m #------------------------ Iteration 969 --------------------------#
[32m[20221125 01:38:49 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.8
[32m[20221125 01:38:49 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 5.0
[32m[20221125 01:38:49 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 8.8
[32m[20221125 01:38:49 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 7.2
[32m[20221125 01:38:49 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 7.6
[32m[20221125 01:38:49 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.6
[32m[20221125 01:38:49 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 8.4
[32m[20221125 01:38:49 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.2
[32m[20221125 01:38:49 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.2
[32m[20221125 01:38:49 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.8
[32m[20221125 01:38:52 @pendulum_agent.py:307][0m Sample time: 3.777531147003174
[32m[20221125 01:39:17 @pendulum_agent.py:312][0m Update time: 25.535982847213745
[32m[20221125 01:39:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:39:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:39:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:39:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:39:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:39:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:39:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:39:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:39:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:39:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:39:18 @pendulum_agent.py:317][0m Evaluation time: 0.6967322826385498
[32m[20221125 01:39:18 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.06
[32m[20221125 01:39:18 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:39:18 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:39:18 @pendulum_agent.py:289][0m Total time: 15427.954246044159
[32m[20221125 01:39:18 @pendulum_agent.py:291][0m 48500000 total steps have happened
[32m[20221125 01:39:18 @pendulum_agent.py:281][0m #------------------------ Iteration 970 --------------------------#
[32m[20221125 01:39:19 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:39:19 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:39:19 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:39:19 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:39:19 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:39:19 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:39:19 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:39:19 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:39:19 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:39:19 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:39:22 @pendulum_agent.py:307][0m Sample time: 3.6141209602355957
[32m[20221125 01:39:31 @pendulum_agent.py:312][0m Update time: 8.90546703338623
[32m[20221125 01:39:31 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:39:31 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:39:31 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:39:31 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:39:31 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:39:31 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:39:31 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:39:31 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:39:31 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:39:31 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:39:32 @pendulum_agent.py:317][0m Evaluation time: 0.677008867263794
[32m[20221125 01:39:32 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:39:32 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:39:32 @pendulum_agent.py:289][0m Total time: 15441.423082828522
[32m[20221125 01:39:32 @pendulum_agent.py:291][0m 48550000 total steps have happened
[32m[20221125 01:39:32 @pendulum_agent.py:281][0m #------------------------ Iteration 971 --------------------------#
[32m[20221125 01:39:33 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:39:33 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:39:33 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:39:33 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:39:33 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:39:33 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:39:33 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:39:33 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:39:33 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:39:33 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:39:36 @pendulum_agent.py:307][0m Sample time: 3.7522289752960205
[32m[20221125 01:39:44 @pendulum_agent.py:312][0m Update time: 8.926213026046753
[32m[20221125 01:39:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:39:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:39:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:39:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:39:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:39:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:39:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:39:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:39:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:39:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:39:45 @pendulum_agent.py:317][0m Evaluation time: 0.7155790328979492
[32m[20221125 01:39:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:39:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:39:45 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:39:45 @pendulum_agent.py:289][0m Total time: 15455.102231025696
[32m[20221125 01:39:45 @pendulum_agent.py:291][0m 48600000 total steps have happened
[32m[20221125 01:39:45 @pendulum_agent.py:281][0m #------------------------ Iteration 972 --------------------------#
[32m[20221125 01:39:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:39:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:39:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:39:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:39:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:39:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:39:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:39:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:39:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:39:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:39:49 @pendulum_agent.py:307][0m Sample time: 3.530463933944702
[32m[20221125 01:39:58 @pendulum_agent.py:312][0m Update time: 9.013386011123657
[32m[20221125 01:39:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:39:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:39:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:39:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:39:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:39:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:39:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:39:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:39:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:39:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:39:59 @pendulum_agent.py:317][0m Evaluation time: 0.8016278743743896
[32m[20221125 01:39:59 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:39:59 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:39:59 @pendulum_agent.py:289][0m Total time: 15468.720597982407
[32m[20221125 01:39:59 @pendulum_agent.py:291][0m 48650000 total steps have happened
[32m[20221125 01:39:59 @pendulum_agent.py:281][0m #------------------------ Iteration 973 --------------------------#
[32m[20221125 01:40:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:40:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:40:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:40:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:40:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:40:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:40:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:40:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:40:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:40:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:40:03 @pendulum_agent.py:307][0m Sample time: 3.601346015930176
[32m[20221125 01:40:12 @pendulum_agent.py:312][0m Update time: 8.812793731689453
[32m[20221125 01:40:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:40:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:40:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:40:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:40:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:40:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:40:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:40:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:40:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:40:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:40:12 @pendulum_agent.py:317][0m Evaluation time: 0.6854991912841797
[32m[20221125 01:40:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:40:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:40:12 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:40:12 @pendulum_agent.py:289][0m Total time: 15482.098190069199
[32m[20221125 01:40:12 @pendulum_agent.py:291][0m 48700000 total steps have happened
[32m[20221125 01:40:12 @pendulum_agent.py:281][0m #------------------------ Iteration 974 --------------------------#
[32m[20221125 01:40:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.0
[32m[20221125 01:40:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.6
[32m[20221125 01:40:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.8
[32m[20221125 01:40:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 5.6
[32m[20221125 01:40:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.4
[32m[20221125 01:40:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.8
[32m[20221125 01:40:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.8
[32m[20221125 01:40:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.0
[32m[20221125 01:40:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.0
[32m[20221125 01:40:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 5.6
[32m[20221125 01:40:16 @pendulum_agent.py:307][0m Sample time: 3.7806999683380127
[32m[20221125 01:40:35 @pendulum_agent.py:312][0m Update time: 18.41832685470581
[32m[20221125 01:40:35 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:40:35 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:40:35 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:40:35 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:40:35 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:40:35 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:40:35 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:40:35 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:40:35 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:40:35 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:40:35 @pendulum_agent.py:317][0m Evaluation time: 0.6895091533660889
[32m[20221125 01:40:36 @pendulum_agent.py:285][0m Average TRAINING episode reward: 5.36
[32m[20221125 01:40:36 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:40:36 @pendulum_agent.py:289][0m Total time: 15505.271506786346
[32m[20221125 01:40:36 @pendulum_agent.py:291][0m 48750000 total steps have happened
[32m[20221125 01:40:36 @pendulum_agent.py:281][0m #------------------------ Iteration 975 --------------------------#
[32m[20221125 01:40:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:40:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:40:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:40:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:40:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:40:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:40:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:40:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:40:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:40:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:40:39 @pendulum_agent.py:307][0m Sample time: 3.6494359970092773
[32m[20221125 01:40:51 @pendulum_agent.py:312][0m Update time: 11.187181949615479
[32m[20221125 01:40:51 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 28.0
[32m[20221125 01:40:51 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 28.0
[32m[20221125 01:40:51 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 28.0
[32m[20221125 01:40:51 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 28.0
[32m[20221125 01:40:51 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 28.0
[32m[20221125 01:40:51 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 28.0
[32m[20221125 01:40:51 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 28.0
[32m[20221125 01:40:51 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 28.0
[32m[20221125 01:40:51 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 28.0
[32m[20221125 01:40:51 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 28.0
[32m[20221125 01:40:51 @pendulum_agent.py:317][0m Evaluation time: 0.6906688213348389
[32m[20221125 01:40:51 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:40:51 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:40:51 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:40:51 @pendulum_agent.py:289][0m Total time: 15521.094514846802
[32m[20221125 01:40:51 @pendulum_agent.py:291][0m 48800000 total steps have happened
[32m[20221125 01:40:51 @pendulum_agent.py:281][0m #------------------------ Iteration 976 --------------------------#
[32m[20221125 01:40:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 7.0
[32m[20221125 01:40:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 7.4
[32m[20221125 01:40:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 6.0
[32m[20221125 01:40:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.2
[32m[20221125 01:40:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1.0
[32m[20221125 01:40:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 7.6
[32m[20221125 01:40:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 6.6
[32m[20221125 01:40:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.6
[32m[20221125 01:40:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.0
[32m[20221125 01:40:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.2
[32m[20221125 01:40:55 @pendulum_agent.py:307][0m Sample time: 3.4971659183502197
[32m[20221125 01:41:05 @pendulum_agent.py:312][0m Update time: 10.437190055847168
[32m[20221125 01:41:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:41:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:41:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:41:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:41:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:41:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:41:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:41:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:41:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:41:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:41:06 @pendulum_agent.py:317][0m Evaluation time: 0.8234338760375977
[32m[20221125 01:41:07 @pendulum_agent.py:285][0m Average TRAINING episode reward: 6.16
[32m[20221125 01:41:07 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:41:07 @pendulum_agent.py:289][0m Total time: 15536.133223056793
[32m[20221125 01:41:07 @pendulum_agent.py:291][0m 48850000 total steps have happened
[32m[20221125 01:41:07 @pendulum_agent.py:281][0m #------------------------ Iteration 977 --------------------------#
[32m[20221125 01:41:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.0
[32m[20221125 01:41:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 2.8
[32m[20221125 01:41:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.6
[32m[20221125 01:41:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.0
[32m[20221125 01:41:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 2.8
[32m[20221125 01:41:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.8
[32m[20221125 01:41:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.8
[32m[20221125 01:41:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.2
[32m[20221125 01:41:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 2.2
[32m[20221125 01:41:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.0
[32m[20221125 01:41:10 @pendulum_agent.py:307][0m Sample time: 3.475471019744873
[32m[20221125 01:41:36 @pendulum_agent.py:312][0m Update time: 26.045596837997437
[32m[20221125 01:41:36 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:41:36 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:41:36 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:41:36 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:41:36 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:41:36 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:41:36 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:41:36 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:41:36 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:41:36 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:41:37 @pendulum_agent.py:317][0m Evaluation time: 1.0235049724578857
[32m[20221125 01:41:37 @pendulum_agent.py:285][0m Average TRAINING episode reward: 3.12
[32m[20221125 01:41:37 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:41:37 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:41:37 @pendulum_agent.py:289][0m Total time: 15566.966173171997
[32m[20221125 01:41:37 @pendulum_agent.py:291][0m 48900000 total steps have happened
[32m[20221125 01:41:37 @pendulum_agent.py:281][0m #------------------------ Iteration 978 --------------------------#
[32m[20221125 01:41:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:41:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:41:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:41:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:41:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:41:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:41:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:41:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:41:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:41:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:41:41 @pendulum_agent.py:307][0m Sample time: 3.346061944961548
[32m[20221125 01:41:49 @pendulum_agent.py:312][0m Update time: 8.792776107788086
[32m[20221125 01:41:50 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:41:50 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:41:50 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:41:50 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:41:50 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:41:50 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:41:50 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:41:50 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:41:50 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:41:50 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:41:51 @pendulum_agent.py:317][0m Evaluation time: 1.1529736518859863
[32m[20221125 01:41:51 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:41:51 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:41:51 @pendulum_agent.py:289][0m Total time: 15580.53475189209
[32m[20221125 01:41:51 @pendulum_agent.py:291][0m 48950000 total steps have happened
[32m[20221125 01:41:51 @pendulum_agent.py:281][0m #------------------------ Iteration 979 --------------------------#
[32m[20221125 01:41:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:41:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:41:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:41:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:41:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:41:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:41:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:41:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:41:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:41:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:41:54 @pendulum_agent.py:307][0m Sample time: 3.3481509685516357
[32m[20221125 01:42:03 @pendulum_agent.py:312][0m Update time: 8.793686151504517
[32m[20221125 01:42:03 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:42:03 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:42:03 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:42:03 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:42:03 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:42:03 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:42:03 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:42:03 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:42:03 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:42:03 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:42:05 @pendulum_agent.py:317][0m Evaluation time: 1.8088798522949219
[32m[20221125 01:42:05 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:42:05 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:42:05 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:42:05 @pendulum_agent.py:289][0m Total time: 15594.773113012314
[32m[20221125 01:42:05 @pendulum_agent.py:291][0m 49000000 total steps have happened
[32m[20221125 01:42:05 @pendulum_agent.py:281][0m #------------------------ Iteration 980 --------------------------#
[32m[20221125 01:42:06 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:42:06 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:42:06 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:42:06 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:42:06 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:42:06 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:42:06 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:42:06 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:42:06 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:42:06 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:42:09 @pendulum_agent.py:307][0m Sample time: 3.539562940597534
[32m[20221125 01:42:18 @pendulum_agent.py:312][0m Update time: 9.432502031326294
[32m[20221125 01:42:18 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:42:18 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:42:18 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:42:18 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:42:18 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:42:18 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:42:18 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:42:18 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:42:18 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:42:18 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:42:19 @pendulum_agent.py:317][0m Evaluation time: 0.7016923427581787
[32m[20221125 01:42:19 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:42:19 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:42:19 @pendulum_agent.py:289][0m Total time: 15608.70403289795
[32m[20221125 01:42:19 @pendulum_agent.py:291][0m 49050000 total steps have happened
[32m[20221125 01:42:19 @pendulum_agent.py:281][0m #------------------------ Iteration 981 --------------------------#
[32m[20221125 01:42:20 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.6
[32m[20221125 01:42:20 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.0
[32m[20221125 01:42:20 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.8
[32m[20221125 01:42:20 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.8
[32m[20221125 01:42:20 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.8
[32m[20221125 01:42:20 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.6
[32m[20221125 01:42:20 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.0
[32m[20221125 01:42:20 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.6
[32m[20221125 01:42:20 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 3.2
[32m[20221125 01:42:20 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.6
[32m[20221125 01:42:23 @pendulum_agent.py:307][0m Sample time: 3.6576859951019287
[32m[20221125 01:42:43 @pendulum_agent.py:312][0m Update time: 20.627156019210815
[32m[20221125 01:42:44 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:42:44 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:42:44 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:42:44 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:42:44 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:42:44 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:42:44 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:42:44 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:42:44 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:42:44 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:42:44 @pendulum_agent.py:317][0m Evaluation time: 0.9353048801422119
[32m[20221125 01:42:45 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.4
[32m[20221125 01:42:45 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:42:45 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:42:45 @pendulum_agent.py:289][0m Total time: 15634.207113981247
[32m[20221125 01:42:45 @pendulum_agent.py:291][0m 49100000 total steps have happened
[32m[20221125 01:42:45 @pendulum_agent.py:281][0m #------------------------ Iteration 982 --------------------------#
[32m[20221125 01:42:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:42:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:42:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:42:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:42:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:42:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:42:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:42:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:42:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:42:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:42:48 @pendulum_agent.py:307][0m Sample time: 3.860584020614624
[32m[20221125 01:42:57 @pendulum_agent.py:312][0m Update time: 8.948498964309692
[32m[20221125 01:42:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:42:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:42:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:42:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:42:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:42:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:42:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:42:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:42:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:42:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:42:58 @pendulum_agent.py:317][0m Evaluation time: 0.9182147979736328
[32m[20221125 01:42:59 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:42:59 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:42:59 @pendulum_agent.py:289][0m Total time: 15648.195481061935
[32m[20221125 01:42:59 @pendulum_agent.py:291][0m 49150000 total steps have happened
[32m[20221125 01:42:59 @pendulum_agent.py:281][0m #------------------------ Iteration 983 --------------------------#
[32m[20221125 01:42:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:42:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:42:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:42:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:42:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:42:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:42:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:42:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:42:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:42:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:43:02 @pendulum_agent.py:307][0m Sample time: 3.845659017562866
[32m[20221125 01:43:15 @pendulum_agent.py:312][0m Update time: 12.642539978027344
[32m[20221125 01:43:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:43:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:43:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:43:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:43:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:43:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:43:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:43:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:43:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:43:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:43:16 @pendulum_agent.py:317][0m Evaluation time: 0.6886091232299805
[32m[20221125 01:43:16 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:43:16 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:43:16 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:43:16 @pendulum_agent.py:289][0m Total time: 15665.652691841125
[32m[20221125 01:43:16 @pendulum_agent.py:291][0m 49200000 total steps have happened
[32m[20221125 01:43:16 @pendulum_agent.py:281][0m #------------------------ Iteration 984 --------------------------#
[32m[20221125 01:43:17 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:43:17 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:43:17 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:43:17 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:43:17 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:43:17 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:43:17 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:43:17 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:43:17 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:43:17 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:43:20 @pendulum_agent.py:307][0m Sample time: 3.5678529739379883
[32m[20221125 01:43:39 @pendulum_agent.py:312][0m Update time: 19.20302104949951
[32m[20221125 01:43:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:43:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:43:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:43:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:43:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:43:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:43:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:43:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:43:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:43:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:43:39 @pendulum_agent.py:317][0m Evaluation time: 0.5691540241241455
[32m[20221125 01:43:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:43:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:43:40 @pendulum_agent.py:289][0m Total time: 15689.27949309349
[32m[20221125 01:43:40 @pendulum_agent.py:291][0m 49250000 total steps have happened
[32m[20221125 01:43:40 @pendulum_agent.py:281][0m #------------------------ Iteration 985 --------------------------#
[32m[20221125 01:43:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:43:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:43:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:43:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:43:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:43:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:43:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:43:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:43:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:43:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:43:43 @pendulum_agent.py:307][0m Sample time: 3.7228496074676514
[32m[20221125 01:43:56 @pendulum_agent.py:312][0m Update time: 12.57944130897522
[32m[20221125 01:43:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:43:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:43:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:43:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:43:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:43:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:43:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:43:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:43:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:43:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:43:57 @pendulum_agent.py:317][0m Evaluation time: 0.5734519958496094
[32m[20221125 01:43:57 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:43:57 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:43:57 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:43:57 @pendulum_agent.py:289][0m Total time: 15706.455132007599
[32m[20221125 01:43:57 @pendulum_agent.py:291][0m 49300000 total steps have happened
[32m[20221125 01:43:57 @pendulum_agent.py:281][0m #------------------------ Iteration 986 --------------------------#
[32m[20221125 01:43:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:43:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:43:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:43:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:43:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:43:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:43:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:43:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:43:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:43:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:44:01 @pendulum_agent.py:307][0m Sample time: 3.8084187507629395
[32m[20221125 01:44:12 @pendulum_agent.py:312][0m Update time: 11.082492113113403
[32m[20221125 01:44:12 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:44:12 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:44:12 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:44:12 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:44:12 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:44:12 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:44:12 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:44:12 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:44:12 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:44:12 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:44:12 @pendulum_agent.py:317][0m Evaluation time: 0.560744047164917
[32m[20221125 01:44:13 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:44:13 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:44:13 @pendulum_agent.py:289][0m Total time: 15722.208492040634
[32m[20221125 01:44:13 @pendulum_agent.py:291][0m 49350000 total steps have happened
[32m[20221125 01:44:13 @pendulum_agent.py:281][0m #------------------------ Iteration 987 --------------------------#
[32m[20221125 01:44:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:44:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:44:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:44:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:44:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:44:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:44:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:44:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:44:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:44:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:44:16 @pendulum_agent.py:307][0m Sample time: 3.8044958114624023
[32m[20221125 01:44:39 @pendulum_agent.py:312][0m Update time: 22.676016092300415
[32m[20221125 01:44:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:44:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:44:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:44:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:44:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:44:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:44:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:44:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:44:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:44:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:44:40 @pendulum_agent.py:317][0m Evaluation time: 0.6638970375061035
[32m[20221125 01:44:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:44:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:44:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:44:40 @pendulum_agent.py:289][0m Total time: 15749.626688957214
[32m[20221125 01:44:40 @pendulum_agent.py:291][0m 49400000 total steps have happened
[32m[20221125 01:44:40 @pendulum_agent.py:281][0m #------------------------ Iteration 988 --------------------------#
[32m[20221125 01:44:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:44:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:44:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:44:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:44:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:44:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:44:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:44:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:44:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:44:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:44:44 @pendulum_agent.py:307][0m Sample time: 3.497972249984741
[32m[20221125 01:44:58 @pendulum_agent.py:312][0m Update time: 14.246301889419556
[32m[20221125 01:44:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:44:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:44:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:44:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:44:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:44:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:44:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:44:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:44:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:44:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:44:59 @pendulum_agent.py:317][0m Evaluation time: 0.8541009426116943
[32m[20221125 01:44:59 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:44:59 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:44:59 @pendulum_agent.py:289][0m Total time: 15768.493335962296
[32m[20221125 01:44:59 @pendulum_agent.py:291][0m 49450000 total steps have happened
[32m[20221125 01:44:59 @pendulum_agent.py:281][0m #------------------------ Iteration 989 --------------------------#
[32m[20221125 01:45:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:45:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:45:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:45:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:45:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:45:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:45:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:45:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:45:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:45:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:45:02 @pendulum_agent.py:307][0m Sample time: 3.3141238689422607
[32m[20221125 01:45:11 @pendulum_agent.py:312][0m Update time: 8.862254858016968
[32m[20221125 01:45:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:45:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:45:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:45:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:45:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:45:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:45:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:45:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:45:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:45:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:45:12 @pendulum_agent.py:317][0m Evaluation time: 1.0293941497802734
[32m[20221125 01:45:12 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:45:12 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:45:12 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:45:12 @pendulum_agent.py:289][0m Total time: 15781.978543043137
[32m[20221125 01:45:12 @pendulum_agent.py:291][0m 49500000 total steps have happened
[32m[20221125 01:45:12 @pendulum_agent.py:281][0m #------------------------ Iteration 990 --------------------------#
[32m[20221125 01:45:13 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.6
[32m[20221125 01:45:13 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 9.2
[32m[20221125 01:45:13 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.0
[32m[20221125 01:45:13 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 5.8
[32m[20221125 01:45:13 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 10.2
[32m[20221125 01:45:13 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.6
[32m[20221125 01:45:13 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.0
[32m[20221125 01:45:13 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 7.6
[32m[20221125 01:45:13 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 6.2
[32m[20221125 01:45:13 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 7.0
[32m[20221125 01:45:16 @pendulum_agent.py:307][0m Sample time: 3.534424066543579
[32m[20221125 01:45:26 @pendulum_agent.py:312][0m Update time: 10.189180850982666
[32m[20221125 01:45:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:45:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:45:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:45:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:45:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:45:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:45:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:45:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:45:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:45:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:45:27 @pendulum_agent.py:317][0m Evaluation time: 1.1371171474456787
[32m[20221125 01:45:28 @pendulum_agent.py:285][0m Average TRAINING episode reward: 7.22
[32m[20221125 01:45:28 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:45:28 @pendulum_agent.py:289][0m Total time: 15797.128609895706
[32m[20221125 01:45:28 @pendulum_agent.py:291][0m 49550000 total steps have happened
[32m[20221125 01:45:28 @pendulum_agent.py:281][0m #------------------------ Iteration 991 --------------------------#
[32m[20221125 01:45:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 6.0
[32m[20221125 01:45:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.0
[32m[20221125 01:45:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 3.8
[32m[20221125 01:45:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.2
[32m[20221125 01:45:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.0
[32m[20221125 01:45:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.0
[32m[20221125 01:45:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 2.8
[32m[20221125 01:45:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 6.4
[32m[20221125 01:45:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.2
[32m[20221125 01:45:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.8
[32m[20221125 01:45:31 @pendulum_agent.py:307][0m Sample time: 3.3435590267181396
[32m[20221125 01:45:40 @pendulum_agent.py:312][0m Update time: 8.90891408920288
[32m[20221125 01:45:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:45:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:45:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:45:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:45:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:45:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:45:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:45:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:45:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:45:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:45:41 @pendulum_agent.py:317][0m Evaluation time: 1.1637170314788818
[32m[20221125 01:45:41 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.52
[32m[20221125 01:45:41 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:45:41 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:45:41 @pendulum_agent.py:289][0m Total time: 15810.81903719902
[32m[20221125 01:45:41 @pendulum_agent.py:291][0m 49600000 total steps have happened
[32m[20221125 01:45:41 @pendulum_agent.py:281][0m #------------------------ Iteration 992 --------------------------#
[32m[20221125 01:45:42 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:45:42 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:45:42 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:45:42 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:45:42 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:45:42 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:45:42 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:45:42 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:45:42 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:45:42 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:45:45 @pendulum_agent.py:307][0m Sample time: 3.7175660133361816
[32m[20221125 01:45:54 @pendulum_agent.py:312][0m Update time: 9.087062120437622
[32m[20221125 01:45:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:45:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:45:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:45:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:45:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:45:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:45:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:45:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:45:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:45:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:45:55 @pendulum_agent.py:317][0m Evaluation time: 0.7116799354553223
[32m[20221125 01:45:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:45:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:45:55 @pendulum_agent.py:289][0m Total time: 15824.62912607193
[32m[20221125 01:45:55 @pendulum_agent.py:291][0m 49650000 total steps have happened
[32m[20221125 01:45:55 @pendulum_agent.py:281][0m #------------------------ Iteration 993 --------------------------#
[32m[20221125 01:45:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:45:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:45:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:45:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:45:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:45:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:45:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:45:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:45:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:45:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:45:59 @pendulum_agent.py:307][0m Sample time: 3.8354580402374268
[32m[20221125 01:46:08 @pendulum_agent.py:312][0m Update time: 9.046280860900879
[32m[20221125 01:46:08 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:46:08 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:46:08 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:46:08 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:46:08 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:46:08 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:46:08 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:46:08 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:46:08 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:46:08 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:46:09 @pendulum_agent.py:317][0m Evaluation time: 0.7158620357513428
[32m[20221125 01:46:09 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:46:09 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:46:09 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:46:09 @pendulum_agent.py:289][0m Total time: 15838.510964870453
[32m[20221125 01:46:09 @pendulum_agent.py:291][0m 49700000 total steps have happened
[32m[20221125 01:46:09 @pendulum_agent.py:281][0m #------------------------ Iteration 994 --------------------------#
[32m[20221125 01:46:10 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:46:10 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:46:10 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:46:10 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:46:10 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:46:10 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:46:10 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:46:10 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:46:10 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:46:10 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:46:12 @pendulum_agent.py:307][0m Sample time: 3.5463852882385254
[32m[20221125 01:46:22 @pendulum_agent.py:312][0m Update time: 9.237122774124146
[32m[20221125 01:46:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:46:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:46:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:46:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:46:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:46:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:46:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:46:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:46:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:46:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:46:22 @pendulum_agent.py:317][0m Evaluation time: 0.7023861408233643
[32m[20221125 01:46:23 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:46:23 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:46:23 @pendulum_agent.py:289][0m Total time: 15852.276171922684
[32m[20221125 01:46:23 @pendulum_agent.py:291][0m 49750000 total steps have happened
[32m[20221125 01:46:23 @pendulum_agent.py:281][0m #------------------------ Iteration 995 --------------------------#
[32m[20221125 01:46:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 5.8
[32m[20221125 01:46:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.4
[32m[20221125 01:46:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.8
[32m[20221125 01:46:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 4.0
[32m[20221125 01:46:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 3.8
[32m[20221125 01:46:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.8
[32m[20221125 01:46:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.2
[32m[20221125 01:46:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 5.0
[32m[20221125 01:46:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.0
[32m[20221125 01:46:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 4.2
[32m[20221125 01:46:26 @pendulum_agent.py:307][0m Sample time: 3.8007471561431885
[32m[20221125 01:46:45 @pendulum_agent.py:312][0m Update time: 18.304462909698486
[32m[20221125 01:46:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:46:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:46:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:46:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:46:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:46:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:46:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:46:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:46:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:46:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:46:45 @pendulum_agent.py:317][0m Evaluation time: 0.5618879795074463
[32m[20221125 01:46:46 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.7
[32m[20221125 01:46:46 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:46:46 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:46:46 @pendulum_agent.py:289][0m Total time: 15875.253727912903
[32m[20221125 01:46:46 @pendulum_agent.py:291][0m 49800000 total steps have happened
[32m[20221125 01:46:46 @pendulum_agent.py:281][0m #------------------------ Iteration 996 --------------------------#
[32m[20221125 01:46:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 3.8
[32m[20221125 01:46:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 4.6
[32m[20221125 01:46:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.4
[32m[20221125 01:46:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.2
[32m[20221125 01:46:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 4.8
[32m[20221125 01:46:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.4
[32m[20221125 01:46:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 5.4
[32m[20221125 01:46:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.6
[32m[20221125 01:46:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.8
[32m[20221125 01:46:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 5.2
[32m[20221125 01:46:49 @pendulum_agent.py:307][0m Sample time: 3.7871310710906982
[32m[20221125 01:46:58 @pendulum_agent.py:312][0m Update time: 9.003784894943237
[32m[20221125 01:46:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:46:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:46:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:46:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:46:59 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:46:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:46:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:46:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:46:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:46:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:46:59 @pendulum_agent.py:317][0m Evaluation time: 0.6852452754974365
[32m[20221125 01:46:59 @pendulum_agent.py:285][0m Average TRAINING episode reward: 4.32
[32m[20221125 01:46:59 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:46:59 @pendulum_agent.py:289][0m Total time: 15889.009011983871
[32m[20221125 01:46:59 @pendulum_agent.py:291][0m 49850000 total steps have happened
[32m[20221125 01:46:59 @pendulum_agent.py:281][0m #------------------------ Iteration 997 --------------------------#
[32m[20221125 01:47:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:47:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:47:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:47:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:47:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:47:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:47:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:47:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:47:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:47:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:47:03 @pendulum_agent.py:307][0m Sample time: 3.579258918762207
[32m[20221125 01:47:21 @pendulum_agent.py:312][0m Update time: 17.522993087768555
[32m[20221125 01:47:21 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:47:21 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:47:21 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:47:21 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:47:21 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:47:21 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:47:21 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:47:21 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:47:21 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:47:21 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:47:21 @pendulum_agent.py:317][0m Evaluation time: 0.6897509098052979
[32m[20221125 01:47:21 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:47:21 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:47:21 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:47:21 @pendulum_agent.py:289][0m Total time: 15911.070141077042
[32m[20221125 01:47:21 @pendulum_agent.py:291][0m 49900000 total steps have happened
[32m[20221125 01:47:21 @pendulum_agent.py:281][0m #------------------------ Iteration 998 --------------------------#
[32m[20221125 01:47:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:47:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:47:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:47:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:47:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:47:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:47:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:47:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:47:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:47:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:47:25 @pendulum_agent.py:307][0m Sample time: 3.6290860176086426
[32m[20221125 01:47:46 @pendulum_agent.py:312][0m Update time: 21.402223825454712
[32m[20221125 01:47:47 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:47:47 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:47:47 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:47:47 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:47:47 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:47:47 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:47:47 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:47:47 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:47:47 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:47:47 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:47:47 @pendulum_agent.py:317][0m Evaluation time: 0.8341560363769531
[32m[20221125 01:47:48 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:47:48 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:47:48 @pendulum_agent.py:289][0m Total time: 15937.21219921112
[32m[20221125 01:47:48 @pendulum_agent.py:291][0m 49950000 total steps have happened
[32m[20221125 01:47:48 @pendulum_agent.py:281][0m #------------------------ Iteration 999 --------------------------#
[32m[20221125 01:47:48 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:47:48 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:47:48 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:47:48 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:47:48 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:47:48 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:47:48 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:47:48 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:47:48 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:47:48 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:47:51 @pendulum_agent.py:307][0m Sample time: 3.347525119781494
[32m[20221125 01:48:00 @pendulum_agent.py:312][0m Update time: 9.127465009689331
[32m[20221125 01:48:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221125 01:48:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221125 01:48:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221125 01:48:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221125 01:48:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221125 01:48:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221125 01:48:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221125 01:48:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221125 01:48:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221125 01:48:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221125 01:48:01 @pendulum_agent.py:317][0m Evaluation time: 1.0324170589447021
[32m[20221125 01:48:01 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221125 01:48:01 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221125 01:48:01 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221125 01:48:01 @pendulum_agent.py:289][0m Total time: 15950.993232011795
[32m[20221125 01:48:01 @pendulum_agent.py:291][0m 50000000 total steps have happened
[32m[20221125 01:48:01 @train.py:60][0m [4m[34mCRITICAL[0m Training completed!
