[32m[20221124 21:22:10 @logger.py:105][0m Log file set to ./tmp/pendulum/swingup/20221124_212210/log/pendulum_swingup-20221124_212210.log
[32m[20221124 21:22:10 @pendulum_agent.py:281][0m #------------------------ Iteration 0 --------------------------#
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:14 @pendulum_agent.py:307][0m Sample time: 3.1671769618988037
[32m[20221124 21:22:24 @pendulum_agent.py:312][0m Update time: 10.182775020599365
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:25 @pendulum_agent.py:317][0m Evaluation time: 0.7066848278045654
[32m[20221124 21:22:25 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:22:25 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:22:25 @pendulum_agent.py:262][0m [4m[34mCRITICAL[0m Get the best episode reward: 0
[32m[20221124 21:22:25 @pendulum_agent.py:266][0m [4m[34mCRITICAL[0m Saving the best checkpoint with rewards 0.00
[32m[20221124 21:22:25 @pendulum_agent.py:289][0m Total time: 14.412011861801147
[32m[20221124 21:22:25 @pendulum_agent.py:291][0m 50000 total steps have happened
[32m[20221124 21:22:25 @pendulum_agent.py:281][0m #------------------------ Iteration 1 --------------------------#
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 10.0
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 8.2
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 6.4
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.2
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 6.0
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 9.6
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 10.6
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 13.6
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 8.2
[32m[20221124 21:22:26 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 5.0
[32m[20221124 21:22:28 @pendulum_agent.py:307][0m Sample time: 3.667067289352417
[32m[20221124 21:22:39 @pendulum_agent.py:312][0m Update time: 10.338197946548462
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:40 @pendulum_agent.py:317][0m Evaluation time: 0.8967838287353516
[32m[20221124 21:22:40 @pendulum_agent.py:285][0m Average TRAINING episode reward: 8.58
[32m[20221124 21:22:40 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:22:40 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:22:40 @pendulum_agent.py:289][0m Total time: 29.60549807548523
[32m[20221124 21:22:40 @pendulum_agent.py:291][0m 100000 total steps have happened
[32m[20221124 21:22:40 @pendulum_agent.py:281][0m #------------------------ Iteration 2 --------------------------#
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:41 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:43 @pendulum_agent.py:307][0m Sample time: 3.320499897003174
[32m[20221124 21:22:53 @pendulum_agent.py:312][0m Update time: 9.787917137145996
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:55 @pendulum_agent.py:317][0m Evaluation time: 1.6933870315551758
[32m[20221124 21:22:55 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:22:55 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:22:55 @pendulum_agent.py:289][0m Total time: 44.73661208152771
[32m[20221124 21:22:55 @pendulum_agent.py:291][0m 150000 total steps have happened
[32m[20221124 21:22:55 @pendulum_agent.py:281][0m #------------------------ Iteration 3 --------------------------#
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:22:56 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:22:59 @pendulum_agent.py:307][0m Sample time: 3.956012010574341
[32m[20221124 21:23:08 @pendulum_agent.py:312][0m Update time: 9.399237155914307
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 8.0
[32m[20221124 21:23:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 8.0
[32m[20221124 21:23:10 @pendulum_agent.py:317][0m Evaluation time: 1.132004976272583
[32m[20221124 21:23:10 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:23:10 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:23:10 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:23:10 @pendulum_agent.py:289][0m Total time: 59.51204705238342
[32m[20221124 21:23:10 @pendulum_agent.py:291][0m 200000 total steps have happened
[32m[20221124 21:23:10 @pendulum_agent.py:281][0m #------------------------ Iteration 4 --------------------------#
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:11 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:14 @pendulum_agent.py:307][0m Sample time: 4.030349016189575
[32m[20221124 21:23:23 @pendulum_agent.py:312][0m Update time: 9.464911937713623
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:317][0m Evaluation time: 0.6265170574188232
[32m[20221124 21:23:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:23:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:23:24 @pendulum_agent.py:289][0m Total time: 73.94265103340149
[32m[20221124 21:23:24 @pendulum_agent.py:291][0m 250000 total steps have happened
[32m[20221124 21:23:24 @pendulum_agent.py:281][0m #------------------------ Iteration 5 --------------------------#
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:29 @pendulum_agent.py:307][0m Sample time: 4.347484827041626
[32m[20221124 21:23:38 @pendulum_agent.py:312][0m Update time: 9.268596887588501
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:39 @pendulum_agent.py:317][0m Evaluation time: 0.7509191036224365
[32m[20221124 21:23:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:23:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:23:39 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:23:39 @pendulum_agent.py:289][0m Total time: 88.58560609817505
[32m[20221124 21:23:39 @pendulum_agent.py:291][0m 300000 total steps have happened
[32m[20221124 21:23:39 @pendulum_agent.py:281][0m #------------------------ Iteration 6 --------------------------#
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:40 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:43 @pendulum_agent.py:307][0m Sample time: 3.7762839794158936
[32m[20221124 21:23:52 @pendulum_agent.py:312][0m Update time: 9.632896900177002
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:53 @pendulum_agent.py:317][0m Evaluation time: 0.8944182395935059
[32m[20221124 21:23:54 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:23:54 @pendulum_agent.py:289][0m Total time: 103.17595791816711
[32m[20221124 21:23:54 @pendulum_agent.py:291][0m 350000 total steps have happened
[32m[20221124 21:23:54 @pendulum_agent.py:281][0m #------------------------ Iteration 7 --------------------------#
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:23:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:23:57 @pendulum_agent.py:307][0m Sample time: 3.759889841079712
[32m[20221124 21:24:07 @pendulum_agent.py:312][0m Update time: 9.495968103408813
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:08 @pendulum_agent.py:317][0m Evaluation time: 1.0805740356445312
[32m[20221124 21:24:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:24:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:24:08 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:24:08 @pendulum_agent.py:289][0m Total time: 117.79941296577454
[32m[20221124 21:24:08 @pendulum_agent.py:291][0m 400000 total steps have happened
[32m[20221124 21:24:08 @pendulum_agent.py:281][0m #------------------------ Iteration 8 --------------------------#
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:12 @pendulum_agent.py:307][0m Sample time: 3.9493608474731445
[32m[20221124 21:24:22 @pendulum_agent.py:312][0m Update time: 10.314635038375854
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:23 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:24 @pendulum_agent.py:317][0m Evaluation time: 1.130450963973999
[32m[20221124 21:24:24 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:24:24 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:24:24 @pendulum_agent.py:289][0m Total time: 133.54208612442017
[32m[20221124 21:24:24 @pendulum_agent.py:291][0m 450000 total steps have happened
[32m[20221124 21:24:24 @pendulum_agent.py:281][0m #------------------------ Iteration 9 --------------------------#
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:25 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:28 @pendulum_agent.py:307][0m Sample time: 3.991119146347046
[32m[20221124 21:24:38 @pendulum_agent.py:312][0m Update time: 9.57673192024231
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:38 @pendulum_agent.py:317][0m Evaluation time: 0.7411489486694336
[32m[20221124 21:24:39 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:24:39 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:24:39 @pendulum_agent.py:289][0m Total time: 148.14663696289062
[32m[20221124 21:24:39 @pendulum_agent.py:291][0m 500000 total steps have happened
[32m[20221124 21:24:39 @pendulum_agent.py:281][0m #------------------------ Iteration 10 --------------------------#
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:42 @pendulum_agent.py:307][0m Sample time: 3.6015400886535645
[32m[20221124 21:24:52 @pendulum_agent.py:312][0m Update time: 9.454082727432251
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:52 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:53 @pendulum_agent.py:317][0m Evaluation time: 1.0222010612487793
[32m[20221124 21:24:53 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:24:53 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:24:53 @pendulum_agent.py:289][0m Total time: 162.54990601539612
[32m[20221124 21:24:53 @pendulum_agent.py:291][0m 550000 total steps have happened
[32m[20221124 21:24:53 @pendulum_agent.py:281][0m #------------------------ Iteration 11 --------------------------#
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:24:54 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:24:57 @pendulum_agent.py:307][0m Sample time: 4.550530910491943
[32m[20221124 21:25:07 @pendulum_agent.py:312][0m Update time: 9.554733991622925
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:07 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:08 @pendulum_agent.py:317][0m Evaluation time: 1.1111979484558105
[32m[20221124 21:25:08 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:25:08 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:25:08 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:25:08 @pendulum_agent.py:289][0m Total time: 178.04467797279358
[32m[20221124 21:25:08 @pendulum_agent.py:291][0m 600000 total steps have happened
[32m[20221124 21:25:08 @pendulum_agent.py:281][0m #------------------------ Iteration 12 --------------------------#
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:09 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:12 @pendulum_agent.py:307][0m Sample time: 3.3175113201141357
[32m[20221124 21:25:22 @pendulum_agent.py:312][0m Update time: 9.878046989440918
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:22 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:23 @pendulum_agent.py:317][0m Evaluation time: 1.1368699073791504
[32m[20221124 21:25:23 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:25:23 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:25:23 @pendulum_agent.py:289][0m Total time: 192.70419716835022
[32m[20221124 21:25:23 @pendulum_agent.py:291][0m 650000 total steps have happened
[32m[20221124 21:25:23 @pendulum_agent.py:281][0m #------------------------ Iteration 13 --------------------------#
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:24 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:27 @pendulum_agent.py:307][0m Sample time: 3.664860963821411
[32m[20221124 21:25:37 @pendulum_agent.py:312][0m Update time: 9.964576959609985
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:37 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:38 @pendulum_agent.py:317][0m Evaluation time: 1.348435878753662
[32m[20221124 21:25:38 @pendulum_agent.py:285][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:25:38 @pendulum_agent.py:286][0m Average EVALUATION episode reward: 0
[32m[20221124 21:25:38 @pendulum_agent.py:256][0m [4m[34mCRITICAL[0m Saving the interval checkpoint with rewards 0.00
[32m[20221124 21:25:38 @pendulum_agent.py:289][0m Total time: 208.03109288215637
[32m[20221124 21:25:38 @pendulum_agent.py:291][0m 700000 total steps have happened
[32m[20221124 21:25:38 @pendulum_agent.py:281][0m #------------------------ Iteration 14 --------------------------#
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:25:39 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
