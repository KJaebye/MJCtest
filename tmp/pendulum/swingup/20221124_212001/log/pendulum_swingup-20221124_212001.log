[32m[20221124 21:20:01 @logger.py:105][0m Log file set to ./tmp/pendulum/swingup/20221124_212001/log/pendulum_swingup-20221124_212001.log
[32m[20221124 21:20:01 @pendulum_agent.py:280][0m #------------------------ Iteration 0 --------------------------#
[32m[20221124 21:20:02 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:20:02 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:20:02 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:20:02 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:20:02 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:20:02 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:20:02 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:20:02 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:20:02 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:20:02 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:20:05 @pendulum_agent.py:308][0m Sample time: 3.243680000305176
[32m[20221124 21:20:14 @pendulum_agent.py:313][0m Update time: 9.641359090805054
[32m[20221124 21:20:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:20:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:20:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:20:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:20:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:20:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:20:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:20:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:20:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:20:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:20:15 @pendulum_agent.py:318][0m Evaluation time: 0.7003650665283203
[32m[20221124 21:20:15 @pendulum_agent.py:284][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:20:15 @pendulum_agent.py:285][0m Average EVALUATION episode reward: 0
[32m[20221124 21:20:15 @pendulum_agent.py:261][0m [4m[34mCRITICAL[0m Get the best episode reward: 0
[32m[20221124 21:20:15 @pendulum_agent.py:265][0m [4m[34mCRITICAL[0m Saving the best checkpoint with rewards 0.00
[32m[20221124 21:20:15 @pendulum_agent.py:290][0m Total time: 13.91720700263977
[32m[20221124 21:20:15 @pendulum_agent.py:292][0m 50000 total steps have happened
[32m[20221124 21:20:15 @pendulum_agent.py:280][0m #------------------------ Iteration 1 --------------------------#
[32m[20221124 21:20:16 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:20:16 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:20:16 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:20:16 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:20:16 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:20:16 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:20:16 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:20:16 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:20:16 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:20:16 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:20:19 @pendulum_agent.py:308][0m Sample time: 3.535144090652466
[32m[20221124 21:20:28 @pendulum_agent.py:313][0m Update time: 9.61981201171875
[32m[20221124 21:20:29 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:20:29 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:20:29 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:20:29 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:20:29 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:20:29 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:20:29 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:20:29 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:20:29 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:20:29 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:20:29 @pendulum_agent.py:318][0m Evaluation time: 0.8934509754180908
[32m[20221124 21:20:30 @pendulum_agent.py:284][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:20:30 @pendulum_agent.py:285][0m Average EVALUATION episode reward: 0
[32m[20221124 21:20:30 @pendulum_agent.py:290][0m Total time: 28.285890102386475
[32m[20221124 21:20:30 @pendulum_agent.py:292][0m 100000 total steps have happened
[32m[20221124 21:20:30 @pendulum_agent.py:280][0m #------------------------ Iteration 2 --------------------------#
[32m[20221124 21:20:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:20:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:20:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:20:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:20:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:20:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:20:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:20:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:20:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:20:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:20:33 @pendulum_agent.py:308][0m Sample time: 3.3320319652557373
[32m[20221124 21:20:43 @pendulum_agent.py:313][0m Update time: 9.63915205001831
[32m[20221124 21:20:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:20:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:20:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:20:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:20:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:20:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:20:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:20:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:20:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:20:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:20:44 @pendulum_agent.py:318][0m Evaluation time: 1.817728042602539
[32m[20221124 21:20:45 @pendulum_agent.py:284][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:20:45 @pendulum_agent.py:285][0m Average EVALUATION episode reward: 0
[32m[20221124 21:20:45 @pendulum_agent.py:290][0m Total time: 43.366848945617676
[32m[20221124 21:20:45 @pendulum_agent.py:292][0m 150000 total steps have happened
[32m[20221124 21:20:45 @pendulum_agent.py:280][0m #------------------------ Iteration 3 --------------------------#
[32m[20221124 21:20:46 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:20:46 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:20:46 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:20:46 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:20:46 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:20:46 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:20:46 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:20:46 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:20:46 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:20:46 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:20:49 @pendulum_agent.py:308][0m Sample time: 3.838468074798584
[32m[20221124 21:20:58 @pendulum_agent.py:313][0m Update time: 9.827311992645264
[32m[20221124 21:20:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:20:59 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:20:59 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:20:59 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:20:59 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:20:59 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:20:59 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:20:59 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:20:59 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:20:59 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:21:00 @pendulum_agent.py:318][0m Evaluation time: 1.164247989654541
[32m[20221124 21:21:00 @pendulum_agent.py:284][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:21:00 @pendulum_agent.py:285][0m Average EVALUATION episode reward: 0
[32m[20221124 21:21:00 @pendulum_agent.py:290][0m Total time: 58.505350828170776
[32m[20221124 21:21:00 @pendulum_agent.py:292][0m 200000 total steps have happened
[32m[20221124 21:21:00 @pendulum_agent.py:280][0m #------------------------ Iteration 4 --------------------------#
[32m[20221124 21:21:01 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:21:01 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:21:01 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:21:01 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:21:01 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:21:01 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:21:01 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:21:01 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:21:01 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:21:01 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:21:04 @pendulum_agent.py:308][0m Sample time: 4.026195287704468
[32m[20221124 21:21:14 @pendulum_agent.py:313][0m Update time: 9.692083835601807
[32m[20221124 21:21:14 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 17.0
[32m[20221124 21:21:14 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 17.0
[32m[20221124 21:21:14 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 17.0
[32m[20221124 21:21:14 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 17.0
[32m[20221124 21:21:14 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 17.0
[32m[20221124 21:21:14 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 17.0
[32m[20221124 21:21:14 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 17.0
[32m[20221124 21:21:14 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 17.0
[32m[20221124 21:21:14 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 17.0
[32m[20221124 21:21:14 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 17.0
[32m[20221124 21:21:14 @pendulum_agent.py:318][0m Evaluation time: 0.5999650955200195
[32m[20221124 21:21:14 @pendulum_agent.py:284][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:21:14 @pendulum_agent.py:285][0m Average EVALUATION episode reward: 0
[32m[20221124 21:21:14 @pendulum_agent.py:290][0m Total time: 73.14158582687378
[32m[20221124 21:21:14 @pendulum_agent.py:292][0m 250000 total steps have happened
[32m[20221124 21:21:14 @pendulum_agent.py:280][0m #------------------------ Iteration 5 --------------------------#
[32m[20221124 21:21:15 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 5.0
[32m[20221124 21:21:15 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 4.4
[32m[20221124 21:21:15 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 3.8
[32m[20221124 21:21:15 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 3.2
[32m[20221124 21:21:15 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 3.4
[32m[20221124 21:21:15 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 4.2
[32m[20221124 21:21:15 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 4.2
[32m[20221124 21:21:15 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 4.0
[32m[20221124 21:21:15 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 3.6
[32m[20221124 21:21:15 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 4.0
[32m[20221124 21:21:18 @pendulum_agent.py:308][0m Sample time: 4.0297911167144775
[32m[20221124 21:21:28 @pendulum_agent.py:313][0m Update time: 9.53208589553833
[32m[20221124 21:21:28 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:21:28 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:21:28 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:21:28 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:21:28 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:21:28 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:21:28 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:21:28 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:21:28 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:21:28 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:21:29 @pendulum_agent.py:318][0m Evaluation time: 0.7616660594940186
[32m[20221124 21:21:29 @pendulum_agent.py:284][0m Average TRAINING episode reward: 3.98
[32m[20221124 21:21:29 @pendulum_agent.py:285][0m Average EVALUATION episode reward: 0
[32m[20221124 21:21:29 @pendulum_agent.py:290][0m Total time: 87.7572112083435
[32m[20221124 21:21:29 @pendulum_agent.py:292][0m 300000 total steps have happened
[32m[20221124 21:21:29 @pendulum_agent.py:280][0m #------------------------ Iteration 6 --------------------------#
[32m[20221124 21:21:30 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:21:30 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:21:30 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:21:30 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:21:30 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:21:30 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:21:30 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:21:30 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:21:30 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:21:30 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:21:33 @pendulum_agent.py:308][0m Sample time: 3.9769349098205566
[32m[20221124 21:21:43 @pendulum_agent.py:313][0m Update time: 9.575488090515137
[32m[20221124 21:21:43 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:21:43 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:21:43 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:21:43 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:21:43 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:21:43 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:21:43 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:21:43 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:21:43 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:21:43 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:21:43 @pendulum_agent.py:318][0m Evaluation time: 0.8334300518035889
[32m[20221124 21:21:44 @pendulum_agent.py:284][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:21:44 @pendulum_agent.py:285][0m Average EVALUATION episode reward: 0
[32m[20221124 21:21:44 @pendulum_agent.py:290][0m Total time: 102.44287300109863
[32m[20221124 21:21:44 @pendulum_agent.py:292][0m 350000 total steps have happened
[32m[20221124 21:21:44 @pendulum_agent.py:280][0m #------------------------ Iteration 7 --------------------------#
[32m[20221124 21:21:45 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:21:45 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:21:45 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:21:45 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:21:45 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:21:45 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:21:45 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:21:45 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:21:45 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:21:45 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:21:47 @pendulum_agent.py:308][0m Sample time: 3.718755006790161
[32m[20221124 21:21:58 @pendulum_agent.py:313][0m Update time: 10.182122945785522
[32m[20221124 21:21:58 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 0.0
[32m[20221124 21:21:58 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 0.0
[32m[20221124 21:21:58 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 0.0
[32m[20221124 21:21:58 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 0.0
[32m[20221124 21:21:58 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 0.0
[32m[20221124 21:21:58 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 0.0
[32m[20221124 21:21:58 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 0.0
[32m[20221124 21:21:58 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 0.0
[32m[20221124 21:21:58 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 0.0
[32m[20221124 21:21:58 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 0.0
[32m[20221124 21:21:59 @pendulum_agent.py:318][0m Evaluation time: 1.0934069156646729
[32m[20221124 21:21:59 @pendulum_agent.py:284][0m Average TRAINING episode reward: 0.0
[32m[20221124 21:21:59 @pendulum_agent.py:285][0m Average EVALUATION episode reward: 0
[32m[20221124 21:21:59 @pendulum_agent.py:290][0m Total time: 117.7659981250763
[32m[20221124 21:21:59 @pendulum_agent.py:292][0m 400000 total steps have happened
[32m[20221124 21:21:59 @pendulum_agent.py:280][0m #------------------------ Iteration 8 --------------------------#
[32m[20221124 21:22:00 @pendulum_agent.py:144][0m agent 0 avg episode training reward: 2.0
[32m[20221124 21:22:00 @pendulum_agent.py:144][0m agent 9 avg episode training reward: 2.4
[32m[20221124 21:22:00 @pendulum_agent.py:144][0m agent 3 avg episode training reward: 2.4
[32m[20221124 21:22:00 @pendulum_agent.py:144][0m agent 1 avg episode training reward: 2.2
[32m[20221124 21:22:00 @pendulum_agent.py:144][0m agent 8 avg episode training reward: 1.4
[32m[20221124 21:22:00 @pendulum_agent.py:144][0m agent 6 avg episode training reward: 2.2
[32m[20221124 21:22:00 @pendulum_agent.py:144][0m agent 2 avg episode training reward: 3.2
[32m[20221124 21:22:00 @pendulum_agent.py:144][0m agent 4 avg episode training reward: 1.2
[32m[20221124 21:22:00 @pendulum_agent.py:144][0m agent 7 avg episode training reward: 1.6
[32m[20221124 21:22:00 @pendulum_agent.py:144][0m agent 5 avg episode training reward: 1.4
[32m[20221124 21:22:03 @pendulum_agent.py:308][0m Sample time: 4.211470127105713
