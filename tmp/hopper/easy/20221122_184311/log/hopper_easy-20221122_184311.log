[32m[20221122 18:43:11 @logger.py:105][0m Log file set to ./tmp/hopper/easy/20221122_184311/log/hopper_easy-20221122_184311.log
[32m[20221122 18:43:11 @hopper_agent.py:268][0m #------------------------ Iteration 0 --------------------------#
[32m[20221122 18:43:15 @hopper_agent.py:300][0m Sample time: 4.027147054672241
[32m[20221122 18:43:25 @hopper_agent.py:305][0m Update time: 9.904447793960571
[32m[20221122 18:43:26 @hopper_agent.py:310][0m Evaluation time: 0.7821710109710693
[32m[20221122 18:43:26 @hopper_agent.py:275][0m [4m[34mCRITICAL[0m Get the best episode reward: 0
[32m[20221122 18:43:26 @hopper_agent.py:253][0m [4m[34mCRITICAL[0m Saving the best checkpoint with rewards 0.00
[32m[20221122 18:43:26 @hopper_agent.py:282][0m Total time: 15.073589086532593
[32m[20221122 18:43:26 @hopper_agent.py:284][0m 50000 total steps have happened
[32m[20221122 18:43:26 @hopper_agent.py:268][0m #------------------------ Iteration 1 --------------------------#
[32m[20221122 18:43:30 @hopper_agent.py:300][0m Sample time: 3.9724621772766113
[32m[20221122 18:43:41 @hopper_agent.py:305][0m Update time: 10.692463874816895
[32m[20221122 18:43:42 @hopper_agent.py:310][0m Evaluation time: 0.9577147960662842
[32m[20221122 18:43:42 @hopper_agent.py:279][0m Train reward episode: 9.491851297653573
[32m[20221122 18:43:42 @hopper_agent.py:280][0m Average episode reward: 0
[32m[20221122 18:43:42 @hopper_agent.py:282][0m Total time: 31.091917037963867
[32m[20221122 18:43:42 @hopper_agent.py:284][0m 100000 total steps have happened
[32m[20221122 18:43:42 @hopper_agent.py:268][0m #------------------------ Iteration 2 --------------------------#
[32m[20221122 18:43:46 @hopper_agent.py:300][0m Sample time: 3.94637393951416
[32m[20221122 18:43:56 @hopper_agent.py:305][0m Update time: 10.083168029785156
[32m[20221122 18:43:59 @hopper_agent.py:310][0m Evaluation time: 2.2702560424804688
[32m[20221122 18:43:59 @hopper_agent.py:279][0m Train reward episode: 14.153391026974795
[32m[20221122 18:43:59 @hopper_agent.py:280][0m Average episode reward: 0
[32m[20221122 18:43:59 @hopper_agent.py:282][0m Total time: 47.78229904174805
[32m[20221122 18:43:59 @hopper_agent.py:284][0m 150000 total steps have happened
[32m[20221122 18:43:59 @hopper_agent.py:268][0m #------------------------ Iteration 3 --------------------------#
[32m[20221122 18:44:03 @hopper_agent.py:300][0m Sample time: 4.140388011932373
[32m[20221122 18:44:13 @hopper_agent.py:305][0m Update time: 10.167147874832153
[32m[20221122 18:44:14 @hopper_agent.py:310][0m Evaluation time: 0.7380590438842773
[32m[20221122 18:44:14 @hopper_agent.py:279][0m Train reward episode: 21.98355740930174
[32m[20221122 18:44:14 @hopper_agent.py:280][0m Average episode reward: 0
[32m[20221122 18:44:14 @hopper_agent.py:282][0m Total time: 63.14063286781311
[32m[20221122 18:44:14 @hopper_agent.py:284][0m 200000 total steps have happened
[32m[20221122 18:44:14 @hopper_agent.py:268][0m #------------------------ Iteration 4 --------------------------#
[32m[20221122 18:44:19 @hopper_agent.py:300][0m Sample time: 4.320785999298096
[32m[20221122 18:44:29 @hopper_agent.py:305][0m Update time: 9.951611042022705
[32m[20221122 18:44:30 @hopper_agent.py:310][0m Evaluation time: 0.8228979110717773
[32m[20221122 18:44:30 @hopper_agent.py:279][0m Train reward episode: 10.068159006185459
[32m[20221122 18:44:30 @hopper_agent.py:280][0m Average episode reward: 0
[32m[20221122 18:44:30 @hopper_agent.py:282][0m Total time: 78.57407188415527
[32m[20221122 18:44:30 @hopper_agent.py:284][0m 250000 total steps have happened
[32m[20221122 18:44:30 @hopper_agent.py:268][0m #------------------------ Iteration 5 --------------------------#
[32m[20221122 18:44:34 @hopper_agent.py:300][0m Sample time: 3.9483468532562256
[32m[20221122 18:44:44 @hopper_agent.py:305][0m Update time: 9.950948238372803
[32m[20221122 18:44:45 @hopper_agent.py:310][0m Evaluation time: 0.894812822341919
[32m[20221122 18:44:45 @hopper_agent.py:279][0m Train reward episode: 0.0
[32m[20221122 18:44:45 @hopper_agent.py:280][0m Average episode reward: 0
[32m[20221122 18:44:45 @hopper_agent.py:282][0m Total time: 93.72074604034424
[32m[20221122 18:44:45 @hopper_agent.py:284][0m 300000 total steps have happened
[32m[20221122 18:44:45 @hopper_agent.py:268][0m #------------------------ Iteration 6 --------------------------#
[32m[20221122 18:44:49 @hopper_agent.py:300][0m Sample time: 4.009424686431885
[32m[20221122 18:44:59 @hopper_agent.py:305][0m Update time: 10.152081966400146
[32m[20221122 18:45:00 @hopper_agent.py:310][0m Evaluation time: 1.086632251739502
[32m[20221122 18:45:01 @hopper_agent.py:279][0m Train reward episode: 11.105543429355494
[32m[20221122 18:45:01 @hopper_agent.py:280][0m Average episode reward: 0
[32m[20221122 18:45:01 @hopper_agent.py:282][0m Total time: 109.31047201156616
[32m[20221122 18:45:01 @hopper_agent.py:284][0m 350000 total steps have happened
[32m[20221122 18:45:01 @hopper_agent.py:268][0m #------------------------ Iteration 7 --------------------------#
