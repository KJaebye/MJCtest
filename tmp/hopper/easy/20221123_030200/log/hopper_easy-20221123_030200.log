[32m[20221123 03:02:00 @logger.py:105][0m Log file set to ./tmp/hopper/easy/20221123_030200/log/hopper_easy-20221123_030200.log
[32m[20221123 03:02:00 @hopper_agent.py:268][0m #------------------------ Iteration 0 --------------------------#
[32m[20221123 03:02:01 @hopper_agent.py:145][0m agent 7 avg episode training reward: 24.359768566335948
[32m[20221123 03:02:01 @hopper_agent.py:145][0m agent 8 avg episode training reward: 23.88094116428038
[32m[20221123 03:02:01 @hopper_agent.py:145][0m agent 4 avg episode training reward: 9.811587130319687
[32m[20221123 03:02:01 @hopper_agent.py:145][0m agent 6 avg episode training reward: 28.167888820658103
[32m[20221123 03:02:01 @hopper_agent.py:145][0m agent 9 avg episode training reward: 27.961761343131666
[32m[20221123 03:02:01 @hopper_agent.py:145][0m agent 2 avg episode training reward: 23.346994710868785
[32m[20221123 03:02:01 @hopper_agent.py:145][0m agent 1 avg episode training reward: 17.43333540860755
[32m[20221123 03:02:01 @hopper_agent.py:145][0m agent 5 avg episode training reward: 14.782653357244532
[32m[20221123 03:02:01 @hopper_agent.py:145][0m agent 3 avg episode training reward: 15.69330584580213
[32m[20221123 03:02:01 @hopper_agent.py:145][0m agent 0 avg episode training reward: 27.03481347473433
[32m[20221123 03:02:06 @hopper_agent.py:300][0m Sample time: 6.332982778549194
[32m[20221123 03:02:23 @hopper_agent.py:305][0m Update time: 16.482348918914795
[32m[20221123 03:02:23 @hopper_agent.py:145][0m agent 1 avg episode training reward: 0.0
[32m[20221123 03:02:23 @hopper_agent.py:145][0m agent 3 avg episode training reward: 0.0
[32m[20221123 03:02:23 @hopper_agent.py:145][0m agent 2 avg episode training reward: 0.0
[32m[20221123 03:02:23 @hopper_agent.py:145][0m agent 4 avg episode training reward: 0.0
[32m[20221123 03:02:23 @hopper_agent.py:145][0m agent 5 avg episode training reward: 0.0
[32m[20221123 03:02:23 @hopper_agent.py:145][0m agent 6 avg episode training reward: 0.0
[32m[20221123 03:02:24 @hopper_agent.py:145][0m agent 0 avg episode training reward: 0.0
[32m[20221123 03:02:24 @hopper_agent.py:145][0m agent 7 avg episode training reward: 0.0
[32m[20221123 03:02:24 @hopper_agent.py:145][0m agent 8 avg episode training reward: 0.0
[32m[20221123 03:02:24 @hopper_agent.py:145][0m agent 9 avg episode training reward: 0.0
[32m[20221123 03:02:25 @hopper_agent.py:310][0m Evaluation time: 2.8229713439941406
[32m[20221123 03:02:26 @hopper_agent.py:275][0m [4m[34mCRITICAL[0m Get the best episode reward: 0
[32m[20221123 03:02:26 @hopper_agent.py:253][0m [4m[34mCRITICAL[0m Saving the best checkpoint with rewards 0.00
[32m[20221123 03:02:26 @hopper_agent.py:282][0m Total time: 26.369244813919067
[32m[20221123 03:02:26 @hopper_agent.py:284][0m 50000 total steps have happened
[32m[20221123 03:02:26 @hopper_agent.py:268][0m #------------------------ Iteration 1 --------------------------#
[32m[20221123 03:02:28 @hopper_agent.py:145][0m agent 0 avg episode training reward: 33.09692901666496
[32m[20221123 03:02:28 @hopper_agent.py:145][0m agent 7 avg episode training reward: 32.96679281388531
[32m[20221123 03:02:28 @hopper_agent.py:145][0m agent 9 avg episode training reward: 39.837533738189734
[32m[20221123 03:02:28 @hopper_agent.py:145][0m agent 6 avg episode training reward: 30.095266487210395
[32m[20221123 03:02:28 @hopper_agent.py:145][0m agent 2 avg episode training reward: 41.80627680335567
[32m[20221123 03:02:28 @hopper_agent.py:145][0m agent 8 avg episode training reward: 35.4824725259939
[32m[20221123 03:02:28 @hopper_agent.py:145][0m agent 3 avg episode training reward: 32.37306716983075
[32m[20221123 03:02:28 @hopper_agent.py:145][0m agent 5 avg episode training reward: 36.76631616075426
[32m[20221123 03:02:28 @hopper_agent.py:145][0m agent 4 avg episode training reward: 24.610719561962785
[32m[20221123 03:02:28 @hopper_agent.py:145][0m agent 1 avg episode training reward: 30.54234693458428
[32m[20221123 03:02:33 @hopper_agent.py:300][0m Sample time: 7.103394985198975
